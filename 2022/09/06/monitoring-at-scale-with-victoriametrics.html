<!DOCTYPE html>
<!--
    Type on Strap jekyll theme v2.4.0
    Theme free for personal and commercial use under the MIT license
    https://github.com/sylhare/Type-on-Strap/blob/master/LICENSE
-->
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=0.5, maximum-scale=5">

    
    <!-- Theme Mode -->
    <script>
        const isAutoTheme = true;
        document.documentElement.setAttribute('data-theme', sessionStorage.getItem('theme'))
    </script>
    

    <!-- Main JS (navbar.js, katex_init.js and masonry_init.js)-->
    <script defer src="/assets/js/main.min.js"></script>

    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/assets/favicon.png" type="image/x-icon">

    

    
    <!-- KaTeX 0.15.2 -->
    <script defer src="/assets/js/vendor/katex.min.js"></script>
    <script defer src="/assets/js/vendor/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
    

    
    <!-- Mermaid 8.13.10 -->
    <script defer src="/assets/js/vendor/mermaid.min.js" onload="mermaid.initialize({startOnLoad:true});"></script>
    

    <!-- Simple Jekyll Search 1.9.1 -->
    <script src="/assets/js/vendor/simple-jekyll-search.min.js" type="text/javascript"></script>

    
    <!-- Matomo -->
    <script>
        var _paq = window._paq = window._paq || [];
        /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
        _paq.push(['trackPageView']);
        _paq.push(['enableLinkTracking']);
        (function() {
            var u="https://bedrockstreaming.matomo.cloud/";
            _paq.push(['setTrackerUrl', u+'matomo.php']);
            _paq.push(['setSiteId', '2']);
            var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
            g.async=true; g.src='//cdn.matomo.cloud/bedrockstreaming.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
        })();
    </script>
    

    <!-- Google Analytics / Cookie Consent -->
    <script>
      const cookieName = 'cookie-notice-dismissed-https://tech.bedrockstreaming.com';
      const isCookieConsent = 'false';
      const analyticsName = '';
    </script>

    
    

    <!-- SEO tags -->
    <meta property="og:image" content="https://tech.bedrockstreaming.com/images/common/banner_xl.jpg">
    
    <meta property="og:type" content="website" />
    
    <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Monitoring at scale with Victoria Metrics | Bedrock Tech Blog</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Monitoring at scale with Victoria Metrics" />
<meta name="author" content="Julien Menan" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="why and how we moved from Prometheus to Victoria Metrics" />
<meta property="og:description" content="why and how we moved from Prometheus to Victoria Metrics" />
<link rel="canonical" href="https://tech.bedrockstreaming.com/2022/09/06/monitoring-at-scale-with-victoriametrics.html" />
<meta property="og:url" content="https://tech.bedrockstreaming.com/2022/09/06/monitoring-at-scale-with-victoriametrics.html" />
<meta property="og:site_name" content="Bedrock Tech Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-09-06T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Monitoring at scale with Victoria Metrics" />
<script type="application/ld+json">
{"description":"why and how we moved from Prometheus to Victoria Metrics","headline":"Monitoring at scale with Victoria Metrics","dateModified":"2022-09-06T00:00:00+00:00","datePublished":"2022-09-06T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://tech.bedrockstreaming.com/2022/09/06/monitoring-at-scale-with-victoriametrics.html"},"url":"https://tech.bedrockstreaming.com/2022/09/06/monitoring-at-scale-with-victoriametrics.html","author":{"@type":"Person","name":"Julien Menan"},"@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <!-- RSS -->
    <link rel="alternate" type="application/atom+xml" title="Bedrock Tech Blog" href="https://tech.bedrockstreaming.com/feed.xml"/>
    <link type="application/atom+xml" rel="alternate" href="https://tech.bedrockstreaming.com/feed.xml" title="Bedrock Tech Blog" />

    <!-- Twitter Cards -->
    <meta name="twitter:title" content="Monitoring at scale with Victoria Metrics">
    <meta name="twitter:description" content="Monitoring at Bedrock :At Bedrock Streaming, a large part of our applications are hosted on Kubernetes clusters, others use the EC2 service from AWS and a sm...">
    
    <meta name="twitter:card" content="summary">
    <meta name="twitter:image" content="https://tech.bedrockstreaming.com/images/common/banner_xl.jpg">
    <meta name="twitter:image:alt" content="Monitoring at scale with Victoria Metrics">
</head>

  <body>
    <header class="site-header">

    <!-- Logo and title -->
	<div class="branding">
        
		<a href="/">
			<img alt="logo img" class="avatar" src="/images/common/br-site-logo.jpg" />
		</a>
        
        <a class="site-title" aria-label="Bedrock Tech Blog" href="/">
        Bedrock Tech Blog
		</a>
	</div>

    <!-- Toggle menu -->
    <nav class="clear">
    <a aria-label="pull" id="pull" class="toggle" href="#">
    <i class="fas fa-bars fa-lg"></i>
    </a>

    <!-- Menu -->
    <ul class="hide">
        

        
            
            
        
            
            
        
            
            <li class="separator"> | </li>
            <li>
                <a class="clear" aria-label="Jobs" title="Jobs" href="/jobs/">
                     Jobs 
                </a>
            </li>
            
            
        
            
            <li class="separator"> | </li>
            <li>
                <a class="clear" aria-label="Last Friday Talks" title="Last Friday Talks" href="/lft/">
                     Last Friday Talks 
                </a>
            </li>
            
            
        
            
            
        
            
            <li class="separator"> | </li>
            <li>
                <a class="clear" aria-label="Meetups & Conferences" title="Meetups & Conferences" href="/meetups/">
                     Meetups & Conferences 
                </a>
            </li>
            
            
        
            
            <li class="separator"> | </li>
            <li>
                <a class="clear" aria-label="OSS" title="OSS" href="/oss/">
                     OSS 
                </a>
            </li>
            
            
        
            
            
        
            
            <li class="separator"> | </li>
            <li>
                <a class="clear" aria-label="Search" title="Search" href="/search/">
                     <i class="fas fa-search" aria-hidden="true"></i>
                    
                </a>
            </li>
            
            
        
            
            <li class="separator"> | </li>
            <li>
                <a class="clear" aria-label="Tags" title="Tags" href="/tags/">
                     <i class="fas fa-tags" aria-hidden="true"></i>
                    
                </a>
            </li>
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
        
        
        <li class="separator"> | </li>
        <li><a id="theme-toggle" title="Monitoring at scale with Victoria Metrics " aria-label="Monitoring at scale with Victoria Metrics" onclick="themeToggle()"></a></li>
        
    </ul>

	</nav>
</header>

    <div class="content">
      <article class="feature-image" >
  <header id="main" style="">
    <div class="title-padder">
      
      <h1 id="Monitoring+at+scale+with+Victoria+Metrics" class="title">Monitoring at scale with Victoria Metrics</h1>
      <div class="post-info">


<a
      href="https://twitter.com/julien_menan"
      target="_blank"
      rel="noopener"
      class="author">
      <img alt="Author's avatar" src="/images/avatar/j_menan.jpg" class="thumbnail">
    

    
      <span class="name">
        Julien Menan
      </span>
    </a><span class="spacer"> - </span>



  <span class="publication-date">
    
    September 06, 2022
  </span>
</div>

      
    </div>
  </header>

  <section class="post-content">
  
      <h1 id="monitoring-at-bedrock-">Monitoring at Bedrock :</h1>
<p>At <a href="https://www.bedrockstreaming.com/">Bedrock Streaming</a>, a large part of our applications are hosted on Kubernetes clusters, others use the EC2 service from AWS and a small part are hosted on “OnPremise” servers.</p>

<p>From 2018 until January 2022, we used Prometheus to monitor all these platforms, because Prometheus met all our needs: keeping control over our monitoring solution and supporting service discovery, which is essential in environments such as Kubernetes or AWS EC2. Prometheus also supports custom exporters we developed internally.</p>

<p>Over the years, our business has grown significantly, so the load on our platforms has increased. Indirectly, the load on our Prometheus instances has also increased, to the point where certain limitations have become too much for us. This is why we have changed our monitoring/alerting stack.</p>

<h1 id="limits-of-prometheus">Limits of Prometheus</h1>
<p>Prometheus does not have a native High Availability mode: to have high availability, we had to duplicate our Prometheus instances. This implies that our targets were “scrapped” by all our Prometheus instances (same for our rules and records).
To avoid this, we had to use sharding, but this made the infrastructure more complex. More information on this subject in this <a href="https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/high-availability.md">documentation</a> from the Prometheus operator</p>

<p>Prometheus is not designed to store metrics on a long-term basis, as mentioned in the <a href="https://prometheus.io/docs/prometheus/latest/storage/#operational-aspects">documentation</a> :</p>

<p><em>&gt; Prometheus’s local storage is not intended to be durable long-term storage; external solutions offer extended retention and data durability.</em></p>

<p>Prometheus’s local storage is not intended to be durable long-term storage; external solutions offer extended retention and data durability.
We worked around this limitation by using Victoria Metrics (VMCluster) as a LongTermStorage via the remote_write protocol</p>

<p>All processes (scrapping, ingest, storage, etc.) were, until now, managed in the same “prometheus” instance, which implied a less flexible and vertical scaling only (since recently a <a href="https://prometheus.io/blog/2021/11/16/agent/">Prometheus agent</a> is available for the “scrapping” part).</p>

<p>The RAM and CPU usage of a Prometheus instance is correlated to the number of metrics (and their cardinality) it has to manage. In our case, several Prometheus instances consumed more than 64 GB of RAM and 26 CPUs each, in order to absorb our peak loads. In a Kubernetes cluster, this high resources consumption can cause problems, especially for scheduling.</p>

<p>The Write-Ahead Log (WAL) system can cause rather slow restarts if the Prometheus instance runs out of RAM and can cause the Prometheus instance to hang for varying lengths of time. During the replay of the WAL, Prometheus doesn’t scrape anything, thus there is no alerting and no way of knowing if something is going on.</p>

<h2 id="the-cardinality-of-metrics">The cardinality of metrics</h2>
<p>When our Kubernetes clusters manage a large number of pods, a constraint quickly appears: cardinality.</p>

<p><em>&gt; The cardinality of a metric is the number of TimeSeries of that metric with single-valued labels.</em></p>

<p><img src="/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/cardinality-example.png" alt="schema of cardinality" /></p>

<p>In the example above, the <code class="language-plaintext highlighter-rouge">status_code</code> label has a cardinality of 5, app has a cardinality of 2 and the overall cardinality of the <code class="language-plaintext highlighter-rouge">server_reponses</code> metric is 10.</p>

<p>In this example, any Prometheus instance can handle this cardinality, but if you add for example the label <code class="language-plaintext highlighter-rouge">pod_name</code> or <code class="language-plaintext highlighter-rouge">client_IP</code> (or both) to the <code class="language-plaintext highlighter-rouge">server_reponses</code> metric, the cardinality increases for each different clients calls and for each pod.</p>

<p>You should read the excellent <a href="https://www.robustperception.io/cardinality-is-key/">article</a> from “Robust Perception” for more details on this subject.</p>

<p>At Bedrock the high cardinality metrics come from our HAProxy ingress. For our needs, we retrieve several labels like the name of the ingress pod as well as its IP address, but more importantly the name and IP address of the destination pod. In a cluster that can grow to more than 15,000 pods, the combination of unique labels (cardinality) is very significant for some of our ingress metrics.</p>

<p>We found that Prometheus performed poorly when we had multiple metrics with high cardinalities (&gt; 100,000), and resulted in over-consumption of RAM.</p>

<p>During a high load event, Prometheus could consume up to 200 GB of RAM before being OOMKilled. When this happened, we would go completely blind as we had no metrics or alerting.
This also impacts us on scalability in our Kubernetes clusters, as we use <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#scaling-on-custom-metrics">CustomMetrics</a> very heavily in HPAs to scale the number of pods in our applications.</p>

<p><em>RAM and CPU consumption of our prometheus instances (the red lines represent the reboots of our instances, we also see a loss of metrics)</em>
<img src="/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/prometheus-ram.png" alt="RAM consumption of prometheus " />
<img src="/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/prometheus-cpu.png" alt="RAM consumption of prometheus " /></p>

<p>Prometheus is still a good solution, which has served its purpose well for several years, but we have reached its limits in our production environments.</p>

<h1 id="replacing-prometheus">Replacing Prometheus?</h1>

<p>We spent time optimizing Prometheus to absorb the amount of metrics and their cardinality, in particular by either directly removing high cardinality metrics if they were totally unused, or by removing the labels of certain metrics that caused high cardinalities.
We have also optimized the Prometheus configuration directly, as well as the maximum IOPS of our EBS. The RAM and CPU consumption of Prometheus is linked to the number of metrics to manage and their cardinality. But we always have more traffic and therefore always more pods in our clusters: we should have perpetually increased Prometheus instances resources. This was a problem for scalability and costs.</p>

<p>Can we replace a critical tool like this? What are our short, medium and long term needs? How can we optimize costs? And especially in what timeframe?
The emergency of recent incidents forced us to exclude solutions such as <a href="https://thanos.io/">Thanos</a> and <a href="https://cortexmetrics.io/">Cortex</a>. Testing these solutions completely would have required too much time, which we did not have.</p>

<p>It is also important to consider that we were already using Victoria Metrics, but only for the Long Term Storage part, without any problems.
Could replacing Prometheus with a stack based entirely on Victoria Metrics overcome the limitations we had with Prometheus?
High availability and fault tolerance is well-supported, their <a href="https://docs.victoriametrics.com/guides/k8s-ha-monitoring-via-vm-cluster.html">documentation</a> explains how to manage this.</p>

<p>Managing long-term data is possible, as we were already doing it.
Victoria Metrics is built around a set of microservices. Each one is built in order to serve a specific job, and each supports vertical and especially horizontal scaling (with sharding). A very important point when used in a Kubernetes environment.</p>

<p>In addition, Victoria Metrics seemed to handle high cardinality metrics better (see <a href="https://valyala.medium.com/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b">article</a> on this subject). It is also possible to do <a href="https://docs.victoriametrics.com/vmagent.html#cardinality-limiter">rate limiting</a> on the number of Time Series to be ingested:</p>

<p>CPU and RAM consumption is lower with better performance than with Prometheus and even other TSDBs, several comparative articles on this subject have already been published:</p>
<ul>
  <li><a href="https://promcon.io/2019-munich/talks/remote-write-storage-wars/">Remote Write Storage Wars</a></li>
  <li><a href="https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f">Prometheus vs VictoriaMetrics benchmark on node_exporter metrics</a></li>
  <li><a href="https://valyala.medium.com/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4">When size matters — benchmarking VictoriaMetrics vs Timescale and InfluxDB</a></li>
  <li><a href="https://medium.com/faun/comparing-thanos-to-victoriametrics-cluster-b193bea1683">Comparing Thanos to VictoriaMetrics cluster</a></li>
</ul>

<p>We also wanted to keep the Prometheus language: <a href="https://prometheus.io/docs/prometheus/latest/querying/basics/">PromQL</a> in order to keep our Grafana dashboards and all our Prometheus alerts. Even though Victoria Metrics offers its own MetricsQL language, it is perfectly compatible with PromQL.</p>

<p>You can see the <a href="https://docs.victoriametrics.com/#prominent-features">main features</a> of Victoria Metrics as well as various <a href="https://docs.victoriametrics.com/#case-studies-and-talks">case studies</a> in their documentation.</p>

<h1 id="poc-of-victoria-metrics">POC of Victoria Metrics</h1>
<p>We wanted to validate the performance and consumption of a stack entirely based on Victoria Metrics, the results were really encouraging.</p>

<p>Test environment :</p>
<ul>
  <li>1500 web app pods</li>
  <li>250 Haproxy Ingress pods (metric with high cardinality enabled)</li>
  <li>3700 scrapped targets</li>
</ul>

<p>Comparative table between Prometheus and Victoria Metrics :</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Prometheus</th>
      <th>Victoria Metrics</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>CPU consumption</td>
      <td>26</td>
      <td>8</td>
    </tr>
    <tr>
      <td>RAM consumption</td>
      <td>30Go</td>
      <td>11Go</td>
    </tr>
    <tr>
      <td>New TimeSeries / min</td>
      <td>50K</td>
      <td>6.5M</td>
    </tr>
    <tr>
      <td>Max active TimeSeries</td>
      <td>7M</td>
      <td>91M</td>
    </tr>
    <tr>
      <td>Max cardinality</td>
      <td>4 metrics &gt; 100K</td>
      <td>10+ metrics &gt; 1M</td>
    </tr>
  </tbody>
</table>

<p><em>Graph on the CPU consumption of Victoria Metrics components</em>
<img src="/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/cpu-poc-vm.png" alt="cpu-usage-poc-vm" /></p>

<p><em>Number of active “TimeSeries” in Victoria Metrics</em>
<img src="/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/active-ts-poc-vm.png" alt="active-ts-poc-vm" /></p>

<p>Our benchmark persuaded us to use Victoria Metrics as a replacement for Prometheus.</p>

<h1 id="implementation-of-victoria-metrics-">Implementation of Victoria Metrics :</h1>
<p>We used the official <a href="https://github.com/VictoriaMetrics/helm-charts/blob/master/charts/victoria-metrics-k8s-stack/README.md">victoria-metrics-k8s-stack</a> Helm chart which is based on an <a href="https://github.com/VictoriaMetrics/helm-charts/tree/master/charts/victoria-metrics-operator">operator</a>. This chart Helm permits to deploy a complete monitoring and alerting stack in a Kubernetes cluster.</p>

<p>A VMCluster (Insert, Select, Storage) is deployed to manage access to metrics. The collection of metrics (push/pull) from exporters in Prometheus format is handled by the VMagent. Its configuration is done in the form of a Prometheus configuration file. It is able to :</p>
<ul>
  <li>Manage the relabeling of metrics.</li>
  <li>Temporarily store the metrics it has collected if the VMCluster is unavailable or not able to send the metrics to the VMCluster.</li>
  <li>Limit the cardinality of metrics.</li>
</ul>

<p>One of the advantages of using this Helm chart is that it will deploy essential components to properly monitor a Kubernetes cluster such as Kube-state-metrics or prometheus-node-exporter, but also scraping configurations for services such as Kubelet, KubeApiServer, KubeControllerManager, KubeDNS, KubeEtcd, KubeScheduler, KubeProxy</p>

<p>Alerting is also managed via a VMAlert component, which will execute the alerting and recording rules set by VictoriaMetrics. Notifications are managed by an Alertmanager which is also deployable via this chart.</p>

<p>One of the advantages of using this Helm chart is that it will deploy essential components to properly monitor a Kubernetes cluster such as <em>Kube-state-metrics</em> or <em>prometheus-node-exporter</em>, but also scraping configurations for services such as <em>Kubelet, KubeApiServer, KubeControllerManager, KubeDNS, KubeEtcd, KubeScheduler, KubeProxy</em></p>

<p><em>This is what our monitoring and alerting stack based on this Helm chart looks like.</em>
<img src="/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/stack-vm.png" alt="stack-vm" /></p>

<h1 id="resumption-of-the-history">Resumption of the history</h1>
<p>We wanted to keep historical metrics of our Kubernetes clusters. Victoria Metrics provides a tool to manage the export and import of data from different TSDB: <a href="https://docs.victoriametrics.com/vmctl.html">vmctl</a>.</p>

<p>In order not to overload our monitoring stack, we splitted the exports into smaller or larger time ranges, depending on the history of the cluster. For clusters with little activity and therefore few metrics, exports/imports were split day by day, for others we had to use smaller time slots.
A home-made bash script launched several kubernetes jobs simultaneously and took care of restarting one of them as soon as another one ended.</p>

<p>Below an extract of the definition of our Kubernetes job with the arguments we used to do our history transfer by time range:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">vmctl</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">victoriametrics/vmctl</span>
        <span class="na">resources</span><span class="pi">:</span>
          <span class="na">requests</span><span class="pi">:</span>
            <span class="na">cpu</span><span class="pi">:</span> <span class="s2">"</span><span class="s">1"</span>
        <span class="na">args</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="s">vm-native</span>
          <span class="pi">-</span> <span class="s">--vm-native-src-addr=http://victoria-metrics-cluster-vmselect.monitoring.svc.cluster.local.:8481/select/001/prometheus</span>
          <span class="pi">-</span> <span class="s">--vm-native-dst-addr=http://vminsert-victoria-metrics-k8s-stack.monitoring.svc.cluster.local.:8480/insert/000/prometheus</span>
          <span class="pi">-</span> <span class="s">--vm-native-filter-match={__name__!~"_vm.*"}</span>
          <span class="pi">-</span> <span class="s">--vm-native-filter-time-start="{ { start } }"</span>
          <span class="pi">-</span> <span class="s">--vm-native-filter-time-end="{ { end } }"</span>
      <span class="na">restartPolicy</span><span class="pi">:</span> <span class="s">Never</span>
</code></pre></div></div>

<h1 id="feedback-after-months-of-use">Feedback after months of use</h1>
<p>Since we have been using our new monitoring stack, we have encountered a few bugs (as with all solutions).
Most of the time, these were not impactful, except for one that caused us a production incident.
We had an overconsumption of RAM of VMStorage which was fixed in version 1.76. I would like to highlight the responsiveness of the VictoriaMetrics team, whether on slack or on GitHub: I have had several discussions with them on various subjects, and they have always been reactive</p>

<p>Victoria Metrics regularly releases new versions, including performance improvements and new features. The <a href="https://docs.victoriametrics.com/CHANGELOG.htm">changelog</a> will give you an idea of the latest improvements and their frequency.</p>

<p>Victoria Metrics has an <a href="https://victoriametrics.com/products/enterprise/">Enterprise</a> version that adds some features, including one that we are interested in but have not yet tested: downsampling.
We have configured a one-year retention for each of our Kubernetes clusters, and on some clusters that’s mean more than 7 TB of data per VMStorage.</p>

<p>The downsampling allows you to configure how many metrics you want to keep per time interval.</p>

<p>In this example: <code class="language-plaintext highlighter-rouge">-downsampling.period=24h:10s,1w:30s,30d:1m,360d:5m</code>, (assuming we collect metrics every 5 seconds) we only keep:</p>
<ul>
  <li>one measurement point every 10 seconds beyond 24 hours (instead of one point every 5 seconds)</li>
  <li>one measurement point every 30 seconds beyond 7 days</li>
  <li>one measurement point every minute beyond 30 days</li>
  <li>one measurement point every 5 minutes beyond one year</li>
</ul>

<p>It is rarely necessary to keep all the measurements of our metrics on such a long scale, when we want to retrieve measurements that are several months old, it is usually to see a trend and not all the measurements.
With this option, we could greatly reduce the storage used by our metrics.</p>

<h1 id="conclusion">Conclusion</h1>
<p>Through this article, you have discovered why and how we migrated our monitoring stack of our Kubernetes clusters at Bedrock from Prometheus to Victoria Metrics.</p>

<p>This was an important and critical subject for us, as monitoring is a critical need.
Now our monitoring stack, based entirely on Victoria Metrics, is robust and capable of absorbing large load peaks.</p>

<p>Here are some indicators of the victoria metrics stack performance of one of our Kubernetes clusters during last 6 months:</p>
<ul>
  <li>active time series: up to 39 million (average 7.4M)</li>
  <li>total number of datapoints: 12 trillion</li>
  <li>ingestion rate : up to 1.3 million new samples per second (average 227K)</li>
  <li>churn rate : up to 117 Million new time series per day (average 30.6 Million)</li>
  <li>disk usage (data + index): 15 TB</li>
  <li>sample rate : up to 4.99M (average 343K)</li>
  <li>scrape target : up to 49K (average 4.4K)</li>
</ul>

<p><img src="/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/total-datapoint-vm-last-6m.png" alt="total-datapoint-vm-last-6m" />
<img src="/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/active-ts-vm-last-6m.png" alt="active-ts-vm-last-6m" />
<img src="/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/ingestion-rate-vm-last-6m.png" alt="ingestion-rate-vm-last-6m" />
<img src="/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/cpu-usage-vm-last-6m.png" alt="cpu-usage-vm-last-6m" />
<img src="/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/ram-usage-vm-last-6m.png" alt="ram-usage-vm-last-6m" />
<img src="/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/churn-rate-vm-last-6m.png" alt="churn-rate-vm-last-6m" />
<img src="/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/sample-rate-vm-last-6m.png" alt="sample-rate-vm-last-6m" />
<img src="/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/scrape-target-vm-last-6m.png" alt="scrape-target-vm-last-6m" /></p>

    
  </section>

  <!-- Social media shares -->
  

<div class="share-buttons">
    <ul class="share-buttons">
        <li class="meta">Share</li>
         
        <li>
            <a href="https://twitter.com/intent/tweet?text=Monitoring+at+scale+with+Victoria+Metrics%20https%3A%2F%2Ftech.bedrockstreaming.com%2F2022%2F09%2F06%2Fmonitoring-at-scale-with-victoriametrics.html"
               target="_blank" title="">
                <i class="fab fa-twitter-square fa-2x" aria-hidden="true"></i>
                <span class="sr-only">Tweet</span>
            </a>
        </li>
             
        <li>
            <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://tech.bedrockstreaming.com/2022/09/06/monitoring-at-scale-with-victoriametrics.html&title=Monitoring+at+scale+with+Victoria+Metrics%20%7C%20Bedrock+Tech+Blog&summary=&source=https://tech.bedrockstreaming.com/2022/09/06/monitoring-at-scale-with-victoriametrics.html"
               target="_blank" title=" LinkedIn">
                <i class="fab fa-linkedin fa-2x" aria-hidden="true"></i>
                <span class="sr-only">Share on LinkedIn</span>
            </a>
        </li>
          
        <li>
            <a href="mailto:?subject=Monitoring at scale with Victoria Metrics%20%7C%20Bedrock Tech Blog&body=https://tech.bedrockstreaming.com/2022/09/06/monitoring-at-scale-with-victoriametrics.html"
               target="_blank" title="">
                <i class="fas fa-envelope-square fa-2x" aria-hidden="true"></i>
                <span class="sr-only">Email</span></a>
        </li>
        
    </ul>
</div>




   <!-- Tag list -->
  
  


  <div class="tag-list">
    <ul>
      
        <li class="meta">Tags</li>
      

      
        <li><a class="button" href="/tags/#cardinality">
          <p><i class="fas fa-tag fa-fw fa-sm"></i> cardinality</p>
        </a></li>
      
        <li><a class="button" href="/tags/#k8s">
          <p><i class="fas fa-tag fa-fw fa-sm"></i> k8s</p>
        </a></li>
      
        <li><a class="button" href="/tags/#kubernetes">
          <p><i class="fas fa-tag fa-fw fa-sm"></i> kubernetes</p>
        </a></li>
      
        <li><a class="button" href="/tags/#monitoring">
          <p><i class="fas fa-tag fa-fw fa-sm"></i> monitoring</p>
        </a></li>
      
        <li><a class="button" href="/tags/#prometheus">
          <p><i class="fas fa-tag fa-fw fa-sm"></i> prometheus</p>
        </a></li>
      
        <li><a class="button" href="/tags/#scaling">
          <p><i class="fas fa-tag fa-fw fa-sm"></i> scaling</p>
        </a></li>
      
        <li><a class="button" href="/tags/#victoriametrics">
          <p><i class="fas fa-tag fa-fw fa-sm"></i> victoriametrics</p>
        </a></li>
      
    </ul>
  </div>



</article>

<!-- Post navigation -->

<div id="post-nav">
    
    <div id="previous-post">
        <a alt="Subtitles, open captions, closed captions, SDH, oh my!" href="/2022/09/20/captioning-in-the-streaming-world.html">
            <p>Previous post</p>
            Subtitles, open captions, closed captions, SDH, oh my!
        </a>
    </div>
    

    
    <div id="next-post">
        <a alt="Is machine learning a unicorn hiding a series of if and else?" href="/2022/09/05/machine-learning-if-else.html">
            <p>Next post</p>
            Is machine learning a unicorn hiding a series of if and else?
        </a>
    </div>
    
</div>



<!--Utterances-->


<!-- Cusdis -->


<!-- Disqus -->


<!-- To change color of links in the page -->
<style>
  header#main {
      background-size: cover;
      background-repeat: no-repeat;
      background-position: center;
  }

  
  .post-content a { color: rgb(251,87,66) !important; }
  .share-buttons a { color: rgb(251,87,66) !important; }
  .tag-list a:not(:hover) { color: rgb(251,87,66) !important; }
  div#post-nav a { color: rgb(251,87,66) !important; }
  footer a { color: rgb(251,87,66) !important; }
  .site-header nav a:hover {  color: rgb(251,87,66) !important; }
  a.button:hover {
    background: rgb(251,87,66) !important;
    border: 1px solid rgb(251,87,66) !important;
    color: white;
    text-decoration: none;
    filter: none;
  }
  header#main {
      background-color: rgb(251,87,66) !important;
      background-image: url('/assets/img/lineart.png');
  }
  

  
</style>

    </div>
    <footer class="site-footer">
    <p class="text">
        Powered by <a href="https://jekyllrb.com/">Jekyll</a> with <a href="https://github.com/sylhare/Type-on-Strap">Type on Strap</a>
</p>
            <div class="footer-icons">
                <ul>
                <!-- Social icons from Font Awesome, if enabled -->
                
<li>
    <a feed.xml href="/feed.xml"
       title="Follow RSS feed"
       target="_blank">
        <span class="fa-stack fa-lg">
            <i class="fas fa-circle fa-stack-2x"></i>
            <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
        </span>
    </a>
</li>



    

    

    

    

    

    

    
        
        
        
        
        <li>
            <a href="https://github.com/BedrockStreaming"
               title="Follow on Github"
               target="_blank"
               rel="noopener">
            <span class="fa-stack fa-lg">
              <i class="fas fa-circle fa-stack-2x"></i>
              <i class="fab fa-github fa-stack-1x fa-inverse"></i>
            </span>
            </a>
        </li>
    

    

    

    

    

    

    
        
        
        
        
        <li>
            <a href="https://www.linkedin.com/company/bedrock-streaming"
               title="Follow on Linkedin"
               target="_blank"
               rel="noopener">
            <span class="fa-stack fa-lg">
              <i class="fas fa-circle fa-stack-2x"></i>
              <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
            </span>
            </a>
        </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    
        
        
        
        
        <li>
            <a href="https://twitter.com/Bedrock_Tech"
               title="Follow on Twitter"
               target="_blank"
               rel="noopener">
            <span class="fa-stack fa-lg">
              <i class="fas fa-circle fa-stack-2x"></i>
              <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
            </span>
            </a>
        </li>
    

    

    

    

    
        
        
        
        
        <li>
            <a href="https://www.youtube.com/channel/UCSwvTdCWHS6ulRaIqdk7lNw"
               title="Follow on Youtube"
               target="_blank"
               rel="noopener">
            <span class="fa-stack fa-lg">
              <i class="fas fa-circle fa-stack-2x"></i>
              <i class="fab fa-youtube fa-stack-1x fa-inverse"></i>
            </span>
            </a>
        </li>
    


                </ul>
            </div>
</footer>



  </body>
</html>
