---
layout: post
title: "How AWS Cloudfront is helping us deliver our Web streaming platform ? "
description: "Feedback on the use of the AWS Cloudfront service for the deployment of high traffic web applications. Configuration example, best practices."
author:
    name: Antoine Caron
avatar:
email:
twitter: Slashgear_
github: Slashgear
category:
tags: [aws, cdn, node.js, react, javascript, frontend]
comments: true
image:
  feature: posts/2022-01-03-cloudfront-web-streaming-platform/hero.png
language: en
---

TODO article en construction üèóÔ∏è en fran√ßais, sera traduit quand il sera structur√©.

## Context

Le web est une plateforme majeur pour la diffusion des contenus de nos clients √† Bedrock.
Des millions d'utilusateurs s'y connectent chaque ann√©e afin d'y regarder leur live, leur replay ou bien directement les s√©ries et films de leur choix.
La diffusion d'√©venement sportifs tel que l'Euro de football 2020 repr√©sente un vrai challenge technique quand au maintient de la stabilit√© et de la performance d'une telle plateforme.

L'application web fonctionne aujourd'hui en mode SSR (Server Side Rendering).
Cela signifie qu'en prod aujourd'hui nous avons des server NodeJS Express qui tournent en prod afin de retourner des pages HTML pr√©rendues cot√© server.
On a fait le choix du SSR il y a plusieurs ann√©es maintenant, pour deux besoins: la SEO et l'am√©lioration du temps de premier affichage sur des devices un peu lent.
En plus des pages HTML, la plateforme web c'est aussi une collection immense d'assets qui permettent au site web de fonctionner: des bundles Javascript, du CSS, des images, des manifests.

![Schema of our cloudfront origin architecture simplified](/images/posts/2022-01-03-cloudfront-web-streaming-platform/web-archi.png)

Aujourd'hui nos clients ont des utilisateurs dans le monde entier, m√™me si bas√©s en Europe de l'ouest.
On peut principalement penser √† nos utilisateurs fran√ßais ultra marins qui ont acc√®s √† nos services.

**Pour r√©pondre √† ces probl√©matiques, l'usage d'un CDN nous a sembl√© n√©cessaire.**

## What is a CDN then ?

CDN pour Content Delevery Network est un service permettant le d√©liverer du contenu √† des utilisateurs √† travers internet (ici nos pages HTML et nos assets).
O√π que l'utilisateur soit dans le monde.
√Ä tous les utilisateurs, m√™me s'ils sont tr√®s nombreux.

Cloudfront est le service de CDN d'AWS. 
En mettant √† disposition des tr√®s nombreux "Edges" dans le monde entier, il permet de fournir une r√©ponse √† un utilisateur au plus pr√®s de sa position.
Cela permet de r√©duire de mani√®re tr√®s importante le time to first byte de nos r√©ponses.

![Worldmap of AWS cloudfront edges](/images/posts/2022-01-03-cloudfront-web-streaming-platform/edges.png)

En √©tant √† Lyon, il m'arrive d'avoir des r√©ponses du Edge de Milan.
En effet, Milan est relativement bien plus pr√®s que Paris.

Noter qu'il est tr√®s facile de savoir quel edge cloudfront vous a r√©pondu (configuration par d√©faut)
Chaque edge est identifiable par un code de trois lettres qui correspondent au code de l'a√©roport international le plus proche (ici: CDG correspond √† l'a√©roport paris charles de gaulle)

```
x-amz-cf-pop: CDG50-C1
```

D√©livrer du contenu au plus proche de l'utilisateur c'est top, √ßa permet th√©oriquement de r√©duire le temps d'attente.
Cela ne r√©soud par le souci de la charge.

La meilleure solution pour r√©pondre √† des probl√©matiques de charge, c'est le cache.

> Tu mets 1 seconde de cache, c'est d√©j√† gagn√© !
>
> [Y. Verry](https://twitter.com/yverry)


Le service Cloudfront permet de facilement mettre en cache des r√©ponses au niveau des server edge.
Si on prend l'exemple de la diffusion d'evenement sportif, les utilisateurs arrivent tr√®s nombreux sur une temporalit√© tr√®s r√©duite.
Mettre du cache (dire √† Cloudfront de mettre en cache page web) permet de soulager √©normement nos servers node.

Mettre en cache des objets dans Cloudfront c'est √©galement am√©liorer les temps de r√©ponse.
Plus besoin d'attendre de nos servers, l'utilisateur re√ßoit directement l'objet mis en cache.
Cloudfront en profite m√™me pour appliquer des algorithm de compression plus performant comme Brotli sur ces objets en cache.

Cloudfront permet en plus de faire du "Edge computing", ex√©cuter du code directement dans les server edge au lieu de le faire dans nos applications.
Lambda at edge, Cloudfront function, Web Application Firewall, vous avez plusieurs feature tr√®s pratiques utiliser directement un service manag√©.

Enfin, par l'usage de regional Edge, les centaines de server edges finaux ne contactent pas votre origin (votre application) quand le cache est invalid√© ou d√©pass√©.

![regional edge usage with Cloudfront](/images/posts/2022-01-03-cloudfront-web-streaming-platform/regional.png)

Cette bonne gestion du cache par niveau nous a m√™me permis de faire une invalidation totale du cache d'une distribution cloudfront quelques minutes avant le d√©but d'un √©venement sans pour autant g√©n√©rer un traffic monstre sur nos servers.

## Configuration used at Bedrock

Apr√®s maintenant plusieurs ann√©es en prod avec Cloudfront, nous avons pu mettre en place quelques pattern d'utilisation qui nous ont bien aid√©s.
Entre gain de stabilit√©, √©conomies et am√©lioration de l'exp√©rience utilisateur, vous y verrez diff√©rents avantages.

### Static fallback

Notre application web React est rendue cot√© server par plusieurs pod NodeJs dans un cluster Kubernetes.
Parfois, il peut arriver que ces pod crash ou bien que le cluster soit indisponible.

> Que faire dans ce cas ? Sans serverside rendering pas de site.

Nous avons donc d√©fini une strat√©gie de fallback en cas de non-disponibilt√© de notre cluster ou de nos server nodejs.
On poss√©dait d√©j√† cette feature avant que l'on migre ce projet dans le cloud AWS comme d√©crit [dans cet article](https://tech.bedrockstreaming.com/spa-mode-isomorphism-js/).

Comme nous utilisons terraform pour g√©rer nos ressources AWS, il nous a suffit de g√©n√©rer une `custom_error_response` pour les code HTTP d'indispo du Cluster.

```hcl
// ... (inside cloudfront definition)
custom_error_response {
    error_code            = 504
    error_caching_min_ttl = 300
    response_code         = 200
    response_page_path    = "/static-index.html"
}
// ...
```

Cela signifie donc que si le cluster nous retourne une _504 Gateway Timeout_ pour l'acc√®s √† une page du site rendue cot√© server, alors cloudfront va retourner le fichier `static_index.html` pour cette URL pendant `error_caching_min_ttl`.
Tout repose sur le fait que nous d√©posons une version statique (Single page app statique) de notre application dans le bucket S3 de notre infrastructure.

L'avantage de cette technique: uniquement les URL qui posent probl√®mes cot√© server vont passer en static.

### Keeping previous assets

Certains utilisateurs rafraichissent peu leur session
On ne peut pas se permettre de faire des assets en 404 √† chaque nouvelle version
N√©cessit√© de garder ces vieux assets
Nettoyage automatique par lifecycle de bucket

### Major versions caching

Migration V4 => V5, expliquer qu'on voulait √©viter le blink du passage d'une version √† l'autre
Cache policy qui prend un cookie de featureFlipping
Paf √ßa marche super

### Cache hit rate tracking


Meilleur performance, 
plus grande stabilit√©, 
r√©duction des co√ªts tr√®s important
Le scaling se faire par les edge et plus par l'origin
Centaine de requetes par minutes m√™me lors d'event majeurs


### Cloudfront log ingestion

Analyse SEO, suivi de metrics


## Conclusion

Apr√®s plus de deux ans d'usage de Cloudfront pour distribuer l'application web, clairement nous ne sommes pas d√©√ßu.
Stabilit√©, performance, permissivit√© des policy custom de cache, Cloudfront poss√®de pas mal d'avantages.
On se doit de remercier Achraf Souk qui nous a plusieurs fois conseill√© sur notre usage de ce service afin d'en tirer le plus partie.

N'arrive pas √† trouver une phrase de fin pour ouvrir sur les CDN en disant qu'on utilise aussi fastly √† Bedrock pour d'autre services.