---
layout: post
title: "Bedrock at We Love Speed 2023"
description: We tell you all about web performance in 2023!
author: team_frontend
tags: [conference, paris, tech, webperf]
color: rgb(251,87,66)
thumbnail: /images/posts/we-love-speed-2023/thumbnail.jpeg
---

The Frontend Bedrock team was present at the 2023 edition of the _We Love Speed_ conference in Paris on May 10. Its aim is to share as widely as possible knowledge and experience in the field of web performance.

Webperf, or web performance, refers to the set of techniques and best practices aimed at optimizing the loading speed and user experience of websites. It covers various aspects such as page loading time, interface responsiveness, animation fluidity, server request processing capacity, etc.

Webbperf is a major challenge in today's web industry, influencing user experience, website visibility and overall commercial success. This article summarizes the topics discussed at this year's _We Love Speed_ conference and gives an overview of the 2023 approach to web performance.

## Why optimize your sites' webperf?

### It's all about money ü§ë

Improving the webperf just for the technical challenge is not interesting in a company perspective and can't make the approach durable. [Boris Schapira in his talk _"Parlons de valeur"_](https://www.youtube.com/watch?v=wh0zCqZRuSs) üá´üá∑ shows how important it is to talk about **value** to make optimisation projects part of an organisation strategy.

Web performance is essential, as it has a direct impact on user satisfaction, engagement and the overall success of a website. Fast performance enables users to access information quickly, interact without delay and navigate smoothly. On the other hand, slow loading times, frozen interfaces or high response times can lead to user frustration, lower engagement and higher bounce rates.

A lot of articles on the net have proved **the impact of the webperf on users' engagement**. So, depending on the site's field, it's relatively easy to link the webperf approach to an objective of user views or loyalty, but also with the brand image. And the company's governance will be able to quickly measure the benefits in terms of return on investment.

### What about SEO?

Moreover, search engines such as Google also place give a relative importance on website performance in their ranking algorithms. Faster, more optimized sites often benefit from better positioning in search results, which can have a significant impact on their visibility and traffic.

However, [Philippe Yonnet's talk _"Quel est le v√©ritable impact des probl√®mes de web performance sur le SEO‚ÄØ?"_](https://www.youtube.com/watch?v=uWqQCOX52i4) üá´üá∑ reveals that actually the Google webperf scoring is in reality quite low in all the parameters taken into account in the ranking algorithm. Relevant content is always the first factor in top positioning. As was the case with responsive design a few years ago, the Google's communication around webperf is aimed more at **encouraging good practices** in the web community than at really penalizing slow sites.

## How do you take up a performance project?

### Build a long-term strategy based on usages

You need a strategy and a speech! [Boris Schapira](https://www.youtube.com/watch?v=wh0zCqZRuSs) üá´üá∑ defines 6 steps:

1. Identify the sticking point
2. Associate a value to the project for the business
3. Invest time for the optimizations
4. Evaluate the ROI
5. Sustaine the approach over time (it should never be a one shot project)

> We now use universally the [Google's Core Web Vitals KPI](https://web.dev/vitals/) to model the user experience:
>
> - Does users have a stable visual response? ‚û°Ô∏è it's measured though the _Cumulative Layout Shift_ (CLS)
> - Do users quickly see content they can trust? ‚û°Ô∏è it's measured though the _Largest Contentful Paint_ (LCP)
> - Can users quickly interact with the page in a qualitative way? ‚û°Ô∏è it's measured though the _First Input Delay_ (FID)

But these KPI are a limited reflection of user experience, and it is hard to link as it to a representative value. **You need to correlate these measures with usages**. There is no magic solution for this but segmenting sessions is a good practice to focus on relevant optimizations:

- take a period of time where the measure is representative (e.g. on our streaming sites, the activity period is mainly in the evening)
- take into account the fact that different actions or events on your site may not involve the same users (so not the same devices, etc.)
- take "short" indicators to measure the impact of the performance (e.g. if users are on a product list, monitor the viewing of the product page and not the purchase of the product)
- take into account the market you're addressing (e.g. food click & collect users are more likely to wait the loading of the next page than users on a retail site)

### Priorization

When it comes to prioritizing performance subjects, there are several strategies to consider. Philip Tellis shed light on the psychological aspect of performance, focusing on cognitive biases.

Tellis made a powerful statement: "If you have a brain, you have a bias." Let's explore three examples that demonstrate how biases can impact your work and how you can leverage them to your advantage.

The negativity bias reveals that negative experiences tend to leave a stronger impression than positive ones, even if their intensity is the same. This is crucial to keep in mind when optimizing your app's performance. Ideally, the slowest page should not be more than 15 times slower than the fastest page. Users might perceive the slower page as the norm for your app. To counteract this bias, it's important to be transparent with your users. You can display a message indicating that the page is slow and assure them that efforts are underway to resolve the issue. Interestingly, slow pages have been associated with a 38% increase in heart rate, similar to watching a horror movie. By prioritizing performance and being honest with your users, you can mitigate stress and anxiety.

The serial position effect highlights that people tend to remember the beginning and end of an experience more vividly. This is particularly relevant for our work in developing applications for Smart TVs, where performance challenges arise in two areas: page loading and remote control navigation. Taking this bias into account, we've learned that investing more time in optimizing page load times can significantly increase end-user satisfaction. Furthermore, statistics show that a 500ms increase in delay leads to a 26% rise in frustration.

The escalation of commitment bias refers to the inclination to persist in an endeavor once a significant investment of money, effort, or time has been made. Applying this bias to our app development, we recognize the importance of ensuring that the initial pages users encounter are fast, as this positively influences user retention. There is a direct correlation between a smooth initial experience and increased user engagement.

These are just three examples among many others that Philip presented in his thought-provoking talk. It was an insightful perspective on performance, viewed through the lens of our cognitive biases. We all possess biases, and as developers, our objective is to acknowledge them and harness their power to inform the future updates of our apps.

https://youtu.be/6KwW5v5rce4

### Community

Here's an improved version of the text:

While optimizing specific parts of your app is essential, it's important to remember that you work in a company composed of diverse individuals with varying roles, perspectives, and concerns. Therefore, it's crucial to extend performance awareness across all departments of your organization.

La Redoute, an international clothing retailer, provides an excellent example of addressing this issue by creating a performance community within their company.

To provide some context, La Redoute faces not only performance issues but also challenges related to synchronization and contributions on their platform.

To tackle these challenges, they established a community that brings together individuals from different departments, including technical, marketing, finance, design, product, SEO, and more.

It's vital to ensure that performance is not solely the responsibility of one department, as each department can contribute valuable insights and support that ultimately benefit the entire company.

This community convenes once a week for 30 minutes to exchange knowledge and share updates on performance-related topics. To keep everyone informed, they create meeting reports to update those who couldn't attend the session or are in different time zones, considering their international presence.

After six months, they began witnessing the initial benefits, and within one year, they deemed the community mature. They continue to hold these meetings, recognizing that the objective is not to prevent all issues but rather to minimize their impact and respond swiftly.

La Redoute's approach is truly inspiring and serves as a great example of fostering collaboration and cross-departmental engagement to address performance challenges.

https://youtu.be/aGi-vxC6ttA

## Avec quels moyens s‚Äôattaquer √† la performance ?

When analyzing a website's performance, it's essential to take several key criteria into account. Here are some of the commonly used performance analysis criteria:

- Largest Contentful Paint (LCP): LCP measures the time it takes for the largest visible element on the page (such as an image or block of text) to be completely rendered on screen. A fast LCP indicates fast page loading and a better user experience.

- Cumulative Layout Shift (CLS): CLS measures the visual stability of the page by evaluating changes in element position during loading. A low CLS means that page elements do not move unexpectedly, providing a more stable and pleasant user experience.

- First Contentful Paint (FCP): FCP measures the time elapsed between the start of navigation and the display of the first element on the screen, whether text, image or other visual element. A fast FCP indicates that the page is loading quickly and gives the impression of responsiveness.

- Time to Interactive (TTI): TTI measures the time it takes for the page to become fully interactive, i.e. users can interact with elements on the page, click on links, fill in forms, etc. A fast TTI is crucial to the success of a site. A fast TTI is crucial for user engagement.

- First Input Delay (FID): FID measures the delay between the user's first interaction with the page (for example, a click on a button) and the page's actual response to that interaction. A short FID indicates high responsiveness and a smooth user experience.

- Interaction to Next Paint (INP): INP is a performance metric that measures the delay between a user interaction and the moment when the next visual update is rendered on the screen. It is a specific metric that evaluates the responsiveness of the website to user actions. A short INP indicates that the website reacts quickly to user actions, resulting in a pleasant, lag-free user experience.

To measure/evaluate your site's performance according to these criteria, there are 3 types of sources: Local (devtools), Synthetic (CI/CD / online scan tools), RUM (Real User Monitoring).

- Local development tools - devtools :

  - Chrome DevTools: A set of development tools integrated into the Chrome browser, for analyzing performance, debugging JavaScript code, inspecting DOM elements, etc.
  - Firefox DevTools: Tools similar to Chrome DevTools, but specific to the Firefox browser. They offer debugging, performance auditing and inspection of web elements.
  - Lighthouse DevTools (Chrome): A Chrome DevTools extension that provides automated audits to evaluate performance, accessibility, SEO optimization, etc.

- Synthetic testing - CI/CD and online analysis tools :

  - WebPageTest: An online tool for evaluating website performance by running tests on different browser configurations, network connections and geographical locations.
  - Lighthouse CI: A Lighthouse-based continuous integration (CI) solution that automates web performance and quality audits with every deployment.

- Real User Monitoring (RUM):
  - New Relic: An application performance monitoring platform that provides real-time visibility into the performance of your web applications, including usage metrics, load times, etc.
  - Grafana: A data visualization platform that can be used to display and analyze performance monitoring data collected from a variety of sources, including RUM tools.

It's important to note that each type of analysis data has its own advantages and is used in specific contexts. Local data is useful for real-time development and debugging, synthetic data enables performance to be compared and optimized in a reproducible way, while RUM data provides a true view of the user experience. It is generally recommended to use a combination of these different data sources to identify/target problems or opportunities for performance improvement.

Once you've identified the relevant performance criteria and used the analysis tools to measure your website's current performance, it's essential to stabilize the various criteria before setting improvement targets. Here are the steps to follow:

1. Stabilize criteria :

   - Analyze the results of the performance measurements for each criterion you've identified. Identify areas where improvements are needed, and problems that affect performance stability. For example, LCP depends on the appearance of the widest element on the page. It's important that this element is always the same on the same page type, otherwise there will be no consistent result and optimization will be impossible.
   - Examine performance metrics over a sufficiently long period of time to detect trends and variations. This will help you understand whether performance problems are constant or sporadic.
   - Identify factors that could influence performance, such as code changes, server updates, new features, content contribution, etc...

2. Setting improvement targets :

   - Determine the performance levels you want to achieve for each criterion, based on benchmarks, best practices or objectives specific to your application.
   - Define measurable and realistic objectives for each performance criterion. For example, you could aim to reduce page load time by 20%, improve server response time by less than 200 ms, or reduce bounce rate by 15%.
   - Prioritize goals according to their impact on your website's user experience and business objectives.

3. Plan and implement improvements :
   - Identify the specific actions to be taken to achieve each improvement objective. This may include code optimizations, server configuration adjustments, resource optimizations, caching, etc.
   - Establish an action plan for each objective, defining the necessary steps, responsibilities, deadlines and resources required.
   - Implement improvements iteratively, and measure performance regularly to assess the impact of changes.
   - Repeat the process of analyzing, stabilizing and improving performance iteratively to continue optimizing your website.

It's important to bear in mind that website performance is often an ongoing process, as needs, functionalities and conditions change over time. It is therefore advisable to regularly monitor performance and continue to identify new opportunities for improvement to deliver a superior user experience.

It's important to be careful when planning and implementing performance improvements. Here are some points to consider:

1. The performance possibilities are not the same between Single Pages Applications (SPA) and Multiple Pages Applications (MPA).
   - MPAs are simple to measure: each page is independent. The first page loads resources and then caches certain resources. It's therefore important to be able to distinguish between measurements based on a user's first visit and those based on browsing (which is much faster).
   - SPAs are more difficult, because apart from the initial page load, there is other page load. Initial loading is often heavier (because of js framework), and therefore slower. Page changes can't be measured simply, which leads to a sharp deterioration in page load criteria, since only the initial load is taken into account. Research is currently underway in browsers to improve the collection of information on page changes in SPAs. This new metric is called soft-navigations and is currently being tested on Chrome and specified by web organizations.
2. The performance metrics mentioned above identify a page's performance on paper. They are used by search engines to classify/order search results (seo). However, they are not perfectly representative of user experience. It's possible to have a super-fast LCP or FCP and still have a feeling of slowness or discomfort on the user's side. For example, a page that quickly displays the thumbnail of a film (LCP validation criterion) but takes a long time to display the film's cast list (which is the content the user wants) won't be great for the user experience.

Sources :

- [Measure or die: rapid diagnostics by Jean-Pierre Vincent](https://www.welovespeed.com/2023/interventions/#diagnostics-rapides)
- [Soft Navigations, it's hard! by Yoav Weiss](https://www.welovespeed.com/2023/interventions/#soft-navigations-are-hard)
- [How to become a Web Performance Sherlock Holmes by Ludovic Lefebvre](https://www.welovespeed.com/2023/interventions/#devenir-sherlock-holmes)
- [Reducing RUM noise by Tim Verreecke](https://www.welovespeed.com/2023/interventions/#noise-canceling-rum)
- [Understanding cognitive bias in performance measurement by Philip Tellis](https://www.welovespeed.com/2023/interventions/#understanding-cognitive-biais-in-performance-measurement)

## Comment am√©liorer sa perf ? Astuces et bonnes pratiques

Etienne ?
