---
layout: post
title: "Bedrock at We Love Speed 2023"
description: We tell you all about web performance in 2023!
author: team_frontend
tags: [conference, paris, tech, webperf]
color: rgb(251,87,66)
thumbnail: /images/posts/we-love-speed-2023/thumbnail.jpeg
---

The Frontend Bedrock team was present at the 2023 edition of the _We Love Speed_ conference in Paris on May 10. Its aim is to share as widely as possible knowledge and experience in the field of web performance.

Webperf, or web performance, refers to the set of techniques and best practices aimed at optimizing the loading speed and user experience of websites. It covers various aspects such as page loading time, interface responsiveness, animation fluidity, server request processing capacity, etc.

Webbperf is a major challenge in today's web industry, influencing user experience, website visibility and overall commercial success. This article summarizes the topics discussed at this year's _We Love Speed_ conference and gives an overview of the 2023 approach to web performance.

## Why optimize your sites' webperf?

### It's all about money ü§ë

Improving the webperf just for the technical challenge is not interesting in a company perspective and can't make the approach durable. [Boris Schapira in his talk _"Parlons de valeur"_](https://www.youtube.com/watch?v=wh0zCqZRuSs) üá´üá∑ shows how important it is to talk about **value** to make optimisation projects part of an organisation strategy.

Web performance is essential, as it has a direct impact on user satisfaction, engagement and the overall success of a website. Fast performance enables users to access information quickly, interact without delay and navigate smoothly. On the other hand, slow loading times, frozen interfaces or high response times can lead to user frustration, lower engagement and higher bounce rates.

A lot of articles on the net have proved **the impact of the webperf on users' engagement** (here is [an great article from Google](https://web.dev/why-speed-matters/) or [hundreds of case studies](https://wpostats.com/) from WPO stats). So, depending on the site's field, it's relatively easy to link the webperf approach to an objective of user views or loyalty, but also with the brand image. And the company's governance will be able to quickly measure the benefits in terms of return on investment.

### What about SEO?

Moreover, search engines such as Google also place give a relative importance on website performance in their ranking algorithms. Faster, more optimized sites often benefit from better positioning in search results, which can have an impact on their visibility and traffic.

However, [Philippe Yonnet's talk _"Quel est le v√©ritable impact des probl√®mes de web performance sur le SEO‚ÄØ?"_](https://www.youtube.com/watch?v=uWqQCOX52i4) üá´üá∑ reveals that actually the Google webperf scoring is in reality quite low in all the parameters taken into account in the ranking algorithm. Relevant content is always the first factor in top positioning. As was the case with responsive design a few years ago, the Google's communication around webperf is aimed more at **encouraging good practices** in the web community than at really penalizing slow sites.

## How do you take up a performance project?

### Build a long-term strategy based on usages

You need a strategy and a speech! [Boris Schapira](https://www.youtube.com/watch?v=wh0zCqZRuSs) üá´üá∑ defines 6 steps:

1. Identify the sticking point
2. Associate a value to the project for the business
3. Invest time for the optimizations
4. Evaluate the ROI
5. Sustaine the approach over time (it should never be a one shot project)

> We now use universally the [Google's Core Web Vitals KPI](https://web.dev/vitals/) to model the user experience:
>
> - Does users have a stable visual response? ‚û°Ô∏è it's measured though the _Cumulative Layout Shift_ (CLS)
> - Do users quickly see content they can trust? ‚û°Ô∏è it's measured though the _Largest Contentful Paint_ (LCP)
> - Can users quickly interact with the page in a qualitative way? ‚û°Ô∏è it's measured though the _First Input Delay_ (FID)

But these KPI are a limited reflection of user experience, and it is hard to link as it to a representative value. **You need to correlate these measures with usages**. There is no magic solution for this but segmenting sessions is a good practice to focus on relevant optimizations:

- take a period of time where the measure is representative (e.g. on our streaming sites, the activity period is mainly in the evening)
- take into account the fact that different actions or events on your site may not involve the same users (so not the same devices, etc.)
- take "short" indicators to measure the impact of the performance (e.g. if users are on a product list, monitor the viewing of the product page and not the purchase of the product)
- take into account the market you're addressing (e.g. food click & collect users are more likely to wait the loading of the next page than users on a retail site)

### Take cognitive biases into account to prioritise optimisations

When it comes to prioritizing performance subjects, there are several strategies to consider. [Philip Tellis in his talk _"Understanding Cognitive Biases in Performance Measurement"_](https://www.youtube.com/watch?v=6KwW5v5rce4) üá¨üáß shed light on the psychological aspect of performance, focusing on cognitive biases.

Tellis made a powerful statement: _"If you have a brain, you have a bias_". Let's explore three examples that demonstrate how biases can impact your work and how you can leverage them to your advantage.

#### Slowest is the norm

The negativity bias reveals that negative experiences tend to leave a stronger impression than positive ones, even if their intensity is the same. This is crucial to keep in mind when optimizing your app's performance. Ideally, the slowest page should not be more than 15 times slower than the fastest page. Users might perceive the slower page as the norm for your app.

To counteract this bias, it's important to be transparent with your users. You can display a message indicating that the page is slow and assure them that efforts are underway to resolve the issue. Interestingly, slow pages have been associated with a 38% increase in heart rate, similar to watching a horror movie. **By prioritizing performance and being honest with your users, you can mitigate stress and anxiety.**

#### Take care at the beginning and end

The serial position effect highlights that people tend to remember the beginning and end of an experience more vividly. This is particularly relevant for our work in developing applications for Smart TVs, where performance challenges arise in two areas: page loading and remote control navigation. Taking this bias into account, we've learned that **investing more time in optimizing page load times can significantly increase end-user satisfaction**. Furthermore, statistics show that a 500ms increase in delay leads to a 26% rise in frustration.

#### Take care at the beginning üòÖ

The escalation of commitment bias refers to the inclination to persist in an endeavor once a significant investment of money, effort, or time has been made. Applying this bias to our app development, we recognize the importance of ensuring that the initial pages users encounter are fast, as this positively influences user retention. **There is a direct correlation between a smooth initial experience and increased user engagement.**

These are just three examples among many others that Philip presented in his thought-provoking talk. It was an insightful perspective on performance, viewed through the lens of our cognitive biases. We all possess biases, and as developers, our objective is to acknowledge them and harness their power to inform the future updates of our apps.

### Performance must be a company-wide concern

While optimizing specific parts of your app is essential, it's important to remember that you work in a company composed of diverse individuals with varying roles, perspectives, and concerns. Therefore, it's crucial to extend performance awareness across all departments of your organization.

La Redoute, an international clothing retailer, provides an excellent example of addressing this issue by creating a performance community within their company though the talk [_"Comment construire une communaut√© Web Perf dans son orga ?"_](https://www.youtube.com/watch?v=aGi-vxC6ttA) üá´üá∑.

To provide some context, La Redoute faces not only performance issues but also challenges related to synchronization and contributions on their platform. To tackle these challenges, they established a community that brings together individuals from different departments, including technical, marketing, finance, design, product, SEO, and more.

It's vital to ensure that performance is not solely the responsibility of one department, as **each department can contribute valuable insights and support that ultimately benefit the entire company**.

This community convenes once a week for 30 minutes to exchange knowledge and share updates on performance-related topics. To keep everyone informed, they create meeting reports to update those who couldn't attend the session or are in different time zones, considering their international presence.

After six months, they began witnessing the initial benefits, and **within one year, they deemed the community mature**. They continue to hold these meetings, recognizing that the objective is not to prevent all issues but rather to minimize their impact and respond swiftly.

La Redoute's approach is truly inspiring and serves as a great example of fostering collaboration and cross-departmental engagement to address performance challenges.

## Use the right tools to target performance issues

When analyzing a website's performance, it's essential to take several key criteria into account. Here are some of the commonly used performance analysis criteria:
![metric.png](/images/posts/2023-07-01-we-love-speed-2023/metric.png)
To measure/evaluate your site's performance according to these criteria, there are 3 types of sources: Local (devtools), Synthetic (CI/CD / online scan tools), RUM (Real User Monitoring).
![metric.png](/images/posts/2023-07-01-we-love-speed-2023/perf-data-source.png)

- Local development tools - devtools :
  - Chrome DevTools: A set of development tools integrated into the Chrome browser, for analyzing performance, debugging JavaScript code, inspecting DOM elements, etc.
  - Firefox DevTools: Tools similar to Chrome DevTools, but specific to the Firefox browser. They offer debugging, performance auditing and inspection of web elements.
  - Lighthouse DevTools (Chrome): A Chrome DevTools extension that provides automated audits to evaluate performance, accessibility, SEO optimization, etc.
- Synthetic testing - CI/CD and online analysis tools :
  - [WebPageTest](https://www.webpagetest.org/): An online tool for evaluating website performance by running tests on different browser configurations, network connections and geographical locations.
  - [Lighthouse CI](https://github.com/GoogleChrome/lighthouse-ci): A Lighthouse-based continuous integration (CI) solution that automates web performance and quality audits with every deployment.
- Real User Monitoring (RUM):
  - [New Relic](https://newrelic.com): An application performance monitoring platform that provides real-time visibility into the performance of your web applications, including usage metrics, load times, etc.
  - [Grafana](https://grafana.com/): A data visualization platform that can be used to display and analyze performance monitoring data collected from a variety of sources, including RUM tools.

![logomosaic.png](/images/posts/2023-07-01-we-love-speed-2023/logomosaic.png)
It's important to note that each type of analysis data has its own advantages and is used in specific contexts. Local data is useful for real-time development and debugging, synthetic data enables performance to be compared and optimized in a reproducible way, while RUM data provides a true view of the user experience. It is generally recommended to use a combination of these different data sources to identify/target problems or opportunities for performance improvement.
Once you've identified the relevant performance criteria and used the analysis tools to measure your website's current performance, it's essential to stabilize the various criteria before setting improvement targets. Here are the steps to follow:

1. Stabilize criteria :

- üßê Analyze the results of the performance measurements for each criterion you've identified. Identify areas where improvements are needed, and problems that affect performance stability. For example, LCP depends on the appearance of the widest element on the page. It's important that this element is always the same on the same page type, otherwise there will be no consistent result and optimization will be impossible.
- üìä Examine performance metrics over a sufficiently long period of time to detect trends and variations. This will help you understand whether performance problems are constant or sporadic.
- üí• Identify factors that could influence performance, such as code changes, server updates, new features, content contribution, etc...

2. Setting improvement targets :

- üéØ Determine the performance levels you want to achieve for each criterion, based on benchmarks, best practices or objectives specific to your application.
- üéöÔ∏è Define measurable and realistic objectives for each performance criterion. For example, you could aim to reduce page load time by 20%, improve server response time by less than 200 ms, or reduce bounce rate by 15%.
- ü§ë Prioritize goals according to their impact on your website's user experience and business objectives.

3. Plan and implement improvements :

- üëÄ Identify the specific actions to be taken to achieve each improvement objective. This may include code optimizations, server configuration adjustments, resource optimizations, caching, etc.
- üóìÔ∏è Establish an action plan for each objective, defining the necessary steps, responsibilities, deadlines and resources required.
- üöß Implement improvements iteratively, and measure performance regularly to assess the impact of changes.
- ‚ôæÔ∏è Repeat the process of analyzing, stabilizing and improving performance iteratively to continue optimizing your website.
  It's important to bear in mind that website performance is often an ongoing process, as needs, functionalities and conditions change over time. It is therefore advisable to regularly monitor performance and continue to identify new opportunities for improvement to deliver a superior user experience.

It's important to be careful when planning and implementing performance improvements. Here are some points to consider:

1. The performance possibilities are not the same between Single Pages Applications (SPA) and Multiple Pages Applications (MPA).
   - MPAs are simple to measure: each page is independent. The first page loads resources and then caches certain resources. It's therefore important to be able to distinguish between measurements based on a user's first visit and those based on browsing (which is much faster).
   - SPAs are more difficult, because apart from the initial page load, there is other page load. Initial loading is often heavier (because of js framework), and therefore slower. Page changes can't be measured simply, which leads to a sharp deterioration in page load criteria, since only the initial load is taken into account. Research is currently underway in browsers to improve the collection of information on page changes in SPAs. This new metric is called soft-navigations and is currently being tested on Chrome and specified by web organizations.
2. The performance metrics mentioned above identify a page's performance on paper. They are used by search engines to classify/order search results (seo). However, they are not perfectly representative of user experience. It's possible to have a super-fast LCP or FCP and still have a feeling of slowness or discomfort on the user's side. For example, a page that quickly displays the thumbnail of a film (LCP validation criterion) but takes a long time to display the film's cast list (which is the content the user wants) won't be great for the user experience.
   Sources :

- [Measure or die: rapid diagnostics by Jean-Pierre Vincent](https://www.welovespeed.com/2023/interventions/#diagnostics-rapides)
- [Soft Navigations, it's hard! by Yoav Weiss](https://www.welovespeed.com/2023/interventions/#soft-navigations-are-hard)
- [How to become a Web Performance Sherlock Holmes by Ludovic Lefebvre](https://www.welovespeed.com/2023/interventions/#devenir-sherlock-holmes)
- [Reducing RUM noise by Tim Verreecke](https://www.welovespeed.com/2023/interventions/#noise-canceling-rum)
- [Understanding cognitive bias in performance measurement by Philip Tellis](https://www.welovespeed.com/2023/interventions/#understanding-cognitive-biais-in-performance-measurement)

## Few tips for implementing performance optimizations

So then, one might ask themselves a question : How do I, actually, improve my performance ? I know what‚Äôs the problem, but how do I fix it ?
Well, obviously, there is no ‚Äúperfect‚Äù answer : What might be enough for one website might not suffice for another, and some websites might also handle their own code well enough so that some improvements are not needed.
No matter what, however, here are some clues as to how you could make some improvements !

### Use bfcache

Did you know that around 10% of a user's navigation consists of clicking on the ‚ÄúGo back‚Äù button of their browser ? More often than not, however, when doing that, our users need to wait for the page to load again, despite the fact that the browser already did that work for us !
Browser developers already noticed that, however, and we recently began to see the apparition of something named the Back/Forward cache (Also simply named bfcache), who‚Äôs goal is to do exactly that : Cache the page the user is leaving, so that if they go back using their browser features, they‚Äôll see the cached page instead. You can find more about [this amazing cache here](https://web.dev/bfcache/) !

### Preloading, Preconnecting and HTML

There is one important rule that you need to always remember when doing HTML : It is parsed line by line, and it can be paused. When your browser is trying to render your page, if it runs across something trying to call an url (Ex: loading a css file), then it‚Äôll wait until said css file is fully loaded, and then again it‚Äôll keep going !
However, you can use the HTML property `rel` to prepare some of that stuff ahead. For example, `rel=‚Äùpreload‚Äù` will tell the browser to start loading said css asynchronously, as soon as they arrive on the page ! Using an API ? Then you can use `rel=‚Äùpreconnect‚Äù` to start your handshakes as soon as you‚Äôre on your page, so that your API is fully ready to send you packages as soon as you need it !

For more details about all of that, feel free to check [Mozilla‚Äôs documentation](https://developer.mozilla.org/en-US/docs/Web/HTML/Attributes/rel) , it contains even more attribute values than the two examples here.
If you want your resource to be even more high-priority, you can go the extra step, and [use the `fetchpriority` attribute](https://web.dev/fetch-priority/), which will be more than glad to fetch as soon as possible your corresponding resources ! As easy as it sounds, [it can have immense benefit](https://twitter.com/senthil_hi/status/1589676464215326720).
However, please be mindful about using these ! Your browser can only do so much at the same time : And if you‚Äôre overusing these, then for your browser everything will become a top-priority, and it won‚Äôt be able to load specifically what you need the most. As a result, you‚Äôll go back to your first issue. Always remember that if everything is important, then nothing is !

### Lazy Loading

Images, and especially high-quality ones, can take up a lot of your time to load. If you‚Äôre using a lot of images on your website, you‚Äôve probably noticed it by now. However, quite often, you‚Äôre not always displaying every image to your user at the same time : Maybe some are located down the page, maybe some are only seen by an user after some time or if they do a specific action : The point is, you don‚Äôt need to load all of these images right from the get-go. That‚Äôs what lazy-loading is for : Only loading the images the user sees right now, and then only, if we have some time, start to load what the user isn‚Äôt seeing yet.
Here again, you have an HTML attribute that can take care of everything for you : Named `loading`, you can pass the value `lazy` to it and it‚Äôll only load your image when approaching the screen. Find out more about that attribute [over here](https://web.dev/browser-level-image-lazy-loading/) !
Do note, however, that lazy-loading is not limited to images only : Maybe you could lazyload your components ? Your thirdparties ? Do you really need your chat component to be ready and available if the user did not click on the chat icone yet ? Do you need the youtube thirdparty to be ready to play the video, if the user still hasn't clicked on said video ? Maybe sometimes, it‚Äôs for the best to increase an action response time if it means that your website is loaded faster.

### 103 Early hints

> Do note that this is an experimental feature ‚ö†Ô∏è

When downloading files from a server (Such as font files, css files, or others), at first, the server does not know what size of packages your browser is able to handle. It will thus need to ‚Äúwarm up‚Äù first, sending more and more packages at once until the browser has reached its limit, at which point it will adapt and keep sending at the highest possible (and manageable) speed.
The 103 Early hints feature allows your browser, while it is connected to the server and not downloading anything (Such as when using a preconnect), to start that warmup round instead of being idle : That way, when the server will be needed to download, it‚Äôll be able to immediately start at maximum output. This will increase the speed at which your application is able to download content from your server, therefore decreasing waiting time for your end user.

### Take care of your CMP !

Nowadays, a lot of websites (And of course, us too), are using a lot of third parties. Whether it is in order to monitor what your user is doing so that you can track their issues more precisely, to gather some data for your teams or to send information for you to sell, there are more and more thirdparties through the internet.
However, each new thirdparty comes with its own compounding issues : Namely, each is adding another domain, meaning another need to connect to a distant API, reheat the connection‚Ä¶ And all of that is taking network time, precious time that you actually need to load a lot more data for your website ! And we‚Äôre not even speaking of them using custom SDKs, using your threads and computing time to run their javascript‚Ä¶
First of all, it is important to understand how your thirdparties work : You CANNOT, and should NEVER try to preconnect to them. Preconnecting to a thirdparty discloses your user IP, which according to GDPR laws at the time of writing, is considered a personnel data. If your user does not consent to sharing their data, you should never try to connect in the first place.
Therefore, you need to collect the user's consent to be able to connect to your thirdparties API : But to collect said consent, you need your Consent Manager to be booted and ready. Therefore, the first improvement to make is to optimize your CMP : Make sure it loads fast, make sure it shares the user‚Äôs consent with you as soon as possible so that you‚Äôre ready to go fetch those thirdparties as soon as you can !

### Self-host blocking thirdparties

Just like we mentioned, many thirdparties are vital : So much that sometimes, you also need them to load in order to display something at all. Maybe, for example, it‚Äôs the thirdparty responsible for your A/B testing : Of course you need it to know what your user will see !
However, it is also important to remember that since your browser has limited network capabilities, it will try to prioritize its requests : And requests that are going to another domain are far down the line.
If you have blocking thirdparties that are mandatory, moving them to your own domain is a good idea to increase your load time : Your browser will prioritize more these requests, your website will know what to display sooner, and will display the right content as soon as possible !

### Use Server-side Rendering (SSR) !

Easier said than done, Server-Side Rendering is a wonderful tool to reduce what‚Äôs called your ‚ÄúTotal Blocking Time‚Äù in your application. By allowing your code to be pre-rendered in your server before being sent to your browser, you can dramatically decrease the time it takes for an user to be able to interact with your page.
You can then fine tune your SSR using librairies and packages such as the [Vue Lazy Hydration](https://www.npmjs.com/package/vue-lazy-hydration) one.
However, this is not a perfect solution : It requires a lot of time, comprises a lot of technically difficult topics, and may require you to change your framework altogether. But there‚Äôs a silver lining : At the time of writing, more and more frameworks are trying to pick up and make more tools available to us to easily access SSR : Astro or Nuxt for example.

## Keep at it! üí™

All in all, performance is definitely anything but an easy task to do. It is not a magic formula that will make all your problems go away. Even if you manage to hold a long workshop of several weeks (or even months!) that will finally fix your performance issues, if it does not become a habit in your developer teams, it will never be over. **Performance is a habit, built through practice and good communication**. But it can be achieved.

_Authors: Etienne Doyon, Alexandre Gory, Maxime Blanc, Florent Dubost_
