<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://tech.bedrockstreaming.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://tech.bedrockstreaming.com/" rel="alternate" type="text/html" /><updated>2023-04-24T07:59:01+00:00</updated><id>https://tech.bedrockstreaming.com/feed.xml</id><title type="html">Bedrock Tech Blog</title><subtitle>Blog technique de Bedrock</subtitle><entry><title type="html">Bedrock à l’AWS Summit Paris 2023</title><link href="https://tech.bedrockstreaming.com/2023/04/20/aws-summit-paris-2023.html" rel="alternate" type="text/html" title="Bedrock à l’AWS Summit Paris 2023" /><published>2023-04-20T00:00:00+00:00</published><updated>2023-04-20T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/04/20/aws-summit-paris-2023</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/04/20/aws-summit-paris-2023.html">&lt;p&gt;L’AWS Summit Paris 2023 s’est déroulé le 4 avril. C’était pour nous l’occasion de découvrir les dernières innovations au cœur des services AWS, comme la solution d’IA d’aide au développement nommée CodeWhisperer. De plus, &lt;a href=&quot;https://twitter.com/pascal_martin&quot;&gt;Pascal Martin, Principal Engineer&lt;/a&gt;, y assistait aussi en tant que speaker pour partager notre expérience en conception et maintenance de Systèmes Distribués.
En plus des deux points précédemment cités, nous verrons aussi comment eTF1 s’est préparé pour la Coupe du Monde de la FIFA 2022, ou de souveraineté et de son application chez AWS.&lt;/p&gt;

&lt;h2 id=&quot;à-vos-côtés-pour-les-grands-moments--aws-tf1-et-la-coupe-du-monde-de-la-fifa-2022&quot;&gt;À vos côtés pour les grands moments : AWS, TF1 et la Coupe du Monde de la FIFA 2022&lt;/h2&gt;

&lt;p&gt;Conférence présentée par :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Imane Zeroual - Senior Technical Account Manager, AWS&lt;/li&gt;
  &lt;li&gt;Djamel Arichi, Head of Managed Services and Support, eTF1&lt;/li&gt;
  &lt;li&gt;Ali Oubabiz, Head of Digital Infrastructure, eTF1&lt;/li&gt;
  &lt;li&gt;Remy Pinsonneau, Architecte, eTF1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-04-20-aws-summit-paris-2023/aws-summit-2023-etf1.jpg&quot; alt=&quot;MyTF1 rq/s pendant un match&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://tech.tf1.fr/&quot;&gt;eTF1&lt;/a&gt; partage son retour d’expérience sur la Coupe du Monde de foot 2022 et les défis surmontés pour que leur plateforme de replay myTF1 propose une parfaite expérience utilisateur tout au long de l’événement.&lt;/p&gt;

&lt;p&gt;La présentation, coanimée par Imane, Senior Technical Manager de chez AWS, permet aussi d’en apprendre un peu plus sur le programme IEM d’accompagnement de clients AWS lors d’événements critiques. Nous avons d’ailleurs déjà exploité ce programme chez Bedrock Streaming.
Challenge technique pour les équipes eTF1, la Coupe du Monde de football 2022 a battu plusieurs records de la plateforme, dont des pics à plus de 2,4 Millions d’utilisateurs simultanés. L’événement a été préparé en collaboration avec les équipes d’AWS pour adapter les infrastructures à recevoir de fortes charges.&lt;/p&gt;

&lt;p&gt;Trois points critiques identifiés :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Authent/backend, les millions d’utilisateurs vont s’authentifier dans une fenêtre de 15 minutes.&lt;/li&gt;
  &lt;li&gt;Delivery vidéo, tout au long de l’événement une forte charge, constante, est attendue.&lt;/li&gt;
  &lt;li&gt;Publicité, pic de charge très important mais ponctuel.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Des scénarios de tests de performances ont été effectués à l’aide de K6, pour chacun des points. La préproduction a servi d’environnement de test, avant d’effectuer une validation finale sur la production. Du travail a été également réalisé sur les services AWS : par exemple, les tables DynamoDB ont été basculées en OnDemand afin de profiter de l’élasticité plus rapide du service, malgré les coûts supplémentaires, comparé au mode provisionné.
Au niveau des clusters Kubernetes, les applications ont été redimensionnées à la hausse (mémoire, cpu, HPA) pour anticiper les pics de charge et ne pas seulement se reposer sur du scaling réactif.&lt;/p&gt;

&lt;p&gt;Lors de la compétition, une War Room était ouverte suivant l’importance des matchs. Elle était composée d’intervenants AWS grâce au programme IEM, de personnels techniques eTF1 et de membres du service management pour pouvoir réagir en cas d’imprévus. 
La War Room a d’ailleurs été mise à contribution puisque la plateforme à subi des attaques DDOS pendant certains matchs. Le CDN Cloudfront et WAF ont permis de les contenir.&lt;/p&gt;

&lt;p&gt;Chez Bedrock Streaming, nous étions curieux de ce retour d’expérience : nous avons préparé ce même type d’événement lors de l’Euro de football 2020. Les défis à surmonter sont les mêmes que ceux que nous avions rencontrés et nous sommes arrivés à des conclusions similaires dans nos choix techniques. Nous avions d’ailleurs développé un outil pour répondre au problème de scalabilité dans kubernetes durant l’Euro 2020 et que nous utilisons toujours aujourd’hui, &lt;a href=&quot;https://tech.bedrockstreaming.com/2022/09/01/kubernetes-prescaling-we-open-source-our-solution.html&quot;&gt;un article de blog à ce sujet est disponible ici&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;comment-bien-débuter-avec-amazon-codewhisperer&quot;&gt;Comment bien débuter avec Amazon CodeWhisperer&lt;/h2&gt;

&lt;p&gt;Conférence présentée par :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Sébastien Butreau, Senior Partner Solutions Architect, AWS&lt;/li&gt;
  &lt;li&gt;Sébastien Grazzini, Principal Solutions Architect, AWS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-04-20-aws-summit-paris-2023/aws-summit-2023-amazon-code-whisperer.jpg&quot; alt=&quot;Amazon Code Whisperer&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Amazon annonce une sortie grand public, prochaine, de son assistant de développement par IA CodeWhisperer (update: depuis, &lt;a href=&quot;https://aws.amazon.com/blogs/aws/amazon-codewhisperer-free-for-individual-use-is-now-generally-available/&quot;&gt;CodeWhisperer est passé GA&lt;/a&gt;).&lt;br /&gt;
Nous avons eu droit à une démonstration de l’outil. En quelques minutes et seulement à l’aide de quelques commentaires, les deux présentateurs ont produit un script python capable de prendre en entrée un répertoire de photos et donner en sortie un JSON qui, pour chaque photo, donnait le nom de la célébrité présente dessus.&lt;/p&gt;

&lt;p&gt;Chez Bedrock Streaming, nous pensons qu’il est très important de suivre ce nouveau tournant que prend l’aide au développement via l’IA depuis quelques mois. Nous prévoyons de tester lors de nos journées R&amp;amp;D Github Copilot et Amazon CodeWhisperer.&lt;/p&gt;

&lt;p&gt;L’outil d’Amazon a quelques atouts, notamment la fonctionnalité de suivi des références qui permet de savoir si du code proposé est similaire à du code utilisé pour l’apprentissage et peut-être protégé par une licence incompatible avec notre usage. De plus, l’intégration du SDK Amazon est assez poussée et cela prend tout son sens, notamment lors du développement pour des lambdas AWS où l’outil semble très performant.&lt;/p&gt;

&lt;h2 id=&quot;bienvenue-dans-le-monde-merveilleux-des-systèmes-distribués&quot;&gt;Bienvenue dans le Monde Merveilleux des Systèmes Distribués&lt;/h2&gt;

&lt;p&gt;Cette année encore, nous avons eu la chance de pouvoir partager notre expérience, lors d’une conférence donnée par &lt;a href=&quot;https://twitter.com/pascal_martin&quot;&gt;Pascal&lt;/a&gt;, Principal Engineer et &lt;a href=&quot;https://aws.amazon.com/developer/community/heroes/pascal-martin/&quot;&gt;AWS Hero&lt;/a&gt; : « Bienvenue dans le Monde Merveilleux des Systèmes Distribués »&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-04-20-aws-summit-paris-2023/aws-summit-2023-pascal-martin.jpg&quot; alt=&quot;Pascal Martin en action !&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Pourquoi s’embêter avec des Systèmes distribués ? Comment en tirer profit ? Quels dangers ? Scalabilité, coordination et résilience : trois grands axes pour ce talk, basé sur l’expérience acquise par les équipes Bedrock, tant infra que devs, depuis plusieurs années.&lt;/p&gt;

&lt;p&gt;En tant que speaker, pouvoir partager avec notre communauté est toujours aussi agréable ! Et, dans le public, il était assez intéressant d’entendre les réactions de nos voisins lorsque Pascal racontait certaines anecdotes ou présentait certains concepts. Les problématiques que nous rencontrons dans nos métiers, nous sommes nombreux à les rencontrer, et c’est tout l’intérêt des événements comme AWS Summit : apprendre les uns des autres !&lt;/p&gt;

&lt;p&gt;Cette présentation n’a malheureusement pas été enregistrée lors du Summit, mais Pascal l’a redonnée depuis à MixIT, où elle a été enregistrée – et les vidéos devraient être bientôt publiées ;-)&lt;/p&gt;

&lt;h2 id=&quot;la-souveraineté-des-données-chez-aws&quot;&gt;La souveraineté des données chez AWS&lt;/h2&gt;

&lt;p&gt;Une des conférences portait sur les thèmes de la Souveraineté dans le Cloud AWS et du Règlement européen Général sur la Protection des Données (RGPD). Lors de cette présentation, Stephan Hadinger (Directeur de la Technologie chez AWS) a exposé le cadre de ce règlement et sa mise en application au sein de l’infrastructure AWS. C’est cette partie qui était, d’après nous, la plus intéressante, étant donnée sa dimension technique.&lt;/p&gt;

&lt;p&gt;RGPD est un regroupement de règles qui régissent et protègent les droits des résidents d’Union Européenne. Il porte sur le respect de la confidentialité et la protection des données personnelles. Toute entreprise exerçant dans l’UE y est soumise. Dans le cas présent, la RGPD couvre à la fois les clients AWS (comme Bedrock) et les utilisateurs finaux (comme les utilisateurs des services Bedrock).&lt;/p&gt;

&lt;p&gt;Chez AWS, la Souveraineté est synonyme d’autonomie stratégique et s’exprime de la façon suivante :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;la possession des données clients : tous les clients AWS ont le contrôle de leurs données et applications, et nous verrons comment ;&lt;/li&gt;
  &lt;li&gt;le choix de la localisation des données, via la possibilité d’héberger l’intégralité des données sur le territoire de son choix, en France par exemple ;&lt;/li&gt;
  &lt;li&gt;l’accès au meilleur de la technologie, qui favorise l’innovation ;&lt;/li&gt;
  &lt;li&gt;et la possibilité de changer de solution (pas de lock-in).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Les clients sont les seuls possesseurs de leurs données, ils en ont le contrôle total : AWS n’a aucun droit d’usage des données de leurs clients. De plus, AWS n’a pas accès aux données et ne déplace pas (géographiquement) les données de ses clients.&lt;/p&gt;

&lt;p&gt;L’implémentation technique de ces concepts repose, entre autres, sur le chiffrement systématique des données. AWS Nitro est une des briques d’architecture qui en est responsable pour les EC2 (depuis 2013 pour la partie réseau). Nitro permet le chiffrement de toute la chaîne de données (réseau, volumes de stockage) et comprend plusieurs composants :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Carte Nitro dédiée au échanges externes (réseau + accès aux EBS, stockage persistant)&lt;/li&gt;
  &lt;li&gt;Carte Nitro pour le stockage local (stockage temporaire attaché à l’hôte)&lt;/li&gt;
  &lt;li&gt;Hyperviseur Nitro (il s’agit d’un hyperviseur basé sur linux KVM, mais grandement modifié pour les besoins, pas de sshd, pas de systemd, pas de couche réseau)&lt;/li&gt;
  &lt;li&gt;Puce de sécurité Nitro (qui empêche le client d’avoir accès aux composants de l’hôte, procède à la mise à jour des firmwares des composants du serveur et gère le sécure boot afin de contrôler l’état des firmwares des composants avant de démarrer l’hôte).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-04-20-aws-summit-paris-2023/aws-summit-2023-nitro.jpg&quot; alt=&quot;AWS Nitro&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Au delà du chiffrement dont il est principalement question ici, Nitro permet aussi de grandement augmenter les performances des EC2 en limitant l’impact de l’hyperviseur sur le CPU utilisé par les clients. Dans le cas d’une virtualisation classique, toutes les tâches listées ci-dessus sont effectuées par le processeur lui-même, grignotant ainsi de la puissance des machines. Ici, Nitro permet de décharger le CPU de ces tâches en le rendant ainsi dédié aux EC2.&lt;/p&gt;

&lt;p&gt;AWS utilise aussi des solutions telles que Key Management Service (KMS) pour chiffrer les données de plus d’une centaine de ses services. Il s’agit là aussi d’un système de protection des données des utilisateurs : seul l’opérateur possédant la clé de chiffrement est capable de lire les données de ces services. 
Une version étendue de KMS est même disponible pour les clients les plus soucieux de la protection de leurs données : &lt;a href=&quot;https://docs.aws.amazon.com/kms/latest/developerguide/keystore-external.html&quot;&gt;External Key Stores&lt;/a&gt;. XKS est un dispositif physique pouvant être hébergé en dehors des locaux d’AWS. Il est même capable de se “défendre” contre les attaques physiques en procédant à l’effacement des clés lors d’une tentative d’intrusion physique. Il s’agit probablement de l’ultime implémentation de sécurité et de souveraineté chez AWS.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-04-20-aws-summit-paris-2023/aws-summit-2023-souverainete-donnees.jpg&quot; alt=&quot;AWS Summit 2023 - Souveraineté des données&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Tout au long de cette conférence, on a bien senti que le but d’AWS, afin de respecter les données de ses usagers, était de faire en sorte de ne pas pouvoir accéder aux données de ses clients.&lt;/p&gt;

&lt;h1 id=&quot;le-mot-de-la-fin&quot;&gt;Le mot de la fin&lt;/h1&gt;

&lt;p&gt;L’AWS Summit comportait plus d’une centaine de sessions et nous avons juste eu l’occasion d’effleurer le contenu proposé lors de cette journée.&lt;/p&gt;

&lt;p&gt;Nous avons commencé à &lt;a href=&quot;https://leanpub.com/6cloud&quot;&gt;migrer vers Le Cloud&lt;/a&gt; en 2018 et notre premier AWS Summit Paris était en 2019 – nous y avions d’ailleurs &lt;a href=&quot;https://www.youtube.com/watch?v=xLELSIEt2xA&amp;amp;list=PL2ime9SGTcqcJWATAbNDvSVsTQyMridf3&amp;amp;index=11&quot;&gt;déjà parlé de cette migration au cours d’un autre événement&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Depuis, que de chemin parcouru ! Cette année, nous pensions moins à Kubernetes, à DynamoDB ou aux optimisations de coûts, sur lesquels nous avons bien bossé depuis 2019. Notre attention était plus attirée vers des sujets que nous avons commencé à travailler plus récemment et où nous avons encore des challenges majeurs, comme les approches pleinement serverless ;-)&lt;/p&gt;</content><author><name>[&quot;p_martin&quot;, &quot;l_caillet&quot;, &quot;v_chabrier&quot;]</name></author><category term="kubernetes" /><category term="cloud" /><category term="devops" /><category term="opensource" /><category term="community" /><category term="conference" /><category term="aws" /><category term="summit" /><category term="paris" /><category term="2023" /><summary type="html">L’AWS Summit Paris 2023 s’est déroulé le 4 avril. C’était pour nous l’occasion de découvrir les dernières innovations au cœur des services AWS, comme la solution d’IA d’aide au développement nommée CodeWhisperer. De plus, Pascal Martin, Principal Engineer, y assistait aussi en tant que speaker pour partager notre expérience en conception et maintenance de Systèmes Distribués. En plus des deux points précédemment cités, nous verrons aussi comment eTF1 s’est préparé pour la Coupe du Monde de la FIFA 2022, ou de souveraineté et de son application chez AWS.</summary></entry><entry><title type="html">Bedrock au Kubernetes Community Days France 2023</title><link href="https://tech.bedrockstreaming.com/2023/04/03/kubernetes-community-days.html" rel="alternate" type="text/html" title="Bedrock au Kubernetes Community Days France 2023" /><published>2023-04-03T00:00:00+00:00</published><updated>2023-04-03T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/04/03/kubernetes-community-days</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/04/03/kubernetes-community-days.html">&lt;p&gt;La première édition de KCD (Kubernetes Community Days) en France s’est déroulée le 7 mars au Centre Pompidou et rassemblant près de 1000 participants pour une belle journée de conférences.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-kcd-france/centre-pompidou.png&quot; alt=&quot;&amp;quot;Accueil centre Pompidou&amp;quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;KCD a rassemblé les communautés tech françaises pour cette journée de partage d’expertise et de retours d’expérience autour de Kubernetes et des technologies Cloud Native et DevOps.&lt;/p&gt;

&lt;p&gt;Solomon Hykes, son acolyte Jérome Petazzoni et l’Éducation Nationale ont présenté la &lt;a href=&quot;https://www.youtube.com/watch?v=OKIehz7p4ug&quot; target=&quot;_blank&quot;&gt;keynote d’ouverture&lt;/a&gt;.
Cette première keynote a permis d’introduire le projet Santorin du Ministère de l’Éducation. C’est un système d’aide à la correction et à la notation pour lequel ils utilisent 3 clusters afin d’analyser 5 millions de copies.&lt;/p&gt;

&lt;center&gt;
  &lt;img alt=&quot;Solomon Hykes et Jérôme Petazzoni&quot; src=&quot;/images/posts/2023-kcd-france/keynote.png&quot; /&gt;
&lt;/center&gt;
&lt;center&gt;Solomon Hykes &amp;amp; Jérôme Petazzoni&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Des grands acteurs de la tech en France tels que Scaleway, OVHCloud, Shadow, eTF1, Back Market, vpTech, Doctolib, Deezer, Carrefour et l’Éducation Nationale étaient présents pour rapporter leurs expériences. 
Les trois salles nommées aux couleurs du drapeau français étaient disponibles tout au long de la journée pour accueillir la quarantaine de conférences organisées par KCD.&lt;/p&gt;

&lt;h3 id=&quot;la-plus-value-dun-portail-développeur-chez-back-market-&quot;&gt;La plus-value d’un portail développeur chez Back Market &lt;a name=&quot;BackMarket&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Conférence présentée par :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sami Farhat - Backend Engineer&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Back Market, entreprise française de commerce électronique, est venue nous parler de leur implémentation 
d’un “DevPortal” basé sur le projet &lt;a href=&quot;https://backstage.io/&quot; target=&quot;_blank&quot;&gt;Backstage.io&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-kcd-france/backmarket-devportal-1.jpg&quot; alt=&quot;&amp;quot;Backstage Main features&amp;quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;La création de ce portail développeur à été initié en 2021 suite au projet de mise à l’échelle et de passage en microservices de leur applications.&lt;/p&gt;

&lt;p&gt;Initialement, chaque nouveau service était créé manuellement et nécessitait du travail dans les équipes d’infrastructure.
En plus de demander du travail lors de leur création, les services n’étaient donc pas systématiquement créés avec les mêmes bases de codes et pouvaient différer dans leurs implémentation.&lt;/p&gt;

&lt;p&gt;Le but était donc d’obtenir une vue centralisée sur les projets et de permettre aux développeurs de créer de nouveaux services eux-mêmes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-kcd-france/backmarket-devportal-2.jpg&quot; alt=&quot;&amp;quot;Central Hub: Goal&amp;quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;La création de ce portail à également permis à Back Market d’initier l’utilisation d’un modèle pour la création de services, ainsi d’uniformiser les architectures et de faciliter le passage en microservices.&lt;/p&gt;

&lt;p&gt;Ils ont également implémenté une vue relationnelle concernant les projets et les équipes qui y sont associées.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-kcd-france/backmarket-devportal-3.jpg&quot; alt=&quot;&amp;quot;Entity Relationships Graph&amp;quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Enfin, pour trouver les projets prioritaires pour la migration en microservices, ils ont créé une vue nommée Coupling scores :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-kcd-france/backmarket-devportal-4.jpg&quot; alt=&quot;&amp;quot;Coupling scores dashboard&amp;quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;C’est une vue qui permet d’obtenir la liste des applications monolithiques avec le taux de couplage le plus élevé.&lt;/p&gt;

&lt;p&gt;Le replay de cette conférence est disponible &lt;a href=&quot;https://www.youtube.com/watch?v=2XghfHsbRtw&quot; target=&quot;_blank&quot;&gt;ici&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;vpc-dans-k8s--pas-aussi-simple-que-ça-en-a-lair-&quot;&gt;VPC dans k8s : Pas aussi simple que ça en a l’air &lt;a name=&quot;Scaleway&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Conférence présentée par :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Louis Portay - Ingénieur DevOps Kapsule Scaleway&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Au tour de Scaleway qui nous ont présenté comment ils ont implémenté les VPC privés dans le service Kaspule, leur Kubernetes managé.
C’est un besoin qui s’est présenté afin d’éviter que les échanges inter-noeuds transitent via le réseau public.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-kcd-france/scaleway-vpc-1.jpg&quot; alt=&quot;&amp;quot;Kaspule sans VPC privé&amp;quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Pour utiliser le réseau privé dans Kaspule, ils ont ajouté une interface nommée “kapsule0” sur les instances utilisées dans la création du cluster. Cette interface est ensuite attachée à &lt;a href=&quot;https://cilium.io/&quot; target=&quot;_blank&quot;&gt;Cilium&lt;/a&gt; dans le cluster.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-kcd-france/scaleway-vpc-2.jpg&quot; alt=&quot;&amp;quot;Kaspule avec VPC privé&amp;quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Cette fonctionnalité est actuellement en bêta, elle sera bientôt disponible de manière régionale.&lt;/p&gt;

&lt;p&gt;Parmi les implémentations futures, Scaleway prévoit de proposer la possibilité de retirer l’interface réseau publique afin que tous les échanges entre Kubelet et le Control Plane passent également via le réseau privé.&lt;/p&gt;

&lt;p&gt;Le replay de cette conférence est disponible &lt;a href=&quot;https://www.youtube.com/watch?v=FobnKozk2Z8&quot; target=&quot;_blank&quot;&gt;ici&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;kubernetes-the-not-so-hard-veepee-way-&quot;&gt;Kubernetes the not so hard Veepee way &lt;a name=&quot;Veepee&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Conférence présentée par :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Loïc Blot - Lead SRE Veepee&lt;/li&gt;
  &lt;li&gt;Mickaël Todorovic - Tribe Lead SRE Veepee&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Loïc et Mickaël de Veepee sont venus présenter l’évolution des infrastructures utilisées par l’entreprise.
Initialement, avant 2019, ils comptaient plus de 10 000 machines virtuelles dans leur parc.
Ces machines hébergaient les applications de Veepee via diverses technologies :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Swarm&lt;/li&gt;
  &lt;li&gt;Rancher&lt;/li&gt;
  &lt;li&gt;Hashicorp Nomad&lt;/li&gt;
  &lt;li&gt;Docker compose&lt;/li&gt;
  &lt;li&gt;LXC&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;En 2019, pour anticiper la gestion de la vente des tickets pour le concert de Céline Dion, ils ont choisi de migrer leurs services sur des clusters Kubernetes.
La première infrastructure était managée via Ansible, ils utilisaient Traefik et un cert manager home made.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-kcd-france/veepee-1.jpg&quot; alt=&quot;&amp;quot;Kubernetes deployment evolution&amp;quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Aujourd’hui, ils fournissent un produit Container as a Service nommé &lt;a href=&quot;https://medium.com/vptech/standardized-deployment-at-vptech-7ebf8b8c6a1b&quot; target=&quot;_blank&quot;&gt;Starfish&lt;/a&gt;. C’est un outil qu’ils ont écrit en Go et qui permet de gérer les applications des équipes Veepee. Ils utilisent également Gitlab et &lt;a href=&quot;https://argoproj.github.io/cd/&quot; target=&quot;_blank&quot;&gt;ArgoCD&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Le replay de cette conférence est disponible &lt;a href=&quot;https://www.youtube.com/watch?v=vD8bVD7-iZo&quot; target=&quot;_blank&quot;&gt;ici&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;La majorité de conférences auxquelles j’ai assisté étaient des retours d’expérience. C’était particulièrement intéressant car en plus de la présentation d’une technologie, nous avons un retour détaillé sur l’usage de cette dernière.&lt;/p&gt;

&lt;p&gt;Merci à tout les speakers pour leur partage de connaissances et aux organisateurs de KCD France.&lt;/p&gt;</content><author><name>Christian VAN DER ZWAARD</name></author><category term="kubernetes" /><category term="cloud" /><category term="devops" /><category term="opensource" /><category term="community" /><category term="conference" /><category term="rex" /><summary type="html">La première édition de KCD (Kubernetes Community Days) en France s’est déroulée le 7 mars au Centre Pompidou et rassemblant près de 1000 participants pour une belle journée de conférences.</summary></entry><entry><title type="html">Retour Conférence Vue Amsterdam 2023</title><link href="https://tech.bedrockstreaming.com/2023/03/31/retour-vue-amsterdam-2023.html" rel="alternate" type="text/html" title="Retour Conférence Vue Amsterdam 2023" /><published>2023-03-31T00:00:00+00:00</published><updated>2023-03-31T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/03/31/retour-vue-amsterdam-2023</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/03/31/retour-vue-amsterdam-2023.html">&lt;p&gt;C’est dans le Theater Amsterdam que se sont déroulés ces deux jours de VueJS Amsterdam, événement faisant partie de la JSWorld Conference, durant toute la semaine.&lt;/p&gt;

&lt;p&gt;De nombreux sponsors étaient là pour l’occasion, ainsi que des écoles comme VueMastery ou VueSchool (proposant une toute nouvelle certification Vue), et des partenaires plus connus comme Storyblok ou Nuxt Labs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-03-31-retour-vue-amsterdam-2023/bedrock-vue-amsterdam-2023-002.jpg&quot; alt=&quot;2023-03-31-retour-vue-amsterdam-2023&quot; /&gt;&lt;/p&gt;

&lt;p&gt;L’ambiance était au rendez-vous dès le début avec une conférence en musique, avec Tim Benniks guitare en main !&lt;/p&gt;

&lt;p&gt;Nous avons ensuite pu profiter de conférences aussi nombreuses que variées. De l’accessibilité à la gestion de l’interface en Vue du leader mondial du transport de marchandises &lt;a href=&quot;https://www.maersk.com/fr-fr/&quot;&gt;Maersk&lt;/a&gt;, en passant par les tests et le guide ultime pour publier un package NPM !&lt;/p&gt;

&lt;p&gt;Sans oublier la grande famille Nuxt qui était (presque) au complet !&lt;/p&gt;

&lt;p&gt;L’ensemble des conférences est visible sur &lt;a href=&quot;https://www.youtube.com/@JSWORLDConference&quot;&gt;la chaîne youtube du JSWorld Conference&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;state-of-vuenion&quot;&gt;State of Vuenion&lt;/h2&gt;

&lt;p&gt;Evan You (créateur de &lt;a href=&quot;https://vuejs.org/&quot;&gt;Vue&lt;/a&gt; et &lt;a href=&quot;https://vitejs.dev/&quot;&gt;Vite&lt;/a&gt;) a présenté un état des lieux et des dernières avancées de Vue, épaulé par Alex Kyriakidis (fondateur de &lt;a href=&quot;https://vueschool.io/&quot;&gt;VueSchool&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-03-31-retour-vue-amsterdam-2023/bedrock-vue-amsterdam-2023-003.jpg&quot; alt=&quot;2023-03-31-retour-vue-amsterdam-2023&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Commençant par un retour sur les nombreuses nouveautés de ces trois dernières années, pour les plus connues Vue 3, Vite, Vitest et Pinia, Evan a d’abord fait un focus sur la position de Vue 3 en tant que version par défaut depuis le 7 février 2022.&lt;/p&gt;

&lt;p&gt;Il a aussi évoqué les avancées relatives à Vue 2.7 (dont l’intégration de la Composition API, du v-bind CSS, etc.) permettant de rapprocher les expériences développeurs entre Vue 2 et Vue 3.&lt;/p&gt;

&lt;p&gt;Evan a ensuite présenté les derniers travaux sur la version core de Vue en version 3. Principalement orientés sur des améliorations concernant la facilité d’utilisation, l’accélération des tests (avec Vitest) ainsi que la vitesse de build (avec Rollup).&lt;/p&gt;

&lt;p&gt;Enfin, Evan a présenté les projets à venir pour le core. La disparition de la Reactivity Transform jugée trop risquée, l’amélioration du server side rendering et la création d’un “vapor mode”, une nouvelle manière de compiler les Single Files Components en optimisant l’utilisation d’un Virtual DOM. Ce dernier permet d’approcher la vitesse de compilation d’une application en JS vanilla, en gardant la puissance du framework !&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;📺 &lt;a href=&quot;https://www.youtube.com/watch?v=I5mGNB-4f0o&quot;&gt;Conférence sur Youtube&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;la-fin-de-vie-de-vue-2&quot;&gt;La fin de vie de Vue 2&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-03-31-retour-vue-amsterdam-2023/bedrock-vue-amsterdam-2023-end-of-vue2.JPG&quot; alt=&quot;2023-03-31-retour-vue-amsterdam-2023&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Après avoir présenté l’état de l’écosystème qui gravite autour de Vue et Vite lors de sa conférence “State of the Vuenion 2023”, Evan You a terminé en dévoilant la date de fin de vie de Vue 2 au 31 décembre 2023.&lt;/p&gt;

&lt;p&gt;Après cette date, la version arrêtera de recevoir des mises à jour ; il sera néanmoins possible de bénéficier de mise à jour payante, bien qu’il soit vivement conseillé de migrer vers la dernière version du framework.&lt;/p&gt;

&lt;p&gt;Une &lt;a href=&quot;https://v2.vuejs.org/lts/&quot;&gt;page dans la documentation&lt;/a&gt; a été mise en place, présentant les options qui s’offrent aux développeurs et aux organismes qui n’ont pas encore migré leurs applications.&lt;/p&gt;

&lt;h2 id=&quot;il-était-une-fois-histoire&quot;&gt;Il était une fois… Histoire&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-03-31-retour-vue-amsterdam-2023/bedrock-vue-amsterdam-2023-histoire.JPG&quot; alt=&quot;2023-03-31-retour-vue-amsterdam-2023&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Guillaume Chau, un des membres de l’équipe de développement de Vue, a présenté l’outil &lt;a href=&quot;https://histoire.dev/&quot;&gt;Histoire&lt;/a&gt; durant une petite demi-heure.&lt;/p&gt;

&lt;p&gt;L’outil est dans la même veine que Storybook. La plupart du temps, il sert à afficher et documenter des composants d’un design system en complète isolation.&lt;/p&gt;

&lt;p&gt;Contrairement à d’autres outils, Histoire est pensé pour s’intégrer parfaitement dans son environnement de développement, de façon à ce que l’écriture des “stories” s’apparente le plus possible à l’écriture et à l’utilisation native de composants Vue.&lt;/p&gt;

&lt;p&gt;Histoire utilise &lt;a href=&quot;https://vitejs.dev/&quot;&gt;Vite&lt;/a&gt; ce qui lui permet de s’intégrer dans un projet qui l’utilise déjà avec très peu de configurations supplémentaires.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;📺 &lt;a href=&quot;https://www.youtube.com/watch?v=Q8LeAg-9ngs&quot;&gt;Conférence sur Youtube&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;une-autre-histoire-de-migration-&quot;&gt;Une autre histoire de… migration !&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-03-31-retour-vue-amsterdam-2023/bedrock-vue-amsterdam-2023-migration-vue3.JPG&quot; alt=&quot;2023-03-31-retour-vue-amsterdam-2023&quot; /&gt;&lt;/p&gt;

&lt;p&gt;La société &lt;a href=&quot;https://www.maersk.com/fr-fr/&quot;&gt;Maersk&lt;/a&gt;, spécialiste dans la logistique des transports, nous a présenté son application destinée entre autres, à la gestion des conteneurs maritimes. Une occasion pour nous faire part de leur processus de migration de Vue 2 vers Vue 3 !&lt;/p&gt;

&lt;p&gt;Réalisant la même migration de version à &lt;a href=&quot;https://bedrockstreaming.com/&quot;&gt;Bedrock Streaming&lt;/a&gt; sur la partie backoffice, nous constatons que nous partageons beaucoup de similitudes !&lt;/p&gt;

&lt;p&gt;Vous trouverez un article dédié sur la migration Vue 2 vers Vue 3 à Bedrock en suivant ce &lt;a href=&quot;https://tech.bedrockstreaming.com/2023/03/25/de-node-js-10-a-node-js-18-nous-avons-rattrape-8-ans-de-retard-et-de-dette-technique-et-seule-une-approche-progressive-et-incrementale-etait-viable.html&quot;&gt;lien&lt;/a&gt; ! 🎉&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;📺 &lt;a href=&quot;https://www.youtube.com/watch?v=93KdAJ8sSjM&quot;&gt;Conférence sur Youtube&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;lets-build-a-virtual-dom&quot;&gt;“Let’s Build A Virtual DOM”&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-03-31-retour-vue-amsterdam-2023/bedrock-vue-amsterdam-2023-virtual-dom.jpg&quot; alt=&quot;2023-03-31-retour-vue-amsterdam-2023&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Certaines conférences étaient aussi l’occasion de rappeler des fondamentaux. Beaucoup de développeurs sont conscients que Vue utilise un système de DOM virtuel pour générer ses pages mais peu savent vraiment ce que cela signifie.&lt;/p&gt;

&lt;p&gt;La conférence de Marc Backes a permis de démystifier cela en développant sur scène un DOM virtuel simple à travers plusieurs cas pratiques.&lt;/p&gt;

&lt;p&gt;Ce dernier a d’ailleurs publié le code écrit sur son Github : https://github.com/themarcba/vue-vdom.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;📺 &lt;a href=&quot;https://www.youtube.com/watch?v=Pf-N8WGu7iQ&quot;&gt;Conférence sur Youtube&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;le-guide-complet-du-packaging-des-librairies&quot;&gt;Le guide complet du packaging des librairies&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-03-31-retour-vue-amsterdam-2023/bedrock-vue-amsterdam-2023-packaging.jpg&quot; alt=&quot;2023-03-31-retour-vue-amsterdam-2023&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Cette conférence était présentée par Bjorn Lu (core team member de Astro, Vite et Svelte), et expliquait comment créer un package d’une librairie et le publier “presque” sans peine.&lt;/p&gt;

&lt;p&gt;En prenant l’exemple d’une librairie extrêmement simple, proposant une fonction d’addition, Bjorn a parcouru les étapes de la création de ce package progressivement, en prenant en compte le fonctionnement d’ESModules, l’ajout du typage, puis le support de CommonJS pour les utilisations sur des anciennes versions de node et de l’export en parallèle des version ESM et CJS.&lt;/p&gt;

&lt;p&gt;Il présente ensuite les outils de build les plus courants ainsi que quelques outsiders, puis prend l’exemple de &lt;a href=&quot;https://github.com/egoist/tsup&quot;&gt;Tsup&lt;/a&gt; pour montrer une commande de build.&lt;/p&gt;

&lt;p&gt;Une solution intéressante pour typer utilisant JSDoc et simplifiant beaucoup les étapes du build completera sa conférence, 
pour enfin terminer par une série d’outils et de “do and don’t” très pratiques dont &lt;a href=&quot;https://publint.dev/&quot;&gt;publint.dev&lt;/a&gt; fait parti.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;📺 &lt;a href=&quot;https://www.youtube.com/watch?v=bzYFCDz817I&quot;&gt;Conférence sur Youtube&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-03-31-retour-vue-amsterdam-2023/bedrock-vue-amsterdam-2023-bedrock-team.JPG&quot; alt=&quot;2023-03-31-retour-vue-amsterdam-2023&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ce séjour à Amsterdam pour assister à cette conférence de deux jours a été enrichissant à bien des égards.
Non seulement la ville est belle et agréable à visiter, mais la découverte d’outils prometteurs répondant à nos besoins a également été un véritable apport pour notre entreprise.&lt;/p&gt;

&lt;h2 id=&quot;pour-en-découvrir-plus&quot;&gt;Pour en découvrir plus&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://vuejs.amsterdam/&quot;&gt;Site VueJS Amsterdam&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.facebook.com/media/set/?vanity=jsworldconf&amp;amp;set=a.687856240008465&quot;&gt;Gallerie photos&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/@JSWORLDConference/videos&quot;&gt;Replay des conférences sur Youtube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>[&quot;pl_perez&quot;, &quot;l_penaguin&quot;, &quot;c_berard&quot;]</name></author><category term="node" /><category term="Node" /><category term="vue" /><category term="vuex" /><category term="pinia" /><category term="vite" /><category term="Vitest" /><category term="TypeScript" /><category term="developer" /><category term="javascript" /><summary type="html">C’est dans le Theater Amsterdam que se sont déroulés ces deux jours de VueJS Amsterdam, événement faisant partie de la JSWorld Conference, durant toute la semaine.</summary></entry><entry><title type="html">De Node.js 10 à Node.js 18, nous avons rattrapé 8 ans de retard et de dette technique</title><link href="https://tech.bedrockstreaming.com/2023/03/25/de-node-js-10-a-node-js-18-nous-avons-rattrape-8-ans-de-retard-et-de-dette-technique-et-seule-une-approche-progressive-et-incrementale-etait-viable.html" rel="alternate" type="text/html" title="De Node.js 10 à Node.js 18, nous avons rattrapé 8 ans de retard et de dette technique" /><published>2023-03-25T00:00:00+00:00</published><updated>2023-03-25T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/03/25/de-node-js-10-a-node-js-18-nous-avons-rattrape-8-ans-de-retard-et-de-dette-technique-%E2%80%94-et-seule-une-approche-progressive-et-incrementale-etait-viable</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/03/25/de-node-js-10-a-node-js-18-nous-avons-rattrape-8-ans-de-retard-et-de-dette-technique-et-seule-une-approche-progressive-et-incrementale-etait-viable.html">&lt;p&gt;Difficile de faire évoluer des applications et améliorer une stack si l’ensemble est basé sur une version obsolète de Node.js… Dans cet article, nous verrons comment nous avons réussi à migrer vers une version récente et maintenue de Node.js grâce à une approche progressive et incrémentale.&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#contexte-général-et-fonctionnel&quot; id=&quot;markdown-toc-contexte-général-et-fonctionnel&quot;&gt;Contexte général et fonctionnel&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#contexte-technique&quot; id=&quot;markdown-toc-contexte-technique&quot;&gt;Contexte technique&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#objectif&quot; id=&quot;markdown-toc-objectif&quot;&gt;Objectif&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#une-première-stratégie-problématique--la-méthode-rhinocéros-&quot; id=&quot;markdown-toc-une-première-stratégie-problématique--la-méthode-rhinocéros-&quot;&gt;Une première stratégie problématique : la méthode “rhinocéros” 🦏&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#la-stratégie-gagnante--une-migration-progressive-&quot; id=&quot;markdown-toc-la-stratégie-gagnante--une-migration-progressive-&quot;&gt;La stratégie gagnante : une migration progressive 📶&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#motivation&quot; id=&quot;markdown-toc-motivation&quot;&gt;Motivation&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#plan-daction&quot; id=&quot;markdown-toc-plan-daction&quot;&gt;Plan d’action&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#difficultés-rencontrées&quot; id=&quot;markdown-toc-difficultés-rencontrées&quot;&gt;Difficultés rencontrées&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#non-découpage-des-étapes-de-migration&quot; id=&quot;markdown-toc-non-découpage-des-étapes-de-migration&quot;&gt;Non découpage des étapes de migration&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#méconnaissance-de-typescript&quot; id=&quot;markdown-toc-méconnaissance-de-typescript&quot;&gt;Méconnaissance de Typescript&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#suppression-précipitée-de-librairies-obsolètes&quot; id=&quot;markdown-toc-suppression-précipitée-de-librairies-obsolètes&quot;&gt;Suppression précipitée de librairies obsolètes&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#non-anticipation-de-la-complexité-liée-à-certaines-dépendances&quot; id=&quot;markdown-toc-non-anticipation-de-la-complexité-liée-à-certaines-dépendances&quot;&gt;Non anticipation de la complexité liée à certaines dépendances&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#entretien-des-applications-legacy-en-même-temps&quot; id=&quot;markdown-toc-entretien-des-applications-legacy-en-même-temps&quot;&gt;Entretien des applications legacy en même temps&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#autres-avantages&quot; id=&quot;markdown-toc-autres-avantages&quot;&gt;Autres avantages&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#uniformisation-des-technologies-au-sein-de-la-société&quot; id=&quot;markdown-toc-uniformisation-des-technologies-au-sein-de-la-société&quot;&gt;Uniformisation des technologies au sein de la société&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#attractivité-et-rétention-des-développeurs&quot; id=&quot;markdown-toc-attractivité-et-rétention-des-développeurs&quot;&gt;Attractivité et rétention des développeurs&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot; id=&quot;markdown-toc-conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;contexte-général-et-fonctionnel&quot;&gt;Contexte général et fonctionnel&lt;/h1&gt;

&lt;p&gt;Bedrock streaming est une co-entreprise (joint-venture) créée en 2020 par M6 Group et RTL Group, permettant à 7 diffuseurs et sociétés de médias dans 5 pays d’Europe de divertir 45 millions d’utilisateurs chaque jour, sur tous les écrans.&lt;/p&gt;

&lt;p&gt;Pour gérer tous leurs utilisateurs ainsi que leurs contenus, notamment vidéos, les clients de Bedrock Streaming accèdent chacun à une constellation d’applications au sein d’un back-office centralisé (appelé BO par la suite).&lt;/p&gt;

&lt;h1 id=&quot;contexte-technique&quot;&gt;Contexte technique&lt;/h1&gt;

&lt;p&gt;De part sa conception initiale, le BO est une application monorepo. Elle fournit (à elle-même donc), des données via une API Symfony 4 (PHP 7.4), consommées uniquement par :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;des applications Vue.js 1 et Vue.js 2 gérées par la team backend (qui historiquement maintient le frontend de quelques applications) ;&lt;/li&gt;
  &lt;li&gt;des applications Vue.js 2 gérées par la team frontend.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Le tout, dans un environnement &lt;a href=&quot;https://github.com/nodejs/Release/blob/main/schedule.json#L50&quot;&gt;Node.js 10&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;objectif&quot;&gt;Objectif&lt;/h1&gt;

&lt;p&gt;Node.js 10 est arrivé en fin de vie le 30 avril 2021. Il n’est donc plus maintenu, que ce soit en terme de fonctionnalités ou en terme de sécurité. Naturellement, toutes les dépendances JS migrent progressivement vers un support des versions de Node.js supérieures, et abandonnent le support de cette version 10 devenue obsolète.&lt;/p&gt;

&lt;p&gt;Il s’agit donc de migrer la version de Node.js vers une version supérieure, dans l’idéal LTS afin de se prémunir d’une obsolescence prématurée. Dans un premier temps, Node.js 12.&lt;/p&gt;

&lt;p&gt;Voici plusieurs raisons qui poussent à migrer Node.js :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Nouvelles fonctionnalités (e.g. nouvelle implémentation pour l’ES6 Module Support expérimental, source : &lt;a href=&quot;https://nodejs.medium.com/announcing-a-new-experimental-modules-1be8d2d6c2ff&quot;&gt;https://nodejs.medium.com/announcing-a-new-experimental-modules-1be8d2d6c2ff&lt;/a&gt; ) ;&lt;/li&gt;
  &lt;li&gt;Abandon de fonctionnalités défaillantes (e.g. via dépréciation) ;&lt;/li&gt;
  &lt;li&gt;Performance (e.g. mise à jour de V8 engine, source : &lt;a href=&quot;https://nodejs.medium.com/introducing-node-js-12-76c41a1b3f3f&quot;&gt;https://nodejs.medium.com/introducing-node-js-12-76c41a1b3f3f&lt;/a&gt; ) ;&lt;/li&gt;
  &lt;li&gt;Sécurité (e.g. mise à jour de TLS, source : &lt;a href=&quot;https://nodejs.medium.com/introducing-node-js-12-76c41a1b3f3f&quot;&gt;https://nodejs.medium.com/introducing-node-js-12-76c41a1b3f3f&lt;/a&gt; ) ;&lt;/li&gt;
  &lt;li&gt;Évolutions des dépendances externes. (e.g. Cypress qui abandonne les versions de Node.js non maintenues et qui requiert Node.js 14, 16 ou 18+, source : &lt;a href=&quot;https://docs.cypress.io/guides/references/changelog#12-0-0&quot;&gt;https://docs.cypress.io/guides/references/changelog#12-0-0&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;une-première-stratégie-problématique--la-méthode-rhinocéros-&quot;&gt;Une première stratégie problématique : la méthode “rhinocéros” 🦏&lt;/h1&gt;

&lt;p&gt;La décision a été prise de migrer le repository de Node.js 10 vers Node.js 12 en début d’année 2021.&lt;/p&gt;

&lt;p&gt;Empiriquement, cette méthode a montré plusieurs limites :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;même si la compilation semblait bien se dérouler, des erreurs apparaissaient au moment de l’affichage de l’UI ➡ Il semblait donc nécessaire de parcourir l’intégralité des écrans afin de déceler toutes les anomalies possibles ➡ Le travail de la QA était alors conséquent ;&lt;/li&gt;
  &lt;li&gt;même lorsqu’une anomalie est corrigée, une nouvelle peut apparaitre ➡ Il fallait re-parcourir les écrans concernés (par exemple, après avoir corrigé une anomalie qui empêche l’apparition d’une modale, de nouvelles anomalies peuvent être décelées au niveau des fonctionnalités que permet cette modale) ➡ Le travail de la QA augmentait de façon exponentielle au fil des corrections d’anomalies ;&lt;/li&gt;
  &lt;li&gt;des dizaines voire centaines de dépendances dans le projet étaient dépendantes de Node.js 10 sans être encore compatibles avec Node.js 12 ➡ Il s’agissait donc de faire le point sur celles-ci, pour trouver des équivalents compatibles.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Après plusieurs mois, bien que bon nombre d’anomalies avaient pu être corrigées, la situation stagnait et la fin ne semblait pas plus proche qu’au début.&lt;/p&gt;

&lt;p&gt;Les raisons de l’échec :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;L’ancienneté de certaines applications. Certaines d’entre elles avaient plus de 8 ans d’existence. En n’ayant subi que quelques corrections seulement. Les connaissances fonctionnelles et techniques s’étaient donc estompées naturellement, en raison d’une absence de documentation (autant fonctionnelle que technique). Il s’agit là des dettes fonctionnelle et technique. Lorsqu’elles sont là, elles sont relativement simples à identifier. Mais c’est déjà trop tard… ;&lt;/li&gt;
  &lt;li&gt;L’absence de mise à jour des technologies. Certaines technologies devenues obsolètes (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jQuery 1.9&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vue.js 1&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Bootstrap 2.3&lt;/code&gt;) imposait non plus un refactor lié à une migration, mais une véritable refonte ;&lt;/li&gt;
  &lt;li&gt;L’absence de tests. La couverture de tests était alors faible voire nulle. Migrer sans régression relevait alors d’une chance non maitrisable ;&lt;/li&gt;
  &lt;li&gt;La façon dont la migration a été lancée était trop téméraire : c’est la méthode rhinocéros.
    &lt;ul&gt;
      &lt;li&gt;création d’une nouvelle branche (et d’une PR pour cette branche)&lt;/li&gt;
      &lt;li&gt;suppression de Node.js 10 et installation de Node.js 12&lt;/li&gt;
      &lt;li&gt;correction de toutes les anomalies qui apparaissent !&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ce fonctionnement peut marcher pour des périmètres techniques plus petits ou du moins dont les contours sont précisément marqués ;&lt;/p&gt;

&lt;p&gt;L’organisation en équipe devenait compliquée. Au fur et à mesure des découvertes des anomalies au sein d’une seule et unique PR, il devenait difficile de suivre tous les sujets, sans découpage précis et rigoureux.&lt;/p&gt;

&lt;p&gt;Face à cette situation, dont les développeurs et testeurs ne semblaient plus voir le bout, il a été décidé d’employer une autre stratégie.&lt;/p&gt;

&lt;h1 id=&quot;la-stratégie-gagnante--une-migration-progressive-&quot;&gt;La stratégie gagnante : une migration progressive 📶&lt;/h1&gt;

&lt;p&gt;De part un essoufflement des développeurs et une nouvelle énergie insufflée par des départs et arrivées dans l’équipe, une nouvelle stratégie a émergé. Face à l’échec de la première, il a été proposé plus simplement de partir sur des bases saines, afin de migrer les applications sur des fondations plus solides car maitrisées.&lt;/p&gt;

&lt;p&gt;Plus techniquement, cela s’est traduit par :&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Création d’un nouveau répertoire &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;modern-apps/&lt;/code&gt; dans le monorepo.&lt;/li&gt;
  &lt;li&gt;Mise en place d’une architecture basée sur Node.js 16 (Oui oui, Node.js 16 directement ! Il s’agissait de la version LTS en cours en date de début 2022.) dans ce répertoire seulement.&lt;/li&gt;
  &lt;li&gt;Migration des applications du BO, une par une, vers une stack plus moderne. En date de début 2023, cette migration est toujours en cours.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;La motivation était principalement portée par :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;une volonté forte d’abandonner des outils et technologies vieillissantes voire obsolètes ;&lt;/li&gt;
  &lt;li&gt;une pression engendrée par l’évolution rapide des technologies :
    &lt;ul&gt;
      &lt;li&gt;Node.js sort une version LTS tous les ans ;&lt;/li&gt;
      &lt;li&gt;Vue.js 3 venait de sortir et l’effort des développeurs du framework allait se porter plutôt sur cette version que sur la version 2.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;une pression engendrée par les autres équipes de la société qui, elles, étaient à jour (pour certaines), dont celle qui proposait des outils JS et TS dont l’équipe pourrait avoir l’usage, comme par exemple une librairie de configuration pour &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;eslint&lt;/code&gt; couplé à &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vue&lt;/code&gt; ;&lt;/li&gt;
  &lt;li&gt;une excitation liée à l’utilisation d’une stack récente et de &lt;em&gt;cutting-edge tools&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;plan-daction&quot;&gt;Plan d’action&lt;/h2&gt;

&lt;p&gt;Cette page blanche a nécessité un plan d’action que voici :&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Création d’une application simplissime en guise de PoC, afin de montrer la viabilité d’un travail sous Node.js 16 dans une sous-partie du projet en parallèle d’un travail toujours actif sous Node.js 10 dans le reste du projet.&lt;/li&gt;
  &lt;li&gt;Mise en place d’une certaines DX vis-à-vis des linters et formatters notamment (ainsi que d’extensions d’IDE), par l’application de règles simples mais strictes, qui évitent aux développeurs les tâches sans plus-value, comme ajuster manuellement l’indentation ou ajouter les points-virgules.&lt;/li&gt;
  &lt;li&gt;Migration des librairies internes au monorepo.&lt;/li&gt;
  &lt;li&gt;Migration du design system, ainsi que des outils afférents (Storybook).&lt;/li&gt;
  &lt;li&gt;Migration d’une première application, la plus simple possible. L’objectif était alors de se rendre compte très concrètement des étapes de migration d’une application, afin d’en tirer une documentation exploitable pour les futures applications. Il en est ressorti que la majeure partie du travail consistait à refactor le code avec les nouvelles technologies choisies, en l’occurrence :
    &lt;ol&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vue.js 3&lt;/code&gt; et sa &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Composition API&lt;/code&gt; (framework JS),&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vite&lt;/code&gt; (serveur de dev et de build),&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Pinia&lt;/code&gt; (global state management),&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vitest&lt;/code&gt; (framework de test unitaire),&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Cypress&lt;/code&gt; dans ses dernières versions (framework de test end-to-end)&lt;/li&gt;
      &lt;li&gt;aussi et surtout &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Typescript&lt;/code&gt; (langage de programmation, sur-couche à JS).&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Migration du processus de build et d’intégration aux templates backend (via notamment une extension Twig implémentée par nos soins, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ViteAppExtension.php&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;Mise en place d’une CI pour ces nouvelles applications, calquée sur celle des anciennes applications : linting, tests pour celles qui en avaient, déploiement en preview, etc.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;En quelques mois seulement, il a été possible d’obtenir un résultat concret. Le répertoire &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;modern-apps/&lt;/code&gt; a été initié en février 2022, et dès avril de la même année, une première application migrée était livrée en production. Et cela, avec un seul développeur à plein temps sur le sujet.&lt;/p&gt;

&lt;h1 id=&quot;difficultés-rencontrées&quot;&gt;Difficultés rencontrées&lt;/h1&gt;

&lt;p&gt;Cette seconde stratégie n’a bien sûr pas été sans encombre. Voici les principales difficultés rencontrées, dont l’équipe a su se prémunir au fil du temps.&lt;/p&gt;

&lt;h2 id=&quot;non-découpage-des-étapes-de-migration&quot;&gt;Non découpage des étapes de migration&lt;/h2&gt;

&lt;p&gt;Lors de la migration d’une des premières applications dont la complexité était légèrement supérieure aux précédentes, nous nous sommes retrouvés embourbés dans une multitude de bugs techniques et fonctionnels. En effet, migrer implique plusieurs changements qui n’ont pas nécessairement de rapport les uns avec les autres :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ajouter des types TS&lt;/li&gt;
  &lt;li&gt;migrer la librairie de Global State Management de &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vuex&lt;/code&gt; vers &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pinia&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;migrer la Global API de Vue (de &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;new Vue()&lt;/code&gt; vers &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;createApp()&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;migrer de l’&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Options API&lt;/code&gt; vers la &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Composition API&lt;/code&gt; de Vue&lt;/li&gt;
  &lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Si tous ces changements sont opérés en même temps, comment réagir lors de l’apparition d’une anomalie ? Comment traquer efficacement cette anomalie ?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Solution adoptée&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Nous avons décidé de découper plus finement nos développements. Une PR doit concerner un périmètre réduit et bien défini. Par exemple, la PR de migration de la librairie de Global State Management ne doit comporter que des modifications à ce sujet, et doit fournir une application fonctionnelle dont les tests passent.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;méconnaissance-de-typescript&quot;&gt;Méconnaissance de Typescript&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;TypeScript is a strongly typed programming language that builds on JavaScript, giving you better tooling at any scale.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Source : &lt;a href=&quot;https://www.typescriptlang.org/&quot;&gt;https://www.typescriptlang.org/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Ce langage de programmation, bien que son adoption parmi les développeurs JS explose, s’est avéré une complète nouveauté dans l’équipe. Il peut être tentant d’écrire des &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;any&lt;/code&gt; partout, ou de supprimer le &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;strict mode&lt;/code&gt;…&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Solution adoptée&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Nous avons décidé d’intégrer TS progressivement sans se mettre trop de pression quant à l’intégralité du typage de nos applications. Typescript permet justement cette intégration progressive aux projets.&lt;/p&gt;

  &lt;p&gt;Un très gros progrès a aussi été réalisé grâce à la génération automatique des types TS à partir de l’API (grâce à l’&lt;em&gt;introspection system&lt;/em&gt; de GraphQL). Les données reçues du backend se voyaient alors avoir une structure directement exploitable dans le frontend.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;suppression-précipitée-de-librairies-obsolètes&quot;&gt;Suppression précipitée de librairies obsolètes&lt;/h2&gt;

&lt;p&gt;Lors du découpage des étapes de migration, une problématique est apparue. Par exemple, si nous souhaitons migrer de &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vuex&lt;/code&gt; vers &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pinia&lt;/code&gt; dans un second temps, comment faire pour que l’application reste fonctionnelle avec &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vuex&lt;/code&gt; dans le premier temps ?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Solution adoptée&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Nous avons décidé de conserver certaines librairies, le temps de la migration des applications. Il peut être tentant de vouloir supprimer immédiatement ce qui nous semble obsolète, mais ces éléments ne seront vraiment obsolètes que lorsque toutes les applications seront migrées ; mais pas le temps qu’elles le soient.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;non-anticipation-de-la-complexité-liée-à-certaines-dépendances&quot;&gt;Non anticipation de la complexité liée à certaines dépendances&lt;/h2&gt;

&lt;p&gt;Bien que cet aspect n’était pas une surprise, certaines librairies ont apporté plus de difficultés que d’autres lors de la migration. Par exemple, l’intégration de Vue 3 et la Composition API impliquait la montée de version de &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vee-validate&lt;/code&gt;, un librairie de validation de formulaire. Il s’est avéré que l’implémentation imposée était radicalement différente de la version précédente (compatible avec Vue 2 et l’Options API), moins intuitive et plus complexe.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Solution adoptée&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Ce cas de figure n’est pas vraiment impressionnant car nous nous y attendions. Nous avons décidé dans un premier temps d’effectuer une certaine veille technique, afin de remettre en cause le choix initial de cette librairie. Il s’est avéré que nous l’avons conservée, ce qui amenait dans un second temps une montée en compétence quant à l’utilisation de celle-ci, en vue de son intégration.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;entretien-des-applications-legacy-en-même-temps&quot;&gt;Entretien des applications legacy en même temps&lt;/h2&gt;

&lt;p&gt;Une application donnée pouvait se retrouver d’une part en cours de migration, et d’autre part devoir recevoir une évolution ou une correction d’anomalie.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Solution adoptée&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Le choix et l’ordre des applications à migrer a été choisi en fonction des priorités en cours. Nous avons choisi de migrer en premier les applications qui ne subissaient que très peu de modifications. Par la suite, et encore aujourd’hui, nous livrons en production rapidement chaque application migrée, afin de ne pas avoir à maintenir plusieurs versions en même temps (la version legacy étant tout de même conservée le temps de s’assurer que la version moderne tourne correctement en production auprès des clients). Dans les très rares cas où une application en cours de migration devait recevoir une évolution ou une correction d’anomalie, nous la traitions dans les 2 versions.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;autres-avantages&quot;&gt;Autres avantages&lt;/h1&gt;

&lt;h2 id=&quot;uniformisation-des-technologies-au-sein-de-la-société&quot;&gt;Uniformisation des technologies au sein de la société&lt;/h2&gt;

&lt;p&gt;Au sein de Bedrock, le back-office n’est pas la seule application. Il existe aussi des applications frontend sur les mêmes technologies pour adresser l’écran web ou les télévisions connectées. Bien que le framework utilisé pour celles-ci soit React.js et non Vue.js, l’outillage peut être uniformisé entre les projets et les équipes. La migration a permis de préparer le terrain pour mettre en place ces outils : TypeScript, PNPM, etc.&lt;/p&gt;

&lt;h2 id=&quot;attractivité-et-rétention-des-développeurs&quot;&gt;Attractivité et rétention des développeurs&lt;/h2&gt;

&lt;p&gt;Cette migration générale permet de mettre en place une stack résolument plus moderne et d’utiliser des outils et technologies plus récents. N’est-ce pas là un argument fort pour attirer des nouveaux développeurs et retenir ceux déjà en place ? Dans l’équipe, plusieurs personnes ont émis des doutes sur leur volonté de rester dans la société si la décision de migrer, et donc d’intégrer des technologies plus à jour, n’avait pas été prise. En date de début 2023, il fait peu de doutes que les projets en Vue 3 sont plus attractifs que les projets en Vue 2…&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;En fin de compte, cette approche progressive et incrémentale, toujours en cours, permet de maintenir dans un répertoire bien défini une stack récente dont les mises à jour sont simples car petites. Par exemple, nous avons récemment migré de Node.js 16 vers Node.js 18… en quelques jours !&lt;/p&gt;

&lt;p&gt;Cette grande aventure, toujours en cours, nous a permis de vraiment prendre conscience qu’il faut entretenir certes les applications mais aussi les versions des frameworks et outils ! Utiliser un nouvel outil ou une nouvelle technologie est un choix fort qu’il faut être capable d’assumer dans le temps.&lt;/p&gt;

&lt;p&gt;Il peut paraitre frustrant d’entretenir des outils, sans gagner en performance ni en productivité mais seulement pour ne pas devenir obsolète. Mettre l’accent sur ces points, tout en sachant bien jauger jusqu’où doivent aller ces upgrades, est la marque d’un certain professionnalisme.&lt;/p&gt;

&lt;p&gt;Il est vrai que dans l’immédiat, la valeur ajoutée pour le client est modérée : les gains restent très techniques, notamment en termes de stabilité et de performances. Ce n’est que plus tard que les gains se feront concrètement sentir : plus d’efficacité et de productivité pour les évolutions, et plus de fiabilité.&lt;/p&gt;

&lt;p&gt;Il est aussi important de savoir reconnaitre qu’une technologie utilisée (parfois avec fierté à ses débuts) est devenue obsolète, et qu’il faut s’en débarrasser pendant qu’il est encore temps.&lt;/p&gt;</content><author><name>Timothé Crespy</name></author><category term="node" /><category term="Node.js" /><category term="vue" /><category term="Vue.js" /><category term="vuex" /><category term="pinia" /><category term="vite" /><category term="Vite.js" /><category term="Vitest" /><category term="TypeScript" /><category term="developer retention" /><category term="migration" /><summary type="html">Difficile de faire évoluer des applications et améliorer une stack si l’ensemble est basé sur une version obsolète de Node.js… Dans cet article, nous verrons comment nous avons réussi à migrer vers une version récente et maintenue de Node.js grâce à une approche progressive et incrémentale.</summary></entry><entry><title type="html">La gamification contre le legacy</title><link href="https://tech.bedrockstreaming.com/2023/03/20/La-gamification-contre-le-legacy.html" rel="alternate" type="text/html" title="La gamification contre le legacy" /><published>2023-03-20T00:00:00+00:00</published><updated>2023-03-20T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/03/20/La-gamification-contre-le-legacy</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/03/20/La-gamification-contre-le-legacy.html">&lt;h2 id=&quot;ce-que-vous-ne-voulez-pas-voir-dans-vos-backlogs&quot;&gt;Ce que vous ne voulez pas voir dans vos backlogs…&lt;/h2&gt;

&lt;p&gt;Elles sont là, tapies dans l’ombre de la colonne “To do” de vos backlogs, attendant que leur heure vienne. À chaque &lt;a href=&quot;https://blog.myagilepartner.fr/index.php/2017/01/17/la-product-backlog-refinement/&quot;&gt;backlog refinement&lt;/a&gt;, vous vous demandez s’il ne faut pas tout simplement les annuler, puisque personne ne les prend en charge… De quoi parle-t-on ? De ces user stories qui existent dans le backlog de chaque équipe technique, pour traiter “un jour” un sujet legacy. Ces petits aides-mémoire de sujets “à ne pas oublier” qui nous poursuivent mais ne sont que peu souvent traités, faute de priorisation.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;Un exemple de backlog legacy&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/Article-Target.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;Un exemple de backlog legacy&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Clean de code mort, montées de versions de layers Terraform, projets de refactoring jamais débutés… autant de sujets pénibles à traiter qui nécessitent du temps… et de la résilience. Parce que bien souvent, débuter l’un de ces sujets revient à s’attaquer à toutes les dépendances liées, à gérer tous les impacts. Et parce qu’il s’agit aussi de tâches redondantes, non-automatisables, n’apportant quasiment aucune valeur business immédiatement mesurable.. Du “run”, pur et simple. Dans le Slack de Bedrock, il y a un emoji tout trouvé pour ce type de tâche : &lt;img alt=&quot;Gif exprimant la souffrance&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/souffrir.gif&quot; height=&quot;30&quot; width=&quot;30&quot; style=&quot;padding: 0&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Bien sûr, on parvient parfois à dégager du temps pour s’atteler à ces user stories. Mais il faut souvent plus d’un sprint pour en venir à bout, et l’équipe en charge de leur réalisation peut rapidement se décourager devant l’ampleur et le caractère répétitif de la tâche.&lt;/p&gt;

&lt;p&gt;Nos équipes Ops et DevOps sont responsables de 23 repositories Terraform. Lorsqu’il a été nécessaire d’upgrader tous nos layers en version 1.x, nous nous sommes d’abord donné pour consigne que chaque personne qui tombait sur un layer obsolète devait le mettre à jour avant de poursuivre son travail. Oui mais voilà, mettre à jour un layer ça ne se fait pas en deux minutes, et bien souvent on refuse d’abandonner ce sur quoi on travaillait jusqu’alors pour mettre à jour sa version de Terraform. La consigne a alors évolué : pour chaque layer à mettre à jour, on créé une US en colonne “to do”… Vous voyez où l’on veut en venir ? 😏&lt;/p&gt;

&lt;p&gt;Pour tenter de venir à bout de ces sujets legacy que l’on traîne comme des boulets, nous avons mis en place depuis octobre 2022 les “Jeudis du fun”, dont l’organisation est prise en charge par la facilitatrice agile et la Project Manager Officer (PMO) du service Infrastructure (autrices de cet article).&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;Logo de la 1ère édition du “jeudi du fun”&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/Article-logo.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;Logo de la 1ère édition du “jeudi du fun”&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;éradiquer-en-gamifiant-challengeant-sentraidant&quot;&gt;Éradiquer en gamifiant, challengeant, s’entraidant.&lt;/h2&gt;

&lt;p&gt;L’idée est simple : faire travailler ensemble, sur une journée, les cinq équipes de la verticale (trois équipes de SysAdmins et deux équipes DevOps) pour faire avancer un sujet legacy. Au cours de cette journée, les profils et les membres d’équipe seront mixés, afin de ne pas travailler avec les mêmes collègues qu’au quotidien. Leads, principal engineer, seniors et juniors : tout le monde participe à la corvée !&lt;/p&gt;

&lt;p&gt;Il est difficile de convoquer 25 personnes sur une journée en leur disant que la journée est banalisée pour traiter des tâches pénibles. Elles viendraient à reculons. Deux axes ont été choisis pour faire de ces journées des journées “particulières” :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Gamifier&lt;/strong&gt; certains moments clés de la journée : la découverte du sujet, la composition des équipes, la remise en jambe du début d’après-midi…&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Challenger&lt;/strong&gt; les participants pour ne pas simplement leur demander de traiter du legacy, mais bien d’être la &lt;em&gt;meilleure&lt;/em&gt; équipe pour traiter du legacy. Celle qui ira le plus loin, qui en fera le plus.&lt;/li&gt;
  &lt;li&gt;(Un troisième axe, plus convivial, est choisi pour la fin de journée : partager un verre tous ensemble.)&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img alt=&quot;Le jeu de découverte du sujet de la 3ème édition : Ansible&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/Article-jeu.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;Le jeu de découverte du sujet de la 3ème édition : Ansible&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Lors de la 1ère édition, en octobre 2022, nous avons proposé aux équipes un grand thème : le repository “SysAdmin/Terraform”, centre névralgique du travail de l’Infra. Il y a beaucoup à faire : les fameux upgrades de layers, du refactoring de code pour industrialiser nos process, des PRs ouvertes et restées en suspens depuis de nombreux mois… chacun peut y trouver son compte. Chacune des six équipes composées ce jour-là disposait de dix minutes pour définir à quel chantier elle s’attaquerait durant la journée. A l’issue de ces dix minutes, le représentant de l’équipe devait présenter aux autres le sujet choisi et l’indicateur qui permettrait de juger si le travail a été accompli ou non, en fin de journée. L’équipe ayant proposé le sujet le plus ambitieux s’est vue attribuer des points bonus, rentrant en compte pour le calcul du score final.&lt;/p&gt;

&lt;p&gt;Pour la seconde édition le mois suivant, le sujet était imposé : toutes les équipes avaient pour objectif de mieux sécuriser les secrets contenus dans le code Bedrock. L’équipe qui en traiterait le plus grand nombre l’emporterait.&lt;/p&gt;

&lt;p&gt;Lors de la dernière édition, en février dernier, la compétition reposait également sur le nombre de points gagnés par chaque équipe en fin de journée. Nous avons attribué un nombre de points à chaque tâche pouvant être traitée dans la journée, en fonction de sa complexité et/ou de sa priorité. Chaque équipe pouvait s’organiser librement : choisir plusieurs petites tâches ou deux plus importantes…&lt;/p&gt;

&lt;p&gt;Bien sûr, pour que la compétition soit totale, chaque édition du jeudi du fun se termine par une remise de prix : distribution de goodies, de cartes “bonus” ou “malus” valables dans nos “vrais” sprints, de gourmandises… il faut que la récompense soit réelle pour que les participants se prennent au jeu.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;Exemple de lot pouvant être remporté lors du “Jeudi du fun”&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/Article-carte.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;Exemple de lot pouvant être remporté lors du “Jeudi du fun”&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Le risque avec la compétition, c’est de se laisser déborder : gagner coûte que coûte, ajouter des points à son compteur en faisant du “quick &amp;amp; dirty”. Jusqu’à présent, la compétition dans la verticale Infra est restée bon enfant : les équipes se défient entre elles tout au long de la journée, des points “bonus” sont réclamés aux organisatrices au moindre prétexte… mais personne ne perd de vue l’objectif principal : venir à bout du sujet.&lt;/p&gt;

&lt;p&gt;Les Jeudis du Fun reposent donc sur le challenge et le jeu. Mais nous avions sous-estimé un autre axe nous permettant de faire de ces journées un succès : l’entraide. A chaque édition, les retours les plus enthousiastes portent sur le fait de passer une journée à travailler en cross-team. SysAdmins et DevOps apprennent les uns des autres, les juniors ont l’occasion de former des leads… et chacun élargit son spectre de compétences. Au-delà du fait de venir à bout de sujets legacy, l’émulation engendrée par ces journées justifie à elle-seule leur organisation.&lt;/p&gt;

&lt;p&gt;Et puis, quitte à faire des jeudis du fun des journées particulières, autant y aller franchement : certains membres de nos équipes n’hésitent pas à venir déguisés pour ajouter une dose de fun. Vous avez croisé une licorne, Pikachu ou un plombier dans l’open space de Bedrock ? Aucun doute, c’était un jeudi ! Un dress code a même été défini lors de l’édition de février 2023.&lt;/p&gt;

&lt;h2 id=&quot;itérer-et-corriger-nos-erreurs-à-chaque-édition&quot;&gt;Itérer, et corriger nos erreurs à chaque édition&lt;/h2&gt;

&lt;p&gt;Trois éditions du “jeudi du fun” ont été organisées jusqu’à présent. À la fin de chaque édition, les organisatrices recueillent le feed-back des participantes et participants, afin de corriger ce qui doit l’être et de capitaliser sur ce qui a marché. Voici le premier bilan que nous pouvons en tirer.&lt;/p&gt;

&lt;h3 id=&quot;de-limportance-du-choix-du-sujet&quot;&gt;&lt;em&gt;De l’importance du choix du sujet&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Le succès de la journée repose sur le choix du sujet. En choisissant un sujet fédérateur, comme lors de notre première édition, et en laissant le soin à chaque équipe de définir quel chantier elle souhaitait mener, nous partions gagnantes. Le repo Sysadmin/Terraform sur lequel nous avons travaillé lors de cette journée est un point de douleur pour l’ensemble de nos équipes : chacun des participants a compris l’intérêt de jouer le jeu et de retrousser ses manches. Les équipes ont même eu du mal à clôturer la journée, car elles voulaient finir ce qu’elles avaient commencé.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;Au cours de la 1ère journée du “Jeudi du fun”&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/Article-slack.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;Au cours de la 1ère journée du “Jeudi du fun”&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Lors de la seconde édition en revanche, le sujet de cette édition a mis la journée en péril. Nous avions demandé aux équipes d’ajouter un niveau de sécurité à l’ensemble des secrets contenus dans la codebase de Bedrock. Cela a suscité quelques difficultés :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Tout d’abord, il s’agissait de trouver une méthode pour identifier tous les secrets concernés. Toutes les équipes du jeudi du fun ont alors planché sur ce sujet, en utilisant des méthodes et outils différents. Au final, nous ne sommes parvenus que tardivement (2h après le lancement de la journée) à nous mettre d’accord sur une méthodologie. Autant de temps perdu que nous aurions pu consacrer au cœur du sujet, la sécurisation des secrets.&lt;/li&gt;
  &lt;li&gt;En nous attaquant à l’ensemble des secrets de Bedrock, nous touchions forcément à des repositories projets dont nous ne sommes pas les &lt;em&gt;code owners.&lt;/em&gt; Ce n’est pas une véritable difficulté en soi, puisqu’au quotidien, nous intervenons fréquemment dans ces repos projets pour accompagner les équipes devs. En revanche, l’ajout d’un niveau de sécurité supplémentaire sur des secrets implique de pouvoir tester, puis de merger nos modifications. Impossible de réaliser ces actions sans les équipes back et front responsables des projets, ou sans impacter leur travail. Notre périmètre d’intervention lors de cette journée à été considérablement limité.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;La complexité du sujet et le constat de notre incapacité à avancer lors de cette journée ont rapidement conduit à un découragement des troupes. Nous sommes tout de même ressortis de cette édition avec des points positifs :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Une meilleure visibilité sur le périmètre de sécurisation à couvrir, en définissant le nombre de secrets concernés,&lt;/li&gt;
  &lt;li&gt;Un workflow visant à détecter à l’avenir tout nouveau secret concerné&lt;/li&gt;
  &lt;li&gt;… et la nécessité de mieux définir les guidelines pour le choix du sujet !&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;entendu-pendant-la-2nde-édition-du-jeudi-du-fun-&quot;&gt;Entendu pendant la 2nde édition du jeudi du fun 😅&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;👧🏻 : “Alors, qu’est-ce que tu fais de beau ?”&lt;/p&gt;

  &lt;p&gt;👦 : “Je souffre”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ces guidelines nous ont aidé à définir le choix de la thématique de la 3ème édition du jeudi du fun. Le sujet devait répondre à ces critères :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Être réalisable en une journée,&lt;/li&gt;
  &lt;li&gt;Permettre de terminer / accélérer un projet ou d’éradiquer du legacy,&lt;/li&gt;
  &lt;li&gt;Être dans le périmètre dont l’infra est le code owner,&lt;/li&gt;
  &lt;li&gt;Et être “morcelable” en sous-périmètres, un pour chaque équipe.&lt;/li&gt;
  &lt;li&gt;Enfin, l’avancée du sujet doit être mesurable.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Pour l’édition de février 2023, nous avons donc “joué” avec la migration Ansible en cours de réalisation dans l’une de nos équipes de SysAdmins. 45 rôles Ansible restaient à migrer vers notre nouveau template Ansible, utilisé pour déployer nos machines on-prem : il y a du travail pour tout le monde, c’est parti !&lt;/p&gt;

&lt;h3 id=&quot;et-finalement-est-ce-que-ça-marche-&quot;&gt;Et finalement, est-ce que ça marche ?&lt;/h3&gt;

&lt;p&gt;Après trois éditions, il nous semble nécessaire de prendre un peu de recul pour analyser si ces journées portent leur fruit. Les équipes sont ravies de travailler ensemble, certes, mais l’objectif principal est-il rempli ? Les jeudis du fun permettent-ils de venir à bout de sujets legacy ?&lt;/p&gt;

&lt;p&gt;La première édition a fortement contribué à éradiquer du legacy : nous avons mis à jour la quasi-totalité des layers Terraform, nous avons mergé ou fermé l’entièreté des PRs, et nous avons initié des travaux de rework. Cependant, nous n’avions pas défini d’indicateurs de réussite assez fiables lors de cette première itération pour quantifier réellement le travail accompli. Si toute la Verticale partage le sentiment d’avoir avancé lors de cette journée, nous ne savons pas le mesurer finement.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;Capture d’écran du repo sysadmin/terraform au cours de la 1ère édition du “Jeudi du fun”&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/Article-git.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;Capture d’écran du repo sysadmin/terraform au cours de la 1ère édition du “Jeudi du fun”&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Pour pallier cette difficulté, nous avions défini un indicateur de suivi très simple pour la seconde édition du jeudi du fun : nombre de secrets à traiter / nombre de secrets traités. Ainsi, nous savons que, lors de cette (difficile) journée, nous avons traité environ un quart du périmètre.&lt;/p&gt;

&lt;p&gt;Au lancement de la 3ème édition du jeudi du fun, nous avions 45 rôles à migrer vers notre nouveau template Ansible. À l’issue de cette journée, l’équipe responsable du sujet n’en avait plus que 10 à traiter. La mutualisation de nos forces a porté ses fruits !&lt;/p&gt;

&lt;p&gt;Insuffisants lors de la première édition, les indicateurs de suivi mis en place dans les éditions suivantes sont cruciaux pour évaluer le ROI de ces journées de travail “particulières”.&lt;/p&gt;

&lt;h2 id=&quot;les-coulisses-du-jeudi-du-fun&quot;&gt;Les coulisses du jeudi du fun&lt;/h2&gt;

&lt;p&gt;Les jeudis du fun sont organisés par deux personnes au sein de la verticale infra. Si les séances de préparation de cette journée (qui débutent environ 3 semaines avant la tenue de l’événement) sont source de beaucoup de rires, il n’empêche qu’elles doivent également répondre à certaines problématiques.&lt;/p&gt;

&lt;h3 id=&quot;sadapter-aux-habitudes-de-travail-de-chacun&quot;&gt;&lt;em&gt;S’adapter aux habitudes de travail de chacun&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;En premier lieu, nous devons organiser une journée à laquelle tous les membres de nos équipes puissent prendre part, qu’ils soient au bureau ou en télétravail. Tous les moments de la journée doivent tenir compte de cet élément, qu’il s’agisse des phases de travail en petits groupes, des sessions en plénière (25 personnes) comme le lancement de la journée, la remise des prix ou les différents jeux qui ponctuent ces jeudis.&lt;/p&gt;

&lt;p&gt;Les phases de travail en équipe sont les plus simples à gérer : nos équipes ont déjà l’habitude au quotidien de travailler avec des collègues à distance. Tout le monde se connecte sur une room de visioconférence, et le tour est joué.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;Team mixte présentiel / distanciel lors du 1er “jeudi du fun”&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/Article-team-hybride.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;Team mixte présentiel / distanciel lors du 1er “jeudi du fun”&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Les moments en plénière sont en revanche plus délicats à gérer, car le brouhaha d’une vingtaine de personnes rassemblées dans une même pièce reste difficilement audible pour les personnes à distance. Un prochain challenge pourrait être d’organiser un jeudi du fun 100% distanciel.&lt;/p&gt;

&lt;p&gt;Il est également nécessaire de tenir compte de la façon de travailler de chacun : si certaines personnes sont capables de travailler en faisant fi du bruit d’un open space, d’autres ont besoin de plus de calme. À chaque édition, nous tentons d’organiser le jeudi du fun sous différentes formes, pour tenir compte des besoins de chacun, mais nous n’avons pas encore trouvé la solution idéale.&lt;/p&gt;

&lt;p&gt;Lors de la première édition, nous étions tous rassemblés dans le même open space, sans dispositif particulier pour les personnes ayant besoin d’un environnement silencieux, et cette journée leur a été difficile à supporter. De nombreuses autres équipes de Bedrock avec qui nous partageons d’habitude cet open space étaient en déplacement ce jour-là, ce qui a néanmoins permis de limiter nos nuisances sonores à notre seule verticale.&lt;/p&gt;

&lt;p&gt;Pour la seconde édition, nous avions réservé un open space dans les locaux de Bedrock pour ne pas prendre le risque de déranger les autres équipes : l’ambiance y a été d’autant plus conviviale mais n’a apporté aucun mieux aux personnes ayant besoin de tranquillité pour travailler.&lt;/p&gt;

&lt;p&gt;Lors de notre dernière édition, nous avons tenté une approche hybride : la plupart des équipes étaient rassemblées dans un même open space, et pour les personnes ayant besoin de s’isoler, une salle de réunion avait été réservée pour l’occasion. Il semble que cette organisation a apporté un mieux pour les personnes souffrant du bruit avec un écueil cependant : elles étaient isolées des autres équipes tout au long de la journée, et le jeudi du fun repose (aussi) sur l’émulation collective…&lt;/p&gt;

&lt;h3 id=&quot;les-autres-limites-de-lorganisation&quot;&gt;&lt;em&gt;Les autres limites de l’organisation&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Au fil des éditions, nous avons rencontré, en tant qu’organisatrices, deux autres limites.&lt;/p&gt;

&lt;p&gt;La première touche au choix du sujet. Si la définition de la thématique de la première journée a été évidente car le repository sysadmin/terraform est source de complaintes quotidiennes, très vite, nous avons eu besoin d’aide pour définir les sujets des éditions suivantes.  &lt;br /&gt;
En effet, il est difficile pour nous d’appréhender un sujet dans sa globalité : y aura-t’il du travail pour chaque équipe ? Le sujet est-il accessible pour tous nos profils, sans montée en compétence préalable ? Quelles sont concrètement les actions à conduire pour venir à bout d’un sujet ? Pour pallier à ce problème, nous avons réalisé un tour de passe-passe : l’équipe qui remporte le jeudi du fun gagne le droit de définir avec nous le sujet de l’édition suivante. Et ça fonctionne ! Les gagnants participent avec plaisir au choix du prochain sujet &lt;del&gt;de torture&lt;/del&gt; de fun !&lt;/p&gt;

&lt;p&gt;La seconde limite concerne la récurrence de l’événement. Initialement, nous avions prévu d’organiser un jeudi du fun par mois, pour venir à bout rapidement de nos sujets legacy. Après les deux premières éditions (organisées en octobre et novembre 2022), nous nous sommes aperçues que nous perdrions le fun de cette journée si elle revenait trop fréquemment. Pour que cet événement reste une journée de travail particulière à laquelle les personnes participent avec plaisir, nous avons fait le choix d’opter pour un format trimestriel.&lt;/p&gt;

&lt;h2 id=&quot;next-steps-et-prochains-défis&quot;&gt;Next steps et prochains défis&lt;/h2&gt;

&lt;p&gt;D’autres améliorations restent à apporter, notamment autour de la gestion du reste à faire. Comment finir correctement les travaux initiés dans cette journée, afin de ne pas créer de nouvelles user stories legacy ? Ce point est tout aussi important que celui sur le travail accompli au cours de ces journées. Entamer un rework et le laisser en chantier génère au moins autant de frustration que le manque de temps pour traiter du legacy.&lt;/p&gt;

&lt;p&gt;Néanmoins, après trois éditions du jeudi du fun, il nous semblait important de partager notre expérience, ne serait-ce que pour convaincre des équipes de devs de Bedrock de venir jouer avec nous lors d’une prochaine édition !&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;Les participants du Jeudi du fun&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/Article-team.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;Les participants du Jeudi du fun&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Pour vous donner un aperçu de comment se déroulent ces fameux jeudis, voici &lt;em&gt;grosso modo&lt;/em&gt; le programme d’une journée :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;⏰ 9h00 Petit déjeuner convivial (car c’est très important de commencer une telle journée en prenant des forces)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;⏰ 9h30 &lt;strong&gt;Début officiel de la journée&lt;/strong&gt; : on se retrouve en plénière, dans une grande salle de réunion, avec tous les participants et on (ré)explique le contexte de la journée ainsi que le programme. 
On commence avec un petit jeu (5 minutes maximum) qui sert à deviner le sujet du jour. Les sujets sont toujours gardés secrets jusqu’au lancement de la journée, ce qui donne lieu à toutes sortes d’hypothèses les jours qui précèdent (“Oui, oui, bien sûr on va recoder toute notre plateforme dans un autre langage jeudi”).On fait monter la pression !  &lt;br /&gt;
L’objectif de ce premier jeu est d’énergiser un maximum nos collègues et de leur permettre de commencer à se projeter sur ce qu’ils vont pouvoir y faire. Le jeu change à chaque fois, pour garder un effet de surprise. 
Ensuite, vient le temps de révéler la constitution des équipes qui changent elles aussi à chaque édition afin de permettre à chaque personne de côtoyer de nouveaux collègues.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;⏰ 10h00 Les équipes partent travailler sur le sujet du jour, à leurs postes de travail&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;⏰ 12h30 - 13h30 Déjeuner&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;⏰ 13h30 Jeu de reprise (facultatif) : on se retrouve autour d’un blind test ou un gartic phone, histoire de passer un bon moment et de se remettre en jambe pour l’après-midi. C’est un court moment de &lt;em&gt;team building&lt;/em&gt; qui est très apprécié la plupart du temps (sauf lorsque les équipes ne veulent pas perdre un minute pour venir à bout de leur objectif !)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;⏰ 14h00 Les équipes reprennent le travail initié le matin et essayent de finir un maximum de choses&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;⏰ 17h30 On se retrouve en plénière pour le débrief de la journée : on fait le point sur le travail accompli, le décompte des points gagnés par chaque équipe et on fait le fameux podium ainsi que la remise des prix. 
On récupère à chaud les premiers retours des participants.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;⏰ 18h00 Le verre de l’amitié&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>[&quot;e_perrin&quot;, &quot;a_ferez&quot;]</name></author><category term="infra" /><category term="legacy" /><category term="retour d&apos;expérience" /><summary type="html">Elles sont là, tapies dans l’ombre de la colonne “To do” de vos backlogs, attendant que leur heure vienne. À chaque backlog refinement, vous vous demandez s’il ne faut pas tout simplement les annuler, puisque personne ne les prend en charge… De quoi parle-t-on ? De ces user stories qui existent dans le backlog…</summary></entry><entry><title type="html">Bedrock Dev Facts #19</title><link href="https://tech.bedrockstreaming.com/2023/03/13/bedrock-dev-facts-19.html" rel="alternate" type="text/html" title="Bedrock Dev Facts #19" /><published>2023-03-13T00:00:00+00:00</published><updated>2023-03-13T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/03/13/bedrock-dev-facts-19</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/03/13/bedrock-dev-facts-19.html">&lt;p&gt;La fin de l’hiver approche, il est temps de faire un bilan ! Quelles bêtises le froid aura-t-il apportées parmi les devs ? ❄️&lt;/p&gt;

&lt;h1 id=&quot;la-confiance-&quot;&gt;La confiance 🤞&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/dev-facts-19/how-to-test.png&quot; alt=&quot;Image d&apos;une Pull Request indiquant &apos;How to test ? Trust me&apos;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;mieux-quun-readme&quot;&gt;Mieux qu’un readme&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Quand le mec t’explique la solution, et finit par :&lt;/p&gt;

  &lt;p&gt;“Enfin ça c’est si mon code a bien continué d’être copié collé partout”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;une-éthique-moi-&quot;&gt;Une éthique, moi ?&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Moi je peux mettre du code dégueulasse un peu partout, c’est pas un problème !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;le-socrate-des-temps-modernes&quot;&gt;Le Socrate des temps modernes&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;La vie est un Spike&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;on-apprend-de-ses-erreurs&quot;&gt;On apprend de ses erreurs&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Set up a reminder “@myself ne jamais dire ‘je finis aujourd’hui’” in this channel at 9h45AM every day.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;en-tout-bien-tout-honneur-️&quot;&gt;En tout bien tout honneur ❤️&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Ah bah go, mets-moi en dur si tu veux.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;git-101&quot;&gt;GIT 101&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;J’en ai connu certains, à chaque fois qu’ils avaient un conflit sur leur branche, ils supprimaient le repo avant de le re-cloner&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ten-seconds-before-disaster&quot;&gt;Ten seconds before disaster&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Le cache, c’est nul !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;shoehashole-boolean-&quot;&gt;shoeHasHole: boolean 👟&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : ‘tin j’ai un trou dans ma chaussure&lt;/p&gt;

  &lt;p&gt;B : Tu es sûr que c’est pas un false ?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;on-a-tous-un-env-de-test-certains-ont-aussi-un-env-de-prod&quot;&gt;On a tous un env de test. Certains ont aussi un env de prod.&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/dev-facts-19/dev-env.png&quot; alt=&quot;Extrait de code définissant la variable DEV_ENV comme égal à prod&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;peur-de-rien-sauf-dune-chose&quot;&gt;Peur de rien, sauf d’une chose…&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : Ça finit en devs qui se reconvertissent Boulanger ça.&lt;/p&gt;

  &lt;p&gt;B : Certes, mais l’inverse est vrai aussi, il arrive que des Boulangers se reconvertissent après être devenus allergiques à la Farine.&lt;/p&gt;

  &lt;p&gt;A : C’est pour ça que je ne me reconvertirai pas en Barman… trop peur…&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;la-confiance-second-épisode-&quot;&gt;La confiance, second épisode 🤞&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;C’est pas n’importe quoi, juste un peu yolo !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;comme-de-leau-de-roche-trouble-&quot;&gt;Comme de l’eau de roche trouble !&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Franchement, je trouve ça clair ! Mais je comprends pas..&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;de-rares-génies-&quot;&gt;De rares génies 💡&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;On est peut-être des lumières, mais ça ne veut pas dire qu’on est tous allumés !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;cassage-de-prod-dans-3-2-1&quot;&gt;Cassage de prod dans 3… 2… 1…&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;J’le sens bien là. J’le sens bien bien bien.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;its-not-a-bug-its-a-feature&quot;&gt;It’s not a bug, it’s a feature&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;J’ai vérifié, le bug marchait bien.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;toujours-lire-les-petites-lignes-&quot;&gt;Toujours lire les petites lignes 🔎&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Tout* marche du coup !&lt;/p&gt;

  &lt;p&gt;(*pour l’instant)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;miaou-&quot;&gt;Miaou 🐱📈&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : Je théorise que le chat ne miaule devant la porte que pour savoir s’il pourrait passer quand il aura envie.&lt;/p&gt;

  &lt;p&gt;B : Ouah ton chat il fait du monitoring de la porte !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;facile-comme-tout-&quot;&gt;Facile comme tout !&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;TKT ! tu mets ton JSON dans le yaml et ça ira !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;une-grande-histoire-damour-épisode-1&quot;&gt;Une grande histoire d’amour, épisode 1&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Moi, j’adore le JSON&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;une-grande-histoire-damour-épisode-2&quot;&gt;Une grande histoire d’amour, épisode 2&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Le mail et le DNS c’est ma grande passion&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;partir-comme-un-roi-&quot;&gt;Partir comme un roi 👑&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/dev-facts-19/mic-drop.png&quot; alt=&quot;Image d&apos;une pull request nommée &amp;quot;Wesh je fais ce squash et je touche plus a rien. Mic drop.&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;les-grandes-questions-de-la-vie-&quot;&gt;Les grandes questions de la vie 🥐&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;D’ailleurs c’est LinkedIn ou pain au linked ?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;lhumour-pour-les-nuls&quot;&gt;L’humour pour les nuls&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : &lt;em&gt;Pouffe de rire&lt;/em&gt;&lt;/p&gt;

  &lt;p&gt;B : Tout va bien ?&lt;/p&gt;

  &lt;p&gt;A : Désolé, je viens de relire ma vanne&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;les-progrès-de-lia-&quot;&gt;Les progrès de l’IA 🤖&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : Alors B, c’est quoi le format de date php de la constante de format ‘c’ ?&lt;/p&gt;

  &lt;p&gt;B : Tu m’as pris pour chatGPT ou quoi ?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;un-stagiaire-en-détresse&quot;&gt;Un stagiaire en détresse&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;TLDR: À l’aide svp&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;la-sécurité-pour-les-nuls&quot;&gt;La sécurité pour les nuls&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Brian is in the Keychain.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;promis-dans-le-contexte-cest-vrai&quot;&gt;Promis dans le contexte c’est vrai&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;On doit afficher des ronds, alors c’est mieux s’ils nous envoient des carrés.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1&gt;😳&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;(Au pire, si on a la main sur une regexp, c’est déjà plus qu’il n’en faut pour me faire rêver)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;la-sélection-naturelle&quot;&gt;La sélection naturelle&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Je suis d’accord que là il y a un bug, mais c’est un bug parce que je suis con !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;-1&quot;&gt;🍵&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Je suis en train de me rappeler de mon weekend, et spoiler mettre du rhum dans son thé ce n’est pas une bonne idée.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;error--task-completed-successfully&quot;&gt;Error : Task completed successfully&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/dev-facts-19/error-success.png&quot; alt=&quot;Screen de popup d&apos;erreur indiquant &apos;Build failed to complete successfully&apos;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;la-confiance-30-&quot;&gt;La confiance, 3.0 🤞&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Coucou, aujourd’hui, je pète la reco (en prod), mais c’est sous contrôle.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;un-instant-de-réalisme&quot;&gt;Un instant de réalisme&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Personnellement, je sais pas ce que je fous en développeur !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;thomas-the-train-&quot;&gt;Thomas the train 🚆&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/dev-facts-19/tchou-tchou.png&quot; alt=&quot;Message de status Slack indiquant &apos;Working remotely from the tchou tchuou&apos;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;turlututu-chapeau-pointu-&quot;&gt;Turlututu chapeau pointu !&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;On aurait dû dire c’est “chapeau perché”.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;mieux-quun-rappel-automatique-&quot;&gt;Mieux qu’un rappel automatique 🤯&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : Du coup, tu as envoyé un mail ?&lt;/p&gt;

  &lt;p&gt;B : Pas encore non ! J’attendais d’y penser !&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Bedrock</name></author><category term="devfacts" /><category term="humour" /><summary type="html">La fin de l’hiver approche, il est temps de faire un bilan ! Quelles bêtises le froid aura-t-il apportées parmi les devs ? ❄️</summary></entry><entry><title type="html">Why is Transit Gateway service not right for us?</title><link href="https://tech.bedrockstreaming.com/2023/03/02/aws_transit_gateway.html" rel="alternate" type="text/html" title="Why is Transit Gateway service not right for us?" /><published>2023-03-02T00:00:00+00:00</published><updated>2023-03-02T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/03/02/aws_transit_gateway</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/03/02/aws_transit_gateway.html">&lt;p&gt;Managing the network of many interconnected AWS accounts can quickly lead to having a messy network architecture.&lt;br /&gt;
Transit Gateway (TGW) service seems to be the way out of this. So how do you know if TGW is right for you?&lt;/p&gt;

&lt;p&gt;This blog post will introduce how the service works and explain why we chose not to carry on with our migration to AWS Transit Gateway.
&lt;!--more--&gt;&lt;/p&gt;
&lt;h2 id=&quot;transit-gateways-backstory&quot;&gt;Transit Gateway’s backstory&lt;/h2&gt;

&lt;p&gt;Transit Gateway is a network transit hub that connects multiple VPCs and On-Premises sites to allows control traffic between them.&lt;br /&gt;
It was created to provide a new approach of network implementation on AWS and to make network administration smoother.&lt;/p&gt;

&lt;p&gt;VPC peering is a point-to-point connection between 2 VPCs.&lt;br /&gt;
It is a great example of complex network management because it adds a new topology to the network architecture.&lt;br /&gt;
On this diagram you can see an example of VPC peering usage. It’s not that messy yet but at scale it will be.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-03-02-aws_tgw/tgw.png&quot; alt=&quot;Network architecture without Transit Gateway&quot; /&gt;&lt;/p&gt;

&lt;p&gt;By acting as a “cloud router”, TGW centralizes network connections and takes control of packet forwarding between VPCs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-03-02-aws_tgw/tgw2.png&quot; alt=&quot;Network architecture with Transit Gateway&quot; /&gt;&lt;/p&gt;

&lt;p&gt;VPC peerings are not required anymore, we go back to a simpler star network topology thanks to Transit Gateway which really does address the complexity and restrictions of VPC peerings.&lt;br /&gt;
At that point, TGW seems to be the perfect answer for a simpler network architecture.&lt;/p&gt;

&lt;h2 id=&quot;what-about-tgw-at-bedrock&quot;&gt;What about TGW at Bedrock?&lt;/h2&gt;

&lt;p&gt;We operate more than 20 different AWS accounts for our customers’ platforms. Each account has a VPC with at least 3 private and 3 public subnets. We also manage AWS accounts for internal tools like ECR repositories, monitoring tools and shared s3 buckets. We configured Site-to-Site VPNs from On-Premises infrastructure to all the VPCs in these accounts.&lt;/p&gt;

&lt;p&gt;From the creation of new AWS accounts to deploying the tenants’ platform, onboarding a new customer requires a lot of work and time.&lt;/p&gt;

&lt;p&gt;Configuring VPCs Site-to-Site VPN is one of the steps that requires a lot of work. This is why we were interested in Transit Gateway at first.&lt;/p&gt;

&lt;h3 id=&quot;proof-of-concept&quot;&gt;Proof of concept&lt;/h3&gt;

&lt;p&gt;We created a production like Proof of Concept infrastructure using three AWS accounts, two different regions, multiple VPCs and a single Site-to-Site VPN from TGW to On-Premises firewall.&lt;/p&gt;

&lt;h4 id=&quot;how-did-we-test-tgw&quot;&gt;How did we test TGW?&lt;/h4&gt;

&lt;p&gt;We started by trying to split routing domains.&lt;br /&gt;
Centralizing network connections also means (with correct ACLs or Security Groups) that VPCs can reach all other VPCs. We want to control that.&lt;br /&gt;
Transit Gateway attachments read their routes in the TGW route table they are associated to. This is how we manage routing domains.&lt;br /&gt;
We create a Transit Gateway routing table and create routes for target networks.&lt;br /&gt;
TGW attachments are able to propagate routes in a route table if we want to. But because of routing domains, we can’t use that option and we have to add routes manually (attachments only read routes in the route table).&lt;/p&gt;

&lt;p&gt;Then we tested Transit Gateway peering.&lt;br /&gt;
TGW is a regional service, this means that we need to have a TGW for each active AWS region. We use TGW peering to interconnect them.&lt;br /&gt;
We expected to have some way to propagate routes dynamically in the Transit Gateway peering route table. But it is not possible.&lt;/p&gt;

&lt;p&gt;The last thing we tested is migrating from VPC Site-to-Site VPN to TGW VPN.&lt;br /&gt;
Because of the amount of VPC Site-to-Site VPN we have, it was important for us to know if we could get a minimal down time on On-Premises to VPC connections when migrating to the Transit Gateway VPN.&lt;br /&gt;
This process requires a lot of time because routes have to be deleted and created manually on each side.&lt;/p&gt;

&lt;p&gt;Even if we noticed some pain points, tests went well. So we decided to initiate the migration to the Transit Gateway service.&lt;/p&gt;

&lt;h3 id=&quot;why-did-we-choose-to-rollback&quot;&gt;Why did we choose to rollback?&lt;/h3&gt;

&lt;p&gt;Everything was okay at first, we successfully migrated two VPC Site-to-Site VPN to our Transit Gateway VPN.&lt;/p&gt;

&lt;p&gt;But then previous pain points became barriers:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;creating and managing routing domains is possible, but makes it impossible to use dynamic route propagation&lt;/li&gt;
  &lt;li&gt;there is not option to propagate routes in VPC route table, they all have to be created manually&lt;/li&gt;
  &lt;li&gt;data transfer cost is too high (and multiplied by the number of region on which you deployed TGW if your packets go through all these regions)&lt;/li&gt;
  &lt;li&gt;migrating to Transit Gateway requires a planned maintenance because there is a network downtime&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We took some time to talk about what to do next and concluded that migrating to Transit Gateway will just move the complexity of configuring VPC Site-to-Site VPNs to configuring TGW attachments and routes.&lt;/p&gt;

&lt;p&gt;AWS support did not suggest enough solutions to the problems we faced, so we decided to rollback to VPC Site-to-Site VPNs.&lt;/p&gt;</content><author><name>Christian VAN DER ZWAARD</name></author><category term="on-premise" /><category term="cloud" /><category term="aws" /><category term="network" /><summary type="html">Managing the network of many interconnected AWS accounts can quickly lead to having a messy network architecture. Transit Gateway (TGW) service seems to be the way out of this. So how do you know if TGW is right for you? This blog post will introduce how the service works and explain why we chose not to carry on with our migration to AWS Transit Gateway.</summary></entry><entry><title type="html">Projet XState</title><link href="https://tech.bedrockstreaming.com/2023/02/08/projet-xstate.html" rel="alternate" type="text/html" title="Projet XState" /><published>2023-02-08T00:00:00+00:00</published><updated>2023-02-08T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/02/08/projet-xstate</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/02/08/projet-xstate.html">&lt;p&gt;Dans une application frontend moderne, la gestion d’état est un élément central de son bon fonctionnement. Malgré les nombreuses librairies disponibles (Redux, MobX, Recoil…), cette tache reste complexe à réaliser et il est facile de perdre le contrôle.&lt;/p&gt;

&lt;p&gt;Dans l’objectif de rester maitre de son application, je vous propose de découvrir XState, une librairie reposant sur le concept de machine à états. Si l’outil ne fait pas tout, le concept de machine à état aide grandement à concevoir une application résiliente.&lt;/p&gt;

&lt;p&gt;Pour présenter au mieux les concepts, la théorie sera suivie de pratique au travers d’un live coding.&lt;/p&gt;</content><author><name>Maxime Blanc</name></author><category term="xstate" /><category term="lyonjs" /><category term="meetup" /><category term="react" /><category term="javascript" /><category term="conference" /><summary type="html">Dans une application frontend moderne, la gestion d’état est un élément central de son bon fonctionnement. Malgré les nombreuses librairies disponibles (Redux, MobX, Recoil…), cette tache reste complexe à réaliser et il est facile de perdre le contrôle.</summary></entry><entry><title type="html">A journey into connected TVs industrialisation process, Part 1</title><link href="https://tech.bedrockstreaming.com/2023/01/10/bedrock-app-launcher.html" rel="alternate" type="text/html" title="A journey into connected TVs industrialisation process, Part 1" /><published>2023-01-10T00:00:00+00:00</published><updated>2023-01-10T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/01/10/bedrock-app-launcher</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/01/10/bedrock-app-launcher.html">&lt;p&gt;At Bedrock, we build and run streaming applications on a wide variety of OTT devices (more than 60 different ecosystems). While testing and experimenting is easy on web and mobile devices, even for non-developers, it’s not as easy for Connected TV (CTV). In this article, you’ll discover how all of our employees can now access testing and pre-release environments on TV devices, with ease and without any technical knowledge.&lt;/p&gt;

&lt;h2 id=&quot;bedrock-tvjs-project&quot;&gt;Bedrock TvJS Project&lt;/h2&gt;

&lt;h3 id=&quot;how-does-it-work-&quot;&gt;How does it work ?&lt;/h3&gt;

&lt;p&gt;To address the growing number of CTVs vendors in the market, we have a one-and-only monorepo project named “TVJS”. It is a React application which we can deploy almost everywhere almost anywhere with the same code, UI and UX. The magic part? There isn’t much manufacturer-specific code in that application, most of those particularities are handled by our homemade JS library named PELO (Platform Easy Life Officer). &lt;em&gt;For non-French readers, “pélo” is a Lyon/Grenoble city slang to designate “someone”.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-01-10-bedrock-app-launcher/pelo-cli.png&quot; alt=&quot;Pelo&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In a few words, PELO is a set of libraries showing a unified front API for TV developers, so they don’t have to keep in mind every TV specific details and custom APIs (like lifecycle, keyboard, storage handling, and more). PELO also provides several CLI tools allowing the use of proprietary manufacturer SDKs, with a common shared API.&lt;/p&gt;

&lt;p&gt;There are at least two ways to deploy a TV application:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;A fully packaged solution, where all application files and resources are stored on the TV. Everytime you want to update it, application you have to go through the manufacturer QA process. Doing so, you can develop either a web application that will run through the TV’s Web Engine, or a native TV application.&lt;/li&gt;
  &lt;li&gt;The hosted solution, where the TV packaged application only redirects to a web application that you are responsible for. It grants much more flexibility, and delivery speed, as deployment and propagation of a new version are almost instantaneous.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We chose the second way as we are addressing a big number of devices and need all the flexibility we can have for deployments – and, sadly, for rollbacks too. Therefore, we host and deploy our CTV applications like any other website and we control the TV Browser Engine to navigate to specific domain names.&lt;/p&gt;

&lt;p&gt;Three teams are working on this project, on the same repository:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a team dedicated to Core features (like catalog, user lifecycle)&lt;/li&gt;
  &lt;li&gt;a team dedicated to Player features (video playback and advertising)&lt;/li&gt;
  &lt;li&gt;and a team supporting legacy devices&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Developer teams are supported by a QA team. It is responsible for functional quality assurance on Pull Requests and pre-releases. Quality assurance designates any processes to ensure a service meets its quality requirements in terms of experience, stability, …&lt;/p&gt;

&lt;h3 id=&quot;develop--release-process&quot;&gt;Develop &amp;amp; release process&lt;/h3&gt;

&lt;p&gt;We do our maximum to ensure the best quality of service and experience of what we deliver to our customers and their end-users. We have a strong culture of automated testing &amp;amp; tech reviewing which allows us to deliver almost without a sweat… Still, at our scale, missing a bug means a bad experience for thousands or millions of people! And that’s something we won’t accept without a fight!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;One of Bedrock’s Values is: ROCK-SOLID, ALWAYS&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As a consequence, we also have dedicated QA teams testing our work for a subset of device models and versions, before it is being merged to the main codebase, and before going to production as part of a release. They are doing so by connecting TVs to specific environments that are deployed on-demand: previews and staging.&lt;/p&gt;

&lt;p&gt;Let’s show off a little bit: at the beginning of 2022, thanks to the TVJS project, we were able to deploy production code to 7 manufacturers, and 38 device versions, meaning 266 combinations to check before launching a release into production! And these numbers are ever increasing!&lt;/p&gt;

&lt;h3 id=&quot;my-wish-make-testing-environments-easily-accessible&quot;&gt;My wish: make testing environments easily accessible&lt;/h3&gt;

&lt;p&gt;We love showing-off a bit over the applications we deliver on such a huge number of device models, but that doesn’t go with ease nor without pain.&lt;/p&gt;

&lt;p&gt;Testing a specific environment on a device was not possible for non-project members (other teams, support, business &amp;amp; product teams, managers …). Starting a preview or a staging application requires a deep understanding of the project, proprietary SDKs (even with our PELO CLI), shell, Git commands and advanced knowledge of how devices work in Developer Mode. This was a major issue: it causes interruptions for developers, slows delivery down, reduces our Time To Market.&lt;/p&gt;

&lt;p&gt;QA teams assigned to the project know its basics, they can use PELO CLI and proprietary SDKs, but cannot debug issues they may encounter with such tools: they have to ask developers to take actions for them (as this is not their core job). Using those tools is also time-consuming and time is of the essence when running quality checks while preparing a release.&lt;/p&gt;

&lt;p&gt;Many teams also want to start environments by themselves, to test their own developments on back-end services, to investigate when a customer creates a support ticket, …
The most important of them are Video teams, responsible for video encoding, transcoding and packaging: they are constantly testing new streams and features, and need a way to test their content by themselves, without asking around for a TVJS developer.&lt;/p&gt;

&lt;h2 id=&quot;our-answer-the-launcher-app-&quot;&gt;Our answer: The Launcher App !&lt;/h2&gt;

&lt;h3 id=&quot;what-does-it-do-&quot;&gt;What does it do ?&lt;/h3&gt;

&lt;p&gt;I’ve developed a TV application to quickly and efficiently start a specific environment. Using the TV remote, people can select the wanted environment and be redirected to it instantly, having the app like they would with the specific app installed.&lt;/p&gt;

&lt;p&gt;Typing long texts is painful for TV users. So, when selecting the preview environment, it shows another set of options where users can input a specific PR number. A background process will ask our Github if it knows the PR number, if it is deployed on the selected customer/manufacturer and will pre-fill the branch name. If not specified, it will default back to our master preview that is updated whenever we merge code to the master branch.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-01-10-bedrock-app-launcher/launcher-demo.gif&quot; alt=&quot;Launcher demo&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;technical-architecture&quot;&gt;Technical Architecture&lt;/h3&gt;

&lt;p&gt;The launcher is part of the TVJS monorepo, developed using React and re-using modules and packages for UI and Navigation allowing it to have minimum maintenance cost.&lt;/p&gt;

&lt;p&gt;For the first iterations of development of the launcher, I hosted it on AWS Amplify, but the Core team quickly integrated it back to a regular production deployment process we have at Bedrock.&lt;/p&gt;

&lt;p&gt;An automatic process builds the javascript bundle and assets and sends everything to AWS S3. The launcher will then be served through Fastly CDN. We build and deploy a unique launcher per compatible manufacturer on their own domain names (as-of-writing, Samsung Tizen, LG webOS and Hisense). For security reasons, those Fastly services are only accessible from our office networks.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-01-10-bedrock-app-launcher/launcher-tech-arch.png&quot; alt=&quot;Launcher technical architecture&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;unreliability-of-launcher-app-installation&quot;&gt;Unreliability of launcher app installation&lt;/h3&gt;

&lt;p&gt;I’m proud of this launcher and it is already saving loads of time for our QA teams ! They love it, as it helps them focus on their primary role: ensuring service &amp;amp; experience quality. Still, installing the launcher application on every device in our office is a huge amount of work! And, unfortunately, not a persistent one.&lt;/p&gt;

&lt;p&gt;To develop and test apps on live devices, we need to set them in “Developer Mode”. And each manufacturer has its own way, more or less time-consuming. Worse, whenever Developer Mode expires, all applications installed during this time are uninstalled from the device! Which means we have to install the launcher again after a brief period of time.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://developer.samsung.com/smarttv/develop/getting-started/using-sdk/tv-device.html&quot;&gt;Tizen Developer Mode&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://webostv.developer.lge.com/develop/getting-started/developer-mode-app&quot;&gt;LG webOS Developer Mode&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That period of time varies. For Samsung Tizen, we’re not absolutely sure, but it’s almost a month. For LG webOS, it is 50 hours if you don’t extend the Developer Mode or if you connect another TV with the same Developer Account.&lt;/p&gt;

&lt;p&gt;Specifically for LG, I did set up a CRON that automatically extends the Developer Mode, but sometimes it is being disconnected without reason… Or a mishandling by team members can cause the CRON to fail.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-01-10-bedrock-app-launcher/webos-cron.png&quot; alt=&quot;LG webOS CRON configuration to extend Developer Mode&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-01-10-bedrock-app-launcher/webos-extend-devmode.gif&quot; alt=&quot;Programmatically extending the Developer Mode on LG webOS&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Therefore, we aren’t 100% sure the launcher application will be up and ready on all the office devices when work begins in the morning, which means developers will have to manually re-install the launcher when asked by another Bedrock employee. It generates frustration for both QA and developers as they are wasting precious time to re-install the launcher.&lt;/p&gt;

&lt;p&gt;Don’t worry though, I already have a couple of ideas to ensure the installation becomes reliable! I’ll talk more about these it in a future article.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Any Bedrock employee can now start an office CTV, use the launcher app, select customer and environment, hit Let’s Go and access the environment they need to work!&lt;/p&gt;

&lt;p&gt;What we started to measure, and hopefully we’ll have more refined metrics over the next months, is the time QA teams are gaining per day. They needed an average of 15 minutes to start up a TV, set up the Developer Mode, and install the wanted app through CLI. They are validating 5 PRs per day, on 2 different devices at minimum, they almost gain one hour per day. That means our Time To Market is faster, and our QA teams have more time to do exploratory testing as well as refining their tests and writing more automated tests. Something that is not as measurable as time, is the enhanced peace of mind for them to go to work every morning knowing they have a tool designed for them to focus on their core work.&lt;/p&gt;

&lt;p&gt;This has improved the QA team overall velocity! And it makes the whole project more accessible for any employee. However, there is still room for improvement regarding launcher deployment and stability over time, and this is something I will cover in our next article.&lt;/p&gt;

&lt;p&gt;I hope you liked this article and it helped you if you’re trying to achieve something similar!&lt;/p&gt;</content><author><name>Bedrock</name></author><summary type="html">At Bedrock, we build and run streaming applications on a wide variety of OTT devices (more than 60 different ecosystems). While testing and experimenting is easy on web and mobile devices, even for non-developers, it’s not as easy for Connected TV (CTV). In this article, you’ll discover how all of our employees can now access testing and pre-release environments on TV devices, with ease and without any technical knowledge.</summary></entry><entry><title type="html">Nos retours sur l’HAProxyConf Paris 2022</title><link href="https://tech.bedrockstreaming.com/2022/12/23/haproxyconf-paris-2022.html" rel="alternate" type="text/html" title="Nos retours sur l’HAProxyConf Paris 2022" /><published>2022-12-23T00:00:00+00:00</published><updated>2022-12-23T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/12/23/haproxyconf-paris-2022</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/12/23/haproxyconf-paris-2022.html">&lt;p&gt;Bedrock était présent lors de la Conférence HAProxy qui se déroulait à Paris en novembre 2022 : en tant que speaker, avec &lt;a href=&quot;https://www.youtube.com/watch?v=5jzOXlmRDao&quot; target=&quot;_blank&quot;&gt;la présentation de Vincent Gallissot&lt;/a&gt;, mais aussi en tant que spectateur. Cet article relate les points forts qui nous ont marqués.&lt;/p&gt;

&lt;p&gt;La présentation de Vincent Gallissot, Lead Cloud Architect chez Bedrock, mettait en valeur l’usage d’HAProxy en tant que brique essentielle de notre infrastructure. Chez Bedrock, nous développons et maintenons une plateforme de streaming qui a été migrée dans le Cloud en 2019. Cette présentation était grandement inspirée de l’article intitulé &lt;a href=&quot;https://tech.bedrockstreaming.com/2021/12/15/scaling-bedrock-video-delivery-to-50-million-users.html&quot; target=&quot;_blank&quot;&gt;“Scaling Bedrock video delivery to 50 million users”&lt;/a&gt;, dans lequel vous trouverez pléthore d’informations concernant nos utilisations d’HAProxy.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-12-23-haproxyconf-paris-2022/keynote_conf_2022_bedrockstreaming.jpg&quot; alt=&quot;Vincent Gallissot presentation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sommaire&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#ce-que-des-millions-de-requêtes-par-seconde-signifient-en-termes-de-coût-et-déconomie-dénergie&quot;&gt;Ce que des millions de requêtes par seconde signifient en termes de coût et d’économie d’énergie&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#un-outil-pour-les-gouverner-tous&quot;&gt;Un outil pour les gouverner tous&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#vous-reprendrez-bien-un-peu-de-pétaoctets-&quot;&gt;Vous reprendrez bien un peu de pétaoctets?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ce-que-des-millions-de-requêtes-par-seconde-signifient-en-termes-de-coût-et-déconomie-dénergie&quot;&gt;Ce que des millions de requêtes par seconde signifient en termes de coût et d’économie d’énergie.&lt;/h2&gt;

&lt;p&gt;La &lt;a href=&quot;https://www.youtube.com/watch?v=GoRnD_21Qgk&quot; target=&quot;_blank&quot;&gt;keynote d’ouverture&lt;/a&gt; avait pour orateur &lt;a href=&quot;https://twitter.com/willytarreau&quot; target=&quot;_blank&quot;&gt;Willy Tarreau&lt;/a&gt;, le Lead Developer d’HAProxy.&lt;br /&gt;
Au travers d’une démonstration concrète mélangeant software et hardware, l’objectif était de :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;transmettre l’idée qu’ajouter une brique logicielle dans un système ne le dégrade pas pour autant, bien au contraire&lt;/li&gt;
  &lt;li&gt;sensibiliser l’audience quant à la consommation d’énergie de nos systèmes&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;contexte-technique-et-premières-améliorations&quot;&gt;Contexte technique et premières améliorations&lt;/h3&gt;

&lt;p&gt;Pour ce premier cas d’étude, Willy Tarreau nous présente le cas d’un service de vente en ligne.&lt;/p&gt;

&lt;p&gt;La stack technique est composée de PHP / pgSQL (NodeJS + Symfony) et les images sont stockées en base de données. C’est cette architecture qui sera mise à l’épreuve lors des tests de charge à venir.&lt;/p&gt;

&lt;p&gt;Dans un premier temps, plusieurs améliorations (sans HAProxy) sont proposées. Il peut s’agir d’un simple rappel, voir d’un pro-tip d’architecture pour les plus novices : Les images en base de données, c’est une mauvaise idée.&lt;/p&gt;

&lt;p&gt;En les déplaçant vers un CDN, le système peut rapidement et simplement doubler ses performances, la base de données étant un goulot d’étranglement. La taille des pages peut être optimisée via l’activation de l’option http “gzip”. Les informations de sessions sont elles aussi enregistrées en base de données. Afin d’améliorer les performances, il est possible d’ajouter du caching via des outils tels que Memcache.&lt;/p&gt;

&lt;p&gt;Suite à cela, une première amélioration d’architecture serait d’ajouter un NLB (Network Load Balancer) en amont du système qui distribuerait les requêtes entrantes vers plusieurs unités de calculs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-12-23-haproxyconf-paris-2022/keynote_conf_2022_request_arch.png&quot; alt=&quot;next architecture schematic keynote&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Schéma d’architecture, première version&lt;/p&gt;

&lt;p&gt;Dans le cas présent, les requêtes entrantes sont distribuées de façon aléatoire entre les différentes unités de traitement. Chacun de ces backends se connectant à la même et unique base de données.&lt;br /&gt;
Le benchmark ci-dessous (efficacité, au sens nombre de requêtes traitées en fonction du nombre d’unités de calcul), ne montre pas une croissance linéaire. Il s’agit d’une courbe tendant vers une pente nulle (voir négative pour les plus grosses architectures).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-12-23-haproxyconf-paris-2022/keynote_conf_2022_nlb_stats.png&quot; alt=&quot;stats of nlb with backends&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Graphique représentant l’efficacité du système en fonction du nombre de backends&lt;/p&gt;

&lt;h3 id=&quot;comment-expliquer-que-cette-architecture-ne-scale-pas-linéairement-&quot;&gt;Comment expliquer que cette architecture ne scale pas linéairement ?&lt;/h3&gt;

&lt;p&gt;Malgré les améliorations apportées pour les sessions grâce au cache, il subsiste encore un problème.&lt;/p&gt;

&lt;p&gt;Le NLB est un composant qui ne fait que répartir la charge sans tenir compte de l’historique des requêtes. En effet, celui-ci va distribuer la charge d’entrée aléatoirement vers les backends.&lt;br /&gt;
Chaque backend reçoit des requêtes provenant de n’importe quel utilisateur impliquant alors un cache-miss très élevé : l’utilisateur est rarement trouvé dans le cache, ce qui génère une requête supplémentaire en base de données et dégrade les performances en plus de consommer inutilement des ressources.&lt;/p&gt;

&lt;h3 id=&quot;et-si-nous-ajoutons-haproxy-à-notre-système-&quot;&gt;Et si nous ajoutons HAProxy à notre système ?&lt;/h3&gt;

&lt;p&gt;C’est ici qu’entre en jeu HAProxy en remplaçant le NLB. Pour cela, pas besoin d’un foudre de guerre en termes de ressources.&lt;/p&gt;

&lt;p&gt;Les tests ont été effectués sur une machine ARM Breadbee cadencée à 1 GHz et possédant 64 Mo de RAM. Nous verrons également par la suite qu’on pourrait même se passer d’une machine supplémentaire.&lt;/p&gt;

&lt;p&gt;Le but d’HAProxy est de spécialiser les caches des backends et plus globalement de forcer les sessions utilisateurs vers les mêmes backends.&lt;/p&gt;

&lt;p&gt;Pour cela, HAProxy effectue une inspection de la couche 7 du trafic et renvoie toutes les requêtes d’un même utilisateur sur une même machine en réduisant ainsi les cache-miss aux seuls cas des nouveaux clients se connectant à la plateforme. Ainsi, le nombre d’appels à la base de données pour récupérer les informations de session est drastiquement réduit, la majorité d’entre elles étant stockées en cache.&lt;/p&gt;

&lt;p&gt;Autre fonctionnalité de taille : HAProxy limite le nombre de requêtes faites en parallèle sur un même backend, ce qui limite les locks de processus et les temps d’attente. Ceci a pour conséquence directe de réduire la consommation CPU.&lt;/p&gt;

&lt;p&gt;Ces deux améliorations permettent à l’application de scaler de façon beaucoup plus linéaire, tout en réduisant les consommations CPU et énergétiques inutiles. Globalement, les performances initiales sont largement dépassées avec deux fois moins de backends.&lt;/p&gt;

&lt;h3 id=&quot;a-partir-de-quand-est-il-intéressant-de-franchir-le-pas-&quot;&gt;A partir de quand est-il intéressant de franchir le pas ?&lt;/h3&gt;

&lt;p&gt;Maintenant que les bénéfices d’HAProxy ont été présentés, la prochaine étape est de se demander : quand est-ce qu’on se lance ? La question est considérée en termes de performance, mais aussi sous un angle pécunier.&lt;br /&gt;
Si HAProxy peut être intégré sans augmenter les coûts du système, c’est encore mieux.&lt;/p&gt;

&lt;p&gt;Ajouter HAProxy dans un système composé d’un seul backend n’apporte pas de bénéfice : il n’y a pas de load-balancing possible. Avec deux backends, si on divise le besoin de processing par deux, nous n’avons plus qu’un seul backend et donc pas de load-balancing possible.&lt;br /&gt;
C’est en fait à partir de 4 backends que l’ajout d’un HAProxy en entrée devient intéressant :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;en retirant 2 serveurs de nos backends en conservant une puissance équivalente (cf les tests ci-dessus)&lt;/li&gt;
  &lt;li&gt;et en recyclant un des deux backends retirés en hôte pour HAProxy
En fin de compte, pour une même puissance de traitement, un backend est retiré ce qui permet de réduire les coûts de fonctionnement. Ce principe s’applique également sur un grand nombre de backends.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;C’est là que prend tout son sens l’expression qui avait été utilisée pour conclure cette keynote : “HAProxy is a free software running on free hardware”.&lt;/p&gt;

&lt;p&gt;Chez Bedrock, nous appliquons aussi ces différentes techniques de Consistent Hashing en entrée de notre CDN vidéo. Nos caches vidéos sont spécialisés et chaque utilisateur est redirigé vers un unique backend lors de la lecture d’une vidéo.&lt;br /&gt;
Pour en savoir plus, vous pouvez consulter notre article au sujet du &lt;a href=&quot;https://tech.bedrockstreaming.com/2021/11/18/hsdo.html&quot; target=&quot;_blank&quot;&gt;Consistent Hashing&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;un-outil-pour-les-gouverner-tous&quot;&gt;Un outil pour les gouverner tous&lt;/h2&gt;

&lt;p&gt;Dans notre activité en informatique, nous sommes amenés à délivrer de plus en plus rapidement des applications, des mises à jour, etc… Nous avons donc adopté la philosophie DevOps et tout un panel d’outils autour de celle-ci afin de sécuriser, monitorer et automatiser chaque étape de nos pipelines de livraison.&lt;/p&gt;

&lt;p&gt;Le cas de figure du load balancing est intéressant dans ce type d’organisation, il est essentiel d’exposer de nouvelles applications sur les environnements de production mais étant donné que la maîtrise de cet outil requiert une compréhension du réseau, la responsabilité incombe souvent à l’équipe Ops de le gérer.&lt;/p&gt;

&lt;h3 id=&quot;vous-souhaitez-mieux-gérer-votre-flotte-haproxy-&quot;&gt;Vous souhaitez mieux gérer votre flotte HAProxy ?&lt;/h3&gt;

&lt;p&gt;Anjelko Iharos, directeur de l’ingénierie à HAProxy Technologies nous a présenté leur nouvel outil d’automatisation : HAProxy Fusion Control Plane, packagé dans la version entreprise de HAProxy.&lt;/p&gt;

&lt;p&gt;Celui-ci va amener une nouvelle interface enrichie afin de gérer toutes les instances HAProxy et les outils gravitant autour de ces dernières.&lt;/p&gt;

&lt;p&gt;On peut citer :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;La possibilité pour les développeurs de router eux-même leurs applications sans avoir besoin d’un Ops dans leurs pipelines de CI via l’API Fusion.&lt;/li&gt;
  &lt;li&gt;Gérer les WAF de HAProxy de manière centralisée et répercuter cette configuration sur un ensemble de clusters/instances.&lt;/li&gt;
  &lt;li&gt;Permettre aux Ops de gérer la structure de leurs load balancers, ajouter de nouvelles instances, gérer les certificats SSL, le tuning des performances depuis un seul point d’entrée.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;est-ce-résilient-&quot;&gt;Est-ce résilient ?&lt;/h3&gt;

&lt;p&gt;Fusion Control Plane est livré avec tout un set de features intéressantes pour assurer sa maintenabilité et sa résilience :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Une pleine observabilité avec une application unifiée de récupération de logs, métriques et rapports dans la même interface. L’export de ces data est possible, notamment pour les transposer dans un dashboard tiers (Grafana, par exemple).&lt;/li&gt;
  &lt;li&gt;Un système de RBAC permettant de mieux gérer les périmètres de chacune des équipes dans le control plane.&lt;/li&gt;
  &lt;li&gt;La gestion centralisée de la configuration, la validation des configurations et le bot management. La partie WAF est packagée avec OWASP (communauté publiant des recommandations pour la sécurisation des applications web) ModSecurity Core Rule Set (CRS) pour la détection des vulnérabilités. Dans le cadre d’un cluster un système de failover automatique avec auto-élection du leader (à la manière de GOSSIP avec Consul).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;une-vue-de-lavenir-&quot;&gt;Une vue de l’avenir ?&lt;/h3&gt;

&lt;p&gt;Aujourd’hui, Fusion Control Plane limite son scope à HAProxy Entreprise et Community Edition, les IngressController ne sont pour le moment pas encore supportés.&lt;/p&gt;

&lt;p&gt;Il n’est pas encore pleinement compatible avec les features offertes par AWS (Gestion des ASG et de Route53) mais c’est en cours de développement chez HAProxy Technologies.&lt;/p&gt;

&lt;p&gt;Le produit semble prometteur et intéressant. Les possibilités qu’il nous offre pour laisser la main aux développeurs sur la mise en place de routes vers leurs applications côté on-premise est vraiment un gros plus, mais il nous manque pour le moment le support de l’IngressController HAProxy utilisé sur nos cluster Kubernetes, ce qui nous empêche d’en profiter au maximum.&lt;/p&gt;

&lt;h2 id=&quot;vous-reprendrez-bien-un-peu-de-pétaoctets-&quot;&gt;Vous reprendrez bien un peu de pétaoctets ?&lt;/h2&gt;

&lt;p&gt;Chez Bedrock, un élément central de notre métier est de fournir de la vidéo à nos utilisateurs. (Incroyable pour une boite qui fait de la VOD hein? 😀).&lt;/p&gt;

&lt;p&gt;Pour ce faire nous avons nos propres serveurs CDN hébergés sur Paris, en complément des CDN publics comme Cloudfront ou Fastly. Cette année nous avons servis plusieurs centaines de PB de données via nos serveurs et nous espérons pouvoir au moins doubler ce trafic l’année prochaine !&lt;/p&gt;

&lt;p&gt;Notre architecture CDN est constituée d’un logiciel appelé LBCDN qui “load-balance” la charge sur les CDN, on-prem et publics, en redirigeant un utilisateur vers un serveur CDN spécifique.&lt;br /&gt;
Nos serveurs en eux-mêmes sont basés sur Nginx avec une configuration assez simple en direct IO sur de gros SSD.&lt;/p&gt;

&lt;p&gt;La HAproxy conf 2022 nous a pas mal inspirés pour répondre à nos problématiques avec ces deux conférences :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.haproxyconf.com/presentations/boost-your-web-apps-with-haproxy-and-varnish/&quot; target=&quot;_blank&quot;&gt;Boost your web apps with HAProxy and Varnish, by Jérémy Lecour CTO of Evolix&lt;/a&gt;:&lt;a href=&quot;https://www.youtube.com/watch?v=3HJUrcEWsl8&quot; target=&quot;_blank&quot;&gt;Video&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.haproxyconf.com/presentations/was-that-really-haproxy/&quot; target=&quot;_blank&quot;&gt;Was That really HAProxy, by Ricardo Nabinger Sanchez performance engineer at Taghos&lt;/a&gt;: &lt;a href=&quot;https://www.youtube.com/watch?v=Qz1zFVFYVcw&quot; target=&quot;_blank&quot;&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ces deux présentations font état d’une architecture sur les CDN intéressante où HAProxy est utilisé pour mettre “en sandwich” l’outil (ou les outils) faisant fonction de CDN.
L’architecture présentée semble permettre une configuration bien plus fine que ce que nous avons actuellement avec seulement Nginx.&lt;/p&gt;

&lt;p&gt;Par exemple, sur nos CDN on-prem nous devons aujourd’hui utiliser une astuce pour que Nginx puisse dynamiquement aller résoudre le nom de domaine du backend sur lequel il source ses fichiers. Cela est déjà un peu dommage de ne pas avoir de mécanisme disponible nativement. De plus, ce mécanisme est difficile à coupler avec d’autres permettant d’avoir du fail-over par exemple.&lt;/p&gt;

&lt;p&gt;C’est ici qu’HAProxy pourrait intervenir pour résoudre notre problématique car il nous permet d’avoir du fail over et des tests plus fins sur l’état de santé des backends.&lt;/p&gt;

&lt;p&gt;De plus, nous sommes en train de tester une solution de second-tier de CDN qui, du fait de la complexité ajoutée à notre architecture de CDN, profiterait beaucoup d’une plus grande finesse de configuration.&lt;/p&gt;

&lt;p&gt;“Mais attends, tu n’as parlé que de HAProxy en backend là, tu triches un peu non? C’est pas un sandwich c’est une tartine de HAProxy là!”
Tout à fait, notre cas d’usage actuel n’a pas forcément besoin d’un HAProxy en frontal de Nginx.&lt;/p&gt;

&lt;p&gt;MAIS!&lt;/p&gt;

&lt;p&gt;C’est là que les conférences sont intéressantes car elles montrent que l’on peut mixer les backends.&lt;br /&gt;
Dans la conférence présentée par Ricardo, l’utilisation de deux backends (Varnish et hyper-cache) sur un même serveur est permise par un HAProxy. Cela permet de profiter de la complémentarité de ces services.&lt;br /&gt;
Dans notre cas, nous n’avons pas besoin de cela mais &lt;a href=&quot;https://www.youtube.com/watch?v=OjoDnlS4_1A&quot; target=&quot;_blank&quot;&gt;une autre conférence&lt;/a&gt; nous a mis la puce à l’oreille : &lt;a href=&quot;https://www.haproxyconf.com/presentations/writing-haproxy-filters-in-rust/&quot; target=&quot;_blank&quot;&gt;Writing HAProxy Filters in Rust&lt;/a&gt;, by Aleksandr Orlenko.&lt;br /&gt;
Cela pourrait nous permettre, avec un HAProxy en frontal, d’agréger plus finement les mesures de performances du serveur afin d’optimiser l’usage de ses ressources, ou déporter une partie du trafic sur un serveur moins chargé, ou encore de récupérer une partie des traitements actuellement effectués par le LBCDN.&lt;/p&gt;

&lt;p&gt;Ajouter cette fonctionnalité serait la belle cerise au kirsch au sommet de ce sandwich de HAProxy.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-12-23-haproxyconf-paris-2022/keynote_conf_2022_cake.png&quot; alt=&quot;cake illustration&quot; /&gt;&lt;/p&gt;

&lt;p&gt;“Il est bizarre ton sandwich”&lt;/p&gt;

&lt;p&gt;“Bon d’accord, c’est plutôt un gâteau à étages.”&lt;/p&gt;

&lt;p&gt;“Ok c’est mieux, mais je préfère les macarons de la HAProxy Conf 2022 quand même.”&lt;/p&gt;

&lt;h2 id=&quot;a-une-prochaine-fois-&quot;&gt;A une prochaine fois !&lt;/h2&gt;

&lt;p&gt;La HAProxyConf, c’était deux jours de conférences avec des orateurs venus de tous les coins du globe.&lt;br /&gt;
Une belle occasion pour nous d’en apprendre plus sur un outil que nous utilisons quotidiennement chez Bedrock.&lt;br /&gt;
Dans cet article, nous n’avons pas pu faire mention de tout ce qui nous a intéressé. Nous pourrions notamment citer les très intéressantes conférences au sujet de :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Docker et leur utilisation de l’outil Keda&lt;/li&gt;
  &lt;li&gt;Ou encore de SoundCloud et leurs mesures anti-DDOS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cette conférence était aussi l’occasion d’échanger avec l’équipe HAProxy autour de sujets techniques qui nous concernent, de voir que nous utilisions déjà certaines bonnes pratiques, mais aussi que nous avions de quoi nous améliorer.&lt;/p&gt;

&lt;p&gt;Suite à cette conférence, c’est HAProxy Fusion que nous attendons le plus. Fusion s’annonce comme l’outil idéal pour manager une flotte d’HAProxy. Jusqu’à présent, nous devions utiliser une solution maison &lt;a href=&quot;https://tech.bedrockstreaming.com/2021/11/18/hsdo&quot; target=&quot;_blank&quot;&gt;HSDO&lt;/a&gt;, fonctionnelle, mais très probablement moins bien intégrée qu’un outil directement fourni par HAProxy.&lt;/p&gt;</content><author><name>Bedrock</name></author><category term="haproxy" /><category term="haproxyconf" /><category term="conference" /><summary type="html">Bedrock était présent lors de la Conférence HAProxy qui se déroulait à Paris en novembre 2022 : en tant que speaker, avec la présentation de Vincent Gallissot, mais aussi en tant que spectateur. Cet article relate les points forts qui nous ont marqués.</summary></entry></feed>