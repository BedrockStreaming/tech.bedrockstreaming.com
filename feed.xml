<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://tech.bedrockstreaming.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://tech.bedrockstreaming.com/" rel="alternate" type="text/html" /><updated>2023-03-16T09:31:42+00:00</updated><id>https://tech.bedrockstreaming.com/feed.xml</id><title type="html">Bedrock Tech Blog</title><subtitle>Blog technique de Bedrock</subtitle><entry><title type="html">Bedrock Dev Facts #19</title><link href="https://tech.bedrockstreaming.com/2023/03/13/bedrock-dev-facts-19.html" rel="alternate" type="text/html" title="Bedrock Dev Facts #19" /><published>2023-03-13T00:00:00+00:00</published><updated>2023-03-13T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/03/13/bedrock-dev-facts-19</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/03/13/bedrock-dev-facts-19.html">&lt;p&gt;La fin de l’hiver approche, il est temps de faire un bilan ! Quelles bêtises le froid aura-t-il apportées parmi les devs ? ❄️&lt;/p&gt;

&lt;h1 id=&quot;la-confiance-&quot;&gt;La confiance 🤞&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/dev-facts-19/how-to-test.png&quot; alt=&quot;Image d&apos;une Pull Request indiquant &apos;How to test ? Trust me&apos;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;mieux-quun-readme&quot;&gt;Mieux qu’un readme&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Quand le mec t’explique la solution, et finit par :&lt;/p&gt;

  &lt;p&gt;“Enfin ça c’est si mon code a bien continué d’être copié collé partout”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;une-éthique-moi-&quot;&gt;Une éthique, moi ?&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Moi je peux mettre du code dégueulasse un peu partout, c’est pas un problème !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;le-socrate-des-temps-modernes&quot;&gt;Le Socrate des temps modernes&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;La vie est un Spike&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;on-apprend-de-ses-erreurs&quot;&gt;On apprend de ses erreurs&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Set up a reminder “@myself ne jamais dire ‘je finis aujourd’hui’” in this channel at 9h45AM every day.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;en-tout-bien-tout-honneur-️&quot;&gt;En tout bien tout honneur ❤️&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Ah bah go, mets-moi en dur si tu veux.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;git-101&quot;&gt;GIT 101&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;J’en ai connu certains, à chaque fois qu’ils avaient un conflit sur leur branche, ils supprimaient le repo avant de le re-cloner&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ten-seconds-before-disaster&quot;&gt;Ten seconds before disaster&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Le cache, c’est nul !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;shoehashole-boolean-&quot;&gt;shoeHasHole: boolean 👟&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : ‘tin j’ai un trou dans ma chaussure&lt;/p&gt;

  &lt;p&gt;B : Tu es sûr que c’est pas un false ?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;on-a-tous-un-env-de-test-certains-ont-aussi-un-env-de-prod&quot;&gt;On a tous un env de test. Certains ont aussi un env de prod.&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/dev-facts-19/dev-env.png&quot; alt=&quot;Extrait de code définissant la variable DEV_ENV comme égal à prod&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;peur-de-rien-sauf-dune-chose&quot;&gt;Peur de rien, sauf d’une chose…&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : Ça finit en devs qui se reconvertissent Boulanger ça.&lt;/p&gt;

  &lt;p&gt;B : Certes, mais l’inverse est vrai aussi, il arrive que des Boulangers se reconvertissent après être devenus allergiques à la Farine.&lt;/p&gt;

  &lt;p&gt;A : C’est pour ça que je ne me reconvertirai pas en Barman… trop peur…&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;la-confiance-second-épisode-&quot;&gt;La confiance, second épisode 🤞&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;C’est pas n’importe quoi, juste un peu yolo !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;comme-de-leau-de-roche-trouble-&quot;&gt;Comme de l’eau de roche trouble !&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Franchement, je trouve ça clair ! Mais je comprends pas..&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;de-rares-génies-&quot;&gt;De rares génies 💡&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;On est peut-être des lumières, mais ça ne veut pas dire qu’on est tous allumés !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;cassage-de-prod-dans-3-2-1&quot;&gt;Cassage de prod dans 3… 2… 1…&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;J’le sens bien là. J’le sens bien bien bien.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;its-not-a-bug-its-a-feature&quot;&gt;It’s not a bug, it’s a feature&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;J’ai vérifié, le bug marchait bien.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;toujours-lire-les-petites-lignes-&quot;&gt;Toujours lire les petites lignes 🔎&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Tout* marche du coup !&lt;/p&gt;

  &lt;p&gt;(*pour l’instant)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;miaou-&quot;&gt;Miaou 🐱📈&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : Je théorise que le chat ne miaule devant la porte que pour savoir s’il pourrait passer quand il aura envie.&lt;/p&gt;

  &lt;p&gt;B : Ouah ton chat il fait du monitoring de la porte !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;facile-comme-tout-&quot;&gt;Facile comme tout !&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;TKT ! tu mets ton JSON dans le yaml et ça ira !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;une-grande-histoire-damour-épisode-1&quot;&gt;Une grande histoire d’amour, épisode 1&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Moi, j’adore le JSON&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;une-grande-histoire-damour-épisode-2&quot;&gt;Une grande histoire d’amour, épisode 2&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Le mail et le DNS c’est ma grande passion&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;partir-comme-un-roi-&quot;&gt;Partir comme un roi 👑&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/dev-facts-19/mic-drop.png&quot; alt=&quot;Image d&apos;une pull request nommée &amp;quot;Wesh je fais ce squash et je touche plus a rien. Mic drop.&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;les-grandes-questions-de-la-vie-&quot;&gt;Les grandes questions de la vie 🥐&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;D’ailleurs c’est LinkedIn ou pain au linked ?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;lhumour-pour-les-nuls&quot;&gt;L’humour pour les nuls&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : &lt;em&gt;Pouffe de rire&lt;/em&gt;&lt;/p&gt;

  &lt;p&gt;B : Tout va bien ?&lt;/p&gt;

  &lt;p&gt;A : Désolé, je viens de relire ma vanne&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;les-progrès-de-lia-&quot;&gt;Les progrès de l’IA 🤖&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : Alors B, c’est quoi le format de date php de la constante de format ‘c’ ?&lt;/p&gt;

  &lt;p&gt;B : Tu m’as pris pour chatGPT ou quoi ?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;un-stagiaire-en-détresse&quot;&gt;Un stagiaire en détresse&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;TLDR: À l’aide svp&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;la-sécurité-pour-les-nuls&quot;&gt;La sécurité pour les nuls&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Brian is in the Keychain.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;promis-dans-le-contexte-cest-vrai&quot;&gt;Promis dans le contexte c’est vrai&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;On doit afficher des ronds, alors c’est mieux s’ils nous envoient des carrés.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1&gt;😳&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;(Au pire, si on a la main sur une regexp, c’est déjà plus qu’il n’en faut pour me faire rêver)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;la-sélection-naturelle&quot;&gt;La sélection naturelle&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Je suis d’accord que là il y a un bug, mais c’est un bug parce que je suis con !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;-1&quot;&gt;🍵&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Je suis en train de me rappeler de mon weekend, et spoiler mettre du rhum dans son thé ce n’est pas une bonne idée.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;error--task-completed-successfully&quot;&gt;Error : Task completed successfully&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/dev-facts-19/error-success.png&quot; alt=&quot;Screen de popup d&apos;erreur indiquant &apos;Build failed to complete successfully&apos;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;la-confiance-30-&quot;&gt;La confiance, 3.0 🤞&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Coucou, aujourd’hui, je pète la reco (en prod), mais c’est sous contrôle.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;un-instant-de-réalisme&quot;&gt;Un instant de réalisme&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Personnellement, je sais pas ce que je fous en développeur !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;thomas-the-train-&quot;&gt;Thomas the train 🚆&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/dev-facts-19/tchou-tchou.png&quot; alt=&quot;Message de status Slack indiquant &apos;Working remotely from the tchou tchuou&apos;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;turlututu-chapeau-pointu-&quot;&gt;Turlututu chapeau pointu !&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;On aurait dû dire c’est “chapeau perché”.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;mieux-quun-rappel-automatique-&quot;&gt;Mieux qu’un rappel automatique 🤯&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : Du coup, tu as envoyé un mail ?&lt;/p&gt;

  &lt;p&gt;B : Pas encore non ! J’attendais d’y penser !&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Bedrock</name></author><category term="devfacts" /><category term="humour" /><summary type="html">La fin de l’hiver approche, il est temps de faire un bilan ! Quelles bêtises le froid aura-t-il apportées parmi les devs ? ❄️</summary></entry><entry><title type="html">Why is Transit Gateway service not right for us?</title><link href="https://tech.bedrockstreaming.com/2023/03/02/aws_transit_gateway.html" rel="alternate" type="text/html" title="Why is Transit Gateway service not right for us?" /><published>2023-03-02T00:00:00+00:00</published><updated>2023-03-02T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/03/02/aws_transit_gateway</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/03/02/aws_transit_gateway.html">&lt;p&gt;Managing the network of many interconnected AWS accounts can quickly lead to having a messy network architecture.&lt;br /&gt;
Transit Gateway (TGW) service seems to be the way out of this. So how do you know if TGW is right for you?&lt;/p&gt;

&lt;p&gt;This blog post will introduce how the service works and explain why we chose not to carry on with our migration to AWS Transit Gateway.
&lt;!--more--&gt;&lt;/p&gt;
&lt;h2 id=&quot;transit-gateways-backstory&quot;&gt;Transit Gateway’s backstory&lt;/h2&gt;

&lt;p&gt;Transit Gateway is a network transit hub that connects multiple VPCs and On-Premises sites to allows control traffic between them.&lt;br /&gt;
It was created to provide a new approach of network implementation on AWS and to make network administration smoother.&lt;/p&gt;

&lt;p&gt;VPC peering is a point-to-point connection between 2 VPCs.&lt;br /&gt;
It is a great example of complex network management because it adds a new topology to the network architecture.&lt;br /&gt;
On this diagram you can see an example of VPC peering usage. It’s not that messy yet but at scale it will be.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-03-02-aws_tgw/tgw.png&quot; alt=&quot;Network architecture without Transit Gateway&quot; /&gt;&lt;/p&gt;

&lt;p&gt;By acting as a “cloud router”, TGW centralizes network connections and takes control of packet forwarding between VPCs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-03-02-aws_tgw/tgw2.png&quot; alt=&quot;Network architecture with Transit Gateway&quot; /&gt;&lt;/p&gt;

&lt;p&gt;VPC peerings are not required anymore, we go back to a simpler star network topology thanks to Transit Gateway which really does address the complexity and restrictions of VPC peerings.&lt;br /&gt;
At that point, TGW seems to be the perfect answer for a simpler network architecture.&lt;/p&gt;

&lt;h2 id=&quot;what-about-tgw-at-bedrock&quot;&gt;What about TGW at Bedrock?&lt;/h2&gt;

&lt;p&gt;We operate more than 20 different AWS accounts for our customers’ platforms. Each account has a VPC with at least 3 private and 3 public subnets. We also manage AWS accounts for internal tools like ECR repositories, monitoring tools and shared s3 buckets. We configured Site-to-Site VPNs from On-Premises infrastructure to all the VPCs in these accounts.&lt;/p&gt;

&lt;p&gt;From the creation of new AWS accounts to deploying the tenants’ platform, onboarding a new customer requires a lot of work and time.&lt;/p&gt;

&lt;p&gt;Configuring VPCs Site-to-Site VPN is one of the steps that requires a lot of work. This is why we were interested in Transit Gateway at first.&lt;/p&gt;

&lt;h3 id=&quot;proof-of-concept&quot;&gt;Proof of concept&lt;/h3&gt;

&lt;p&gt;We created a production like Proof of Concept infrastructure using three AWS accounts, two different regions, multiple VPCs and a single Site-to-Site VPN from TGW to On-Premises firewall.&lt;/p&gt;

&lt;h4 id=&quot;how-did-we-test-tgw&quot;&gt;How did we test TGW?&lt;/h4&gt;

&lt;p&gt;We started by trying to split routing domains.&lt;br /&gt;
Centralizing network connections also means (with correct ACLs or Security Groups) that VPCs can reach all other VPCs. We want to control that.&lt;br /&gt;
Transit Gateway attachments read their routes in the TGW route table they are associated to. This is how we manage routing domains.&lt;br /&gt;
We create a Transit Gateway routing table and create routes for target networks.&lt;br /&gt;
TGW attachments are able to propagate routes in a route table if we want to. But because of routing domains, we can’t use that option and we have to add routes manually (attachments only read routes in the route table).&lt;/p&gt;

&lt;p&gt;Then we tested Transit Gateway peering.&lt;br /&gt;
TGW is a regional service, this means that we need to have a TGW for each active AWS region. We use TGW peering to interconnect them.&lt;br /&gt;
We expected to have some way to propagate routes dynamically in the Transit Gateway peering route table. But it is not possible.&lt;/p&gt;

&lt;p&gt;The last thing we tested is migrating from VPC Site-to-Site VPN to TGW VPN.&lt;br /&gt;
Because of the amount of VPC Site-to-Site VPN we have, it was important for us to know if we could get a minimal down time on On-Premises to VPC connections when migrating to the Transit Gateway VPN.&lt;br /&gt;
This process requires a lot of time because routes have to be deleted and created manually on each side.&lt;/p&gt;

&lt;p&gt;Even if we noticed some pain points, tests went well. So we decided to initiate the migration to the Transit Gateway service.&lt;/p&gt;

&lt;h3 id=&quot;why-did-we-choose-to-rollback&quot;&gt;Why did we choose to rollback?&lt;/h3&gt;

&lt;p&gt;Everything was okay at first, we successfully migrated two VPC Site-to-Site VPN to our Transit Gateway VPN.&lt;/p&gt;

&lt;p&gt;But then previous pain points became barriers:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;creating and managing routing domains is possible, but makes it impossible to use dynamic route propagation&lt;/li&gt;
  &lt;li&gt;there is not option to propagate routes in VPC route table, they all have to be created manually&lt;/li&gt;
  &lt;li&gt;data transfer cost is too high (and multiplied by the number of region on which you deployed TGW if your packets go through all these regions)&lt;/li&gt;
  &lt;li&gt;migrating to Transit Gateway requires a planned maintenance because there is a network downtime&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We took some time to talk about what to do next and concluded that migrating to Transit Gateway will just move the complexity of configuring VPC Site-to-Site VPNs to configuring TGW attachments and routes.&lt;/p&gt;

&lt;p&gt;AWS support did not suggest enough solutions to the problems we faced, so we decided to rollback to VPC Site-to-Site VPNs.&lt;/p&gt;</content><author><name>Christian VAN DER ZWAARD</name></author><category term="on-premise" /><category term="cloud" /><category term="aws" /><category term="network" /><summary type="html">Managing the network of many interconnected AWS accounts can quickly lead to having a messy network architecture. Transit Gateway (TGW) service seems to be the way out of this. So how do you know if TGW is right for you? This blog post will introduce how the service works and explain why we chose not to carry on with our migration to AWS Transit Gateway.</summary></entry><entry><title type="html">Projet XState</title><link href="https://tech.bedrockstreaming.com/2023/02/08/projet-xstate.html" rel="alternate" type="text/html" title="Projet XState" /><published>2023-02-08T00:00:00+00:00</published><updated>2023-02-08T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/02/08/projet-xstate</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/02/08/projet-xstate.html">&lt;p&gt;Dans une application frontend moderne, la gestion d’état est un élément central de son bon fonctionnement. Malgré les nombreuses librairies disponibles (Redux, MobX, Recoil…), cette tache reste complexe à réaliser et il est facile de perdre le contrôle.&lt;/p&gt;

&lt;p&gt;Dans l’objectif de rester maitre de son application, je vous propose de découvrir XState, une librairie reposant sur le concept de machine à états. Si l’outil ne fait pas tout, le concept de machine à état aide grandement à concevoir une application résiliente.&lt;/p&gt;

&lt;p&gt;Pour présenter au mieux les concepts, la théorie sera suivie de pratique au travers d’un live coding.&lt;/p&gt;</content><author><name>Maxime Blanc</name></author><category term="xstate" /><category term="lyonjs" /><category term="meetup" /><category term="react" /><category term="javascript" /><category term="conference" /><summary type="html">Dans une application frontend moderne, la gestion d’état est un élément central de son bon fonctionnement. Malgré les nombreuses librairies disponibles (Redux, MobX, Recoil…), cette tache reste complexe à réaliser et il est facile de perdre le contrôle.</summary></entry><entry><title type="html">A journey into connected TVs industrialisation process, Part 1</title><link href="https://tech.bedrockstreaming.com/2023/01/10/bedrock-app-launcher.html" rel="alternate" type="text/html" title="A journey into connected TVs industrialisation process, Part 1" /><published>2023-01-10T00:00:00+00:00</published><updated>2023-01-10T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/01/10/bedrock-app-launcher</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/01/10/bedrock-app-launcher.html">&lt;p&gt;At Bedrock, we build and run streaming applications on a wide variety of OTT devices (more than 60 different ecosystems). While testing and experimenting is easy on web and mobile devices, even for non-developers, it’s not as easy for Connected TV (CTV). In this article, you’ll discover how all of our employees can now access testing and pre-release environments on TV devices, with ease and without any technical knowledge.&lt;/p&gt;

&lt;h2 id=&quot;bedrock-tvjs-project&quot;&gt;Bedrock TvJS Project&lt;/h2&gt;

&lt;h3 id=&quot;how-does-it-work-&quot;&gt;How does it work ?&lt;/h3&gt;

&lt;p&gt;To address the growing number of CTVs vendors in the market, we have a one-and-only monorepo project named “TVJS”. It is a React application which we can deploy almost everywhere almost anywhere with the same code, UI and UX. The magic part? There isn’t much manufacturer-specific code in that application, most of those particularities are handled by our homemade JS library named PELO (Platform Easy Life Officer). &lt;em&gt;For non-French readers, “pélo” is a Lyon/Grenoble city slang to designate “someone”.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-01-10-bedrock-app-launcher/pelo-cli.png&quot; alt=&quot;Pelo&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In a few words, PELO is a set of libraries showing a unified front API for TV developers, so they don’t have to keep in mind every TV specific details and custom APIs (like lifecycle, keyboard, storage handling, and more). PELO also provides several CLI tools allowing the use of proprietary manufacturer SDKs, with a common shared API.&lt;/p&gt;

&lt;p&gt;There are at least two ways to deploy a TV application:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;A fully packaged solution, where all application files and resources are stored on the TV. Everytime you want to update it, application you have to go through the manufacturer QA process. Doing so, you can develop either a web application that will run through the TV’s Web Engine, or a native TV application.&lt;/li&gt;
  &lt;li&gt;The hosted solution, where the TV packaged application only redirects to a web application that you are responsible for. It grants much more flexibility, and delivery speed, as deployment and propagation of a new version are almost instantaneous.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We chose the second way as we are addressing a big number of devices and need all the flexibility we can have for deployments – and, sadly, for rollbacks too. Therefore, we host and deploy our CTV applications like any other website and we control the TV Browser Engine to navigate to specific domain names.&lt;/p&gt;

&lt;p&gt;Three teams are working on this project, on the same repository:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a team dedicated to Core features (like catalog, user lifecycle)&lt;/li&gt;
  &lt;li&gt;a team dedicated to Player features (video playback and advertising)&lt;/li&gt;
  &lt;li&gt;and a team supporting legacy devices&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Developer teams are supported by a QA team. It is responsible for functional quality assurance on Pull Requests and pre-releases. Quality assurance designates any processes to ensure a service meets its quality requirements in terms of experience, stability, …&lt;/p&gt;

&lt;h3 id=&quot;develop--release-process&quot;&gt;Develop &amp;amp; release process&lt;/h3&gt;

&lt;p&gt;We do our maximum to ensure the best quality of service and experience of what we deliver to our customers and their end-users. We have a strong culture of automated testing &amp;amp; tech reviewing which allows us to deliver almost without a sweat… Still, at our scale, missing a bug means a bad experience for thousands or millions of people! And that’s something we won’t accept without a fight!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;One of Bedrock’s Values is: ROCK-SOLID, ALWAYS&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As a consequence, we also have dedicated QA teams testing our work for a subset of device models and versions, before it is being merged to the main codebase, and before going to production as part of a release. They are doing so by connecting TVs to specific environments that are deployed on-demand: previews and staging.&lt;/p&gt;

&lt;p&gt;Let’s show off a little bit: at the beginning of 2022, thanks to the TVJS project, we were able to deploy production code to 7 manufacturers, and 38 device versions, meaning 266 combinations to check before launching a release into production! And these numbers are ever increasing!&lt;/p&gt;

&lt;h3 id=&quot;my-wish-make-testing-environments-easily-accessible&quot;&gt;My wish: make testing environments easily accessible&lt;/h3&gt;

&lt;p&gt;We love showing-off a bit over the applications we deliver on such a huge number of device models, but that doesn’t go with ease nor without pain.&lt;/p&gt;

&lt;p&gt;Testing a specific environment on a device was not possible for non-project members (other teams, support, business &amp;amp; product teams, managers …). Starting a preview or a staging application requires a deep understanding of the project, proprietary SDKs (even with our PELO CLI), shell, Git commands and advanced knowledge of how devices work in Developer Mode. This was a major issue: it causes interruptions for developers, slows delivery down, reduces our Time To Market.&lt;/p&gt;

&lt;p&gt;QA teams assigned to the project know its basics, they can use PELO CLI and proprietary SDKs, but cannot debug issues they may encounter with such tools: they have to ask developers to take actions for them (as this is not their core job). Using those tools is also time-consuming and time is of the essence when running quality checks while preparing a release.&lt;/p&gt;

&lt;p&gt;Many teams also want to start environments by themselves, to test their own developments on back-end services, to investigate when a customer creates a support ticket, …
The most important of them are Video teams, responsible for video encoding, transcoding and packaging: they are constantly testing new streams and features, and need a way to test their content by themselves, without asking around for a TVJS developer.&lt;/p&gt;

&lt;h2 id=&quot;our-answer-the-launcher-app-&quot;&gt;Our answer: The Launcher App !&lt;/h2&gt;

&lt;h3 id=&quot;what-does-it-do-&quot;&gt;What does it do ?&lt;/h3&gt;

&lt;p&gt;I’ve developed a TV application to quickly and efficiently start a specific environment. Using the TV remote, people can select the wanted environment and be redirected to it instantly, having the app like they would with the specific app installed.&lt;/p&gt;

&lt;p&gt;Typing long texts is painful for TV users. So, when selecting the preview environment, it shows another set of options where users can input a specific PR number. A background process will ask our Github if it knows the PR number, if it is deployed on the selected customer/manufacturer and will pre-fill the branch name. If not specified, it will default back to our master preview that is updated whenever we merge code to the master branch.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-01-10-bedrock-app-launcher/launcher-demo.gif&quot; alt=&quot;Launcher demo&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;technical-architecture&quot;&gt;Technical Architecture&lt;/h3&gt;

&lt;p&gt;The launcher is part of the TVJS monorepo, developed using React and re-using modules and packages for UI and Navigation allowing it to have minimum maintenance cost.&lt;/p&gt;

&lt;p&gt;For the first iterations of development of the launcher, I hosted it on AWS Amplify, but the Core team quickly integrated it back to a regular production deployment process we have at Bedrock.&lt;/p&gt;

&lt;p&gt;An automatic process builds the javascript bundle and assets and sends everything to AWS S3. The launcher will then be served through Fastly CDN. We build and deploy a unique launcher per compatible manufacturer on their own domain names (as-of-writing, Samsung Tizen, LG webOS and Hisense). For security reasons, those Fastly services are only accessible from our office networks.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-01-10-bedrock-app-launcher/launcher-tech-arch.png&quot; alt=&quot;Launcher technical architecture&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;unreliability-of-launcher-app-installation&quot;&gt;Unreliability of launcher app installation&lt;/h3&gt;

&lt;p&gt;I’m proud of this launcher and it is already saving loads of time for our QA teams ! They love it, as it helps them focus on their primary role: ensuring service &amp;amp; experience quality. Still, installing the launcher application on every device in our office is a huge amount of work! And, unfortunately, not a persistent one.&lt;/p&gt;

&lt;p&gt;To develop and test apps on live devices, we need to set them in “Developer Mode”. And each manufacturer has its own way, more or less time-consuming. Worse, whenever Developer Mode expires, all applications installed during this time are uninstalled from the device! Which means we have to install the launcher again after a brief period of time.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://developer.samsung.com/smarttv/develop/getting-started/using-sdk/tv-device.html&quot;&gt;Tizen Developer Mode&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://webostv.developer.lge.com/develop/getting-started/developer-mode-app&quot;&gt;LG webOS Developer Mode&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That period of time varies. For Samsung Tizen, we’re not absolutely sure, but it’s almost a month. For LG webOS, it is 50 hours if you don’t extend the Developer Mode or if you connect another TV with the same Developer Account.&lt;/p&gt;

&lt;p&gt;Specifically for LG, I did set up a CRON that automatically extends the Developer Mode, but sometimes it is being disconnected without reason… Or a mishandling by team members can cause the CRON to fail.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-01-10-bedrock-app-launcher/webos-cron.png&quot; alt=&quot;LG webOS CRON configuration to extend Developer Mode&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-01-10-bedrock-app-launcher/webos-extend-devmode.gif&quot; alt=&quot;Programmatically extending the Developer Mode on LG webOS&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Therefore, we aren’t 100% sure the launcher application will be up and ready on all the office devices when work begins in the morning, which means developers will have to manually re-install the launcher when asked by another Bedrock employee. It generates frustration for both QA and developers as they are wasting precious time to re-install the launcher.&lt;/p&gt;

&lt;p&gt;Don’t worry though, I already have a couple of ideas to ensure the installation becomes reliable! I’ll talk more about these it in a future article.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Any Bedrock employee can now start an office CTV, use the launcher app, select customer and environment, hit Let’s Go and access the environment they need to work!&lt;/p&gt;

&lt;p&gt;What we started to measure, and hopefully we’ll have more refined metrics over the next months, is the time QA teams are gaining per day. They needed an average of 15 minutes to start up a TV, set up the Developer Mode, and install the wanted app through CLI. They are validating 5 PRs per day, on 2 different devices at minimum, they almost gain one hour per day. That means our Time To Market is faster, and our QA teams have more time to do exploratory testing as well as refining their tests and writing more automated tests. Something that is not as measurable as time, is the enhanced peace of mind for them to go to work every morning knowing they have a tool designed for them to focus on their core work.&lt;/p&gt;

&lt;p&gt;This has improved the QA team overall velocity! And it makes the whole project more accessible for any employee. However, there is still room for improvement regarding launcher deployment and stability over time, and this is something I will cover in our next article.&lt;/p&gt;

&lt;p&gt;I hope you liked this article and it helped you if you’re trying to achieve something similar!&lt;/p&gt;</content><author><name>Bedrock</name></author><summary type="html">At Bedrock, we build and run streaming applications on a wide variety of OTT devices (more than 60 different ecosystems). While testing and experimenting is easy on web and mobile devices, even for non-developers, it’s not as easy for Connected TV (CTV). In this article, you’ll discover how all of our employees can now access testing and pre-release environments on TV devices, with ease and without any technical knowledge.</summary></entry><entry><title type="html">Nos retours sur l’HAProxyConf Paris 2022</title><link href="https://tech.bedrockstreaming.com/2022/12/23/haproxyconf-paris-2022.html" rel="alternate" type="text/html" title="Nos retours sur l’HAProxyConf Paris 2022" /><published>2022-12-23T00:00:00+00:00</published><updated>2022-12-23T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/12/23/haproxyconf-paris-2022</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/12/23/haproxyconf-paris-2022.html">&lt;p&gt;Bedrock était présent lors de la Conférence HAProxy qui se déroulait à Paris en novembre 2022 : en tant que speaker, avec la présentation de Vincent Gallissot, mais aussi en tant que spectateur. Cet article relate les points forts qui nous ont marqués.&lt;/p&gt;

&lt;p&gt;La présentation de Vincent Gallissot, Lead Cloud Architect chez Bedrock, mettait en valeur l’usage d’HAProxy en tant que brique essentielle de notre infrastructure. Chez Bedrock, nous développons et maintenons une plateforme de streaming qui a été migrée dans le Cloud en 2019. Cette présentation était grandement inspirée de l’article intitulé &lt;a href=&quot;https://tech.bedrockstreaming.com/2021/12/15/scaling-bedrock-video-delivery-to-50-million-users.html&quot; target=&quot;_blank&quot;&gt;“Scaling Bedrock video delivery to 50 million users”&lt;/a&gt;, dans lequel vous trouverez pléthore d’informations concernant nos utilisations d’HAProxy.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-12-23-haproxyconf-paris-2022/keynote_conf_2022_bedrockstreaming.jpg&quot; alt=&quot;Vincent Gallissot presentation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sommaire&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#ce-que-des-millions-de-requêtes-par-seconde-signifient-en-termes-de-coût-et-déconomie-dénergie&quot;&gt;Ce que des millions de requêtes par seconde signifient en termes de coût et d’économie d’énergie&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#un-outil-pour-les-gouverner-tous&quot;&gt;Un outil pour les gouverner tous&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#vous-reprendrez-bien-un-peu-de-pétaoctets-&quot;&gt;Vous reprendrez bien un peu de pétaoctets?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ce-que-des-millions-de-requêtes-par-seconde-signifient-en-termes-de-coût-et-déconomie-dénergie&quot;&gt;Ce que des millions de requêtes par seconde signifient en termes de coût et d’économie d’énergie.&lt;/h2&gt;

&lt;p&gt;La keynote d’ouverture avait pour orateur &lt;a href=&quot;https://twitter.com/willytarreau&quot; target=&quot;_blank&quot;&gt;Willy Tarreau&lt;/a&gt;, le Lead Developer d’HAProxy.&lt;br /&gt;
Au travers d’une démonstration concrète mélangeant software et hardware, l’objectif était de :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;transmettre l’idée qu’ajouter une brique logicielle dans un système ne le dégrade pas pour autant, bien au contraire&lt;/li&gt;
  &lt;li&gt;sensibiliser l’audience quant à la consommation d’énergie de nos systèmes&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;contexte-technique-et-premières-améliorations&quot;&gt;Contexte technique et premières améliorations&lt;/h3&gt;

&lt;p&gt;Pour ce premier cas d’étude, Willy Tarreau nous présente le cas d’un service de vente en ligne.&lt;/p&gt;

&lt;p&gt;La stack technique est composée de PHP / pgSQL (NodeJS + Symfony) et les images sont stockées en base de données. C’est cette architecture qui sera mise à l’épreuve lors des tests de charge à venir.&lt;/p&gt;

&lt;p&gt;Dans un premier temps, plusieurs améliorations (sans HAProxy) sont proposées. Il peut s’agir d’un simple rappel, voir d’un pro-tip d’architecture pour les plus novices : Les images en base de données, c’est une mauvaise idée.&lt;/p&gt;

&lt;p&gt;En les déplaçant vers un CDN, le système peut rapidement et simplement doubler ses performances, la base de données étant un goulot d’étranglement. La taille des pages peut être optimisée via l’activation de l’option http “gzip”. Les informations de sessions sont elles aussi enregistrées en base de données. Afin d’améliorer les performances, il est possible d’ajouter du caching via des outils tels que Memcache.&lt;/p&gt;

&lt;p&gt;Suite à cela, une première amélioration d’architecture serait d’ajouter un NLB (Network Load Balancer) en amont du système qui distribuerait les requêtes entrantes vers plusieurs unités de calculs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-12-23-haproxyconf-paris-2022/keynote_conf_2022_request_arch.png&quot; alt=&quot;next architecture schematic keynote&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Schéma d’architecture, première version&lt;/p&gt;

&lt;p&gt;Dans le cas présent, les requêtes entrantes sont distribuées de façon aléatoire entre les différentes unités de traitement. Chacun de ces backends se connectant à la même et unique base de données.&lt;br /&gt;
Le benchmark ci-dessous (efficacité, au sens nombre de requêtes traitées en fonction du nombre d’unités de calcul), ne montre pas une croissance linéaire. Il s’agit d’une courbe tendant vers une pente nulle (voir négative pour les plus grosses architectures).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-12-23-haproxyconf-paris-2022/keynote_conf_2022_nlb_stats.png&quot; alt=&quot;stats of nlb with backends&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Graphique représentant l’efficacité du système en fonction du nombre de backends&lt;/p&gt;

&lt;h3 id=&quot;comment-expliquer-que-cette-architecture-ne-scale-pas-linéairement-&quot;&gt;Comment expliquer que cette architecture ne scale pas linéairement ?&lt;/h3&gt;

&lt;p&gt;Malgré les améliorations apportées pour les sessions grâce au cache, il subsiste encore un problème.&lt;/p&gt;

&lt;p&gt;Le NLB est un composant qui ne fait que répartir la charge sans tenir compte de l’historique des requêtes. En effet, celui-ci va distribuer la charge d’entrée aléatoirement vers les backends.&lt;br /&gt;
Chaque backend reçoit des requêtes provenant de n’importe quel utilisateur impliquant alors un cache-miss très élevé : l’utilisateur est rarement trouvé dans le cache, ce qui génère une requête supplémentaire en base de données et dégrade les performances en plus de consommer inutilement des ressources.&lt;/p&gt;

&lt;h3 id=&quot;et-si-nous-ajoutons-haproxy-à-notre-système-&quot;&gt;Et si nous ajoutons HAProxy à notre système ?&lt;/h3&gt;

&lt;p&gt;C’est ici qu’entre en jeu HAProxy en remplaçant le NLB. Pour cela, pas besoin d’un foudre de guerre en termes de ressources.&lt;/p&gt;

&lt;p&gt;Les tests ont été effectués sur une machine ARM Breadbee cadencée à 1 GHz et possédant 64 Mo de RAM. Nous verrons également par la suite qu’on pourrait même se passer d’une machine supplémentaire.&lt;/p&gt;

&lt;p&gt;Le but d’HAProxy est de spécialiser les caches des backends et plus globalement de forcer les sessions utilisateurs vers les mêmes backends.&lt;/p&gt;

&lt;p&gt;Pour cela, HAProxy effectue une inspection de la couche 7 du trafic et renvoie toutes les requêtes d’un même utilisateur sur une même machine en réduisant ainsi les cache-miss aux seuls cas des nouveaux clients se connectant à la plateforme. Ainsi, le nombre d’appels à la base de données pour récupérer les informations de session est drastiquement réduit, la majorité d’entre elles étant stockées en cache.&lt;/p&gt;

&lt;p&gt;Autre fonctionnalité de taille : HAProxy limite le nombre de requêtes faites en parallèle sur un même backend, ce qui limite les locks de processus et les temps d’attente. Ceci a pour conséquence directe de réduire la consommation CPU.&lt;/p&gt;

&lt;p&gt;Ces deux améliorations permettent à l’application de scaler de façon beaucoup plus linéaire, tout en réduisant les consommations CPU et énergétiques inutiles. Globalement, les performances initiales sont largement dépassées avec deux fois moins de backends.&lt;/p&gt;

&lt;h3 id=&quot;a-partir-de-quand-est-il-intéressant-de-franchir-le-pas-&quot;&gt;A partir de quand est-il intéressant de franchir le pas ?&lt;/h3&gt;

&lt;p&gt;Maintenant que les bénéfices d’HAProxy ont été présentés, la prochaine étape est de se demander : quand est-ce qu’on se lance ? La question est considérée en termes de performance, mais aussi sous un angle pécunier.&lt;br /&gt;
Si HAProxy peut être intégré sans augmenter les coûts du système, c’est encore mieux.&lt;/p&gt;

&lt;p&gt;Ajouter HAProxy dans un système composé d’un seul backend n’apporte pas de bénéfice : il n’y a pas de load-balancing possible. Avec deux backends, si on divise le besoin de processing par deux, nous n’avons plus qu’un seul backend et donc pas de load-balancing possible.&lt;br /&gt;
C’est en fait à partir de 4 backends que l’ajout d’un HAProxy en entrée devient intéressant :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;en retirant 2 serveurs de nos backends en conservant une puissance équivalente (cf les tests ci-dessus)&lt;/li&gt;
  &lt;li&gt;et en recyclant un des deux backends retirés en hôte pour HAProxy
En fin de compte, pour une même puissance de traitement, un backend est retiré ce qui permet de réduire les coûts de fonctionnement. Ce principe s’applique également sur un grand nombre de backends.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;C’est là que prend tout son sens l’expression qui avait été utilisée pour conclure cette keynote : “HAProxy is a free software running on free hardware”.&lt;/p&gt;

&lt;p&gt;Chez Bedrock, nous appliquons aussi ces différentes techniques de Consistent Hashing en entrée de notre CDN vidéo. Nos caches vidéos sont spécialisés et chaque utilisateur est redirigé vers un unique backend lors de la lecture d’une vidéo.&lt;br /&gt;
Pour en savoir plus, vous pouvez consulter notre article au sujet du &lt;a href=&quot;https://tech.bedrockstreaming.com/2021/11/18/hsdo.html&quot; target=&quot;_blank&quot;&gt;Consistent Hashing&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;un-outil-pour-les-gouverner-tous&quot;&gt;Un outil pour les gouverner tous&lt;/h2&gt;

&lt;p&gt;Dans notre activité en informatique, nous sommes amenés à délivrer de plus en plus rapidement des applications, des mises à jour, etc… Nous avons donc adopté la philosophie DevOps et tout un panel d’outils autour de celle-ci afin de sécuriser, monitorer et automatiser chaque étape de nos pipelines de livraison.&lt;/p&gt;

&lt;p&gt;Le cas de figure du load balancing est intéressant dans ce type d’organisation, il est essentiel d’exposer de nouvelles applications sur les environnements de production mais étant donné que la maîtrise de cet outil requiert une compréhension du réseau, la responsabilité incombe souvent à l’équipe Ops de le gérer.&lt;/p&gt;

&lt;h3 id=&quot;vous-souhaitez-mieux-gérer-votre-flotte-haproxy-&quot;&gt;Vous souhaitez mieux gérer votre flotte HAProxy ?&lt;/h3&gt;

&lt;p&gt;Anjelko Iharos, directeur de l’ingénierie à HAProxy Technologies nous a présenté leur nouvel outil d’automatisation : HAProxy Fusion Control Plane, packagé dans la version entreprise de HAProxy.&lt;/p&gt;

&lt;p&gt;Celui-ci va amener une nouvelle interface enrichie afin de gérer toutes les instances HAProxy et les outils gravitant autour de ces dernières.&lt;/p&gt;

&lt;p&gt;On peut citer :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;La possibilité pour les développeurs de router eux-même leurs applications sans avoir besoin d’un Ops dans leurs pipelines de CI via l’API Fusion.&lt;/li&gt;
  &lt;li&gt;Gérer les WAF de HAProxy de manière centralisée et répercuter cette configuration sur un ensemble de clusters/instances.&lt;/li&gt;
  &lt;li&gt;Permettre aux Ops de gérer la structure de leurs load balancers, ajouter de nouvelles instances, gérer les certificats SSL, le tuning des performances depuis un seul point d’entrée.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;est-ce-résilient-&quot;&gt;Est-ce résilient ?&lt;/h3&gt;

&lt;p&gt;Fusion Control Plane est livré avec tout un set de features intéressantes pour assurer sa maintenabilité et sa résilience :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Une pleine observabilité avec une application unifiée de récupération de logs, métriques et rapports dans la même interface. L’export de ces data est possible, notamment pour les transposer dans un dashboard tiers (Grafana, par exemple).&lt;/li&gt;
  &lt;li&gt;Un système de RBAC permettant de mieux gérer les périmètres de chacune des équipes dans le control plane.&lt;/li&gt;
  &lt;li&gt;La gestion centralisée de la configuration, la validation des configurations et le bot management. La partie WAF est packagée avec OWASP (communauté publiant des recommandations pour la sécurisation des applications web) ModSecurity Core Rule Set (CRS) pour la détection des vulnérabilités. Dans le cadre d’un cluster un système de failover automatique avec auto-élection du leader (à la manière de GOSSIP avec Consul).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;une-vue-de-lavenir-&quot;&gt;Une vue de l’avenir ?&lt;/h3&gt;

&lt;p&gt;Aujourd’hui, Fusion Control Plane limite son scope à HAProxy Entreprise et Community Edition, les IngressController ne sont pour le moment pas encore supportés.&lt;/p&gt;

&lt;p&gt;Il n’est pas encore pleinement compatible avec les features offertes par AWS (Gestion des ASG et de Route53) mais c’est en cours de développement chez HAProxy Technologies.&lt;/p&gt;

&lt;p&gt;Le produit semble prometteur et intéressant. Les possibilités qu’il nous offre pour laisser la main aux développeurs sur la mise en place de routes vers leurs applications côté on-premise est vraiment un gros plus, mais il nous manque pour le moment le support de l’IngressController HAProxy utilisé sur nos cluster Kubernetes, ce qui nous empêche d’en profiter au maximum.&lt;/p&gt;

&lt;h2 id=&quot;vous-reprendrez-bien-un-peu-de-pétaoctets-&quot;&gt;Vous reprendrez bien un peu de pétaoctets ?&lt;/h2&gt;

&lt;p&gt;Chez Bedrock, un élément central de notre métier est de fournir de la vidéo à nos utilisateurs. (Incroyable pour une boite qui fait de la VOD hein? 😀).&lt;/p&gt;

&lt;p&gt;Pour ce faire nous avons nos propres serveurs CDN hébergés sur Paris, en complément des CDN publics comme Cloudfront ou Fastly. Cette année nous avons servis plusieurs centaines de PB de données via nos serveurs et nous espérons pouvoir au moins doubler ce trafic l’année prochaine !&lt;/p&gt;

&lt;p&gt;Notre architecture CDN est constituée d’un logiciel appelé LBCDN qui “load-balance” la charge sur les CDN, on-prem et publics, en redirigeant un utilisateur vers un serveur CDN spécifique.&lt;br /&gt;
Nos serveurs en eux-mêmes sont basés sur Nginx avec une configuration assez simple en direct IO sur de gros SSD.&lt;/p&gt;

&lt;p&gt;La HAproxy conf 2022 nous a pas mal inspirés pour répondre à nos problématiques avec ces deux conférences :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.haproxyconf.com/presentations/boost-your-web-apps-with-haproxy-and-varnish/&quot; target=&quot;_blank&quot;&gt;Boost your web apps with HAProxy and Varnish, by Jérémy Lecour CTO of Evolix&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.haproxyconf.com/presentations/was-that-really-haproxy/&quot; target=&quot;_blank&quot;&gt;Was That really HAProxy, by Ricardo Nabinger Sanchez performance engineer at Taghos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ces deux présentations font état d’une architecture sur les CDN intéressante où HAProxy est utilisé pour mettre “en sandwich” l’outil (ou les outils) faisant fonction de CDN.
L’architecture présentée semble permettre une configuration bien plus fine que ce que nous avons actuellement avec seulement Nginx.&lt;/p&gt;

&lt;p&gt;Par exemple, sur nos CDN on-prem nous devons aujourd’hui utiliser une astuce pour que Nginx puisse dynamiquement aller résoudre le nom de domaine du backend sur lequel il source ses fichiers. Cela est déjà un peu dommage de ne pas avoir de mécanisme disponible nativement. De plus, ce mécanisme est difficile à coupler avec d’autres permettant d’avoir du fail-over par exemple.&lt;/p&gt;

&lt;p&gt;C’est ici qu’HAProxy pourrait intervenir pour résoudre notre problématique car il nous permet d’avoir du fail over et des tests plus fins sur l’état de santé des backends.&lt;/p&gt;

&lt;p&gt;De plus, nous sommes en train de tester une solution de second-tier de CDN qui, du fait de la complexité ajoutée à notre architecture de CDN, profiterait beaucoup d’une plus grande finesse de configuration.&lt;/p&gt;

&lt;p&gt;“Mais attends, tu n’as parlé que de HAProxy en backend là, tu triches un peu non? C’est pas un sandwich c’est une tartine de HAProxy là!”
Tout à fait, notre cas d’usage actuel n’a pas forcément besoin d’un HAProxy en frontal de Nginx.&lt;/p&gt;

&lt;p&gt;MAIS!&lt;/p&gt;

&lt;p&gt;C’est là que les conférences sont intéressantes car elles montrent que l’on peut mixer les backends.&lt;br /&gt;
Dans la conférence présentée par Ricardo, l’utilisation de deux backends (Varnish et hyper-cache) sur un même serveur est permise par un HAProxy. Cela permet de profiter de la complémentarité de ces services.&lt;br /&gt;
Dans notre cas, nous n’avons pas besoin de cela mais une autre conférence nous a mis la puce à l’oreille : &lt;a href=&quot;https://www.haproxyconf.com/presentations/writing-haproxy-filters-in-rust/&quot; target=&quot;_blank&quot;&gt;Writing HAProxy Filters in Rust&lt;/a&gt;, by Aleksandr Orlenko.&lt;br /&gt;
Cela pourrait nous permettre, avec un HAProxy en frontal, d’agréger plus finement les mesures de performances du serveur afin d’optimiser l’usage de ses ressources, ou déporter une partie du trafic sur un serveur moins chargé, ou encore de récupérer une partie des traitements actuellement effectués par le LBCDN.&lt;/p&gt;

&lt;p&gt;Ajouter cette fonctionnalité serait la belle cerise au kirsch au sommet de ce sandwich de HAProxy.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-12-23-haproxyconf-paris-2022/keynote_conf_2022_cake.png&quot; alt=&quot;cake illustration&quot; /&gt;&lt;/p&gt;

&lt;p&gt;“Il est bizarre ton sandwich”&lt;/p&gt;

&lt;p&gt;“Bon d’accord, c’est plutôt un gâteau à étages.”&lt;/p&gt;

&lt;p&gt;“Ok c’est mieux, mais je préfère les macarons de la HAProxy Conf 2022 quand même.”&lt;/p&gt;

&lt;h2 id=&quot;a-une-prochaine-fois-&quot;&gt;A une prochaine fois !&lt;/h2&gt;

&lt;p&gt;La HAProxyConf, c’était deux jours de conférences avec des orateurs venus de tous les coins du globe.&lt;br /&gt;
Une belle occasion pour nous d’en apprendre plus sur un outil que nous utilisons quotidiennement chez Bedrock.&lt;br /&gt;
Dans cet article, nous n’avons pas pu faire mention de tout ce qui nous a intéressé. Nous pourrions notamment citer les très intéressantes conférences au sujet de :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Docker et leur utilisation de l’outil Keda&lt;/li&gt;
  &lt;li&gt;Ou encore de SoundCloud et leurs mesures anti-DDOS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cette conférence était aussi l’occasion d’échanger avec l’équipe HAProxy autour de sujets techniques qui nous concernent, de voir que nous utilisions déjà certaines bonnes pratiques, mais aussi que nous avions de quoi nous améliorer.&lt;/p&gt;

&lt;p&gt;Suite à cette conférence, c’est HAProxy Fusion que nous attendons le plus. Fusion s’annonce comme l’outil idéal pour manager une flotte d’HAProxy. Jusqu’à présent, nous devions utiliser une solution maison &lt;a href=&quot;https://tech.bedrockstreaming.com/2021/11/18/hsdo&quot; target=&quot;_blank&quot;&gt;HSDO&lt;/a&gt;, fonctionnelle, mais très probablement moins bien intégrée qu’un outil directement fourni par HAProxy.&lt;/p&gt;</content><author><name>Bedrock</name></author><category term="haproxy" /><category term="haproxyconf" /><category term="conference" /><summary type="html">Bedrock était présent lors de la Conférence HAProxy qui se déroulait à Paris en novembre 2022 : en tant que speaker, avec la présentation de Vincent Gallissot, mais aussi en tant que spectateur. Cet article relate les points forts qui nous ont marqués.</summary></entry><entry><title type="html">How Micro-Services changed our caching architecture</title><link href="https://tech.bedrockstreaming.com/2022/12/23/varnish-operator.html" rel="alternate" type="text/html" title="How Micro-Services changed our caching architecture" /><published>2022-12-23T00:00:00+00:00</published><updated>2022-12-23T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/12/23/varnish-operator</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/12/23/varnish-operator.html">&lt;p&gt;At Bedrock we use Cloudfront or Fastly for two different reason. To protect our applications from potential Distributed Denial of Service Attack. And to provide a layer of cache in front of our applications. No need to go down to the app for an easily cacheable response.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;before the project&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image0.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;At least that is what we thought in 2018 when we were migrating from on premise to the Cloud.&lt;/p&gt;

&lt;p&gt;At that time we had a Varnish instance caching everything at the border  of our on premise infrastructure. All the applications were running either on virtual machines or on bare metal servers. Those applications were mostly called by the end-user’s browser. Whenever an application called another application it did it through Varnish.&lt;/p&gt;

&lt;p&gt;This is ideal if applications are mostly called from the outside world. The Varnish instance caches all cacheable content, and it does not cost too much time as it was in the same Data Center.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;historically-before-2018&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image2.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;
In 2023, we think otherwise. We have now a &lt;a href=&quot;https://kops.sigs.k8s.io/&quot;&gt;KOps&lt;/a&gt; managed Kubernetes cluster running on EC2 spot instances in private subnets at AWS. As we migrated to the cloud we also embarked on the journey of splitting monolith into smaller more manageable microservices.&lt;/p&gt;

&lt;p&gt;With less monoliths the Bedrock product is more resilient and easier to scale but it changes the topologies of network calls. Before there were far more calls coming from the internet from end-users browsers. Now with the new architecture coming into place inter-app requests have increased.&lt;/p&gt;

&lt;p&gt;One solution would be to directly call the ingress of the applications, staying inside the cluster but without the benefit of caching as it is handled by the CDN. This would lead to unsustainable increase in CPU usage, and probably very little gain in terms of response time.&lt;/p&gt;

&lt;p&gt;A better solution for us would be to have the caching of CDN inside the cluster. This would enable us to have fast response time and little to no increase in CPU usage.&lt;/p&gt;

&lt;h1 id=&quot;enter-varnish-operator&quot;&gt;Enter Varnish-Operator&lt;/h1&gt;

&lt;p&gt;We tested the project &lt;a href=&quot;https://github.com/IBM/varnish-operator&quot;&gt;IBM/Varnish-Operator&lt;/a&gt;. This project allows us to create Custom Resources for Kubernetes handled by the Varnish-Operator. This object is called a VarnishCluster, the configuration is pretty simple to get started. This enables us to have a caching layer, between the Ingress-Controller and the Application.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;varnishcluster&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image1.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;VarnishCluster also uses Varnish Configuration Language (VCL) which we are pretty familiar with since we use Varnish On-Premise since 2015, and developers use it regularly to configure Fastly distribution.&lt;/p&gt;

&lt;p&gt;By adding cache using VarnishCluster to an application that is not fully cacheable, we almost divided it’s average response time by two. It is not a surprise as inter api calls used to look like the following graph:&lt;/p&gt;
&lt;center&gt;&lt;img alt=&quot;before-varnishcluster&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image3.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;We changed parameters in the application after adding VarnishCluster so that it calls other app inside the cluster like in the following graph:&lt;/p&gt;
&lt;center&gt;&lt;img alt=&quot;after-varnishcluster&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image4.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;a-few-details&quot;&gt;A few details&lt;/h1&gt;

&lt;p&gt;Before I wrap this up, here are a few details about the implementations.&lt;/p&gt;

&lt;p&gt;As you will be able to read in the Varnish documentation:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“By default Varnish will use 100 megabytes of malloc(3) storage for caching objects, if you want to cache more than that, you should look at the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-s&lt;/code&gt; argument.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So if you give many Gigs of memory to your Varnish container it won’t be attributed to the Varnish process. You can set it with the argument &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-s storage=malloc,&amp;lt;Number&amp;gt;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;As we use only Spot nodes that can be terminated by AWS at any moment with only 2 minutes notice, we want to give more resilience to our Varnish Clusters pod as cache is stored in RAM memory.
You lose all your cache at each restart of the Varnish Container.&lt;/p&gt;

&lt;p&gt;We configured &lt;a href=&quot;https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity&quot;&gt;podAntiAffinity&lt;/a&gt; between application pods and VarnishClusters’ to avoid scheduling those pods on the same node and be vulnerable to reclaims.&lt;/p&gt;

&lt;p&gt;We added a &lt;a href=&quot;https://kubernetes.io/docs/tasks/run-application/configure-pdb/&quot;&gt;podDisruptionBudget&lt;/a&gt; to avoid losing all our pods at the same time. We also customized the VCL a bit to make Varnish serve stale content in case our application is unreachable.&lt;/p&gt;

&lt;p&gt;We also added a Prometheus Service Monitor to make sure all Varnish metrics would be scraped by &lt;a href=&quot;https://tech.bedrockstreaming.com/2022/09/06/monitoring-at-scale-with-victoriametrics.html&quot;&gt;Victoria Metrics&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;in-the-future&quot;&gt;In the Future&lt;/h1&gt;

&lt;p&gt;In next versions we would like to add the possibility to configure &lt;a href=&quot;https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#priorityclass&quot;&gt;PriorityClass&lt;/a&gt; of VarnishClusters pod. PriorityClasses are used to order workloads priority.
In a context of scaling and of scarcity of resources, the scheduler will evict pods of lower priority to make room for the pod it is trying to schedule.&lt;/p&gt;

&lt;p&gt;For now our VarnishCluster’s pods have the PriorityClass by default but it is more critical than any other applications as it holds a cache in its memory.&lt;/p&gt;

&lt;p&gt;Also we do not have logs of Varnish. We would like to be able to stream VarnishLog content into &lt;a href=&quot;https://grafana.com/oss/loki/&quot;&gt;Loki&lt;/a&gt;. This would be super useful to debug and to investigate if we ever encounter bugs or unexpected behaviors.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;center&gt;&lt;img alt=&quot;average-Response-time after apps call through VarnishCluster&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image5.png&quot; /&gt;
&lt;p&gt;Average response time going down, red bar is when we pushed it in production&lt;/p&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;With the generalization of microservices, Bedrock needed to rethink its architecture to optimize not only for browser to API calls but also for more API to API usage. By adding VarnishCluster in front of our applications and calling them directly from inside the cluster we improved significantly the Bedrock product.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/IBM/varnish-operator&quot;&gt;The Github project&lt;/a&gt; is still young and lacks important features, we hope with this article to help draw attention to this project and potential contributors.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;meme-contribute-pls&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image6.jpg&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Arthur Zinck</name></author><category term="on-premise" /><category term="cloud" /><category term="cdn" /><category term="varnish" /><category term="aws" /><category term="cloud" /><category term="fastly" /><category term="varnish-operator" /><category term="cloudfront" /><category term="alb" /><summary type="html">At Bedrock we use Cloudfront or Fastly for two different reason. To protect our applications from potential Distributed Denial of Service Attack. And to provide a layer of cache in front of our applications. No need to go down to the app for an easily cacheable response.</summary></entry><entry><title type="html">Ce que nous retenons de la droidcon London 2022</title><link href="https://tech.bedrockstreaming.com/2022/11/22/droidcon-london-2022.html" rel="alternate" type="text/html" title="Ce que nous retenons de la droidcon London 2022" /><published>2022-11-22T00:00:00+00:00</published><updated>2022-11-22T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/11/22/droidcon-london-2022</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/11/22/droidcon-london-2022.html">&lt;p&gt;La communauté Android a apporté le soleil sur Londres les 27 et 28 octobre 2022. La droidcon London a réuni plus de 1400 développeurs autour de l’écosystème Android, de ses outils et enjeux actuels. Jetpack Compose, évidemment, mais aussi Gradle, modularisation, optimisation et autres sujets plus divers ont été abordés lors de ce rendez-vous incontournable pour la communauté.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/entrance.jpg&quot; alt=&quot;droidcon London 2022 entrance&quot; /&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#ça-compile----rafi-panoyan&quot; id=&quot;markdown-toc-ça-compile----rafi-panoyan&quot;&gt;Ça compile ? - Rafi Panoyan&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#vous-reprendrez-bien-un-peu-de-gradle-enterprise-&quot; id=&quot;markdown-toc-vous-reprendrez-bien-un-peu-de-gradle-enterprise-&quot;&gt;Vous reprendrez bien un peu de Gradle Enterprise ?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#dessine-moi-un-module&quot; id=&quot;markdown-toc-dessine-moi-un-module&quot;&gt;&lt;em&gt;Dessine-moi un module&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#trucs-et-astuces&quot; id=&quot;markdown-toc-trucs-et-astuces&quot;&gt;Trucs et astuces&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#design-the-world---damien-cuny&quot; id=&quot;markdown-toc-design-the-world---damien-cuny&quot;&gt;Design the world - Damien Cuny&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#to-compose&quot; id=&quot;markdown-toc-to-compose&quot;&gt;To Compose&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#design-system&quot; id=&quot;markdown-toc-design-system&quot;&gt;Design System&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#vers-linfini-et-au-delà&quot; id=&quot;markdown-toc-vers-linfini-et-au-delà&quot;&gt;Vers l’infini et au-delà&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#la-gestion-des-erreurs---david-yim&quot; id=&quot;markdown-toc-la-gestion-des-erreurs---david-yim&quot;&gt;&lt;strong&gt;La gestion des erreurs&lt;/strong&gt; - David Yim&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#vérification-des-entrées&quot; id=&quot;markdown-toc-vérification-des-entrées&quot;&gt;Vérification des entrées&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#le-type-either&quot; id=&quot;markdown-toc-le-type-either&quot;&gt;Le type Either&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#kotlin-result&quot; id=&quot;markdown-toc-kotlin-result&quot;&gt;Kotlin Result&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#conclusion&quot; id=&quot;markdown-toc-conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#à-la-prochaine-&quot; id=&quot;markdown-toc-à-la-prochaine-&quot;&gt;À la prochaine !&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ça-compile----rafi-panoyan&quot;&gt;Ça compile ? - Rafi Panoyan&lt;/h2&gt;

&lt;p&gt;Les sujets de compilation ont tenu une place très importante lors de cette édition de la droidcon Londres 2022. 
Qu’il s’agisse d’optimiser ses temps de compilation, de repenser la création de modules et des dépendances entre eux, de factoriser les logiques des scripts de compilation, 
nous avons eu une emphase claire sur l’importance d’adresser ces sujets.&lt;/p&gt;

&lt;h3 id=&quot;vous-reprendrez-bien-un-peu-de-gradle-enterprise-&quot;&gt;Vous reprendrez bien un peu de Gradle Enterprise ?&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/nellyspageli&quot;&gt;Nelson Osacky&lt;/a&gt;, qui travaille chez Gradle, a présenté tous les outils que la formule &lt;a href=&quot;https://gradle.com/&quot;&gt;Gradle Entreprise&lt;/a&gt; met à disposition des développeurs pour analyser en détail les compilations.&lt;/p&gt;

&lt;p&gt;Vous voulez vérifier que la compilation incrémentale est bien appliquée partout où cela est possible ? Un script permet de comparer, dans des conditions reproductibles, 
les entrées et sorties de vos builds, et analyse les tâches empêchant ce mécanisme central dans la réduction des temps de compilation.&lt;/p&gt;

&lt;p&gt;Vous voulez vous assurer que Gradle est bien capable de retrouver le cache de vos tâches sur un même poste ou bien depuis le cloud ? 
Là aussi des outils vous permettent d’identifier précisemment les points qui ne tirent pas parti de ces mécanismes.&lt;/p&gt;

&lt;p&gt;On regrettera que ces outils soient disponibles uniquement pour la formule payante de Gradle. Cependant, les &lt;a href=&quot;https://scans.gradle.com/&quot;&gt;scans Gradle&lt;/a&gt; sont, eux,
gratuits et illimités, et permettent tout de même de mesurer et comparer des compilations et ainsi suivre l’impact des différentes optimisations que vous pourriez apporter.&lt;/p&gt;

&lt;h3 id=&quot;dessine-moi-un-module&quot;&gt;&lt;em&gt;Dessine-moi un module&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;La modularisation ayant un impact sur les temps de compilation, plusieurs conférences ont abordé ce sujet très en vogue dans la communauté Android.&lt;/p&gt;

&lt;p&gt;Un point de vue intéressant de &lt;a href=&quot;https://twitter.com/josef_raska&quot;&gt;Josef Raska&lt;/a&gt; nous invite à nous poser la question de la pertinence de modulariser selon le contexte. 
Ne pas suivre une tendance mais se poser la question de l’utilité d’un nouveau module, et encore plus de ses dépendances avec les autres modules. 
Voilà des propos qui invitent à mesurer concrètement l’impact du chantier de la modularisation dans nos applications.&lt;/p&gt;

&lt;p&gt;Ainsi, si on peut penser que modulariser permet de réduire les temps de compilation (en tirant parti de la parallélisation des tâches par exemple), 
un chemin de dépendances trop long entre le module initial et la dépendance la plus profonde va entraîner une augmentation du temps de compilation.&lt;/p&gt;

&lt;p&gt;Vigilance, donc, sur les “hubs de dépendances” (ces dépendances dont beaucoup de modules ont besoin, et qui ont besoin de beaucoup de modules).&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/dep-hub.png&quot; alt=&quot;Dependency hub&quot; /&gt;
  &lt;figcaption&gt;1. Hub de dépendances&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;hr /&gt;

&lt;p&gt;De la même manière, un chemin de dépendances de trop grande profondeur ne permettra pas de tirer parti de la parallélisation des tâches de compilation.
Sur le schéma ci-dessous, on peut voir qu’un chemin de profondeur 4 existe pour aller du module applicatif vers le module le plus bas dans la hiérarchie.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/dep-height.png&quot; alt=&quot;Dependency height&quot; /&gt;
  &lt;figcaption&gt;2. Profondeur de dépendances&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;hr /&gt;

&lt;p&gt;Josef Raska propose le schéma suivant avec un découpage API/implémentation afin de réduire au maximum cette profondeur, et ainsi compiler plus rapidement.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/dep-height-fix.png&quot; alt=&quot;Dependency height fix&quot; /&gt;
  &lt;figcaption&gt;3. Profondeur de dépendances réduite&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;hr /&gt;

&lt;p&gt;Android Studio et son analyse de dépendances peut être très utile pour vérifier et mesurer cela.
Josef Raska a d’ailleurs créé un plugin Gradle afin de spécifier ces règles à l’echelle d’un projet et de s’assurer qu’elles soient respectées : &lt;a href=&quot;https://github.com/jraska/modules-graph-assert&quot;&gt;modules-graph-assert&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;trucs-et-astuces&quot;&gt;Trucs et astuces&lt;/h3&gt;

&lt;p&gt;Après ces conseils très avisés mais structurellement chronophages à mettre en place (surtout sur de gros projets déjà créés), d’autres conférenciers se sont plutôt tournés vers les “quick-win”. Des changements peu coûteux, aux gains plus modestes mais qui s’additionnent, il en existe quelques-uns.&lt;/p&gt;

&lt;p&gt;Ainsi, si Gradle nous permet d’activer des fonctionnalités de caching (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;org.gradle.unsafe.configuration-cache=true&lt;/code&gt; pour gagner du temps lors de la phase de configuration par exemple), il est aussi possible de désactiver des fonctionnalités du plugin Android si elles ne nous sont pas utiles.&lt;/p&gt;

&lt;p&gt;Voici une petite liste des propriétés qui sont activées par défaut, même lorsqu’elles ne sont pas utilisées dans les modules :&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;android {
  buildFeatures {
    buildConfig false
    aidl false
    renderScript false
    resValues false
    shaders false
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Si vous n’utilisez pas les valeurs liées à la configuration de votre compilation, ne générez pas de &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BuildConfig&lt;/code&gt;.
Si vous n’avez pas de resources dans votre module, désactivez la génération de &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;resValue&lt;/code&gt; !&lt;/p&gt;

&lt;p&gt;Retrouvez ici la liste de ces fonctionnalités, leur utilité et leurs valeurs par défaut : &lt;a href=&quot;https://developer.android.com/reference/tools/gradle-api/4.1/com/android/build/api/dsl/BuildFeatures&quot;&gt;BuildFeatures&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;design-the-world---damien-cuny&quot;&gt;Design the world - Damien Cuny&lt;/h2&gt;

&lt;p&gt;Il y a un peu plus d’un an sortait la version 1.0 de &lt;a href=&quot;https://developer.android.com/jetpack/compose&quot;&gt;Jetpack Compose&lt;/a&gt;, le nouveau toolkit déclaratif pour la création d’interfaces Android. D’autre part, le design system &lt;a href=&quot;https://m3.material.io/&quot;&gt;Material Design 3&lt;/a&gt; vient de sortir en version stable et son implémentation &lt;a href=&quot;https://developer.android.com/jetpack/androidx/releases/compose-material&quot;&gt;Compose Material&lt;/a&gt; sont également disponibles.&lt;br /&gt;
Avec tout cela, le design a, cette année encore, tenu une place de choix dans l’agenda de cette droidcon 2022 à Londres.&lt;br /&gt;
Mais comment utiliser tout cela correctement ? Comment s’en servir pour implémenter un design system personnalisé ? Jusqu’où peut-on aller ?
Autant de questions auxquelles ont tenté de répondre les nombreuses présentations sur le sujet.&lt;/p&gt;

&lt;h3 id=&quot;to-compose&quot;&gt;To Compose&lt;/h3&gt;

&lt;p&gt;Compose facilite beaucoup de choses dans l’implémentation et le maintien d’interfaces sur Android. Cependant, cela nécessite de réapprendre à faire certaines choses que l’on maîtrise déjà avec le système de &lt;a href=&quot;https://developer.android.com/reference/android/view/View&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;View&lt;/code&gt;&lt;/a&gt;.&lt;br /&gt;
Dessiner dans un canvas en est une, et &lt;a href=&quot;https://twitter.com/hi_man_shoe&quot;&gt;Himanshu Singh&lt;/a&gt; dans sa présentation &lt;em&gt;“Composing in your canvas”&lt;/em&gt;, nous montre les pièges à éviter pour réaliser cela avec Compose.&lt;/p&gt;

&lt;p&gt;La recomposition peut également être source de problèmes et de latences si Compose est mal utilisé. Dans sa présentation &lt;em&gt;“Understanding recomposition performance pitfalls”&lt;/em&gt;, &lt;a href=&quot;https://twitter.com/jossiwolf&quot;&gt;Jossi Wolf&lt;/a&gt; et &lt;a href=&quot;https://twitter.com/shikasd_&quot;&gt;Andrei Shikov&lt;/a&gt; nous donnent, à partir d’un exemple concret, les meilleures astuces pour l’utiliser à bon escient.&lt;/p&gt;

&lt;h3 id=&quot;design-system&quot;&gt;Design System&lt;/h3&gt;

&lt;p&gt;En faisant le parallèle avec la saga épique de JRR Tolkien, &lt;a href=&quot;https://medium.com/@danielbbeleza&quot;&gt;Daniel Beleza&lt;/a&gt;, dans sa présentation &lt;em&gt;“One design system to rule them all”&lt;/em&gt;, nous explique comment il a réussi, tout en se passant de &lt;a href=&quot;https://material.io&quot;&gt;Material design&lt;/a&gt;, à unifier et automatiser son propre design system.&lt;br /&gt;
Cela demande, évidemment, une collaboration totale de la part de l’équipe de design, mais une fois cette intégration faite, les bénéfices et l’autonomie se ressentent de part et d’autre.&lt;br /&gt;
Des outils tel que &lt;a href=&quot;https://www.figma.com/&quot;&gt;Figma&lt;/a&gt;, &lt;a href=&quot;https://square.github.io/kotlinpoet/&quot;&gt;Kotlin Poet&lt;/a&gt; ou des plugins Android Studio custom lui ont permis d’automatiser ensuite ce processus.&lt;/p&gt;

&lt;p&gt;Material Design est un design system. Il a l’avantage d’être bien documenté, uniforme et régulièrement enrichi. De plus, il est déjà implémenté dans l’ancien système de View Android et plus récemment dans Jetpack Compose avec &lt;a href=&quot;https://developer.android.com/jetpack/androidx/releases/compose-material&quot;&gt;Compose Material&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Une des différences majeures entre Compose et le système de View sur Android est son découpage. Dans Compose, Material n’est implémenté et n’apparaît que dans la partie la plus hautes alors que dans le système de View, son implémentation est répartie dans toutes les couches de la librairie.&lt;br /&gt;
Il est donc assez complexe de se passer de Material avec le système de View mais cela est complétement envisageable, voire recommandé, dans certains cas avec Compose.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/views-vs-compose.png&quot; alt=&quot;Views VS Compose&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Pour illustrer cela &lt;a href=&quot;https://twitter.com/seebrock3r&quot;&gt;Sebastiano Poggi&lt;/a&gt; (la moitié de &lt;a href=&quot;https://www.youtube.com/c/CodewiththeItalians&quot;&gt;Coding with the italians&lt;/a&gt;) est venu nous présenter, dans &lt;em&gt;“Compose beyond Material”&lt;/em&gt;, les questions à se poser avant de se lancer dans son design system et comment le package &lt;a href=&quot;https://developer.android.com/jetpack/androidx/releases/compose-foundation&quot;&gt;Foundation&lt;/a&gt; de Compose peut nous aider.&lt;/p&gt;

&lt;p&gt;Pour terminer il nous donne de nombreux conseils concrets sur l’implémentation de composants sans Material. Le principal, rejoint la présentation d’introduction de cette droidcon, &lt;em&gt;“The Silver Bullet Syndrome Director’s Cut - Complexity Strikes Back!”&lt;/em&gt;, un bon design system est un design system qui correspond à nos besoins et qui y répond le plus simplement possible.&lt;/p&gt;

&lt;h3 id=&quot;vers-linfini-et-au-delà&quot;&gt;Vers l’infini et au-delà&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/chrisbanes&quot;&gt;Chris Bane&lt;/a&gt; et &lt;a href=&quot;https://twitter.com/mrmans0n&quot;&gt;Nacho Lopez&lt;/a&gt; dans leur présentation &lt;em&gt;“Branching out Jetpack Compose”&lt;/em&gt;, nous ont raconté comment l’aventure du passage à Compose s’est déroulée chez Twitter, une des premières apps à l’adopter.&lt;br /&gt;
Avec une code base aussi conséquente (plus de &lt;strong&gt;1000 modules&lt;/strong&gt;, dont 300 pour le design, répartis sur plus de 30 équipes), ils ont dû progressivement convaincre les équipes, les former et les accompagner.&lt;br /&gt;
La question de continuer à utiliser Material Design s’est également posée chez eux. Ils l’ont dans un premier temps conservé pour faciliter le passage sur Compose, pour finalement le retirer complètement en se basant, eux aussi, sur le package Foundation.&lt;br /&gt;
Leur présentation résume bien l’ensemble des étapes et des questions par lesquelles ils sont passés pour accomplir cette transition.&lt;/p&gt;

&lt;p&gt;Afin de remettre les choses en perspective, &lt;a href=&quot;https://twitter.com/askashdavies&quot;&gt;Ash Davies&lt;/a&gt; nous rappelle que Compose est un simple pattern de développement multiplateforme. De ce fait, il peux être appliqué à autre chose qu’à de l’UI comme le propose Jetpack Compose. Il nous explique dans &lt;em&gt;“Demystifying Molecule: Running Your Own Compositions For Fun And Profit”&lt;/em&gt;, comment l’appliquer à la couche domaine d’un projet pour le “Fun”.&lt;/p&gt;

&lt;h2 id=&quot;la-gestion-des-erreurs---david-yim&quot;&gt;&lt;strong&gt;La gestion des erreurs&lt;/strong&gt; - David Yim&lt;/h2&gt;

&lt;p&gt;La gestion des erreurs a été le sujet de plusieurs présentations à la droidcon. Ces présentations avaient pour objectif de servir de piqûre de rappel sur l’importance de bien prendre en compte ce problème concernant tous les développeurs. Aujourd’hui, nous avons tous les outils pour gérer facilement nos erreurs. Cependant, par paresse et comme nous préférons penser de manière positive, nous ne pensons souvent qu’aux cas de succès et les cas d’erreurs sont souvent brouillons voire ne sont même pas spécifiés.&lt;/p&gt;

&lt;p&gt;Les speakers m’ont marqué avec un exemple de mauvaise gestion d’erreur qui a coûté plusieurs centaines de milliers de dollars. L’exemple parlait d’une faille sur le site japonais de 7-Eleven, une chaîne de supérettes, dont elle a été victime. Dans la base de données de ce projet, les développeurs ont ajouté un champ “date de naissance” comme nullable. Plus tard, ce champ est devenu non-nullable. Par paresse, le développeur qui a rendu ce champ non-nullable a mis par défaut un 1er janvier 2019 sur cette date lorsqu’elle n’était pas renseignée, simplement pour satisfaire son compilateur. Le problème est que ce champ fut plus tard utilisé dans la fonctionnalité de mot de passe oublié du site. En utilisant la date par défaut du 1er janvier 2019, un hacker a pu récupérer des comptes utilisateurs et voler des informations bancaires. Cet exemple m’a marqué par l’habitude que nous avons en tant que développeur de nous soucier que de satisfaire notre compilateur plutôt que de vraiment discuter de solutions réfléchies à nos problèmes techniques.&lt;/p&gt;

&lt;p&gt;Plusieurs méthodes de gestion des erreurs existent et les speakers en ont présentés quelques-unes.&lt;/p&gt;

&lt;h4 id=&quot;vérification-des-entrées&quot;&gt;Vérification des entrées&lt;/h4&gt;

&lt;p&gt;L’une des méthode pour être certain de ne pas avoir de problème est de vérifier les données que l’on reçoit. Prenons un exemple simple :&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;data class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Rien n’empêche d’instancier cette classe de la manière suivante :&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;email&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Cela peut créer des problèmes par le futur, alors qu’il y a un moyen d’éviter cela&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Email&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Regex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;EMAIL_FORMAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;matches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Email format is not correct&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;data class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Email&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Cette méthode peut paraître un peu exagérée dans cet exemple. Mais dans un contexte où la classe &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;User&lt;/code&gt; serait utilisée par un grand nombre d’équipes et que les règles métier de l’&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Email&lt;/code&gt; serait complexe, cette méthode prendrait tout son sens pour éviter d’avoir de mauvaises surprises !&lt;/p&gt;

&lt;h4 id=&quot;le-type-either&quot;&gt;Le type Either&lt;/h4&gt;

&lt;p&gt;Le type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Either&lt;/code&gt; est un moyen de différencier les cas de succès des cas d’erreurs. Il est disponible dans la &lt;a href=&quot;https://arrow-kt.io/&quot;&gt;librairie Arrow&lt;/a&gt; ou facilement reproduisible :&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;sealed&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nothing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;()&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Nothing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;L’utilisation de ce type est qu’il est soit un type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt;, soit un type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt;. On peut ainsi définir par exemple que le &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt; est un cas de succès et que le type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt; est un cas d’erreur.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;data class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;when&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Left&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;The user is called ${(either as Either.Left&amp;lt;User&amp;gt;).value.name}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Right&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;either&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Grâce à ce type, on peut par exemple savoir si un appel à une API a réussi ou non, ce qui nous permet de gérer plus facilement nos cas d’erreurs.&lt;/p&gt;

&lt;h4 id=&quot;kotlin-result&quot;&gt;Kotlin Result&lt;/h4&gt;

&lt;p&gt;La classe &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Result&lt;/code&gt; est similaire au type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Either&lt;/code&gt; et a pour avantage d’être directement inclue dans Kotlin et que l’on n’a pas à se synchroniser pour savoir si le côté gauche est le cas de succès ou d’erreur.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;data class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;when&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isSuccess&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;The user is called ${result.getOrNull()?.name}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isFailure&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exceptionOrNull&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nc&quot;&gt;OU&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;onSuccess&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;The user is called ${user.name}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;onFailure&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Plusieurs méthodes existent pour prendre en compte nos cas d’erreurs. Laquelle est la meilleure ? Eh bien vous vous y attendez sûrement, mais ça dépend ! On choisira une méthode ou une autre selon ce qui nous arrange par rapport à la situation, nos choix d’outils techniques ou nos effectifs. L’important étant de prendre en compte ces cas d’erreurs et de ne pas laisser leur résolution au hasard. Les cas d’erreurs ne sont en fait que d’autres usecases de l’utilisateur et souvent ne sont pas des edgecase. Ils méritent donc d’être tout autant réfléchis et spécifiés que les cas de succès !&lt;/p&gt;

&lt;h2 id=&quot;à-la-prochaine-&quot;&gt;À la prochaine !&lt;/h2&gt;

&lt;p&gt;Il est toujours intéressant de mesurer l’engouement pour tel ou tel sujet dans la communauté Android en analysant les présentations lors des différentes conférences technologiques.&lt;/p&gt;

&lt;p&gt;Sans aucun doute, cette droidcon était sous le signe de Jetpack Compose, qui bénéficie d’un suivi et d’un engagement fort de Google et de toute la communauté.&lt;br /&gt;
Tout l’enjeu ici est de rester au contact des innovations et de l’évolution de la plateforme Android, et Jetpack Compose offre un défi que nous avons commencé à relever chez Bedrock.&lt;/p&gt;

&lt;p&gt;Nous attendons avec impatience de voir où va Android, et avons à coeur de participer à cette aventure qui nous lie tous !&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/hall.jpg&quot; alt=&quot;Hall droidcon London 2022&quot; /&gt;&lt;/p&gt;</content><author><name>[&quot;rpanoyan&quot;, &quot;d_yim&quot;, &quot;d_cuny&quot;]</name></author><category term="android" /><category term="droidcon" /><category term="conference" /><summary type="html">La communauté Android a apporté le soleil sur Londres les 27 et 28 octobre 2022. La droidcon London a réuni plus de 1400 développeurs autour de l’écosystème Android, de ses outils et enjeux actuels. Jetpack Compose, évidemment, mais aussi Gradle, modularisation, optimisation et autres sujets plus divers ont été abordés lors de ce rendez-vous incontournable pour la communauté.</summary></entry><entry><title type="html">How many DynamoDB RCU and WCU should we reserve to achieve maximum cost reductions, when our workloads are changing all the time?</title><link href="https://tech.bedrockstreaming.com/2022/11/22/dynamodb-reservations.html" rel="alternate" type="text/html" title="How many DynamoDB RCU and WCU should we reserve to achieve maximum cost reductions, when our workloads are changing all the time?" /><published>2022-11-22T00:00:00+00:00</published><updated>2022-11-22T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/11/22/dynamodb-reservations</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/11/22/dynamodb-reservations.html">&lt;p&gt;Many of the microservices in our VOD and Replay platform use DynamoDB as their database.&lt;br /&gt;
Performance is very good if the data is architected for it, scalability is reasonably fast, and the serverless aspect offloads a lot of the administration and hosting work. Whether it’s performance, resilience or time-to-market, DynamoDB helps us achieve our business goals.&lt;/p&gt;

&lt;p&gt;That said, when we spend several hundred thousand dollars on DynamoDB every year, any optimization is good for us!&lt;/p&gt;

&lt;p&gt;With DynamoDB, committing to a certain capacity for a year can help reduce costs – up to 50% savings on that capacity. But how do we know how much to reserve when traffic on our platform varies throughout the day?&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#dynamodb-a-not-always-obvious-cost-model&quot;&gt;DynamoDB: a not always obvious cost model!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#how-many-wcus-and-rcus-do-we-consume&quot;&gt;How many WCUs and RCUs do we consume?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#in-theory-how-much-should-we-reserve-to-achieve-maximum-savings&quot;&gt;In theory: how much should we reserve, to achieve maximum savings?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#in-practice-lets-calculate-how-much-to-reserve&quot;&gt;In practice: let’s calculate how much to reserve!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#finally-lets-create-those-reservations&quot;&gt;Finally, let’s create those reservations!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#after-reserving-viewing-the-costs&quot;&gt;After reserving, viewing the costs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;dynamodb-a-not-always-obvious-cost-model&quot;&gt;DynamoDB: a not always obvious cost model!&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;&lt;a href=&quot;#in-practice-lets-calculate-how-much-to-reserve&quot;&gt;To skip all the theory about how DynamoDB is priced and WCUs, RCU, on-demand and provisionned billing modes, click here…&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;DynamoDB is serverless&lt;sup id=&quot;fnref:serverless-but-still-some-work&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:serverless-but-still-some-work&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But, as with many AWS services, you have to think for a while before you really understand DynamoDB costs…&lt;/p&gt;

&lt;h3 id=&quot;out-of-scope-costs&quot;&gt;Out of scope costs&lt;/h3&gt;

&lt;p&gt;We pay for the volume of data stored, the volume of data backed up. These costs are outside the scope of this article and I won’t talk about them again today. They are not zero, however, and can even be a significant part of your bill – for example, if you store large data for a long time&lt;sup id=&quot;fnref:dynamodb-standard-ia&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:dynamodb-standard-ia&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; in DynamoDB. Something you probably shouldn’t do!&lt;/p&gt;

&lt;h3 id=&quot;wcus-and-rcus&quot;&gt;WCUs and RCUs&lt;/h3&gt;

&lt;p&gt;Each DynamoDB table can be configured in either &lt;em&gt;on-demand&lt;/em&gt; or &lt;em&gt;provisioned&lt;/em&gt; billing mode.&lt;/p&gt;

&lt;p&gt;In the second case, we pay for RCUs &lt;em&gt;(Read Capacity Units)&lt;/em&gt; and WCUs &lt;em&gt;(Write Capacity Units)&lt;/em&gt;, depending on the capacity we provision for each table.&lt;br /&gt;
Reservations only matter for these RCUs and WCUs, in purple in the screenshot below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/01-ddb-cost-by-api-operation.png&quot; alt=&quot;Cost by API Operation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Over the past year, our WCU and RCU costs in provisioned mode represent about half of our DynamoDB costs.&lt;br /&gt;
Storage and backups have costs that we consider negligible today.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;And, from a financial standpoint, we work with far too many pay-per-request tables&lt;sup id=&quot;fnref:why-so-much-pay-per-request&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:why-so-much-pay-per-request&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; for my taste.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/dynamodb/pricing/&quot;&gt;The documentation&lt;/a&gt; will tell you more, but in very broad terms:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;One WCU is consumed when writing one line of data. Or for each 1 KB block written.&lt;/li&gt;
  &lt;li&gt;One RCU is consumed to read one line of data. Or for each 4 KB block read.&lt;/li&gt;
  &lt;li&gt;In eventually-consistent read mode, only 1/2 RCU is consumed to read one line of data. Or for each 4 KB block.&lt;/li&gt;
  &lt;li&gt;Transactional mode costs twice as much.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As you can imagine, the first optimization is to store only what is necessary and to request DynamoDB in the way that best meets the needs of the application, including consistency and costs. Developing a data schema that efficiently meets the needs of the application is crucial. I highly recommend you read &lt;a href=&quot;https://www.dynamodbbook.com/&quot;&gt;Alex DeBrie’s very good “The DynamoDB Book”&lt;/a&gt;! Financial optimization based on reservations should – and can – only come afterwards, when usage patterns have been dealt with.&lt;/p&gt;

&lt;h3 id=&quot;the-on-demand--pay-per-request-mode&quot;&gt;The on-demand / pay-per-request mode&lt;/h3&gt;

&lt;p&gt;In &lt;em&gt;on-demand&lt;/em&gt; mode, we &lt;em&gt;theoretically&lt;/em&gt; don’t have to worry about scalability, DynamoDB handles it for us&lt;sup id=&quot;fnref:dynamodb-on-demand-scalability&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:dynamodb-on-demand-scalability&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;In this mode, we pay for each RCU and WCU we consume. If we don’t use DynamoDB, we don’t pay. If we use DynamoDB, we pay.&lt;br /&gt;
The counterpart is that RCUs and WCUs are more expensive in this mode than in the one presented below.&lt;/p&gt;

&lt;p&gt;This mode is therefore very practical, in my opinion, in two cases:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In an environment where we only perform a few queries from time to time (dev, staging).&lt;/li&gt;
  &lt;li&gt;For tables that are usually not used much, but receive large and sudden peaks of requests at certain times.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This mode is not adapted, especially because costs are too high:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For tables where consumption is stable or varies slowly. Typically, tables for which usage follows our daily traffic wave, which is gentle enough on most applications for a reactive auto-scaling mechanism to meet our needs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;provisioned-mode&quot;&gt;Provisioned mode&lt;/h3&gt;

&lt;p&gt;In &lt;em&gt;provisioned&lt;/em&gt; mode, we configure how many RCUs and WCUs we want and we pay for that number of RCUs and WCUs – no matter if we consume them or not.&lt;br /&gt;
This billing mode is therefore less flexible than &lt;em&gt;on-demand&lt;/em&gt;. On the other hand, RCUs and WCUs are less expensive.&lt;/p&gt;

&lt;p&gt;In &lt;em&gt;provisioned&lt;/em&gt; mode, we can set up an auto-scaler on the RCUs and WCUs of the tables that need it. It will dynamically reconfigure the provisioned RCUs and WCUs for those tables, to approximate the actual usage. With an auto-scaler, we can pay as close as possible to our actual consumption, at the provisioned price, which is lower than the on-demand one.&lt;br /&gt;
However, scale-out is not instantaneous: it takes several minutes to detect it needs to act, and then up to several minutes &lt;em&gt;(especially on a large table)&lt;/em&gt; to do so. Also, scale-in can only be triggered around once per hour. For more detailed information, read &lt;a href=&quot;https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html&quot;&gt;the documentation&lt;/a&gt; and &lt;a href=&quot;https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ServiceQuotas.html&quot;&gt;the quota page&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This mode is especially recommended, in my opinion and considering our workloads:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;As often as possible, since each RCU and WCU costs much less than in on-demand mode.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This mode is not suitable:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;On tables where consumption varies very abruptly.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;in-provisioned-mode-reservations&quot;&gt;In provisioned mode, reservations&lt;/h3&gt;

&lt;p&gt;By agreeing to pay for a certain amount of RCU and WCU for one year &lt;em&gt;(or even three years in some regions)&lt;/em&gt;, these RCU and WCU become even cheaper: up to ~50%&lt;sup id=&quot;fnref:50-percent-savings&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:50-percent-savings&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; cheaper than in default-provisioned mode.&lt;br /&gt;
Reserving capacity is a great way to considerably reduce the cost of read/write operations on DynamoDB!&lt;/p&gt;

&lt;p&gt;Reservations lock us for one year. We will pay for the reserved RCUs and WCUs, whether we use them or not.&lt;br /&gt;
It is therefore important to calculate correctly the reservations to be made.&lt;/p&gt;

&lt;p&gt;Also, we pay a part of the total yearly amount at the beginning of the commitment &lt;em&gt;(= “upfront”)&lt;/em&gt;, which means we must be able to invest a certain amount in advance.&lt;br /&gt;
The other part is spread over all the months of the commitment period.&lt;/p&gt;

&lt;p&gt;As a consequence, the &lt;em&gt;big question&lt;/em&gt;, to which the rest of this document tries to answer, is: &lt;em&gt;“how many RCU and WCU should we reserve to keep our costs as low as possible?”&lt;/em&gt;&lt;br /&gt;
When our consumption varies throughout the day, this calculation is pretty fun ;-)&lt;/p&gt;

&lt;p&gt;Reservations are global to an AWS account, or even to all accounts on a consolidated bill&lt;sup id=&quot;fnref:consolidated-billing&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:consolidated-billing&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;→ Reserved pricing is documented on the &lt;a href=&quot;https://aws.amazon.com/dynamodb/pricing/provisioned/&quot;&gt;page of “provisioned” pricing&lt;/a&gt;.&lt;br /&gt;
→ You can also read &lt;a href=&quot;https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-reservation-models/amazon-dynamodb-reservations.html&quot;&gt;this whitepaper&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;how-many-wcus-and-rcus-do-we-consume&quot;&gt;How many WCUs and RCUs do we consume?&lt;/h2&gt;

&lt;p&gt;For the rest of our reasoning and this article, we only count the consumption in &lt;em&gt;provisioned&lt;/em&gt; mode (and exclude &lt;em&gt;on-demand&lt;/em&gt;), since that’s where we can play with reservations.&lt;br /&gt;
Also, we count provisioned WCU and RCU and not what is actually consumed – so beware of any potential &lt;em&gt;waste&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;On the DynamoDB Web Console home screen, we can see, for an account and a region, how many WCUs and RCUs are provisioned at the current time:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/02-ddb-capacity-used-right-now-in-one-account-and-region.png&quot; alt=&quot;DynamoDB Capacity used, right now, in one account and region&quot; /&gt;&lt;/p&gt;

&lt;p&gt;But these numbers only give a view at a given instant, in a single AWS account and in a single region.&lt;br /&gt;
We deploy our platform across dozens of accounts and multiple regions, with traffic that changes throughout the day, so this is not enough.&lt;/p&gt;

&lt;h3 id=&quot;table-wcusrcus&quot;&gt;Table WCUs/RCUs&lt;/h3&gt;

&lt;p&gt;For a global view of all tables in an account in a region, we can query Cloudwatch Metrics, analyzing the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ProvisionedWriteCapacityUnits&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ProvisionedReadCapacityUnits&lt;/code&gt; metrics:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/03-ddb-write-capacity-per-table-cloudwatch-metrics-CENSORED.png&quot; alt=&quot;Write capacity per table, Cloudwatch metrics&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The Stacked Area view shows, at any given time, the total WCUs (or RCUs) provisioned for all of our tables, in an account and a region.&lt;/p&gt;

&lt;h3 id=&quot;wcurcu-of-gsi&quot;&gt;WCU/RCU of GSI&lt;/h3&gt;

&lt;p&gt;We also need to count the WCUs/RCUs of the Global Secondary Indexes – and these are different metrics! Or, at least, the metrics are shown in a different category in the Cloudwatch web console.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/04-ddb-write-capacity-per-gsi-cloudwatch-metrics-CENSORED.png&quot; alt=&quot;Write capacity per GSI, Cloudwatch metrics&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;so-in-total&quot;&gt;So, in total…&lt;/h3&gt;

&lt;p&gt;To get the total, you have to consider this metric for the tables and for the Global Secondary Indexes! In the Cloudwatch console, you have to search in two categories.&lt;br /&gt;
Graphing it all :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/05-ddb-write-capacity-all-cloudwatch-metrics-CENSORED.png&quot; alt=&quot;Total write capacity, Cloudwatch metrics&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Of course, this is to be looked at for WCUs, but also for RCUs, following exactly the same principle.&lt;br /&gt;
And, again, we’re working in multiple accounts and regions.&lt;/p&gt;

&lt;h2 id=&quot;in-theory-how-much-should-we-reserve-to-achieve-maximum-savings&quot;&gt;In theory: how much should we reserve, to achieve maximum savings?&lt;/h2&gt;

&lt;p&gt;Once we know how much capacity we’re actually using, we can move on to reservations.&lt;/p&gt;

&lt;p&gt;But the calculation would be far too easy if our usage was flat!&lt;br /&gt;
In reality, thanks to auto-scaling, our provisioned capacity follows our usual traffic pattern: a wave.&lt;/p&gt;

&lt;p&gt;And, two things:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;if we reserve more than we provision, we’ll waste money.&lt;/li&gt;
  &lt;li&gt;if we reserve less than we provision, we won’t save as much as we could.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reserve-at-the-bottom-of-the-wave&quot;&gt;Reserve at the bottom of the wave&lt;/h3&gt;

&lt;p&gt;A first idea is to reserve the lowest value we provision throughout the day: what we provision at the bottom of our traffic wave, at night.&lt;/p&gt;

&lt;p&gt;In this case, we are not wasting money, as we always provision 100% or more of our reservation.&lt;br /&gt;
But we are probably minimizing our savings, since we are provisioning more than the reservation, all day long.&lt;/p&gt;

&lt;h3 id=&quot;reserve-at-the-top-of-the-wave&quot;&gt;Reserve at the top of the wave&lt;/h3&gt;

&lt;p&gt;A second idea, kind of the opposite, is to reserve the highest value we provision throughout the day.&lt;br /&gt;
This way, we will never pay the full rate for any WCU/RCU.&lt;/p&gt;

&lt;p&gt;But, in this case, we will be wasting a lot of money, since all day long we will be provisioning less than our reservation.&lt;br /&gt;
This is a &lt;em&gt;bad idea&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;reserve-in-the-middle-thanks-to-careful-calculations&quot;&gt;Reserve “in the middle”, thanks to careful calculations&lt;/h3&gt;

&lt;p&gt;Now, the real solution: calculate the &lt;em&gt;right value&lt;/em&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Less than &lt;em&gt;the highest value&lt;/em&gt;, to minimize waste.&lt;/li&gt;
  &lt;li&gt;And more than &lt;em&gt;the lowest value&lt;/em&gt;, to optimize savings.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;in-practice-lets-calculate-how-much-to-reserve&quot;&gt;In practice: let’s calculate how much to reserve!&lt;/h2&gt;

&lt;p&gt;Manipulating metrics in Cloudwatch, for visualization, may be acceptable, although we rarely do it since we use other stacks for our metrics. And aggregating metrics from multiple accounts should be feasible &lt;em&gt;(we haven’t tried it)&lt;/em&gt;.&lt;br /&gt;
But for calculations, it is not enough.&lt;/p&gt;

&lt;h3 id=&quot;exporting-metrics&quot;&gt;Exporting metrics&lt;/h3&gt;

&lt;p&gt;As a first step, we exported the metrics visualized above, to be able to manipulate them in another tool – in a spreadsheet, for example.&lt;br /&gt;
To export these metrics from Cloudwatch, we can query its API. We need to do this for all accounts and for each table, which is complicated to do manually.&lt;/p&gt;

&lt;p&gt;To simplify the task, we started working with a script that exports this data to a CSV file.&lt;br /&gt;
Specifically, this script exports one data point per hour: the number of WCUs or RCUs actually provisioned during that hour.&lt;/p&gt;

&lt;p&gt;Running this script for a &lt;em&gt;representative week&lt;/em&gt;, we have enough data to calculate the ideal reservations.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;🗓️ Representative week?&lt;/strong&gt;&lt;br /&gt;
Of course, we have to be careful to choose the week we focus on.&lt;br /&gt;
If we work with data from a week with a huge unexplained peak of traffic, the results of our calculation will fit that week, but not so much to the rest of the year!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;a-google-spreadsheet-calculation&quot;&gt;A Google Spreadsheet calculation&lt;/h3&gt;

&lt;p&gt;Importing this data into a Google Spreadsheet, we get two columns: a date+time and a number of WCUs.&lt;br /&gt;
And this is for each one-hour range during an entire week:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-01-date-and-conso-english.png&quot; alt=&quot;Date and usage&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;ℹ️ Only twelve hours&lt;/strong&gt;&lt;br /&gt;
Here, I only reproduce twelve rows corresponding to twelve hours, but keep in mind that there are actually 168 rows in my spreadsheet: one row per hour, 24 hours per day, for 7 days.&lt;br /&gt;
Also, the values used for this article are all &lt;em&gt;simulated&lt;/em&gt;, to avoid sharing sensitive information, but they scrupulously respect the shape of our traffic and usage wave.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The next step is to integrate the cost of these WCUs.&lt;br /&gt;
Easy anough, we multiply the number of WCUs by the cost of a WCU in Paris, i.e. $0.000772.&lt;br /&gt;
And the sum of the cost of each line gives us the total cost, without reservation:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-02-cost-without-reservation-english.png&quot; alt=&quot;Costs, without any reservation&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;the-calculations-on-an-assumption&quot;&gt;The calculations, on an assumption&lt;/h3&gt;

&lt;p&gt;Now, let’s assume, for the time being, that we reserve 25,000 WCUs:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The upfront, each hour, is $5.07991.&lt;/li&gt;
  &lt;li&gt;And, each hour, we also have to pay $3.82500 for this capacity, since the upfront is only partial.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In addition:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;During some hours, when we consume less than 25,000 WCU, we will not pay anything extra.&lt;/li&gt;
  &lt;li&gt;During some other hours, when we consume more than 25,000 WCU, we will have to pay a supplement, at the full provisioned rate.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Adding these data, we obtain a different hourly cost, often lower than the one determined above.&lt;br /&gt;
And, therefore, we get a lower total cost as well:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-03-cout-including-reservations-english.png&quot; alt=&quot;Costs, with reservations&quot; /&gt;&lt;/p&gt;

&lt;p&gt;With this hypothesis of a 25,000 WCU reservation, over these twelve hours, we would pay 135 dollars instead of 229 dollars without reservation.&lt;br /&gt;
We would then realize 40.96% savings!&lt;/p&gt;

&lt;h3 id=&quot;the-calculations-until-we-find-the-right-value&quot;&gt;The calculations, until we find the right value&lt;/h3&gt;

&lt;p&gt;Of course, during the hours when we consume less than 25,000 WCU, we are wasting capacity: we are paying for it, without using it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-04-waste-english.png&quot; alt=&quot;Wasted reservations&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The goal of the game is to find the &lt;em&gt;right number&lt;/em&gt; of WCUs to reserve: we want to reduce the total cost as much as possible, maximizing the percentage of savings.&lt;/p&gt;

&lt;p&gt;To do so, we try different values for the number of WCUs reserved, until we find the one that maximizes the percentage of savings:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-05-maximize-percentage-savings-table-english.png&quot; alt=&quot;Maximizing savings percentages (table)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here’s the same thing as a graph:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-05-maximize-percentage-savings-graphic-english.png&quot; alt=&quot;Maximizing savings percentages (graph)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here, over these twelve hours, the optimal approach would be to reserve 23,000 WCU.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;💪 Getting real: an entire week&lt;/strong&gt;&lt;br /&gt;
In reality, we perform exactly the same calculation and we follow this very same logic, on 168 lines of data, corresponding to a &lt;em&gt;representative week&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;easier-calculations&quot;&gt;Easier calculations?&lt;/h3&gt;

&lt;p&gt;The first year we tried to reserve capacity, we quickly wrote a script to collect the data from Cloudwatch and export it as CSV.&lt;/p&gt;

&lt;p&gt;We still haven’t, after three or four years now, written a program that would perform the calculations based on this data to come up with the &lt;em&gt;right value&lt;/em&gt; for the number of WCUs or RCUs to reserve.&lt;br /&gt;
As a matter of facts, copying and pasting data from the CSV export to a spreadsheet only takes a minute, we reuse the same year after year, and its visual aspect is nice!&lt;/p&gt;

&lt;p&gt;Also, we only do these calculations and reservations twice a year, so we don’t spend too much time working on this, while still refining more often than once each year.&lt;br /&gt;
Each time, the process takes two of us&lt;sup id=&quot;fnref:pair-reserving&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:pair-reserving&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt; about two hours, or one day per year in total… And the most time-consuming part is talking to our colleagues who are heavy DynamoDB users, and asking them &lt;em&gt;“are you planning to reduce the consumption of your project over the coming year?”&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;finally-lets-create-those-reservations&quot;&gt;Finally, let’s create those reservations!&lt;/h2&gt;

&lt;p&gt;We calculated how many WCUs and how many RCUs we should reserve to achieve the best possible savings, hoping the week we chose to base our calculations on was actually a &lt;em&gt;representative week&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;a-commitment-be-careful&quot;&gt;A commitment: be careful…&lt;/h3&gt;

&lt;p&gt;A reservation commits us to pay for a year, whether we use this capacity or not.&lt;/p&gt;

&lt;p&gt;So, it’s always a good idea to take a moment to validate with our colleagues that they are not planning to use less DynamoDB in the near future.&lt;br /&gt;
Of course, the answer is often partly &lt;em&gt;“it depends”&lt;/em&gt;, since usage depends on new projects as well as on the traffic on our platforms, but if we can already anticipate the next planned optimizations, it’s always a good thing.&lt;/p&gt;

&lt;p&gt;In November 2022, we can only open DynamoDB reservations for one year if we work in the AWS Paris region.&lt;br /&gt;
Other regions &lt;em&gt;(us-east-1 for example) allow&lt;/em&gt; reservations for three years, which means more substantial savings. On the other hand, would we be willing to commit for three years and lose a major advantage of &lt;em&gt;The Cloud&lt;/em&gt;, its flexibility?&lt;/p&gt;

&lt;h3 id=&quot;which-account-to-reserve-on&quot;&gt;Which account to reserve on?&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/dynamodb/pricing/provisioned/&quot;&gt;The documentation&lt;/a&gt; says (emphasis mine):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you have multiple accounts linked with consolidated billing, &lt;strong&gt;reserved capacity units purchased&lt;/strong&gt; either &lt;strong&gt;at the payer account level&lt;/strong&gt; or linked account level &lt;strong&gt;are shared with all accounts connected to the payer account&lt;/strong&gt;.&lt;br /&gt;
Reserved capacity is applied first to the account that purchased it and then any unused capacity is applied to other linked accounts.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We have configured our AWS accounts to have a single payer account.&lt;br /&gt;
We have decided to make all our reservations in this account and they are applied to the child accounts without discrimination.&lt;br /&gt;
This applies to DynamoDB but also to RDS, EC2, Elasticache…&lt;/p&gt;

&lt;h3 id=&quot;reserving&quot;&gt;Reserving!&lt;/h3&gt;

&lt;p&gt;To reserve, we go through the AWS DynamoDB Web console, in our payer account, in the region where these reservations will be used.&lt;/p&gt;

&lt;p&gt;On this screen, you can see how many WCUs and RCUs we have already reserved.&lt;br /&gt;
Since we make several reservations during the year, the reservations already in progress are to be subtracted from the values calculated above!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/ddb-reservations-history-CENSORED.png&quot; alt=&quot;Reservations history&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To create a new reservation, click on &lt;em&gt;“Purchase reserved capacity”&lt;/em&gt; and fill in the form ;-)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/creating-a-reservation-23k.png&quot; alt=&quot;Reserving 23,000 WCU: this is not free!&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;after-reserving-viewing-the-costs&quot;&gt;After reserving, viewing the costs&lt;/h2&gt;

&lt;p&gt;Once the reservations are made, in AWS Cost Explorer, the upfront cost is clearly visible.&lt;br /&gt;
It is charged at once, on the day we opened the reservation:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/cost-explorer-after-reservation-01-CENSORED.png&quot; alt=&quot;Cost Explorer, after reserving&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To have a daily view of WCU/RCU costs &lt;em&gt;(reserved + provisioned in addition to reservations)&lt;/em&gt;, remember to fill in &lt;em&gt;“Show costs as: Amortized costs”&lt;/em&gt; to smooth the monthly price of reservations over all days of the month:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/cost-explorer-after-reservation-02-amortized-CENSORED.png&quot; alt=&quot;Amortized view&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Reservations and one payer account&lt;/strong&gt;&lt;br /&gt;
Since reservations, which cover the bulk of our DynamoDB costs, are made on our payer account, the bulk of our DynamoDB costs go back to this account… And not to the tenant/environment accounts.&lt;br /&gt;
Good luck tracking costs and allocating them to projects and teams 💪&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;We work with DynamoDB a lot, for several dozen microservices, and we face several types of infrastructure costs: on-demand reads/writes, provisioned reads/writes, storage, backups.&lt;br /&gt;
In exchange for a loss of flexibility and through reservations that commit us for a year, AWS allows us to reduce the cost of provisioned reads/writes.&lt;/p&gt;

&lt;p&gt;Determining how much to reserve, in the face of a constantly changing load, is not easy.&lt;br /&gt;
We need to have a certain vision on the evolution of usage, over a year, and must accept to lose flexibility.&lt;br /&gt;
And we need to find the &lt;em&gt;right values&lt;/em&gt; to reserve for read and write capacity.&lt;/p&gt;

&lt;p&gt;With three or four years of hindsight, by making reservations twice a year and by following the method detailed in this article, we realize savings of about 30% to 35% on our read and write capacity in provisioned mode.&lt;br /&gt;
On our scale, this saving represents several tens of thousands of dollars per year – which is great, considering we only spend a few hours working on this every six months!&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:serverless-but-still-some-work&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;DynamoDB is one of the &lt;em&gt;most serverless&lt;/em&gt; services we use and I like it a lot. Still, there are a few &lt;em&gt;admin&lt;/em&gt; tasks left in our hands. Typically, we have to specify the capacity we need and configure an auto-scaler. We also have to enable encryption, backups, to setup permissions – and to check all this is done, for all tables, managed by many teams. &lt;a href=&quot;#fnref:serverless-but-still-some-work&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:dynamodb-standard-ia&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;If you do store a lot of data for a long time in DynamoDB, take a look at &lt;a href=&quot;https://aws.amazon.com/dynamodb/standard-ia/&quot;&gt;Standard-IA&lt;/a&gt;, it might help you reduce costs. &lt;a href=&quot;#fnref:dynamodb-standard-ia&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:why-so-much-pay-per-request&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Why do we use pay-per-request so much? Well, in short, because this mode is more flexible than the provisioned one, and several of our projects are willing to pay much more in exchange for this flexibility. &lt;a href=&quot;#fnref:why-so-much-pay-per-request&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:dynamodb-on-demand-scalability&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;DynamoDB in on-demand mode and scalability: in practice, AWS hides what’s going on, but doesn’t scale to infinity instantly either. &lt;a href=&quot;#fnref:dynamodb-on-demand-scalability&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:50-percent-savings&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;50% is kind of the maximum possible saving we can achieve if our usage is flat and we reserve exactly what we provision. Flat usage might be what you see on your applications, but it’s not how our platform works! &lt;a href=&quot;#fnref:50-percent-savings&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:consolidated-billing&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;At Bedrock, we have a dedicated billing account – a &lt;em&gt;“payer account”&lt;/em&gt; – that aggregates costs from all our other accounts. Reservations are also shared amongst all (whitelisted) accounts that have a shared payer account. &lt;a href=&quot;#fnref:consolidated-billing&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:pair-reserving&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;For these kind of calculations and reservations, we usually work in pair, as this involves large amounts of money. Lowering risk of doing a costly mistake is quite a good idea. &lt;a href=&quot;#fnref:pair-reserving&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Pascal Martin</name></author><category term="aws" /><category term="dynamodb" /><category term="finops" /><summary type="html">Many of the microservices in our VOD and Replay platform use DynamoDB as their database. Performance is very good if the data is architected for it, scalability is reasonably fast, and the serverless aspect offloads a lot of the administration and hosting work. Whether it’s performance, resilience or time-to-market, DynamoDB helps us achieve our business goals. That said, when we spend several hundred thousand dollars on DynamoDB every year, any optimization is good for us! With DynamoDB, committing to a certain capacity for a year can help reduce costs – up to 50% savings on that capacity. But how do we know how much to reserve when traffic on our platform varies throughout the day?</summary></entry><entry><title type="html">Ce que nous avons retenu de la SymfonyCon - Disneyland Paris 2022</title><link href="https://tech.bedrockstreaming.com/2022/11/17/symfonycon.html" rel="alternate" type="text/html" title="Ce que nous avons retenu de la SymfonyCon - Disneyland Paris 2022" /><published>2022-11-17T00:00:00+00:00</published><updated>2022-11-17T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/11/17/symfonycon</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/11/17/symfonycon.html">&lt;p&gt;En cette fin d’année, une petite équipe de chez Bedrock a assisté au grand retour de la SymfonyCon 2022 après 3 ans d’absence. 
Nous avons eu la chance de découvrir les nouveautés liées à Symfony 6.2 et d’assister aux conférences sur de nombreux sujets techs à Disneyland.
La keynote présentée par &lt;a href=&quot;https://github.com/fabpot&quot;&gt;Fabien Potencier&lt;/a&gt;, le créateur de Symfony, nous donne un avant-goût des nouvelles fonctionnalités qui seront présentes dans la future version de Symfony.
Au programme, un nouveau composant Webhooks ainsi que l’évolution du composant Mailer.&lt;/p&gt;

&lt;h2 id=&quot;unleashing-the-power-of-lazy-objects-in-php&quot;&gt;Unleashing the power of lazy objects in PHP&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://connect.symfony.com/profile/nicolas-grekas&quot;&gt;Nicolas Grekas&lt;/a&gt;, habitué de la scène PHP et membre de la Symfony Core Team, nous a présenté les différentes façons d’utiliser les lazy objects en PHP et plus spécifiquement à l’aide de Symfony. &lt;/p&gt;

&lt;p&gt;Les lazy objects sont des objets instanciés vides qui peuplent leurs propriétés eux-mêmes seulement quand ils sont utilisés.
Ils sont utiles lors de l’instanciation de lourds objets peu appelés, cela permet de faire du lazy loading.&lt;/p&gt;

&lt;p&gt;Nicolas nous a aussi présenté deux nouveaux traits prochainement disponibles sur Symfony 6.2 permettant de travailler avec ces objets.
Les &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VirtualInheritanceProxies&lt;/code&gt; et les &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GhostsObjects&lt;/code&gt; sont deux nouvelles possibilités pour implémenter plus facilement des lazy objects en plus du &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ValueHolder&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;advanced-git-magic&quot;&gt;Advanced Git magic&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://connect.symfony.com/profile/paulinevos&quot;&gt;Pauline Vos&lt;/a&gt; nous représente GIT en dehors de son usage quotidien, comment aller plus loin que les pull, commit, push et merge habituels, elle nous livre donc une présentation sur une méthode de debug en utilisant GIT.&lt;/p&gt;

&lt;p&gt;Retour dans un premier temps sur l’importance des commits dit “atomic” avec comme règles :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Chaque commit se résume à un fix ou une feature&lt;/li&gt;
  &lt;li&gt;Chaque commit doit fonctionner (tous les tests doivent passer)&lt;/li&gt;
  &lt;li&gt;Chaque message et description doivent être clairs et concis&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Pauline introduit ensuite la commande &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git rebase -i&lt;/code&gt; qui permet un rebase interactif servant notamment à réécrire notre historique.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/symfonycon2022/IMG-0785.jpg&quot; alt=&quot;git rebase intéractif&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Vient ensuite l’utilisation de la commande &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git reflog&lt;/code&gt;, commande avec laquelle nous pouvons obtenir le détail des commandes lancées sur la branche, elle peut de ce fait être utile pour réparer une erreur.&lt;/p&gt;

&lt;h4 id=&quot;comment-utiliser-toutes-ces-commandes-git-pour-debugger-&quot;&gt;Comment utiliser toutes ces commandes GIT pour debugger ?&lt;/h4&gt;
&lt;p&gt;Une démonstration de la commande &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git bisect&lt;/code&gt; et de toutes ses options qui permettent d’identifier le commit qui a introduit le bug en faisant une recherche dichotomique.&lt;/p&gt;

&lt;p&gt;Pauline pousse la réflexion plus loin en alliant la commande &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git bisect&lt;/code&gt; avec un script de debug ou un test unitaire.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;“Write it, push it and find where it breaks”&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Afin de tirer parti de cette méthode, il est important que chaque commit soit fonctionnel, tous les tests doivent donc passer.&lt;/p&gt;

&lt;p&gt;Vous pouvez également retrouver &lt;a href=&quot;https://www.pauline-vos.nl/fix-bugs-%e2%9a%a1-fast-with-regression-tests-and-auto-bisect/&quot;&gt;un article de Pauline&lt;/a&gt; à ce sujet sur son blog personnel.&lt;/p&gt;

&lt;h2 id=&quot;schrödingers-sql---the-sql-inside-the-doctrine-box&quot;&gt;Schrödinger’s SQL - The SQL inside the Doctrine box&lt;/h2&gt;

&lt;p&gt;Au début de sa conférence &lt;a href=&quot;https://connect.symfony.com/profile/senseexception&quot;&gt;Claudio Zizza&lt;/a&gt; insiste sur le fait de bien connaître nos bases de données et le langage utilisé pour les requêter, il évoque notamment les différences entre MySQL et PostgreSQL. Ensuite, il nous a parlé de Doctrine ORM, des fonctions que nous apprécions tant, car elles nous facilitent la vie. 
Puis, il a rappelé l’importance de savoir faire des requêtes SQL même si nous utilisons Doctrine. Comprendre le SQL peut nous permettre d’optimiser notre utilisation de Doctrine et donc de mieux appréhender son fonctionnement. 
Il insiste aussi sur le fait que SQL “seul” est bien plus puissant que DQL (Doctrine Query Language). 
Pour terminer, Claudio nous a donné quelques recommandations de lecture pour apprendre le SQL ainsi qu’un site permettant de tester nos requêtes.&lt;/p&gt;

&lt;h2 id=&quot;advanced-test-driven-development&quot;&gt;Advanced Test Driven Development&lt;/h2&gt;

&lt;p&gt;Durant cette conférence, &lt;a href=&quot;https://connect.symfony.com/profile/mollokhan&quot;&gt;Diego Aguiar&lt;/a&gt;, développeur de chez SymfonyCasts nous rappelle ce qu’est le &lt;strong&gt;TDD (Test Driven Development)&lt;/strong&gt;, son histoire, les différentes techniques ainsi que des astuces afin de nous débloquer et bien sûr les cas où il ne semble pas utile d’utiliser le TDD.&lt;/p&gt;

&lt;p&gt;À retenir, le TDD est une discipline, il faut beaucoup d’entraînement et répéter continuellement ces exercices.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/symfonycon2022/IMG-0848.jpg&quot; alt=&quot;tdd discipline&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;“Fake it till you make it”&lt;/strong&gt;&lt;/em&gt;, il s’agit d’abord d’écrire son code de test en utilisant par exemple des assertions, des tests avec différentes sorties et ensuite de produire le code qui va résoudre ces tests.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/symfonycon2022/IMG-0852.jpg&quot; alt=&quot;Fake it till you make it&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;“ Write your test code, produce it and repeat.”&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;pourquoi-nous-retrouvons-nous-parfois-bloqués-&quot;&gt;Pourquoi nous retrouvons nous parfois bloqués ?&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Les tests écrits sont peut-être faux&lt;/li&gt;
  &lt;li&gt;Les tests ne sont pas assez segmentés&lt;/li&gt;
  &lt;li&gt;Le code écrit est peut-être trop spécifique&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;comment-se-débloquer-&quot;&gt;Comment se débloquer ?&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Continuer et trouver un test plus simple&lt;/li&gt;
  &lt;li&gt;Refactoriser le code en production qui met en difficulté&lt;/li&gt;
  &lt;li&gt;Écrire les différents use-cases&lt;/li&gt;
  &lt;li&gt;Passer outre les tests un instant&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Les cas les plus favorables au TDD sont les nouvelles fonctionnalités qui n’ont pas de lien avec du code legacy. En ce qui concerne les cas non pertinent au TDD, nous retrouvons les cas de configuration, de découverte de code et de requêtes.&lt;/p&gt;

&lt;p&gt;Pour conclure, Diego nous rappelle que le TDD est bien évidemment plus un outil qu’une règle.&lt;/p&gt;

&lt;h2 id=&quot;dynamic-validation-with-symfony&quot;&gt;Dynamic Validation With Symfony&lt;/h2&gt;

&lt;p&gt;Tout en se basant sur les évolutions des Pokémon, &lt;a href=&quot;https://connect.symfony.com/profile/marionleherisson&quot;&gt;Marion Hurteau&lt;/a&gt; a introduit le principe de validation dynamique. Par exemple, vérifier que le nom de notre Pokémon contient bien 10 caractères, ou encore les différentes règles d’évolution en fonction du type de Pokémon. 
À l’aide d’exemples de code qui sont disponibles sur son repo Git, elle a passé en revue les façons d’implémenter des validations à l’aide du composant &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Symfony Validator&lt;/code&gt;.
Au fil de sa présentation, la complexité des contraintes croît ce qui permet de voir un éventail de possibilités.&lt;/p&gt;

&lt;h2 id=&quot;from-monolith-to-decoupledwait-why-is-that-one-getting-bigger&quot;&gt;From monolith to decoupled…wait, why is that one getting bigger?!?&lt;/h2&gt;
&lt;p&gt;Lors de cette conférence, &lt;a href=&quot;https://connect.symfony.com/profile/shawnaspoor&quot;&gt;Shawna Spoor&lt;/a&gt; est venue nous parler de comment découper un monolithe en une multitude de microservices grâce au “Strangler Fig Pat”. Elle a commencé par nous rappeler les avantages et les inconvénients des microservices comparé à un monolithe.&lt;/p&gt;

&lt;p&gt;Suite à cela, elle nous a donné les différentes étapes pour découper une application monolithe en micro-services et cela sans jamais arrêter le développement de nouvelles features:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Choisir une fonctionnalité qui peut être découpée&lt;/li&gt;
  &lt;li&gt;Créé le nouveau Service&lt;/li&gt;
  &lt;li&gt;Déplacer le trafic vers le nouveau service&lt;/li&gt;
  &lt;li&gt;Recommencer jusqu’à la disparition du monolithe&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On peut résumer ce pattern via l’image ci-dessous, le tronc représente le monolithe et les branches qui l’étranglent lentement correspondent aux micro-services.
&lt;img src=&quot;https://w2j6m4k9.rocketcdn.me/wp-content/uploads/2019/09/Strangler-Tree-Header-Big-1024x576.png&quot; alt=&quot;Strangler Fig Paterne&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;from-a-legacy-monolith-to-a-symfony-service-oriented-architecture-with-zero-downtime&quot;&gt;From a legacy Monolith to a Symfony Service Oriented Architecture with zero downtime&lt;/h2&gt;
&lt;p&gt;Lors de la conférence présentée par &lt;a href=&quot;https://connect.symfony.com/profile/skigun&quot;&gt;Clément Bertillon&lt;/a&gt;, nous avons pu voir comment son équipe a transformé leur ancienne application monolithe composée de milliers de fichiers PHP en un monorepo décomposé en micro-services en utilisant le &lt;strong&gt;Strangler Fig&lt;/strong&gt; pattern et cela sans aucune rupture de service ni arrêter le développement de nouvelles features.&lt;/p&gt;

&lt;p&gt;De manière très simplifiée, ils ont installé Symfony, mis le code legacy dans un dossier à la racine du projet, le routeur symfony permet d’accéder au nouveau micro-service tout en redirigeant vers le legacy si aucun contrôleur n’a été trouvé. Il a conclu avec les règles d’or et comment analyser les performances via Blackfire.
Ces deux conférences sur le &lt;strong&gt;Strangler fig&lt;/strong&gt; paterne, mon permis de mettre en place un micro projet dans un de nos projets, tout en le cloisonnant du code parent (règles d’or vérifié grâce à l’outil présenté &lt;a href=&quot;https://github.com/qossmic/deptrac&quot;&gt;deptrac&lt;/a&gt;). Ce principe nous permettra de le transformer en micro service très facilement.&lt;/p&gt;

&lt;h2 id=&quot;phpstan-advanced-types&quot;&gt;PHPStan: Advanced Types&lt;/h2&gt;
&lt;p&gt;Cette conférence centrée sur l’outil d’analyse statique de code : PHPStan, a été présentée par son créateur &lt;a href=&quot;https://connect.symfony.com/profile/mirtes&quot;&gt;Ondřej Mirtes&lt;/a&gt;.
Il a commencé par nous rappeler quelle est la différence entre un langage compilé et un langage interprété, le premier ne se compile pas s’il y a des erreurs alors que le second ne plante qu’à l’exécution. Le but de PHPStan est de nous aider à identifier toutes les erreurs sans avoir besoin d’exécuter le code.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/symfonycon2022/phpstan.png&quot; alt=&quot;PHPstan&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Cet outil analyse toutes les fonctions, les propriétés, le typage PHP, mais aussi la PHPDoc. Ondřej nous a ensuite parlé de tous les types PHPStan avec des exemples, en voici quelques un qui ont marqué notre attention :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;non-empty-array&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;non-empty-string&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;literal-string&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;integer-range&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;integer-mask&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;integer-maskof&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conditional return types, union types, intersection types&lt;/code&gt; …&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Il finit en nous rappelant que l’utilisation de &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;@var&lt;/code&gt; est une mauvaise pratique et qu’il vaut mieux renforcer le typage quitte à modifier la documentation des &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vendor&lt;/code&gt; via les &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Stub files&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;gnap-the-future-of-oauth&quot;&gt;GNAP: The future of OAuth&lt;/h2&gt;
&lt;p&gt;[&lt;a href=&quot;https://slides.com/chalasr/gnap-the-future-of-oauth-2fefdf&quot;&gt;Slides&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://connect.symfony.com/profile/chalas_r&quot;&gt;Robin Chalas&lt;/a&gt; @chalas_r nous a présenté GNAP (Grant Negotiation and Authorization Protocol) : une initiative pour développer la prochaine génération de protocoles d’autorisation.
Pour mieux comprendre les enjeux, nous sommes repartis de l’historique d’oauth, ses évolutions et ses écueils. Le constat étant que même si de nombreux problèmes connus ont été résolus, aujourd’hui, pour bien utiliser OAuth 2, il faut lire une douzaine de RFC et s’assurer qu’elles soient pertinentes pour les différents cas d’utilisation.&lt;/p&gt;

&lt;p&gt;L’augmentation de la complexité du protocole dégrade l’expérience du développeur, ce qui va à l’encontre de son objectif principal qui est la simplicité pour les développeurs de clients.&lt;/p&gt;

&lt;p&gt;GNAP (prononcé “nap”) est une complète réécriture afin de répondre aux besoins en sécurité des applications modernes :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Pensé pour tous les clients, plateformes (pas uniquement web, possibilités de deeplinking mobile par exemple)&lt;/li&gt;
  &lt;li&gt;les interactions sont un concept clé&lt;/li&gt;
  &lt;li&gt;Du chiffrement partout et des mécanismes de rotation extensibles&lt;/li&gt;
  &lt;li&gt;Plusieurs Access Tokens / grant request&lt;/li&gt;
  &lt;li&gt;Gestion de l’identité intégrée&lt;/li&gt;
  &lt;li&gt;Plus developer friendly&lt;/li&gt;
  &lt;li&gt;Pas rétrocompatible avec OAUTH2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ce protocole est toujours à l’état de brouillon, le groupe de travail a été monté en octobre 2020 et lors du dernier rassemblement (nov. 2022), aucune modification du protocole n’a été actée. Le speaker conclut sur la nécessité de commencer à travailler sur l’implémentation de ce protocole dans l’écosystème PHP afin de supporter ce nouveau standard dont la finalisation ne devrait plus tarder. 
Pour aller plus loin &lt;a href=&quot;https://oauth.xyz/&quot;&gt;https://oauth.xyz/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;a-self-training-journey-to-the-certification-symfony&quot;&gt;A self-training journey to the certification Symfony&lt;/h2&gt;
&lt;p&gt;Cette conférence traite de la méthodologie et des bonnes pratiques pour obtenir la fameuse certification Symfony.
En effet, la conférencière, &lt;a href=&quot;https://connect.symfony.com/profile/ca-jou&quot;&gt;Camille Jouan&lt;/a&gt;, nous présente sa manière de préparer l’examen.
Elle commence par énoncer son plan d’action :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Rassembler un maximum d’informations (Symfony doc, site pour la préparation à la certification, etc)&lt;/li&gt;
  &lt;li&gt;Organiser un plan autour du quoi/comment/pourquoi&lt;/li&gt;
  &lt;li&gt;Faire une timeline avec les étapes prévues&lt;/li&gt;
  &lt;li&gt;Se fixer un objectif dans le temps&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;L’idée est d’accepter que cela ne sera pas parfait et que des retouches vont y être apportées&lt;/p&gt;

&lt;p&gt;Pour Camille, l’idéal serait de pouvoir faire un test blanc au bout d’un certain temps de préparation sans “grandes convictions” : le but étant de se familiariser avec l’exercice.
Si les fonds sont disponibles, &lt;a href=&quot;https://training.sensiolabs.com/fr/courses/SF5PRECERTIF-preparation-certifcation-symfony-5-online-sensiolabs-university&quot;&gt;un training est proposé par Sensiolabs&lt;/a&gt;.
En fonction de cet examen blanc, ajuster son plan, se concentrer sur des parties qui doivent être approfondies.
Un autre point sur lequel la conférencière a insisté est le monitoring : régulièrement faire un bilan sur son avancée pour s’adapter.
Des outils comme Trello, Excel, Google permettent d’en avoir une vision globale.&lt;/p&gt;

&lt;p&gt;Il est important de parler de ce projet autour de soi, notamment auprès de ses proches pour avoir du soutien, mais également auprès de son entreprise qui peut éventuellement proposer une subvention et ou un aménagement du temps de travail.&lt;/p&gt;

&lt;p&gt;Elle conclut son intervention par un dernier conseil : cette méthodologie est adaptable à la vie quotidienne et peut être utile dans d’autres situations.&lt;/p&gt;

&lt;h2 id=&quot;notre-retour-dexpérience&quot;&gt;Notre retour d’expérience&lt;/h2&gt;
&lt;p&gt;Cette nouvelle édition de la SymfonyCon nous a permis de découvrir ou d’approfondir certaines connaissances. 
Nous pouvons aussi nous rendre compte de notre travail quotidien et prendre du recul sur celui-ci.
Cette expérience anglophone était très enrichissante et les conférences proposées étaient variées.
Il y avait de la résolution de problèmes techniques, des retours d’expériences ou encore de la télémétrie.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/symfonycon2022/IMG-0773.jpg&quot; alt=&quot;Fresque Lego symfony&quot; /&gt;&lt;/p&gt;</content><author><name>backend</name></author><category term="conferences" /><category term="backend" /><category term="symfony" /><category term="php" /><summary type="html">En cette fin d’année, une petite équipe de chez Bedrock a assisté au grand retour de la SymfonyCon 2022 après 3 ans d’absence. Nous avons eu la chance de découvrir les nouveautés liées à Symfony 6.2 et d’assister aux conférences sur de nombreux sujets techs à Disneyland. La keynote présentée par Fabien Potencier, le créateur de Symfony, nous donne un avant-goût des nouvelles fonctionnalités qui seront présentes dans la future version de Symfony. Au programme, un nouveau composant Webhooks ainsi que l’évolution du composant Mailer.</summary></entry><entry><title type="html">Un onboarding facilité grâce à la revue de code!</title><link href="https://tech.bedrockstreaming.com/2022/11/15/onboarding-revue-code.html" rel="alternate" type="text/html" title="Un onboarding facilité grâce à la revue de code!" /><published>2022-11-15T00:00:00+00:00</published><updated>2022-11-15T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/11/15/onboarding-revue-code</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/11/15/onboarding-revue-code.html">&lt;p&gt;Au sein des équipes de développement, une activité bien connue est celle de la revue de code, et 
plus 
précisément de la &lt;strong&gt;revue du delta du code&lt;/strong&gt;. Il s’agit de l’inspection par nos 
pairs du code proposé par nos soins, qui se trouve ainsi commenté pour répondre aux 
exigences de qualité de l’équipe et du projet.&lt;/p&gt;

&lt;p&gt;Les risques d’incompréhensions inhérents à la communication écrite, de malentendus
ou encore les remarques &lt;em&gt;malheureuses&lt;/em&gt; peuvent rendre cet exercice redouté tant par les 
relecteurs et relectrices 
que 
par celles et ceux dont le code est relu.&lt;/p&gt;

&lt;p&gt;Avant d’arriver chez Bedrock, j’étais un peu 
inquiète. Je savais déjà que les 9 personnes de ma future équipe font tou(te)s de la revue de code. 
&lt;strong&gt;Comment échangerons-nous? Saurai-je faire “bonne impression” via mes commentaires 
sur leur code ?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;En arrivant, j’ai été très 
agréablement surprise de découvrir que l’équipe applique un 
standard, celui des conventions de commentaires, &lt;a href=&quot;https://conventionalcomments.org/&quot;&gt;ou conventional comments&lt;/a&gt;. &lt;strong&gt;Grâce à cela, mon 
onboarding a été grandement facilité&lt;/strong&gt; et j’ai découvert une façon plus efficace d’écrire mes 
commentaires !&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt; : cet article est inspiré de ma conférence “&lt;em&gt;Revue de code : on n’est pas 
venu-e-s pour
souffrir !&lt;/em&gt;” donnée à l’occasion du meet-up anniversaire Duchess chez Dataiku en 2022 et &lt;a href=&quot;https://afup.org/talks/4038-revue-de-code-on-n-est-pas-venu-pour-souffrir&quot;&gt;au Forum
PHP 2022&lt;/a&gt;.&lt;/p&gt;

&lt;iframe width=&quot;1127&quot; height=&quot;773&quot; src=&quot;https://www.youtube.com/embed/LVh6iQtJW2I&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h2 id=&quot;petit-rappel--pourquoi-faisons-nous-des-revues-de-code-&quot;&gt;Petit rappel : pourquoi faisons-nous des revues de code ?&lt;/h2&gt;

&lt;p&gt;Passer en revue le code proposé par ses co-équipier(e)s est largement répandu dans les 
équipes de développeurs et développeuses. Bien sûr, la qualité du code en elle-même se trouve 
améliorée 
car chacun apporte un regard neuf sur ce qui est proposé, mais ce n’est pas tout. La 
revue de code est également une façon de nous tenir informé(e) de 
l’implémentation de nouvelles features, d’apprendre autant du métier que de la 
technique et enfin, d’apprendre à travailler ensemble.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-07-code-review-onboarding/code-review.png&quot; alt=&quot;Pourquoi faisons-nous de la code review ?&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Voici une 
petite liste non exhaustive de l’intérêt de la revue de code :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Améliorer la qualité et la lisibilité du code grâce aux remarques de toutes les
personnes de l’équipe&lt;/li&gt;
  &lt;li&gt;Appliquer les standards adoptés par l’équipe (et les apprendre !)&lt;/li&gt;
  &lt;li&gt;Détecter et corriger les éventuels bugs fonctionnels&lt;/li&gt;
  &lt;li&gt;Favoriser la collaboration en équipe&lt;/li&gt;
  &lt;li&gt;Former les développeurs et développeuses au fur et à mesure des remarques&lt;/li&gt;
  &lt;li&gt;Partager les responsabilités : en approuvant une pull request ou une merge request, nous
sommes responsables en tant qu’équipe du code ajouté/modifié au tronc commun !&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;et-parfois-on-souffre&quot;&gt;…Et parfois, on souffre&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-07-code-review-onboarding/parfois-on-souffre.png&quot; alt=&quot;parfois on souffre&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Mais parfois, ce n’est pas tout rose. Les commentaires qu’on laisse peuvent vexer. On 
peut nous-même être vexé. Car certains jours, on peut manquer d’empathie. On peut avoir 
l’impression d’être plus compétent(e) en 
critiquant les autres, on veut se rassurer en se montrant plus qualifié(e). On peut également 
être habitué(e) à une culture de la compétition, nous poussant ainsi à faire des remarques désagréables à nos pairs.&lt;/p&gt;

&lt;h2 id=&quot;comment-le-formatage-de-commentaire-a-t-il-amélioré-mon-arrivée-dans-léquipe-&quot;&gt;Comment le formatage de commentaire a-t-il amélioré mon arrivée dans l’équipe ?&lt;/h2&gt;

&lt;p&gt;La standardisation des commentaires a énormément amélioré mon intégration dans 
l’équipe. En effet, grâce à cela :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;J’ai pu rapidement me rendre compte de ce qui était bloquant / non bloquant et ainsi me 
&lt;strong&gt;concentrer sur les actions essentielles et prioritaires&lt;/strong&gt; à mener;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;je n’ai pas eu à me poser de questions sur le ton employé par mes collègues ni sur leur 
intention&lt;/strong&gt;;&lt;/li&gt;
  &lt;li&gt;j’ai pu rapidement faire moi-même des revues de code &lt;strong&gt;sans craindre d’être mal comprise&lt;/strong&gt;;&lt;/li&gt;
  &lt;li&gt;j’ai eu des retours qui m’ont permis de &lt;strong&gt;progresser sur la connaissance du fonctionnel&lt;/strong&gt; et 
des standards de la team.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;améliorer-sa-posture&quot;&gt;Améliorer sa posture&lt;/h2&gt;

&lt;p&gt;Avant de parler du standard, je vous propose de nous interroger sur 
notre posture en tant que développeur et développeuse. Recevoir ou donner des commentaires, ce 
n’est pas aisé pour tous. &lt;strong&gt;Notre ego peut interférer et dégrader la qualité de nos 
échanges avec nos collègues&lt;/strong&gt;. Aussi, avant de chercher à formater nos commentaires, nous pouvons 
nous interroger sur leur contenu.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-07-code-review-onboarding/egoless.png&quot; alt=&quot;Egoless programming&quot; /&gt;&lt;/p&gt;

&lt;p&gt;L’Egoless Programming, proposé par &lt;a href=&quot;https://en.wikipedia.org/wiki/Gerald_Weinberg&quot;&gt;Gerald Weinberg&lt;/a&gt; en 1971 dans son livre &lt;em&gt;The Psychology of 
Computer Programming&lt;/em&gt;, présente une dizaine de commandements pour nous 
aider à progresser.&lt;/p&gt;

&lt;p&gt;Le principe est le suivant : &lt;strong&gt;réduire au minimum les facteurs personnels lors des interactions 
avec ses pairs&lt;/strong&gt;, pour favoriser le travail en équipe et produire le maximum de qualité.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Critiquez le code au lieu des personnes,&lt;/li&gt;
  &lt;li&gt;Soyez factuels sur le code,&lt;/li&gt;
  &lt;li&gt;N’attaquez jamais les personnes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Je vous recommande de regarder cette excellente conférence sur l’egoless programming, où Olivier 
Thelu prend le temps de revenir sur tous les concepts :&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/728605321?h=60e48e1686&amp;amp;title=0&amp;amp;byline=0&amp;amp;portrait=0&quot; width=&quot;1127&quot; height=&quot;773&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;a href=&quot;https://vimeo.com/728605321&quot;&gt;Les 10 commandements de la programmation sans &amp;eacute;go - Olivier Thelu - MiXiT 2022&lt;/a&gt; from &lt;a href=&quot;https://vimeo.com/mixitconf&quot;&gt;MiXiT&lt;/a&gt; on &lt;a href=&quot;https://vimeo.com&quot;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Une autre excellente conférence de Kim Laï Trinh, lead développeur, et son &lt;a href=&quot;https://afup.org/talks/3415-auto-critique-de-la-revue-de-code-bienveillante&quot;&gt;“Auto-critique de la 
revue de code
bienveillante”&lt;/a&gt;.&lt;/p&gt;

&lt;iframe width=&quot;1127&quot; height=&quot;773&quot; src=&quot;https://www.youtube.com/embed/jMzhP1n19e8&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h2 id=&quot;formatez-vos-commentaires-&quot;&gt;Formatez vos commentaires !&lt;/h2&gt;

&lt;p&gt;Une fois qu’on a adopté une posture qui nous aide à mieux recevoir et donner des commentaires dans le cadre de nos revues de code, on peut réfléchir à la façon dont on les formate.&lt;/p&gt;

&lt;p&gt;Grâce au standard des &lt;a href=&quot;https://conventionalcomments.org/&quot;&gt;conventional comments&lt;/a&gt;, nous disposons d’une convention pour écrire des 
commentaires clairs et visuels et limiter les incompréhensions. Chacun de nous est invité 
à réfléchir à l’intention de son commentaire &lt;strong&gt;avant&lt;/strong&gt; de l’écrire.&lt;/p&gt;

&lt;p&gt;Par exemple, avec ce commentaire qui peut prêter à confusion (le OMG qui signifie “Oh my god” 
peut être autant interprété comme quelque chose de négatif que de positif, notamment ici puisque 
nous n’avons pas le contexte 😈) :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-07-code-review-onboarding/commentaire-omg.png&quot; alt=&quot;Utilisateur Kittycat dit : &amp;quot;Omg&amp;quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ce commentaire peut être préfixé par &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;praise&lt;/code&gt;, ce qui signifie éloge. Cela change radicalement 
le ton du commentaire.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-07-code-review-onboarding/commentaire-praise-omg.png&quot; alt=&quot;praise : Omg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Voici un autre exemple laconique : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Poubelle&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-07-code-review-onboarding/commentaire-poubelle.png&quot; alt=&quot;Poubelle&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Celui-ci peut être amélioré en étant préfixé par l’étiquette &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nitpick&lt;/code&gt;, qui signifie 
“tatillonner”, ce qui diminue également son ton dramatique. De plus, l’urgence peut être 
indiquée (ici, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;non-bloquant&lt;/code&gt;) et le contexte est décrit et peut être exploité grâce à un patch 
proposant un code de remplacement.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-07-code-review-onboarding/commentaire-nitpick.png&quot; alt=&quot;nitpick (non-bloquant): le résultat peut être directement retourné (patch)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;La compréhension du commentaire est facilitée par l’effort fourni pour ajouter le maximum de
contexte possible. On gagne en lisibilité grâce à la catégorisation (étiquette), qui nous permet
également d’immédiatement savoir de quoi on parle. Par exemple, une &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;question&lt;/code&gt; ne sera pas lue
de la même façon qu’une &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;suggestion&lt;/code&gt; !&lt;/p&gt;

&lt;p&gt;La contextualisation permet de savoir si on traite le retour immédiatement ou si on ouvre une
nouvelle pull request plus tard, pour rémedier au point soulevé. On limite ainsi les
quiproquos ou les pertes de temps sur des actions non prioritaires.
Et surtout, on limite les mauvaises impressions sur le ton employé.&lt;/p&gt;

&lt;h3 id=&quot;description-du-standard&quot;&gt;Description du standard&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;label&amp;gt; [decorations]: &amp;lt;subject&amp;gt;

[discussion]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;étiquette (label)&lt;/strong&gt; : “étiquette” pour signifier de quel genre de commentaire il s’agit&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;sujet (subject)&lt;/strong&gt; : le commentaire en lui-même&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;contexte supplémentaire (decorations)&lt;/strong&gt; (optionnel)  : labels supplémentaires pour donner plus d’indications (entre parenthèses, séparés par des virgules).
Exemple : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;non-blocking&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;blocking&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test&lt;/code&gt; …&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;discussion (optional)&lt;/strong&gt; : contexte, raisonnement ou tout autre élément pour aider à 
comprendre le « pourquoi » et les « prochaines étapes » pour résoudre le commentaire&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;les-labels&quot;&gt;Les labels&lt;/h3&gt;

&lt;p&gt;Voici la liste de labels ou étiquettes, extraits du standard :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;praise&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nitpick&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;suggestion&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;issue&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;todo&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;question&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;thought&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;chore&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;typo&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;polish&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quibble&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;L’équipe est, bien entendu, libre de choisir ou d’inventer ses labels ! Chez nous, le choix a été 
fait de respecter le standard tel qu’il est proposé, mais cela pourrait être rediscuté si besoin.&lt;/p&gt;

&lt;p&gt;Voici quelques définitions (pour le reste, &lt;a href=&quot;https://conventionalcomments.org/&quot;&gt;se référer au site du standard&lt;/a&gt;):&lt;/p&gt;

&lt;h4 id=&quot;praise-éloge&quot;&gt;Praise (éloge)&lt;/h4&gt;

&lt;p&gt;Grâce à ce commentaire, on souligne quelque chose de positif, on encourage la personne. Bien 
entendu, pas de second degré !&lt;/p&gt;

&lt;h4 id=&quot;suggestion-suggestion&quot;&gt;Suggestion (suggestion)&lt;/h4&gt;

&lt;p&gt;Les suggestions sont la majorité des commentaires qu’on laisse, en général. Il s’agit 
d’améliorations à apporter au sujet actuel. On cherchera à être explicite et clair,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;expliquer en quoi il s’agit d’une amélioration;&lt;/li&gt;
  &lt;li&gt;utiliser des patchs;&lt;/li&gt;
  &lt;li&gt;utiliser des décorations &lt;strong&gt;blocking&lt;/strong&gt; ou &lt;strong&gt;non-blocking&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;issue-problème&quot;&gt;Issue (problème)&lt;/h4&gt;

&lt;p&gt;Grâce aux issues, on met en évidence des problèmes spécifiques. Idéalement, on couple ce 
commentaire avec une &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Suggestion&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&quot;thought-pensée&quot;&gt;Thought (pensée)&lt;/h4&gt;

&lt;p&gt;Les pensées sont des idées qui surgissent lors de la relecture du code. Celles-ci ne sont pas 
bloquantes par nature, mais sont extrêmement précieuses, car elles peuvent conduire à des 
possibilités de mentorat.&lt;/p&gt;

&lt;h2 id=&quot;appropriez-vous-la-méthode-&quot;&gt;Appropriez-vous la méthode !&lt;/h2&gt;

&lt;p&gt;Bien entendu, vous n’êtes pas obligé d’utiliser toute la liste de labels proposée par le 
standard. Vous pouvez en choisir quelques uns, ou bien carrément vous en inspirer et créer les 
vôtres. C’est le choix qu’ont fait Camille et son équipe, &lt;a href=&quot;https://www.24joursdeweb.fr/2021/conventional-comments-faire-des-revues-de-code-avec-le-smiley/&quot;&gt;qu’elle décrit dans cet excellent 
article 
sur les conventional Comments et l’utilisation des emojis&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Ainsi, l’équipe a porté son choix sur une liste d’étiquettes illustrées par des emojis, qui 
traduisent à fois l’intention du commentaire et son urgence.
Voici quelques exemples, tirés de l’article :&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;🥜 peanuts&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;❓ question&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;💬 discussion&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;🚨 alerte&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;🚫 no-go&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;👏 bravo&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;⚠️ warning&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;☠️ bad idea&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;✨ magic&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;🔥 burn-it-all&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;quelques-autres-bonnes-pratiques-donboarding&quot;&gt;Quelques autres bonnes pratiques d’onboarding&lt;/h2&gt;

&lt;p&gt;Bien entendu, il y a plein d’autres façons d’aider vos nouveaux développeurs ou
nouvelles développeuses à découvrir le code. Voici quelques autres idées :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;On peut se familiariser avec le workflow d’une publication de pull request ou de merge 
request en faisant une petite modification (ajouter son nom dans un fichier, par exemple ?);&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;on peut être accompagné(e) d’un “buddy” qui nous est assigné à l’arrivée dans l’entreprise avec 
qui on fait les premières revues de code en direct, et pas par écrit.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Une dernière bonne pratique très largement répandue : si les échanges par commentaires sont trop 
nombreux sur une même pull request, pourquoi ne pas se retrouver directement et résoudre en pair 
les 
points discutés ?&lt;/p&gt;</content><author><name>Anne-Laure de Boissieu</name></author><category term="team" /><summary type="html">Au sein des équipes de développement, une activité bien connue est celle de la revue de code, et plus précisément de la revue du delta du code. Il s’agit de l’inspection par nos pairs du code proposé par nos soins, qui se trouve ainsi commenté pour répondre aux exigences de qualité de l’équipe et du projet.</summary></entry></feed>