<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://tech.bedrockstreaming.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://tech.bedrockstreaming.com/" rel="alternate" type="text/html" /><updated>2023-01-06T10:23:47+00:00</updated><id>https://tech.bedrockstreaming.com/feed.xml</id><title type="html">Bedrock Tech Blog</title><subtitle>Blog technique de Bedrock</subtitle><entry><title type="html">Nos retours sur l’HAProxyConf Paris 2022</title><link href="https://tech.bedrockstreaming.com/2022/12/23/haproxyconf-paris-2022.html" rel="alternate" type="text/html" title="Nos retours sur l’HAProxyConf Paris 2022" /><published>2022-12-23T00:00:00+00:00</published><updated>2022-12-23T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/12/23/haproxyconf-paris-2022</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/12/23/haproxyconf-paris-2022.html">&lt;p&gt;Bedrock était présent lors de la Conférence HAProxy qui se déroulait à Paris en novembre 2022 : en tant que speaker, avec la présentation de Vincent Gallissot, mais aussi en tant que spectateur. Cet article relate les points forts qui nous ont marqués.&lt;/p&gt;

&lt;p&gt;La présentation de Vincent Gallissot, Lead Cloud Architect chez Bedrock, mettait en valeur l’usage d’HAProxy en tant que brique essentielle de notre infrastructure. Chez Bedrock, nous développons et maintenons une plateforme de streaming qui a été migrée dans le Cloud en 2019. Cette présentation était grandement inspirée de l’article intitulé &lt;a href=&quot;https://tech.bedrockstreaming.com/2021/12/15/scaling-bedrock-video-delivery-to-50-million-users.html&quot; target=&quot;_blank&quot;&gt;“Scaling Bedrock video delivery to 50 million users”&lt;/a&gt;, dans lequel vous trouverez pléthore d’informations concernant nos utilisations d’HAProxy.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-12-23-haproxyconf-paris-2022/keynote_conf_2022_bedrockstreaming.jpg&quot; alt=&quot;Vincent Gallissot presentation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sommaire&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#ce-que-des-millions-de-requêtes-par-seconde-signifient-en-termes-de-coût-et-déconomie-dénergie&quot;&gt;Ce que des millions de requêtes par seconde signifient en termes de coût et d’économie d’énergie&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#un-outil-pour-les-gouverner-tous&quot;&gt;Un outil pour les gouverner tous&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#vous-reprendrez-bien-un-peu-de-pétaoctets-&quot;&gt;Vous reprendrez bien un peu de pétaoctets?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ce-que-des-millions-de-requêtes-par-seconde-signifient-en-termes-de-coût-et-déconomie-dénergie&quot;&gt;Ce que des millions de requêtes par seconde signifient en termes de coût et d’économie d’énergie.&lt;/h2&gt;

&lt;p&gt;La keynote d’ouverture avait pour orateur &lt;a href=&quot;https://twitter.com/willytarreau&quot; target=&quot;_blank&quot;&gt;Willy Tarreau&lt;/a&gt;, le Lead Developer d’HAProxy.&lt;br /&gt;
Au travers d’une démonstration concrète mélangeant software et hardware, l’objectif était de :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;transmettre l’idée qu’ajouter une brique logicielle dans un système ne le dégrade pas pour autant, bien au contraire&lt;/li&gt;
  &lt;li&gt;sensibiliser l’audience quant à la consommation d’énergie de nos systèmes&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;contexte-technique-et-premières-améliorations&quot;&gt;Contexte technique et premières améliorations&lt;/h3&gt;

&lt;p&gt;Pour ce premier cas d’étude, Willy Tarreau nous présente le cas d’un service de vente en ligne.&lt;/p&gt;

&lt;p&gt;La stack technique est composée de PHP / pgSQL (NodeJS + Symfony) et les images sont stockées en base de données. C’est cette architecture qui sera mise à l’épreuve lors des tests de charge à venir.&lt;/p&gt;

&lt;p&gt;Dans un premier temps, plusieurs améliorations (sans HAProxy) sont proposées. Il peut s’agir d’un simple rappel, voir d’un pro-tip d’architecture pour les plus novices : Les images en base de données, c’est une mauvaise idée.&lt;/p&gt;

&lt;p&gt;En les déplaçant vers un CDN, le système peut rapidement et simplement doubler ses performances, la base de données étant un goulot d’étranglement. La taille des pages peut être optimisée via l’activation de l’option http “gzip”. Les informations de sessions sont elles aussi enregistrées en base de données. Afin d’améliorer les performances, il est possible d’ajouter du caching via des outils tels que Memcache.&lt;/p&gt;

&lt;p&gt;Suite à cela, une première amélioration d’architecture serait d’ajouter un NLB (Network Load Balancer) en amont du système qui distribuerait les requêtes entrantes vers plusieurs unités de calculs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-12-23-haproxyconf-paris-2022/keynote_conf_2022_request_arch.png&quot; alt=&quot;next architecture schematic keynote&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Schéma d’architecture, première version&lt;/p&gt;

&lt;p&gt;Dans le cas présent, les requêtes entrantes sont distribuées de façon aléatoire entre les différentes unités de traitement. Chacun de ces backends se connectant à la même et unique base de données.&lt;br /&gt;
Le benchmark ci-dessous (efficacité, au sens nombre de requêtes traitées en fonction du nombre d’unités de calcul), ne montre pas une croissance linéaire. Il s’agit d’une courbe tendant vers une pente nulle (voir négative pour les plus grosses architectures).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-12-23-haproxyconf-paris-2022/keynote_conf_2022_nlb_stats.png&quot; alt=&quot;stats of nlb with backends&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Graphique représentant l’efficacité du système en fonction du nombre de backends&lt;/p&gt;

&lt;h3 id=&quot;comment-expliquer-que-cette-architecture-ne-scale-pas-linéairement-&quot;&gt;Comment expliquer que cette architecture ne scale pas linéairement ?&lt;/h3&gt;

&lt;p&gt;Malgré les améliorations apportées pour les sessions grâce au cache, il subsiste encore un problème.&lt;/p&gt;

&lt;p&gt;Le NLB est un composant qui ne fait que répartir la charge sans tenir compte de l’historique des requêtes. En effet, celui-ci va distribuer la charge d’entrée aléatoirement vers les backends.&lt;br /&gt;
Chaque backend reçoit des requêtes provenant de n’importe quel utilisateur impliquant alors un cache-miss très élevé : l’utilisateur est rarement trouvé dans le cache, ce qui génère une requête supplémentaire en base de données et dégrade les performances en plus de consommer inutilement des ressources.&lt;/p&gt;

&lt;h3 id=&quot;et-si-nous-ajoutons-haproxy-à-notre-système-&quot;&gt;Et si nous ajoutons HAProxy à notre système ?&lt;/h3&gt;

&lt;p&gt;C’est ici qu’entre en jeu HAProxy en remplaçant le NLB. Pour cela, pas besoin d’un foudre de guerre en termes de ressources.&lt;/p&gt;

&lt;p&gt;Les tests ont été effectués sur une machine ARM Breadbee cadencée à 1 GHz et possédant 64 Mo de RAM. Nous verrons également par la suite qu’on pourrait même se passer d’une machine supplémentaire.&lt;/p&gt;

&lt;p&gt;Le but d’HAProxy est de spécialiser les caches des backends et plus globalement de forcer les sessions utilisateurs vers les mêmes backends.&lt;/p&gt;

&lt;p&gt;Pour cela, HAProxy effectue une inspection de la couche 7 du trafic et renvoie toutes les requêtes d’un même utilisateur sur une même machine en réduisant ainsi les cache-miss aux seuls cas des nouveaux clients se connectant à la plateforme. Ainsi, le nombre d’appels à la base de données pour récupérer les informations de session est drastiquement réduit, la majorité d’entre elles étant stockées en cache.&lt;/p&gt;

&lt;p&gt;Autre fonctionnalité de taille : HAProxy limite le nombre de requêtes faites en parallèle sur un même backend, ce qui limite les locks de processus et les temps d’attente. Ceci a pour conséquence directe de réduire la consommation CPU.&lt;/p&gt;

&lt;p&gt;Ces deux améliorations permettent à l’application de scaler de façon beaucoup plus linéaire, tout en réduisant les consommations CPU et énergétiques inutiles. Globalement, les performances initiales sont largement dépassées avec deux fois moins de backends.&lt;/p&gt;

&lt;h3 id=&quot;a-partir-de-quand-est-il-intéressant-de-franchir-le-pas-&quot;&gt;A partir de quand est-il intéressant de franchir le pas ?&lt;/h3&gt;

&lt;p&gt;Maintenant que les bénéfices d’HAProxy ont été présentés, la prochaine étape est de se demander : quand est-ce qu’on se lance ? La question est considérée en termes de performance, mais aussi sous un angle pécunier.&lt;br /&gt;
Si HAProxy peut être intégré sans augmenter les coûts du système, c’est encore mieux.&lt;/p&gt;

&lt;p&gt;Ajouter HAProxy dans un système composé d’un seul backend n’apporte pas de bénéfice : il n’y a pas de load-balancing possible. Avec deux backends, si on divise le besoin de processing par deux, nous n’avons plus qu’un seul backend et donc pas de load-balancing possible.&lt;br /&gt;
C’est en fait à partir de 4 backends que l’ajout d’un HAProxy en entrée devient intéressant :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;en retirant 2 serveurs de nos backends en conservant une puissance équivalente (cf les tests ci-dessus)&lt;/li&gt;
  &lt;li&gt;et en recyclant un des deux backends retirés en hôte pour HAProxy
En fin de compte, pour une même puissance de traitement, un backend est retiré ce qui permet de réduire les coûts de fonctionnement. Ce principe s’applique également sur un grand nombre de backends.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;C’est là que prend tout son sens l’expression qui avait été utilisée pour conclure cette keynote : “HAProxy is a free software running on free hardware”.&lt;/p&gt;

&lt;p&gt;Chez Bedrock, nous appliquons aussi ces différentes techniques de Consistent Hashing en entrée de notre CDN vidéo. Nos caches vidéos sont spécialisés et chaque utilisateur est redirigé vers un unique backend lors de la lecture d’une vidéo.&lt;br /&gt;
Pour en savoir plus, vous pouvez consulter notre article au sujet du &lt;a href=&quot;https://tech.bedrockstreaming.com/2021/11/18/hsdo.html&quot; target=&quot;_blank&quot;&gt;Consistent Hashing&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;un-outil-pour-les-gouverner-tous&quot;&gt;Un outil pour les gouverner tous&lt;/h2&gt;

&lt;p&gt;Dans notre activité en informatique, nous sommes amenés à délivrer de plus en plus rapidement des applications, des mises à jour, etc… Nous avons donc adopté la philosophie DevOps et tout un panel d’outils autour de celle-ci afin de sécuriser, monitorer et automatiser chaque étape de nos pipelines de livraison.&lt;/p&gt;

&lt;p&gt;Le cas de figure du load balancing est intéressant dans ce type d’organisation, il est essentiel d’exposer de nouvelles applications sur les environnements de production mais étant donné que la maîtrise de cet outil requiert une compréhension du réseau, la responsabilité incombe souvent à l’équipe Ops de le gérer.&lt;/p&gt;

&lt;h3 id=&quot;vous-souhaitez-mieux-gérer-votre-flotte-haproxy-&quot;&gt;Vous souhaitez mieux gérer votre flotte HAProxy ?&lt;/h3&gt;

&lt;p&gt;Anjelko Iharos, directeur de l’ingénierie à HAProxy Technologies nous a présenté leur nouvel outil d’automatisation : HAProxy Fusion Control Plane, packagé dans la version entreprise de HAProxy.&lt;/p&gt;

&lt;p&gt;Celui-ci va amener une nouvelle interface enrichie afin de gérer toutes les instances HAProxy et les outils gravitant autour de ces dernières.&lt;/p&gt;

&lt;p&gt;On peut citer :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;La possibilité pour les développeurs de router eux-même leurs applications sans avoir besoin d’un Ops dans leurs pipelines de CI via l’API Fusion.&lt;/li&gt;
  &lt;li&gt;Gérer les WAF de HAProxy de manière centralisée et répercuter cette configuration sur un ensemble de clusters/instances.&lt;/li&gt;
  &lt;li&gt;Permettre aux Ops de gérer la structure de leurs load balancers, ajouter de nouvelles instances, gérer les certificats SSL, le tuning des performances depuis un seul point d’entrée.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;est-ce-résilient-&quot;&gt;Est-ce résilient ?&lt;/h3&gt;

&lt;p&gt;Fusion Control Plane est livré avec tout un set de features intéressantes pour assurer sa maintenabilité et sa résilience :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Une pleine observabilité avec une application unifiée de récupération de logs, métriques et rapports dans la même interface. L’export de ces data est possible, notamment pour les transposer dans un dashboard tiers (Grafana, par exemple).&lt;/li&gt;
  &lt;li&gt;Un système de RBAC permettant de mieux gérer les périmètres de chacune des équipes dans le control plane.&lt;/li&gt;
  &lt;li&gt;La gestion centralisée de la configuration, la validation des configurations et le bot management. La partie WAF est packagée avec OWASP (communauté publiant des recommandations pour la sécurisation des applications web) ModSecurity Core Rule Set (CRS) pour la détection des vulnérabilités. Dans le cadre d’un cluster un système de failover automatique avec auto-élection du leader (à la manière de GOSSIP avec Consul).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;une-vue-de-lavenir-&quot;&gt;Une vue de l’avenir ?&lt;/h3&gt;

&lt;p&gt;Aujourd’hui, Fusion Control Plane limite son scope à HAProxy Entreprise et Community Edition, les IngressController ne sont pour le moment pas encore supportés.&lt;/p&gt;

&lt;p&gt;Il n’est pas encore pleinement compatible avec les features offertes par AWS (Gestion des ASG et de Route53) mais c’est en cours de développement chez HAProxy Technologies.&lt;/p&gt;

&lt;p&gt;Le produit semble prometteur et intéressant. Les possibilités qu’il nous offre pour laisser la main aux développeurs sur la mise en place de routes vers leurs applications côté on-premise est vraiment un gros plus, mais il nous manque pour le moment le support de l’IngressController HAProxy utilisé sur nos cluster Kubernetes, ce qui nous empêche d’en profiter au maximum.&lt;/p&gt;

&lt;h2 id=&quot;vous-reprendrez-bien-un-peu-de-pétaoctets-&quot;&gt;Vous reprendrez bien un peu de pétaoctets ?&lt;/h2&gt;

&lt;p&gt;Chez Bedrock, un élément central de notre métier est de fournir de la vidéo à nos utilisateurs. (Incroyable pour une boite qui fait de la VOD hein? 😀).&lt;/p&gt;

&lt;p&gt;Pour ce faire nous avons nos propres serveurs CDN hébergés sur Paris, en complément des CDN publics comme Cloudfront ou Fastly. Cette année nous avons servis plusieurs centaines de PB de données via nos serveurs et nous espérons pouvoir au moins doubler ce trafic l’année prochaine !&lt;/p&gt;

&lt;p&gt;Notre architecture CDN est constituée d’un logiciel appelé LBCDN qui “load-balance” la charge sur les CDN, on-prem et publics, en redirigeant un utilisateur vers un serveur CDN spécifique.&lt;br /&gt;
Nos serveurs en eux-mêmes sont basés sur Nginx avec une configuration assez simple en direct IO sur de gros SSD.&lt;/p&gt;

&lt;p&gt;La HAproxy conf 2022 nous a pas mal inspirés pour répondre à nos problématiques avec ces deux conférences :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.haproxyconf.com/presentations/boost-your-web-apps-with-haproxy-and-varnish/&quot; target=&quot;_blank&quot;&gt;Boost your web apps with HAProxy and Varnish, by Jérémy Lecour CTO of Evolix&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.haproxyconf.com/presentations/was-that-really-haproxy/&quot; target=&quot;_blank&quot;&gt;Was That really HAProxy, by Ricardo Nabinger Sanchez performance engineer at Taghos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ces deux présentations font état d’une architecture sur les CDN intéressante où HAProxy est utilisé pour mettre “en sandwich” l’outil (ou les outils) faisant fonction de CDN.
L’architecture présentée semble permettre une configuration bien plus fine que ce que nous avons actuellement avec seulement Nginx.&lt;/p&gt;

&lt;p&gt;Par exemple, sur nos CDN on-prem nous devons aujourd’hui utiliser une astuce pour que Nginx puisse dynamiquement aller résoudre le nom de domaine du backend sur lequel il source ses fichiers. Cela est déjà un peu dommage de ne pas avoir de mécanisme disponible nativement. De plus, ce mécanisme est difficile à coupler avec d’autres permettant d’avoir du fail-over par exemple.&lt;/p&gt;

&lt;p&gt;C’est ici qu’HAProxy pourrait intervenir pour résoudre notre problématique car il nous permet d’avoir du fail over et des tests plus fins sur l’état de santé des backends.&lt;/p&gt;

&lt;p&gt;De plus, nous sommes en train de tester une solution de second-tier de CDN qui, du fait de la complexité ajoutée à notre architecture de CDN, profiterait beaucoup d’une plus grande finesse de configuration.&lt;/p&gt;

&lt;p&gt;“Mais attends, tu n’as parlé que de HAProxy en backend là, tu triches un peu non? C’est pas un sandwich c’est une tartine de HAProxy là!”
Tout à fait, notre cas d’usage actuel n’a pas forcément besoin d’un HAProxy en frontal de Nginx.&lt;/p&gt;

&lt;p&gt;MAIS!&lt;/p&gt;

&lt;p&gt;C’est là que les conférences sont intéressantes car elles montrent que l’on peut mixer les backends.&lt;br /&gt;
Dans la conférence présentée par Ricardo, l’utilisation de deux backends (Varnish et hyper-cache) sur un même serveur est permise par un HAProxy. Cela permet de profiter de la complémentarité de ces services.&lt;br /&gt;
Dans notre cas, nous n’avons pas besoin de cela mais une autre conférence nous a mis la puce à l’oreille : &lt;a href=&quot;https://www.haproxyconf.com/presentations/writing-haproxy-filters-in-rust/&quot; target=&quot;_blank&quot;&gt;Writing HAProxy Filters in Rust&lt;/a&gt;, by Aleksandr Orlenko.&lt;br /&gt;
Cela pourrait nous permettre, avec un HAProxy en frontal, d’agréger plus finement les mesures de performances du serveur afin d’optimiser l’usage de ses ressources, ou déporter une partie du trafic sur un serveur moins chargé, ou encore de récupérer une partie des traitements actuellement effectués par le LBCDN.&lt;/p&gt;

&lt;p&gt;Ajouter cette fonctionnalité serait la belle cerise au kirsch au sommet de ce sandwich de HAProxy.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-12-23-haproxyconf-paris-2022/keynote_conf_2022_cake.png&quot; alt=&quot;cake illustration&quot; /&gt;&lt;/p&gt;

&lt;p&gt;“Il est bizarre ton sandwich”&lt;/p&gt;

&lt;p&gt;“Bon d’accord, c’est plutôt un gâteau à étages.”&lt;/p&gt;

&lt;p&gt;“Ok c’est mieux, mais je préfère les macarons de la HAProxy Conf 2022 quand même.”&lt;/p&gt;

&lt;h2 id=&quot;a-une-prochaine-fois-&quot;&gt;A une prochaine fois !&lt;/h2&gt;

&lt;p&gt;La HAProxyConf, c’était deux jours de conférences avec des orateurs venus de tous les coins du globe.&lt;br /&gt;
Une belle occasion pour nous d’en apprendre plus sur un outil que nous utilisons quotidiennement chez Bedrock.&lt;br /&gt;
Dans cet article, nous n’avons pas pu faire mention de tout ce qui nous a intéressé. Nous pourrions notamment citer les très intéressantes conférences au sujet de :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Docker et leur utilisation de l’outil Keda&lt;/li&gt;
  &lt;li&gt;Ou encore de SoundCloud et leurs mesures anti-DDOS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cette conférence était aussi l’occasion d’échanger avec l’équipe HAProxy autour de sujets techniques qui nous concernent, de voir que nous utilisions déjà certaines bonnes pratiques, mais aussi que nous avions de quoi nous améliorer.&lt;/p&gt;

&lt;p&gt;Suite à cette conférence, c’est HAProxy Fusion que nous attendons le plus. Fusion s’annonce comme l’outil idéal pour manager une flotte d’HAProxy. Jusqu’à présent, nous devions utiliser une solution maison &lt;a href=&quot;https://tech.bedrockstreaming.com/2021/11/18/hsdo&quot; target=&quot;_blank&quot;&gt;HSDO&lt;/a&gt;, fonctionnelle, mais très probablement moins bien intégrée qu’un outil directement fourni par HAProxy.&lt;/p&gt;</content><author><name>Bedrock</name></author><category term="haproxy" /><category term="haproxyconf" /><category term="conference" /><summary type="html">Bedrock était présent lors de la Conférence HAProxy qui se déroulait à Paris en novembre 2022 : en tant que speaker, avec la présentation de Vincent Gallissot, mais aussi en tant que spectateur. Cet article relate les points forts qui nous ont marqués.</summary></entry><entry><title type="html">How Micro-Services changed our caching architecture</title><link href="https://tech.bedrockstreaming.com/2022/12/23/varnish-operator.html" rel="alternate" type="text/html" title="How Micro-Services changed our caching architecture" /><published>2022-12-23T00:00:00+00:00</published><updated>2022-12-23T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/12/23/varnish-operator</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/12/23/varnish-operator.html">&lt;p&gt;At Bedrock we use Cloudfront or Fastly for two different reason. To protect our applications from potential Distributed Denial of Service Attack. And to provide a layer of cache in front of our applications. No need to go down to the app for an easily cacheable response.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;before the project&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image0.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;At least that is what we thought in 2018 when we were migrating from on premise to the Cloud.&lt;/p&gt;

&lt;p&gt;At that time we had a Varnish instance caching everything at the border  of our on premise infrastructure. All the applications were running either on virtual machines or on bare metal servers. Those applications were mostly called by the end-user’s browser. Whenever an application called another application it did it through Varnish.&lt;/p&gt;

&lt;p&gt;This is ideal if applications are mostly called from the outside world. The Varnish instance caches all cacheable content, and it does not cost too much time as it was in the same Data Center.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;historically-before-2018&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image2.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;
In 2023, we think otherwise. We have now a &lt;a href=&quot;https://kops.sigs.k8s.io/&quot;&gt;KOps&lt;/a&gt; managed Kubernetes cluster running on EC2 spot instances in private subnets at AWS. As we migrated to the cloud we also embarked on the journey of splitting monolith into smaller more manageable microservices.&lt;/p&gt;

&lt;p&gt;With less monoliths the Bedrock product is more resilient and easier to scale but it changes the topologies of network calls. Before there were far more calls coming from the internet from end-users browsers. Now with the new architecture coming into place inter-app requests have increased.&lt;/p&gt;

&lt;p&gt;One solution would be to directly call the ingress of the applications, staying inside the cluster but without the benefit of caching as it is handled by the CDN. This would lead to unsustainable increase in CPU usage, and probably very little gain in terms of response time.&lt;/p&gt;

&lt;p&gt;A better solution for us would be to have the caching of CDN inside the cluster. This would enable us to have fast response time and little to no increase in CPU usage.&lt;/p&gt;

&lt;h1 id=&quot;enter-varnish-operator&quot;&gt;Enter Varnish-Operator&lt;/h1&gt;

&lt;p&gt;We tested the project &lt;a href=&quot;https://github.com/IBM/varnish-operator&quot;&gt;IBM/Varnish-Operator&lt;/a&gt;. This project allows us to create Custom Resources for Kubernetes handled by the Varnish-Operator. This object is called a VarnishCluster, the configuration is pretty simple to get started. This enables us to have a caching layer, between the Ingress-Controller and the Application.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;varnishcluster&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image1.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;VarnishCluster also uses Varnish Configuration Language (VCL) which we are pretty familiar with since we use Varnish On-Premise since 2015, and developers use it regularly to configure Fastly distribution.&lt;/p&gt;

&lt;p&gt;By adding cache using VarnishCluster to an application that is not fully cacheable, we almost divided it’s average response time by two. It is not a surprise as inter api calls used to look like the following graph:&lt;/p&gt;
&lt;center&gt;&lt;img alt=&quot;before-varnishcluster&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image3.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;We changed parameters in the application after adding VarnishCluster so that it calls other app inside the cluster like in the following graph:&lt;/p&gt;
&lt;center&gt;&lt;img alt=&quot;after-varnishcluster&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image4.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;a-few-details&quot;&gt;A few details&lt;/h1&gt;

&lt;p&gt;Before I wrap this up, here are a few details about the implementations.&lt;/p&gt;

&lt;p&gt;As you will be able to read in the Varnish documentation:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“By default Varnish will use 100 megabytes of malloc(3) storage for caching objects, if you want to cache more than that, you should look at the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-s&lt;/code&gt; argument.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So if you give many Gigs of memory to your Varnish container it won’t be attributed to the Varnish process. You can set it with the argument &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-s storage=malloc,&amp;lt;Number&amp;gt;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;As we use only Spot nodes that can be terminated by AWS at any moment with only 2 minutes notice, we want to give more resilience to our Varnish Clusters pod as cache is stored in RAM memory.
You lose all your cache at each restart of the Varnish Container.&lt;/p&gt;

&lt;p&gt;We configured &lt;a href=&quot;https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity&quot;&gt;podAntiAffinity&lt;/a&gt; between application pods and VarnishClusters’ to avoid scheduling those pods on the same node and be vulnerable to reclaims.&lt;/p&gt;

&lt;p&gt;We added a &lt;a href=&quot;https://kubernetes.io/docs/tasks/run-application/configure-pdb/&quot;&gt;podDisruptionBudget&lt;/a&gt; to avoid losing all our pods at the same time. We also customized the VCL a bit to make Varnish serve stale content in case our application is unreachable.&lt;/p&gt;

&lt;p&gt;We also added a Prometheus Service Monitor to make sure all Varnish metrics would be scraped by &lt;a href=&quot;https://tech.bedrockstreaming.com/2022/09/06/monitoring-at-scale-with-victoriametrics.html&quot;&gt;Victoria Metrics&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;in-the-future&quot;&gt;In the Future&lt;/h1&gt;

&lt;p&gt;In next versions we would like to add the possibility to configure &lt;a href=&quot;https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#priorityclass&quot;&gt;PriorityClass&lt;/a&gt; of VarnishClusters pod. PriorityClasses are used to order workloads priority.
In a context of scaling and of scarcity of resources, the scheduler will evict pods of lower priority to make room for the pod it is trying to schedule.&lt;/p&gt;

&lt;p&gt;For now our VarnishCluster’s pods have the PriorityClass by default but it is more critical than any other applications as it holds a cache in its memory.&lt;/p&gt;

&lt;p&gt;Also we do not have logs of Varnish. We would like to be able to stream VarnishLog content into &lt;a href=&quot;https://grafana.com/oss/loki/&quot;&gt;Loki&lt;/a&gt;. This would be super useful to debug and to investigate if we ever encounter bugs or unexpected behaviors.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;center&gt;&lt;img alt=&quot;average-Response-time after apps call through VarnishCluster&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image5.png&quot; /&gt;
&lt;p&gt;Average response time going down, red bar is when we pushed it in production&lt;/p&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;With the generalization of microservices, Bedrock needed to rethink its architecture to optimize not only for browser to API calls but also for more API to API usage. By adding VarnishCluster in front of our applications and calling them directly from inside the cluster we improved significantly the Bedrock product.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/IBM/varnish-operator&quot;&gt;The Github project&lt;/a&gt; is still young and lacks important features, we hope with this article to help draw attention to this project and potential contributors.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;meme-contribute-pls&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image6.jpg&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Arthur Zinck</name></author><category term="on-premise" /><category term="cloud" /><category term="cdn" /><category term="varnish" /><category term="aws" /><category term="cloud" /><category term="fastly" /><category term="varnish-operator" /><category term="cloudfront" /><category term="alb" /><summary type="html">At Bedrock we use Cloudfront or Fastly for two different reason. To protect our applications from potential Distributed Denial of Service Attack. And to provide a layer of cache in front of our applications. No need to go down to the app for an easily cacheable response.</summary></entry><entry><title type="html">Ce que nous retenons de la droidcon London 2022</title><link href="https://tech.bedrockstreaming.com/2022/11/22/droidcon-london-2022.html" rel="alternate" type="text/html" title="Ce que nous retenons de la droidcon London 2022" /><published>2022-11-22T00:00:00+00:00</published><updated>2022-11-22T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/11/22/droidcon-london-2022</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/11/22/droidcon-london-2022.html">&lt;p&gt;La communauté Android a apporté le soleil sur Londres les 27 et 28 octobre 2022. La droidcon London a réuni plus de 1400 développeurs autour de l’écosystème Android, de ses outils et enjeux actuels. Jetpack Compose, évidemment, mais aussi Gradle, modularisation, optimisation et autres sujets plus divers ont été abordés lors de ce rendez-vous incontournable pour la communauté.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/entrance.jpg&quot; alt=&quot;droidcon London 2022 entrance&quot; /&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#ça-compile----rafi-panoyan&quot; id=&quot;markdown-toc-ça-compile----rafi-panoyan&quot;&gt;Ça compile ? - Rafi Panoyan&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#vous-reprendrez-bien-un-peu-de-gradle-enterprise-&quot; id=&quot;markdown-toc-vous-reprendrez-bien-un-peu-de-gradle-enterprise-&quot;&gt;Vous reprendrez bien un peu de Gradle Enterprise ?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#dessine-moi-un-module&quot; id=&quot;markdown-toc-dessine-moi-un-module&quot;&gt;&lt;em&gt;Dessine-moi un module&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#trucs-et-astuces&quot; id=&quot;markdown-toc-trucs-et-astuces&quot;&gt;Trucs et astuces&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#design-the-world---damien-cuny&quot; id=&quot;markdown-toc-design-the-world---damien-cuny&quot;&gt;Design the world - Damien Cuny&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#to-compose&quot; id=&quot;markdown-toc-to-compose&quot;&gt;To Compose&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#design-system&quot; id=&quot;markdown-toc-design-system&quot;&gt;Design System&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#vers-linfini-et-au-delà&quot; id=&quot;markdown-toc-vers-linfini-et-au-delà&quot;&gt;Vers l’infini et au-delà&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#la-gestion-des-erreurs---david-yim&quot; id=&quot;markdown-toc-la-gestion-des-erreurs---david-yim&quot;&gt;&lt;strong&gt;La gestion des erreurs&lt;/strong&gt; - David Yim&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#vérification-des-entrées&quot; id=&quot;markdown-toc-vérification-des-entrées&quot;&gt;Vérification des entrées&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#le-type-either&quot; id=&quot;markdown-toc-le-type-either&quot;&gt;Le type Either&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#kotlin-result&quot; id=&quot;markdown-toc-kotlin-result&quot;&gt;Kotlin Result&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#conclusion&quot; id=&quot;markdown-toc-conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#à-la-prochaine-&quot; id=&quot;markdown-toc-à-la-prochaine-&quot;&gt;À la prochaine !&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ça-compile----rafi-panoyan&quot;&gt;Ça compile ? - Rafi Panoyan&lt;/h2&gt;

&lt;p&gt;Les sujets de compilation ont tenu une place très importante lors de cette édition de la droidcon Londres 2022. 
Qu’il s’agisse d’optimiser ses temps de compilation, de repenser la création de modules et des dépendances entre eux, de factoriser les logiques des scripts de compilation, 
nous avons eu une emphase claire sur l’importance d’adresser ces sujets.&lt;/p&gt;

&lt;h3 id=&quot;vous-reprendrez-bien-un-peu-de-gradle-enterprise-&quot;&gt;Vous reprendrez bien un peu de Gradle Enterprise ?&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/nellyspageli&quot;&gt;Nelson Osacky&lt;/a&gt;, qui travaille chez Gradle, a présenté tous les outils que la formule &lt;a href=&quot;https://gradle.com/&quot;&gt;Gradle Entreprise&lt;/a&gt; met à disposition des développeurs pour analyser en détail les compilations.&lt;/p&gt;

&lt;p&gt;Vous voulez vérifier que la compilation incrémentale est bien appliquée partout où cela est possible ? Un script permet de comparer, dans des conditions reproductibles, 
les entrées et sorties de vos builds, et analyse les tâches empêchant ce mécanisme central dans la réduction des temps de compilation.&lt;/p&gt;

&lt;p&gt;Vous voulez vous assurer que Gradle est bien capable de retrouver le cache de vos tâches sur un même poste ou bien depuis le cloud ? 
Là aussi des outils vous permettent d’identifier précisemment les points qui ne tirent pas parti de ces mécanismes.&lt;/p&gt;

&lt;p&gt;On regrettera que ces outils soient disponibles uniquement pour la formule payante de Gradle. Cependant, les &lt;a href=&quot;https://scans.gradle.com/&quot;&gt;scans Gradle&lt;/a&gt; sont, eux,
gratuits et illimités, et permettent tout de même de mesurer et comparer des compilations et ainsi suivre l’impact des différentes optimisations que vous pourriez apporter.&lt;/p&gt;

&lt;h3 id=&quot;dessine-moi-un-module&quot;&gt;&lt;em&gt;Dessine-moi un module&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;La modularisation ayant un impact sur les temps de compilation, plusieurs conférences ont abordé ce sujet très en vogue dans la communauté Android.&lt;/p&gt;

&lt;p&gt;Un point de vue intéressant de &lt;a href=&quot;https://twitter.com/josef_raska&quot;&gt;Josef Raska&lt;/a&gt; nous invite à nous poser la question de la pertinence de modulariser selon le contexte. 
Ne pas suivre une tendance mais se poser la question de l’utilité d’un nouveau module, et encore plus de ses dépendances avec les autres modules. 
Voilà des propos qui invitent à mesurer concrètement l’impact du chantier de la modularisation dans nos applications.&lt;/p&gt;

&lt;p&gt;Ainsi, si on peut penser que modulariser permet de réduire les temps de compilation (en tirant parti de la parallélisation des tâches par exemple), 
un chemin de dépendances trop long entre le module initial et la dépendance la plus profonde va entraîner une augmentation du temps de compilation.&lt;/p&gt;

&lt;p&gt;Vigilance, donc, sur les “hubs de dépendances” (ces dépendances dont beaucoup de modules ont besoin, et qui ont besoin de beaucoup de modules).&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/dep-hub.png&quot; alt=&quot;Dependency hub&quot; /&gt;
  &lt;figcaption&gt;1. Hub de dépendances&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;hr /&gt;

&lt;p&gt;De la même manière, un chemin de dépendances de trop grande profondeur ne permettra pas de tirer parti de la parallélisation des tâches de compilation.
Sur le schéma ci-dessous, on peut voir qu’un chemin de profondeur 4 existe pour aller du module applicatif vers le module le plus bas dans la hiérarchie.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/dep-height.png&quot; alt=&quot;Dependency height&quot; /&gt;
  &lt;figcaption&gt;2. Profondeur de dépendances&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;hr /&gt;

&lt;p&gt;Josef Raska propose le schéma suivant avec un découpage API/implémentation afin de réduire au maximum cette profondeur, et ainsi compiler plus rapidement.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/dep-height-fix.png&quot; alt=&quot;Dependency height fix&quot; /&gt;
  &lt;figcaption&gt;3. Profondeur de dépendances réduite&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;hr /&gt;

&lt;p&gt;Android Studio et son analyse de dépendances peut être très utile pour vérifier et mesurer cela.
Josef Raska a d’ailleurs créé un plugin Gradle afin de spécifier ces règles à l’echelle d’un projet et de s’assurer qu’elles soient respectées : &lt;a href=&quot;https://github.com/jraska/modules-graph-assert&quot;&gt;modules-graph-assert&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;trucs-et-astuces&quot;&gt;Trucs et astuces&lt;/h3&gt;

&lt;p&gt;Après ces conseils très avisés mais structurellement chronophages à mettre en place (surtout sur de gros projets déjà créés), d’autres conférenciers se sont plutôt tournés vers les “quick-win”. Des changements peu coûteux, aux gains plus modestes mais qui s’additionnent, il en existe quelques-uns.&lt;/p&gt;

&lt;p&gt;Ainsi, si Gradle nous permet d’activer des fonctionnalités de caching (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;org.gradle.unsafe.configuration-cache=true&lt;/code&gt; pour gagner du temps lors de la phase de configuration par exemple), il est aussi possible de désactiver des fonctionnalités du plugin Android si elles ne nous sont pas utiles.&lt;/p&gt;

&lt;p&gt;Voici une petite liste des propriétés qui sont activées par défaut, même lorsqu’elles ne sont pas utilisées dans les modules :&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;android {
  buildFeatures {
    buildConfig false
    aidl false
    renderScript false
    resValues false
    shaders false
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Si vous n’utilisez pas les valeurs liées à la configuration de votre compilation, ne générez pas de &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BuildConfig&lt;/code&gt;.
Si vous n’avez pas de resources dans votre module, désactivez la génération de &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;resValue&lt;/code&gt; !&lt;/p&gt;

&lt;p&gt;Retrouvez ici la liste de ces fonctionnalités, leur utilité et leurs valeurs par défaut : &lt;a href=&quot;https://developer.android.com/reference/tools/gradle-api/4.1/com/android/build/api/dsl/BuildFeatures&quot;&gt;BuildFeatures&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;design-the-world---damien-cuny&quot;&gt;Design the world - Damien Cuny&lt;/h2&gt;

&lt;p&gt;Il y a un peu plus d’un an sortait la version 1.0 de &lt;a href=&quot;https://developer.android.com/jetpack/compose&quot;&gt;Jetpack Compose&lt;/a&gt;, le nouveau toolkit déclaratif pour la création d’interfaces Android. D’autre part, le design system &lt;a href=&quot;https://m3.material.io/&quot;&gt;Material Design 3&lt;/a&gt; vient de sortir en version stable et son implémentation &lt;a href=&quot;https://developer.android.com/jetpack/androidx/releases/compose-material&quot;&gt;Compose Material&lt;/a&gt; sont également disponibles.&lt;br /&gt;
Avec tout cela, le design a, cette année encore, tenu une place de choix dans l’agenda de cette droidcon 2022 à Londres.&lt;br /&gt;
Mais comment utiliser tout cela correctement ? Comment s’en servir pour implémenter un design system personnalisé ? Jusqu’où peut-on aller ?
Autant de questions auxquelles ont tenté de répondre les nombreuses présentations sur le sujet.&lt;/p&gt;

&lt;h3 id=&quot;to-compose&quot;&gt;To Compose&lt;/h3&gt;

&lt;p&gt;Compose facilite beaucoup de choses dans l’implémentation et le maintien d’interfaces sur Android. Cependant, cela nécessite de réapprendre à faire certaines choses que l’on maîtrise déjà avec le système de &lt;a href=&quot;https://developer.android.com/reference/android/view/View&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;View&lt;/code&gt;&lt;/a&gt;.&lt;br /&gt;
Dessiner dans un canvas en est une, et &lt;a href=&quot;https://twitter.com/hi_man_shoe&quot;&gt;Himanshu Singh&lt;/a&gt; dans sa présentation &lt;em&gt;“Composing in your canvas”&lt;/em&gt;, nous montre les pièges à éviter pour réaliser cela avec Compose.&lt;/p&gt;

&lt;p&gt;La recomposition peut également être source de problèmes et de latences si Compose est mal utilisé. Dans sa présentation &lt;em&gt;“Understanding recomposition performance pitfalls”&lt;/em&gt;, &lt;a href=&quot;https://twitter.com/jossiwolf&quot;&gt;Jossi Wolf&lt;/a&gt; et &lt;a href=&quot;https://twitter.com/shikasd_&quot;&gt;Andrei Shikov&lt;/a&gt; nous donnent, à partir d’un exemple concret, les meilleures astuces pour l’utiliser à bon escient.&lt;/p&gt;

&lt;h3 id=&quot;design-system&quot;&gt;Design System&lt;/h3&gt;

&lt;p&gt;En faisant le parallèle avec la saga épique de JRR Tolkien, &lt;a href=&quot;https://medium.com/@danielbbeleza&quot;&gt;Daniel Beleza&lt;/a&gt;, dans sa présentation &lt;em&gt;“One design system to rule them all”&lt;/em&gt;, nous explique comment il a réussi, tout en se passant de &lt;a href=&quot;https://material.io&quot;&gt;Material design&lt;/a&gt;, à unifier et automatiser son propre design system.&lt;br /&gt;
Cela demande, évidemment, une collaboration totale de la part de l’équipe de design, mais une fois cette intégration faite, les bénéfices et l’autonomie se ressentent de part et d’autre.&lt;br /&gt;
Des outils tel que &lt;a href=&quot;https://www.figma.com/&quot;&gt;Figma&lt;/a&gt;, &lt;a href=&quot;https://square.github.io/kotlinpoet/&quot;&gt;Kotlin Poet&lt;/a&gt; ou des plugins Android Studio custom lui ont permis d’automatiser ensuite ce processus.&lt;/p&gt;

&lt;p&gt;Material Design est un design system. Il a l’avantage d’être bien documenté, uniforme et régulièrement enrichi. De plus, il est déjà implémenté dans l’ancien système de View Android et plus récemment dans Jetpack Compose avec &lt;a href=&quot;https://developer.android.com/jetpack/androidx/releases/compose-material&quot;&gt;Compose Material&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Une des différences majeures entre Compose et le système de View sur Android est son découpage. Dans Compose, Material n’est implémenté et n’apparaît que dans la partie la plus hautes alors que dans le système de View, son implémentation est répartie dans toutes les couches de la librairie.&lt;br /&gt;
Il est donc assez complexe de se passer de Material avec le système de View mais cela est complétement envisageable, voire recommandé, dans certains cas avec Compose.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/views-vs-compose.png&quot; alt=&quot;Views VS Compose&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Pour illustrer cela &lt;a href=&quot;https://twitter.com/seebrock3r&quot;&gt;Sebastiano Poggi&lt;/a&gt; (la moitié de &lt;a href=&quot;https://www.youtube.com/c/CodewiththeItalians&quot;&gt;Coding with the italians&lt;/a&gt;) est venu nous présenter, dans &lt;em&gt;“Compose beyond Material”&lt;/em&gt;, les questions à se poser avant de se lancer dans son design system et comment le package &lt;a href=&quot;https://developer.android.com/jetpack/androidx/releases/compose-foundation&quot;&gt;Foundation&lt;/a&gt; de Compose peut nous aider.&lt;/p&gt;

&lt;p&gt;Pour terminer il nous donne de nombreux conseils concrets sur l’implémentation de composants sans Material. Le principal, rejoint la présentation d’introduction de cette droidcon, &lt;em&gt;“The Silver Bullet Syndrome Director’s Cut - Complexity Strikes Back!”&lt;/em&gt;, un bon design system est un design system qui correspond à nos besoins et qui y répond le plus simplement possible.&lt;/p&gt;

&lt;h3 id=&quot;vers-linfini-et-au-delà&quot;&gt;Vers l’infini et au-delà&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/chrisbanes&quot;&gt;Chris Bane&lt;/a&gt; et &lt;a href=&quot;https://twitter.com/mrmans0n&quot;&gt;Nacho Lopez&lt;/a&gt; dans leur présentation &lt;em&gt;“Branching out Jetpack Compose”&lt;/em&gt;, nous ont raconté comment l’aventure du passage à Compose s’est déroulée chez Twitter, une des premières apps à l’adopter.&lt;br /&gt;
Avec une code base aussi conséquente (plus de &lt;strong&gt;1000 modules&lt;/strong&gt;, dont 300 pour le design, répartis sur plus de 30 équipes), ils ont dû progressivement convaincre les équipes, les former et les accompagner.&lt;br /&gt;
La question de continuer à utiliser Material Design s’est également posée chez eux. Ils l’ont dans un premier temps conservé pour faciliter le passage sur Compose, pour finalement le retirer complètement en se basant, eux aussi, sur le package Foundation.&lt;br /&gt;
Leur présentation résume bien l’ensemble des étapes et des questions par lesquelles ils sont passés pour accomplir cette transition.&lt;/p&gt;

&lt;p&gt;Afin de remettre les choses en perspective, &lt;a href=&quot;https://twitter.com/askashdavies&quot;&gt;Ash Davies&lt;/a&gt; nous rappelle que Compose est un simple pattern de développement multiplateforme. De ce fait, il peux être appliqué à autre chose qu’à de l’UI comme le propose Jetpack Compose. Il nous explique dans &lt;em&gt;“Demystifying Molecule: Running Your Own Compositions For Fun And Profit”&lt;/em&gt;, comment l’appliquer à la couche domaine d’un projet pour le “Fun”.&lt;/p&gt;

&lt;h2 id=&quot;la-gestion-des-erreurs---david-yim&quot;&gt;&lt;strong&gt;La gestion des erreurs&lt;/strong&gt; - David Yim&lt;/h2&gt;

&lt;p&gt;La gestion des erreurs a été le sujet de plusieurs présentations à la droidcon. Ces présentations avaient pour objectif de servir de piqûre de rappel sur l’importance de bien prendre en compte ce problème concernant tous les développeurs. Aujourd’hui, nous avons tous les outils pour gérer facilement nos erreurs. Cependant, par paresse et comme nous préférons penser de manière positive, nous ne pensons souvent qu’aux cas de succès et les cas d’erreurs sont souvent brouillons voire ne sont même pas spécifiés.&lt;/p&gt;

&lt;p&gt;Les speakers m’ont marqué avec un exemple de mauvaise gestion d’erreur qui a coûté plusieurs centaines de milliers de dollars. L’exemple parlait d’une faille sur le site japonais de 7-Eleven, une chaîne de supérettes, dont elle a été victime. Dans la base de données de ce projet, les développeurs ont ajouté un champ “date de naissance” comme nullable. Plus tard, ce champ est devenu non-nullable. Par paresse, le développeur qui a rendu ce champ non-nullable a mis par défaut un 1er janvier 2019 sur cette date lorsqu’elle n’était pas renseignée, simplement pour satisfaire son compilateur. Le problème est que ce champ fut plus tard utilisé dans la fonctionnalité de mot de passe oublié du site. En utilisant la date par défaut du 1er janvier 2019, un hacker a pu récupérer des comptes utilisateurs et voler des informations bancaires. Cet exemple m’a marqué par l’habitude que nous avons en tant que développeur de nous soucier que de satisfaire notre compilateur plutôt que de vraiment discuter de solutions réfléchies à nos problèmes techniques.&lt;/p&gt;

&lt;p&gt;Plusieurs méthodes de gestion des erreurs existent et les speakers en ont présentés quelques-unes.&lt;/p&gt;

&lt;h4 id=&quot;vérification-des-entrées&quot;&gt;Vérification des entrées&lt;/h4&gt;

&lt;p&gt;L’une des méthode pour être certain de ne pas avoir de problème est de vérifier les données que l’on reçoit. Prenons un exemple simple :&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;data class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Rien n’empêche d’instancier cette classe de la manière suivante :&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;email&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Cela peut créer des problèmes par le futur, alors qu’il y a un moyen d’éviter cela&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Email&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Regex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;EMAIL_FORMAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;matches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Email format is not correct&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;data class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Email&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Cette méthode peut paraître un peu exagérée dans cet exemple. Mais dans un contexte où la classe &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;User&lt;/code&gt; serait utilisée par un grand nombre d’équipes et que les règles métier de l’&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Email&lt;/code&gt; serait complexe, cette méthode prendrait tout son sens pour éviter d’avoir de mauvaises surprises !&lt;/p&gt;

&lt;h4 id=&quot;le-type-either&quot;&gt;Le type Either&lt;/h4&gt;

&lt;p&gt;Le type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Either&lt;/code&gt; est un moyen de différencier les cas de succès des cas d’erreurs. Il est disponible dans la &lt;a href=&quot;https://arrow-kt.io/&quot;&gt;librairie Arrow&lt;/a&gt; ou facilement reproduisible :&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;sealed&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nothing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;()&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Nothing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;L’utilisation de ce type est qu’il est soit un type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt;, soit un type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt;. On peut ainsi définir par exemple que le &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt; est un cas de succès et que le type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt; est un cas d’erreur.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;data class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;when&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Left&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;The user is called ${(either as Either.Left&amp;lt;User&amp;gt;).value.name}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Right&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;either&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Grâce à ce type, on peut par exemple savoir si un appel à une API a réussi ou non, ce qui nous permet de gérer plus facilement nos cas d’erreurs.&lt;/p&gt;

&lt;h4 id=&quot;kotlin-result&quot;&gt;Kotlin Result&lt;/h4&gt;

&lt;p&gt;La classe &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Result&lt;/code&gt; est similaire au type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Either&lt;/code&gt; et a pour avantage d’être directement inclue dans Kotlin et que l’on n’a pas à se synchroniser pour savoir si le côté gauche est le cas de succès ou d’erreur.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;data class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;when&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isSuccess&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;The user is called ${result.getOrNull()?.name}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isFailure&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exceptionOrNull&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nc&quot;&gt;OU&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;onSuccess&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;The user is called ${user.name}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;onFailure&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Plusieurs méthodes existent pour prendre en compte nos cas d’erreurs. Laquelle est la meilleure ? Eh bien vous vous y attendez sûrement, mais ça dépend ! On choisira une méthode ou une autre selon ce qui nous arrange par rapport à la situation, nos choix d’outils techniques ou nos effectifs. L’important étant de prendre en compte ces cas d’erreurs et de ne pas laisser leur résolution au hasard. Les cas d’erreurs ne sont en fait que d’autres usecases de l’utilisateur et souvent ne sont pas des edgecase. Ils méritent donc d’être tout autant réfléchis et spécifiés que les cas de succès !&lt;/p&gt;

&lt;h2 id=&quot;à-la-prochaine-&quot;&gt;À la prochaine !&lt;/h2&gt;

&lt;p&gt;Il est toujours intéressant de mesurer l’engouement pour tel ou tel sujet dans la communauté Android en analysant les présentations lors des différentes conférences technologiques.&lt;/p&gt;

&lt;p&gt;Sans aucun doute, cette droidcon était sous le signe de Jetpack Compose, qui bénéficie d’un suivi et d’un engagement fort de Google et de toute la communauté.&lt;br /&gt;
Tout l’enjeu ici est de rester au contact des innovations et de l’évolution de la plateforme Android, et Jetpack Compose offre un défi que nous avons commencé à relever chez Bedrock.&lt;/p&gt;

&lt;p&gt;Nous attendons avec impatience de voir où va Android, et avons à coeur de participer à cette aventure qui nous lie tous !&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/hall.jpg&quot; alt=&quot;Hall droidcon London 2022&quot; /&gt;&lt;/p&gt;</content><author><name>[&quot;rpanoyan&quot;, &quot;d_yim&quot;, &quot;d_cuny&quot;]</name></author><category term="android" /><category term="droidcon" /><category term="conference" /><summary type="html">La communauté Android a apporté le soleil sur Londres les 27 et 28 octobre 2022. La droidcon London a réuni plus de 1400 développeurs autour de l’écosystème Android, de ses outils et enjeux actuels. Jetpack Compose, évidemment, mais aussi Gradle, modularisation, optimisation et autres sujets plus divers ont été abordés lors de ce rendez-vous incontournable pour la communauté.</summary></entry><entry><title type="html">How many DynamoDB RCU and WCU should we reserve to achieve maximum cost reductions, when our workloads are changing all the time?</title><link href="https://tech.bedrockstreaming.com/2022/11/22/dynamodb-reservations.html" rel="alternate" type="text/html" title="How many DynamoDB RCU and WCU should we reserve to achieve maximum cost reductions, when our workloads are changing all the time?" /><published>2022-11-22T00:00:00+00:00</published><updated>2022-11-22T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/11/22/dynamodb-reservations</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/11/22/dynamodb-reservations.html">&lt;p&gt;Many of the microservices in our VOD and Replay platform use DynamoDB as their database.&lt;br /&gt;
Performance is very good if the data is architected for it, scalability is reasonably fast, and the serverless aspect offloads a lot of the administration and hosting work. Whether it’s performance, resilience or time-to-market, DynamoDB helps us achieve our business goals.&lt;/p&gt;

&lt;p&gt;That said, when we spend several hundred thousand dollars on DynamoDB every year, any optimization is good for us!&lt;/p&gt;

&lt;p&gt;With DynamoDB, committing to a certain capacity for a year can help reduce costs – up to 50% savings on that capacity. But how do we know how much to reserve when traffic on our platform varies throughout the day?&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#dynamodb-a-not-always-obvious-cost-model&quot;&gt;DynamoDB: a not always obvious cost model!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#how-many-wcus-and-rcus-do-we-consume&quot;&gt;How many WCUs and RCUs do we consume?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#in-theory-how-much-should-we-reserve-to-achieve-maximum-savings&quot;&gt;In theory: how much should we reserve, to achieve maximum savings?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#in-practice-lets-calculate-how-much-to-reserve&quot;&gt;In practice: let’s calculate how much to reserve!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#finally-lets-create-those-reservations&quot;&gt;Finally, let’s create those reservations!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#after-reserving-viewing-the-costs&quot;&gt;After reserving, viewing the costs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;dynamodb-a-not-always-obvious-cost-model&quot;&gt;DynamoDB: a not always obvious cost model!&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;&lt;a href=&quot;#in-practice-lets-calculate-how-much-to-reserve&quot;&gt;To skip all the theory about how DynamoDB is priced and WCUs, RCU, on-demand and provisionned billing modes, click here…&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;DynamoDB is serverless&lt;sup id=&quot;fnref:serverless-but-still-some-work&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:serverless-but-still-some-work&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But, as with many AWS services, you have to think for a while before you really understand DynamoDB costs…&lt;/p&gt;

&lt;h3 id=&quot;out-of-scope-costs&quot;&gt;Out of scope costs&lt;/h3&gt;

&lt;p&gt;We pay for the volume of data stored, the volume of data backed up. These costs are outside the scope of this article and I won’t talk about them again today. They are not zero, however, and can even be a significant part of your bill – for example, if you store large data for a long time&lt;sup id=&quot;fnref:dynamodb-standard-ia&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:dynamodb-standard-ia&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; in DynamoDB. Something you probably shouldn’t do!&lt;/p&gt;

&lt;h3 id=&quot;wcus-and-rcus&quot;&gt;WCUs and RCUs&lt;/h3&gt;

&lt;p&gt;Each DynamoDB table can be configured in either &lt;em&gt;on-demand&lt;/em&gt; or &lt;em&gt;provisioned&lt;/em&gt; billing mode.&lt;/p&gt;

&lt;p&gt;In the second case, we pay for RCUs &lt;em&gt;(Read Capacity Units)&lt;/em&gt; and WCUs &lt;em&gt;(Write Capacity Units)&lt;/em&gt;, depending on the capacity we provision for each table.&lt;br /&gt;
Reservations only matter for these RCUs and WCUs, in purple in the screenshot below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/01-ddb-cost-by-api-operation.png&quot; alt=&quot;Cost by API Operation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Over the past year, our WCU and RCU costs in provisioned mode represent about half of our DynamoDB costs.&lt;br /&gt;
Storage and backups have costs that we consider negligible today.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;And, from a financial standpoint, we work with far too many pay-per-request tables&lt;sup id=&quot;fnref:why-so-much-pay-per-request&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:why-so-much-pay-per-request&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; for my taste.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/dynamodb/pricing/&quot;&gt;The documentation&lt;/a&gt; will tell you more, but in very broad terms:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;One WCU is consumed when writing one line of data. Or for each 1 KB block written.&lt;/li&gt;
  &lt;li&gt;One RCU is consumed to read one line of data. Or for each 4 KB block read.&lt;/li&gt;
  &lt;li&gt;In eventually-consistent read mode, only 1/2 RCU is consumed to read one line of data. Or for each 4 KB block.&lt;/li&gt;
  &lt;li&gt;Transactional mode costs twice as much.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As you can imagine, the first optimization is to store only what is necessary and to request DynamoDB in the way that best meets the needs of the application, including consistency and costs. Developing a data schema that efficiently meets the needs of the application is crucial. I highly recommend you read &lt;a href=&quot;https://www.dynamodbbook.com/&quot;&gt;Alex DeBrie’s very good “The DynamoDB Book”&lt;/a&gt;! Financial optimization based on reservations should – and can – only come afterwards, when usage patterns have been dealt with.&lt;/p&gt;

&lt;h3 id=&quot;the-on-demand--pay-per-request-mode&quot;&gt;The on-demand / pay-per-request mode&lt;/h3&gt;

&lt;p&gt;In &lt;em&gt;on-demand&lt;/em&gt; mode, we &lt;em&gt;theoretically&lt;/em&gt; don’t have to worry about scalability, DynamoDB handles it for us&lt;sup id=&quot;fnref:dynamodb-on-demand-scalability&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:dynamodb-on-demand-scalability&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;In this mode, we pay for each RCU and WCU we consume. If we don’t use DynamoDB, we don’t pay. If we use DynamoDB, we pay.&lt;br /&gt;
The counterpart is that RCUs and WCUs are more expensive in this mode than in the one presented below.&lt;/p&gt;

&lt;p&gt;This mode is therefore very practical, in my opinion, in two cases:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In an environment where we only perform a few queries from time to time (dev, staging).&lt;/li&gt;
  &lt;li&gt;For tables that are usually not used much, but receive large and sudden peaks of requests at certain times.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This mode is not adapted, especially because costs are too high:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For tables where consumption is stable or varies slowly. Typically, tables for which usage follows our daily traffic wave, which is gentle enough on most applications for a reactive auto-scaling mechanism to meet our needs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;provisioned-mode&quot;&gt;Provisioned mode&lt;/h3&gt;

&lt;p&gt;In &lt;em&gt;provisioned&lt;/em&gt; mode, we configure how many RCUs and WCUs we want and we pay for that number of RCUs and WCUs – no matter if we consume them or not.&lt;br /&gt;
This billing mode is therefore less flexible than &lt;em&gt;on-demand&lt;/em&gt;. On the other hand, RCUs and WCUs are less expensive.&lt;/p&gt;

&lt;p&gt;In &lt;em&gt;provisioned&lt;/em&gt; mode, we can set up an auto-scaler on the RCUs and WCUs of the tables that need it. It will dynamically reconfigure the provisioned RCUs and WCUs for those tables, to approximate the actual usage. With an auto-scaler, we can pay as close as possible to our actual consumption, at the provisioned price, which is lower than the on-demand one.&lt;br /&gt;
However, scale-out is not instantaneous: it takes several minutes to detect it needs to act, and then up to several minutes &lt;em&gt;(especially on a large table)&lt;/em&gt; to do so. Also, scale-in can only be triggered around once per hour. For more detailed information, read &lt;a href=&quot;https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html&quot;&gt;the documentation&lt;/a&gt; and &lt;a href=&quot;https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ServiceQuotas.html&quot;&gt;the quota page&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This mode is especially recommended, in my opinion and considering our workloads:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;As often as possible, since each RCU and WCU costs much less than in on-demand mode.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This mode is not suitable:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;On tables where consumption varies very abruptly.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;in-provisioned-mode-reservations&quot;&gt;In provisioned mode, reservations&lt;/h3&gt;

&lt;p&gt;By agreeing to pay for a certain amount of RCU and WCU for one year &lt;em&gt;(or even three years in some regions)&lt;/em&gt;, these RCU and WCU become even cheaper: up to ~50%&lt;sup id=&quot;fnref:50-percent-savings&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:50-percent-savings&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; cheaper than in default-provisioned mode.&lt;br /&gt;
Reserving capacity is a great way to considerably reduce the cost of read/write operations on DynamoDB!&lt;/p&gt;

&lt;p&gt;Reservations lock us for one year. We will pay for the reserved RCUs and WCUs, whether we use them or not.&lt;br /&gt;
It is therefore important to calculate correctly the reservations to be made.&lt;/p&gt;

&lt;p&gt;Also, we pay a part of the total yearly amount at the beginning of the commitment &lt;em&gt;(= “upfront”)&lt;/em&gt;, which means we must be able to invest a certain amount in advance.&lt;br /&gt;
The other part is spread over all the months of the commitment period.&lt;/p&gt;

&lt;p&gt;As a consequence, the &lt;em&gt;big question&lt;/em&gt;, to which the rest of this document tries to answer, is: &lt;em&gt;“how many RCU and WCU should we reserve to keep our costs as low as possible?”&lt;/em&gt;&lt;br /&gt;
When our consumption varies throughout the day, this calculation is pretty fun ;-)&lt;/p&gt;

&lt;p&gt;Reservations are global to an AWS account, or even to all accounts on a consolidated bill&lt;sup id=&quot;fnref:consolidated-billing&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:consolidated-billing&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;→ Reserved pricing is documented on the &lt;a href=&quot;https://aws.amazon.com/dynamodb/pricing/provisioned/&quot;&gt;page of “provisioned” pricing&lt;/a&gt;.&lt;br /&gt;
→ You can also read &lt;a href=&quot;https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-reservation-models/amazon-dynamodb-reservations.html&quot;&gt;this whitepaper&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;how-many-wcus-and-rcus-do-we-consume&quot;&gt;How many WCUs and RCUs do we consume?&lt;/h2&gt;

&lt;p&gt;For the rest of our reasoning and this article, we only count the consumption in &lt;em&gt;provisioned&lt;/em&gt; mode (and exclude &lt;em&gt;on-demand&lt;/em&gt;), since that’s where we can play with reservations.&lt;br /&gt;
Also, we count provisioned WCU and RCU and not what is actually consumed – so beware of any potential &lt;em&gt;waste&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;On the DynamoDB Web Console home screen, we can see, for an account and a region, how many WCUs and RCUs are provisioned at the current time:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/02-ddb-capacity-used-right-now-in-one-account-and-region.png&quot; alt=&quot;DynamoDB Capacity used, right now, in one account and region&quot; /&gt;&lt;/p&gt;

&lt;p&gt;But these numbers only give a view at a given instant, in a single AWS account and in a single region.&lt;br /&gt;
We deploy our platform across dozens of accounts and multiple regions, with traffic that changes throughout the day, so this is not enough.&lt;/p&gt;

&lt;h3 id=&quot;table-wcusrcus&quot;&gt;Table WCUs/RCUs&lt;/h3&gt;

&lt;p&gt;For a global view of all tables in an account in a region, we can query Cloudwatch Metrics, analyzing the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ProvisionedWriteCapacityUnits&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ProvisionedReadCapacityUnits&lt;/code&gt; metrics:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/03-ddb-write-capacity-per-table-cloudwatch-metrics-CENSORED.png&quot; alt=&quot;Write capacity per table, Cloudwatch metrics&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The Stacked Area view shows, at any given time, the total WCUs (or RCUs) provisioned for all of our tables, in an account and a region.&lt;/p&gt;

&lt;h3 id=&quot;wcurcu-of-gsi&quot;&gt;WCU/RCU of GSI&lt;/h3&gt;

&lt;p&gt;We also need to count the WCUs/RCUs of the Global Secondary Indexes – and these are different metrics! Or, at least, the metrics are shown in a different category in the Cloudwatch web console.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/04-ddb-write-capacity-per-gsi-cloudwatch-metrics-CENSORED.png&quot; alt=&quot;Write capacity per GSI, Cloudwatch metrics&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;so-in-total&quot;&gt;So, in total…&lt;/h3&gt;

&lt;p&gt;To get the total, you have to consider this metric for the tables and for the Global Secondary Indexes! In the Cloudwatch console, you have to search in two categories.&lt;br /&gt;
Graphing it all :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/05-ddb-write-capacity-all-cloudwatch-metrics-CENSORED.png&quot; alt=&quot;Total write capacity, Cloudwatch metrics&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Of course, this is to be looked at for WCUs, but also for RCUs, following exactly the same principle.&lt;br /&gt;
And, again, we’re working in multiple accounts and regions.&lt;/p&gt;

&lt;h2 id=&quot;in-theory-how-much-should-we-reserve-to-achieve-maximum-savings&quot;&gt;In theory: how much should we reserve, to achieve maximum savings?&lt;/h2&gt;

&lt;p&gt;Once we know how much capacity we’re actually using, we can move on to reservations.&lt;/p&gt;

&lt;p&gt;But the calculation would be far too easy if our usage was flat!&lt;br /&gt;
In reality, thanks to auto-scaling, our provisioned capacity follows our usual traffic pattern: a wave.&lt;/p&gt;

&lt;p&gt;And, two things:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;if we reserve more than we provision, we’ll waste money.&lt;/li&gt;
  &lt;li&gt;if we reserve less than we provision, we won’t save as much as we could.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reserve-at-the-bottom-of-the-wave&quot;&gt;Reserve at the bottom of the wave&lt;/h3&gt;

&lt;p&gt;A first idea is to reserve the lowest value we provision throughout the day: what we provision at the bottom of our traffic wave, at night.&lt;/p&gt;

&lt;p&gt;In this case, we are not wasting money, as we always provision 100% or more of our reservation.&lt;br /&gt;
But we are probably minimizing our savings, since we are provisioning more than the reservation, all day long.&lt;/p&gt;

&lt;h3 id=&quot;reserve-at-the-top-of-the-wave&quot;&gt;Reserve at the top of the wave&lt;/h3&gt;

&lt;p&gt;A second idea, kind of the opposite, is to reserve the highest value we provision throughout the day.&lt;br /&gt;
This way, we will never pay the full rate for any WCU/RCU.&lt;/p&gt;

&lt;p&gt;But, in this case, we will be wasting a lot of money, since all day long we will be provisioning less than our reservation.&lt;br /&gt;
This is a &lt;em&gt;bad idea&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;reserve-in-the-middle-thanks-to-careful-calculations&quot;&gt;Reserve “in the middle”, thanks to careful calculations&lt;/h3&gt;

&lt;p&gt;Now, the real solution: calculate the &lt;em&gt;right value&lt;/em&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Less than &lt;em&gt;the highest value&lt;/em&gt;, to minimize waste.&lt;/li&gt;
  &lt;li&gt;And more than &lt;em&gt;the lowest value&lt;/em&gt;, to optimize savings.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;in-practice-lets-calculate-how-much-to-reserve&quot;&gt;In practice: let’s calculate how much to reserve!&lt;/h2&gt;

&lt;p&gt;Manipulating metrics in Cloudwatch, for visualization, may be acceptable, although we rarely do it since we use other stacks for our metrics. And aggregating metrics from multiple accounts should be feasible &lt;em&gt;(we haven’t tried it)&lt;/em&gt;.&lt;br /&gt;
But for calculations, it is not enough.&lt;/p&gt;

&lt;h3 id=&quot;exporting-metrics&quot;&gt;Exporting metrics&lt;/h3&gt;

&lt;p&gt;As a first step, we exported the metrics visualized above, to be able to manipulate them in another tool – in a spreadsheet, for example.&lt;br /&gt;
To export these metrics from Cloudwatch, we can query its API. We need to do this for all accounts and for each table, which is complicated to do manually.&lt;/p&gt;

&lt;p&gt;To simplify the task, we started working with a script that exports this data to a CSV file.&lt;br /&gt;
Specifically, this script exports one data point per hour: the number of WCUs or RCUs actually provisioned during that hour.&lt;/p&gt;

&lt;p&gt;Running this script for a &lt;em&gt;representative week&lt;/em&gt;, we have enough data to calculate the ideal reservations.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;🗓️ Representative week?&lt;/strong&gt;&lt;br /&gt;
Of course, we have to be careful to choose the week we focus on.&lt;br /&gt;
If we work with data from a week with a huge unexplained peak of traffic, the results of our calculation will fit that week, but not so much to the rest of the year!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;a-google-spreadsheet-calculation&quot;&gt;A Google Spreadsheet calculation&lt;/h3&gt;

&lt;p&gt;Importing this data into a Google Spreadsheet, we get two columns: a date+time and a number of WCUs.&lt;br /&gt;
And this is for each one-hour range during an entire week:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-01-date-and-conso-english.png&quot; alt=&quot;Date and usage&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;ℹ️ Only twelve hours&lt;/strong&gt;&lt;br /&gt;
Here, I only reproduce twelve rows corresponding to twelve hours, but keep in mind that there are actually 168 rows in my spreadsheet: one row per hour, 24 hours per day, for 7 days.&lt;br /&gt;
Also, the values used for this article are all &lt;em&gt;simulated&lt;/em&gt;, to avoid sharing sensitive information, but they scrupulously respect the shape of our traffic and usage wave.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The next step is to integrate the cost of these WCUs.&lt;br /&gt;
Easy anough, we multiply the number of WCUs by the cost of a WCU in Paris, i.e. $0.000772.&lt;br /&gt;
And the sum of the cost of each line gives us the total cost, without reservation:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-02-cost-without-reservation-english.png&quot; alt=&quot;Costs, without any reservation&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;the-calculations-on-an-assumption&quot;&gt;The calculations, on an assumption&lt;/h3&gt;

&lt;p&gt;Now, let’s assume, for the time being, that we reserve 25,000 WCUs:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The upfront, each hour, is $5.07991.&lt;/li&gt;
  &lt;li&gt;And, each hour, we also have to pay $3.82500 for this capacity, since the upfront is only partial.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In addition:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;During some hours, when we consume less than 25,000 WCU, we will not pay anything extra.&lt;/li&gt;
  &lt;li&gt;During some other hours, when we consume more than 25,000 WCU, we will have to pay a supplement, at the full provisioned rate.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Adding these data, we obtain a different hourly cost, often lower than the one determined above.&lt;br /&gt;
And, therefore, we get a lower total cost as well:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-03-cout-including-reservations-english.png&quot; alt=&quot;Costs, with reservations&quot; /&gt;&lt;/p&gt;

&lt;p&gt;With this hypothesis of a 25,000 WCU reservation, over these twelve hours, we would pay 135 dollars instead of 229 dollars without reservation.&lt;br /&gt;
We would then realize 40.96% savings!&lt;/p&gt;

&lt;h3 id=&quot;the-calculations-until-we-find-the-right-value&quot;&gt;The calculations, until we find the right value&lt;/h3&gt;

&lt;p&gt;Of course, during the hours when we consume less than 25,000 WCU, we are wasting capacity: we are paying for it, without using it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-04-waste-english.png&quot; alt=&quot;Wasted reservations&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The goal of the game is to find the &lt;em&gt;right number&lt;/em&gt; of WCUs to reserve: we want to reduce the total cost as much as possible, maximizing the percentage of savings.&lt;/p&gt;

&lt;p&gt;To do so, we try different values for the number of WCUs reserved, until we find the one that maximizes the percentage of savings:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-05-maximize-percentage-savings-table-english.png&quot; alt=&quot;Maximizing savings percentages (table)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here’s the same thing as a graph:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-05-maximize-percentage-savings-graphic-english.png&quot; alt=&quot;Maximizing savings percentages (graph)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here, over these twelve hours, the optimal approach would be to reserve 23,000 WCU.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;💪 Getting real: an entire week&lt;/strong&gt;&lt;br /&gt;
In reality, we perform exactly the same calculation and we follow this very same logic, on 168 lines of data, corresponding to a &lt;em&gt;representative week&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;easier-calculations&quot;&gt;Easier calculations?&lt;/h3&gt;

&lt;p&gt;The first year we tried to reserve capacity, we quickly wrote a script to collect the data from Cloudwatch and export it as CSV.&lt;/p&gt;

&lt;p&gt;We still haven’t, after three or four years now, written a program that would perform the calculations based on this data to come up with the &lt;em&gt;right value&lt;/em&gt; for the number of WCUs or RCUs to reserve.&lt;br /&gt;
As a matter of facts, copying and pasting data from the CSV export to a spreadsheet only takes a minute, we reuse the same year after year, and its visual aspect is nice!&lt;/p&gt;

&lt;p&gt;Also, we only do these calculations and reservations twice a year, so we don’t spend too much time working on this, while still refining more often than once each year.&lt;br /&gt;
Each time, the process takes two of us&lt;sup id=&quot;fnref:pair-reserving&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:pair-reserving&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt; about two hours, or one day per year in total… And the most time-consuming part is talking to our colleagues who are heavy DynamoDB users, and asking them &lt;em&gt;“are you planning to reduce the consumption of your project over the coming year?”&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;finally-lets-create-those-reservations&quot;&gt;Finally, let’s create those reservations!&lt;/h2&gt;

&lt;p&gt;We calculated how many WCUs and how many RCUs we should reserve to achieve the best possible savings, hoping the week we chose to base our calculations on was actually a &lt;em&gt;representative week&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;a-commitment-be-careful&quot;&gt;A commitment: be careful…&lt;/h3&gt;

&lt;p&gt;A reservation commits us to pay for a year, whether we use this capacity or not.&lt;/p&gt;

&lt;p&gt;So, it’s always a good idea to take a moment to validate with our colleagues that they are not planning to use less DynamoDB in the near future.&lt;br /&gt;
Of course, the answer is often partly &lt;em&gt;“it depends”&lt;/em&gt;, since usage depends on new projects as well as on the traffic on our platforms, but if we can already anticipate the next planned optimizations, it’s always a good thing.&lt;/p&gt;

&lt;p&gt;In November 2022, we can only open DynamoDB reservations for one year if we work in the AWS Paris region.&lt;br /&gt;
Other regions &lt;em&gt;(us-east-1 for example) allow&lt;/em&gt; reservations for three years, which means more substantial savings. On the other hand, would we be willing to commit for three years and lose a major advantage of &lt;em&gt;The Cloud&lt;/em&gt;, its flexibility?&lt;/p&gt;

&lt;h3 id=&quot;which-account-to-reserve-on&quot;&gt;Which account to reserve on?&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/dynamodb/pricing/provisioned/&quot;&gt;The documentation&lt;/a&gt; says (emphasis mine):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you have multiple accounts linked with consolidated billing, &lt;strong&gt;reserved capacity units purchased&lt;/strong&gt; either &lt;strong&gt;at the payer account level&lt;/strong&gt; or linked account level &lt;strong&gt;are shared with all accounts connected to the payer account&lt;/strong&gt;.&lt;br /&gt;
Reserved capacity is applied first to the account that purchased it and then any unused capacity is applied to other linked accounts.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We have configured our AWS accounts to have a single payer account.&lt;br /&gt;
We have decided to make all our reservations in this account and they are applied to the child accounts without discrimination.&lt;br /&gt;
This applies to DynamoDB but also to RDS, EC2, Elasticache…&lt;/p&gt;

&lt;h3 id=&quot;reserving&quot;&gt;Reserving!&lt;/h3&gt;

&lt;p&gt;To reserve, we go through the AWS DynamoDB Web console, in our payer account, in the region where these reservations will be used.&lt;/p&gt;

&lt;p&gt;On this screen, you can see how many WCUs and RCUs we have already reserved.&lt;br /&gt;
Since we make several reservations during the year, the reservations already in progress are to be subtracted from the values calculated above!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/ddb-reservations-history-CENSORED.png&quot; alt=&quot;Reservations history&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To create a new reservation, click on &lt;em&gt;“Purchase reserved capacity”&lt;/em&gt; and fill in the form ;-)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/creating-a-reservation-23k.png&quot; alt=&quot;Reserving 23,000 WCU: this is not free!&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;after-reserving-viewing-the-costs&quot;&gt;After reserving, viewing the costs&lt;/h2&gt;

&lt;p&gt;Once the reservations are made, in AWS Cost Explorer, the upfront cost is clearly visible.&lt;br /&gt;
It is charged at once, on the day we opened the reservation:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/cost-explorer-after-reservation-01-CENSORED.png&quot; alt=&quot;Cost Explorer, after reserving&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To have a daily view of WCU/RCU costs &lt;em&gt;(reserved + provisioned in addition to reservations)&lt;/em&gt;, remember to fill in &lt;em&gt;“Show costs as: Amortized costs”&lt;/em&gt; to smooth the monthly price of reservations over all days of the month:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/cost-explorer-after-reservation-02-amortized-CENSORED.png&quot; alt=&quot;Amortized view&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Reservations and one payer account&lt;/strong&gt;&lt;br /&gt;
Since reservations, which cover the bulk of our DynamoDB costs, are made on our payer account, the bulk of our DynamoDB costs go back to this account… And not to the tenant/environment accounts.&lt;br /&gt;
Good luck tracking costs and allocating them to projects and teams 💪&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;We work with DynamoDB a lot, for several dozen microservices, and we face several types of infrastructure costs: on-demand reads/writes, provisioned reads/writes, storage, backups.&lt;br /&gt;
In exchange for a loss of flexibility and through reservations that commit us for a year, AWS allows us to reduce the cost of provisioned reads/writes.&lt;/p&gt;

&lt;p&gt;Determining how much to reserve, in the face of a constantly changing load, is not easy.&lt;br /&gt;
We need to have a certain vision on the evolution of usage, over a year, and must accept to lose flexibility.&lt;br /&gt;
And we need to find the &lt;em&gt;right values&lt;/em&gt; to reserve for read and write capacity.&lt;/p&gt;

&lt;p&gt;With three or four years of hindsight, by making reservations twice a year and by following the method detailed in this article, we realize savings of about 30% to 35% on our read and write capacity in provisioned mode.&lt;br /&gt;
On our scale, this saving represents several tens of thousands of dollars per year – which is great, considering we only spend a few hours working on this every six months!&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:serverless-but-still-some-work&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;DynamoDB is one of the &lt;em&gt;most serverless&lt;/em&gt; services we use and I like it a lot. Still, there are a few &lt;em&gt;admin&lt;/em&gt; tasks left in our hands. Typically, we have to specify the capacity we need and configure an auto-scaler. We also have to enable encryption, backups, to setup permissions – and to check all this is done, for all tables, managed by many teams. &lt;a href=&quot;#fnref:serverless-but-still-some-work&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:dynamodb-standard-ia&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;If you do store a lot of data for a long time in DynamoDB, take a look at &lt;a href=&quot;https://aws.amazon.com/dynamodb/standard-ia/&quot;&gt;Standard-IA&lt;/a&gt;, it might help you reduce costs. &lt;a href=&quot;#fnref:dynamodb-standard-ia&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:why-so-much-pay-per-request&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Why do we use pay-per-request so much? Well, in short, because this mode is more flexible than the provisioned one, and several of our projects are willing to pay much more in exchange for this flexibility. &lt;a href=&quot;#fnref:why-so-much-pay-per-request&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:dynamodb-on-demand-scalability&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;DynamoDB in on-demand mode and scalability: in practice, AWS hides what’s going on, but doesn’t scale to infinity instantly either. &lt;a href=&quot;#fnref:dynamodb-on-demand-scalability&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:50-percent-savings&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;50% is kind of the maximum possible saving we can achieve if our usage is flat and we reserve exactly what we provision. Flat usage might be what you see on your applications, but it’s not how our platform works! &lt;a href=&quot;#fnref:50-percent-savings&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:consolidated-billing&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;At Bedrock, we have a dedicated billing account – a &lt;em&gt;“payer account”&lt;/em&gt; – that aggregates costs from all our other accounts. Reservations are also shared amongst all (whitelisted) accounts that have a shared payer account. &lt;a href=&quot;#fnref:consolidated-billing&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:pair-reserving&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;For these kind of calculations and reservations, we usually work in pair, as this involves large amounts of money. Lowering risk of doing a costly mistake is quite a good idea. &lt;a href=&quot;#fnref:pair-reserving&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Pascal Martin</name></author><category term="aws" /><category term="dynamodb" /><category term="finops" /><summary type="html">Many of the microservices in our VOD and Replay platform use DynamoDB as their database. Performance is very good if the data is architected for it, scalability is reasonably fast, and the serverless aspect offloads a lot of the administration and hosting work. Whether it’s performance, resilience or time-to-market, DynamoDB helps us achieve our business goals. That said, when we spend several hundred thousand dollars on DynamoDB every year, any optimization is good for us! With DynamoDB, committing to a certain capacity for a year can help reduce costs – up to 50% savings on that capacity. But how do we know how much to reserve when traffic on our platform varies throughout the day?</summary></entry><entry><title type="html">Ce que nous avons retenu de la SymfonyCon - Disneyland Paris 2022</title><link href="https://tech.bedrockstreaming.com/2022/11/17/symfonycon.html" rel="alternate" type="text/html" title="Ce que nous avons retenu de la SymfonyCon - Disneyland Paris 2022" /><published>2022-11-17T00:00:00+00:00</published><updated>2022-11-17T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/11/17/symfonycon</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/11/17/symfonycon.html">&lt;p&gt;En cette fin d’année, une petite équipe de chez Bedrock a assisté au grand retour de la SymfonyCon 2022 après 3 ans d’absence. 
Nous avons eu la chance de découvrir les nouveautés liées à Symfony 6.2 et d’assister aux conférences sur de nombreux sujets techs à Disneyland.
La keynote présentée par &lt;a href=&quot;https://github.com/fabpot&quot;&gt;Fabien Potencier&lt;/a&gt;, le créateur de Symfony, nous donne un avant-goût des nouvelles fonctionnalités qui seront présentes dans la future version de Symfony.
Au programme, un nouveau composant Webhooks ainsi que l’évolution du composant Mailer.&lt;/p&gt;

&lt;h2 id=&quot;unleashing-the-power-of-lazy-objects-in-php&quot;&gt;Unleashing the power of lazy objects in PHP&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://connect.symfony.com/profile/nicolas-grekas&quot;&gt;Nicolas Grekas&lt;/a&gt;, habitué de la scène PHP et membre de la Symfony Core Team, nous a présenté les différentes façons d’utiliser les lazy objects en PHP et plus spécifiquement à l’aide de Symfony. &lt;/p&gt;

&lt;p&gt;Les lazy objects sont des objets instanciés vides qui peuplent leurs propriétés eux-mêmes seulement quand ils sont utilisés.
Ils sont utiles lors de l’instanciation de lourds objets peu appelés, cela permet de faire du lazy loading.&lt;/p&gt;

&lt;p&gt;Nicolas nous a aussi présenté deux nouveaux traits prochainement disponibles sur Symfony 6.2 permettant de travailler avec ces objets.
Les &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VirtualInheritanceProxies&lt;/code&gt; et les &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GhostsObjects&lt;/code&gt; sont deux nouvelles possibilités pour implémenter plus facilement des lazy objects en plus du &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ValueHolder&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;advanced-git-magic&quot;&gt;Advanced Git magic&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://connect.symfony.com/profile/paulinevos&quot;&gt;Pauline Vos&lt;/a&gt; nous représente GIT en dehors de son usage quotidien, comment aller plus loin que les pull, commit, push et merge habituels, elle nous livre donc une présentation sur une méthode de debug en utilisant GIT.&lt;/p&gt;

&lt;p&gt;Retour dans un premier temps sur l’importance des commits dit “atomic” avec comme règles :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Chaque commit se résume à un fix ou une feature&lt;/li&gt;
  &lt;li&gt;Chaque commit doit fonctionner (tous les tests doivent passer)&lt;/li&gt;
  &lt;li&gt;Chaque message et description doivent être clairs et concis&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Pauline introduit ensuite la commande &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git rebase -i&lt;/code&gt; qui permet un rebase interactif servant notamment à réécrire notre historique.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/symfonycon2022/IMG-0785.jpg&quot; alt=&quot;git rebase intéractif&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Vient ensuite l’utilisation de la commande &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git reflog&lt;/code&gt;, commande avec laquelle nous pouvons obtenir le détail des commandes lancées sur la branche, elle peut de ce fait être utile pour réparer une erreur.&lt;/p&gt;

&lt;h4 id=&quot;comment-utiliser-toutes-ces-commandes-git-pour-debugger-&quot;&gt;Comment utiliser toutes ces commandes GIT pour debugger ?&lt;/h4&gt;
&lt;p&gt;Une démonstration de la commande &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git bisect&lt;/code&gt; et de toutes ses options qui permettent d’identifier le commit qui a introduit le bug en faisant une recherche dichotomique.&lt;/p&gt;

&lt;p&gt;Pauline pousse la réflexion plus loin en alliant la commande &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git bisect&lt;/code&gt; avec un script de debug ou un test unitaire.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;“Write it, push it and find where it breaks”&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Afin de tirer parti de cette méthode, il est important que chaque commit soit fonctionnel, tous les tests doivent donc passer.&lt;/p&gt;

&lt;p&gt;Vous pouvez également retrouver &lt;a href=&quot;https://www.pauline-vos.nl/fix-bugs-%e2%9a%a1-fast-with-regression-tests-and-auto-bisect/&quot;&gt;un article de Pauline&lt;/a&gt; à ce sujet sur son blog personnel.&lt;/p&gt;

&lt;h2 id=&quot;schrödingers-sql---the-sql-inside-the-doctrine-box&quot;&gt;Schrödinger’s SQL - The SQL inside the Doctrine box&lt;/h2&gt;

&lt;p&gt;Au début de sa conférence &lt;a href=&quot;https://connect.symfony.com/profile/senseexception&quot;&gt;Claudio Zizza&lt;/a&gt; insiste sur le fait de bien connaître nos bases de données et le langage utilisé pour les requêter, il évoque notamment les différences entre MySQL et PostgreSQL. Ensuite, il nous a parlé de Doctrine ORM, des fonctions que nous apprécions tant, car elles nous facilitent la vie. 
Puis, il a rappelé l’importance de savoir faire des requêtes SQL même si nous utilisons Doctrine. Comprendre le SQL peut nous permettre d’optimiser notre utilisation de Doctrine et donc de mieux appréhender son fonctionnement. 
Il insiste aussi sur le fait que SQL “seul” est bien plus puissant que DQL (Doctrine Query Language). 
Pour terminer, Claudio nous a donné quelques recommandations de lecture pour apprendre le SQL ainsi qu’un site permettant de tester nos requêtes.&lt;/p&gt;

&lt;h2 id=&quot;advanced-test-driven-development&quot;&gt;Advanced Test Driven Development&lt;/h2&gt;

&lt;p&gt;Durant cette conférence, &lt;a href=&quot;https://connect.symfony.com/profile/mollokhan&quot;&gt;Diego Aguiar&lt;/a&gt;, développeur de chez SymfonyCasts nous rappelle ce qu’est le &lt;strong&gt;TDD (Test Driven Development)&lt;/strong&gt;, son histoire, les différentes techniques ainsi que des astuces afin de nous débloquer et bien sûr les cas où il ne semble pas utile d’utiliser le TDD.&lt;/p&gt;

&lt;p&gt;À retenir, le TDD est une discipline, il faut beaucoup d’entraînement et répéter continuellement ces exercices.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/symfonycon2022/IMG-0848.jpg&quot; alt=&quot;tdd discipline&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;“Fake it till you make it”&lt;/strong&gt;&lt;/em&gt;, il s’agit d’abord d’écrire son code de test en utilisant par exemple des assertions, des tests avec différentes sorties et ensuite de produire le code qui va résoudre ces tests.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/symfonycon2022/IMG-0852.jpg&quot; alt=&quot;Fake it till you make it&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;“ Write your test code, produce it and repeat.”&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;pourquoi-nous-retrouvons-nous-parfois-bloqués-&quot;&gt;Pourquoi nous retrouvons nous parfois bloqués ?&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Les tests écrits sont peut-être faux&lt;/li&gt;
  &lt;li&gt;Les tests ne sont pas assez segmentés&lt;/li&gt;
  &lt;li&gt;Le code écrit est peut-être trop spécifique&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;comment-se-débloquer-&quot;&gt;Comment se débloquer ?&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Continuer et trouver un test plus simple&lt;/li&gt;
  &lt;li&gt;Refactoriser le code en production qui met en difficulté&lt;/li&gt;
  &lt;li&gt;Écrire les différents use-cases&lt;/li&gt;
  &lt;li&gt;Passer outre les tests un instant&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Les cas les plus favorables au TDD sont les nouvelles fonctionnalités qui n’ont pas de lien avec du code legacy. En ce qui concerne les cas non pertinent au TDD, nous retrouvons les cas de configuration, de découverte de code et de requêtes.&lt;/p&gt;

&lt;p&gt;Pour conclure, Diego nous rappelle que le TDD est bien évidemment plus un outil qu’une règle.&lt;/p&gt;

&lt;h2 id=&quot;dynamic-validation-with-symfony&quot;&gt;Dynamic Validation With Symfony&lt;/h2&gt;

&lt;p&gt;Tout en se basant sur les évolutions des Pokémon, &lt;a href=&quot;https://connect.symfony.com/profile/marionleherisson&quot;&gt;Marion Hurteau&lt;/a&gt; a introduit le principe de validation dynamique. Par exemple, vérifier que le nom de notre Pokémon contient bien 10 caractères, ou encore les différentes règles d’évolution en fonction du type de Pokémon. 
À l’aide d’exemples de code qui sont disponibles sur son repo Git, elle a passé en revue les façons d’implémenter des validations à l’aide du composant &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Symfony Validator&lt;/code&gt;.
Au fil de sa présentation, la complexité des contraintes croît ce qui permet de voir un éventail de possibilités.&lt;/p&gt;

&lt;h2 id=&quot;from-monolith-to-decoupledwait-why-is-that-one-getting-bigger&quot;&gt;From monolith to decoupled…wait, why is that one getting bigger?!?&lt;/h2&gt;
&lt;p&gt;Lors de cette conférence, &lt;a href=&quot;https://connect.symfony.com/profile/shawnaspoor&quot;&gt;Shawna Spoor&lt;/a&gt; est venue nous parler de comment découper un monolithe en une multitude de microservices grâce au “Strangler Fig Pat”. Elle a commencé par nous rappeler les avantages et les inconvénients des microservices comparé à un monolithe.&lt;/p&gt;

&lt;p&gt;Suite à cela, elle nous a donné les différentes étapes pour découper une application monolithe en micro-services et cela sans jamais arrêter le développement de nouvelles features:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Choisir une fonctionnalité qui peut être découpée&lt;/li&gt;
  &lt;li&gt;Créé le nouveau Service&lt;/li&gt;
  &lt;li&gt;Déplacer le trafic vers le nouveau service&lt;/li&gt;
  &lt;li&gt;Recommencer jusqu’à la disparition du monolithe&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On peut résumer ce pattern via l’image ci-dessous, le tronc représente le monolithe et les branches qui l’étranglent lentement correspondent aux micro-services.
&lt;img src=&quot;https://w2j6m4k9.rocketcdn.me/wp-content/uploads/2019/09/Strangler-Tree-Header-Big-1024x576.png&quot; alt=&quot;Strangler Fig Paterne&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;from-a-legacy-monolith-to-a-symfony-service-oriented-architecture-with-zero-downtime&quot;&gt;From a legacy Monolith to a Symfony Service Oriented Architecture with zero downtime&lt;/h2&gt;
&lt;p&gt;Lors de la conférence présentée par &lt;a href=&quot;https://connect.symfony.com/profile/skigun&quot;&gt;Clément Bertillon&lt;/a&gt;, nous avons pu voir comment son équipe a transformé leur ancienne application monolithe composée de milliers de fichiers PHP en un monorepo décomposé en micro-services en utilisant le &lt;strong&gt;Strangler Fig&lt;/strong&gt; pattern et cela sans aucune rupture de service ni arrêter le développement de nouvelles features.&lt;/p&gt;

&lt;p&gt;De manière très simplifiée, ils ont installé Symfony, mis le code legacy dans un dossier à la racine du projet, le routeur symfony permet d’accéder au nouveau micro-service tout en redirigeant vers le legacy si aucun contrôleur n’a été trouvé. Il a conclu avec les règles d’or et comment analyser les performances via Blackfire.
Ces deux conférences sur le &lt;strong&gt;Strangler fig&lt;/strong&gt; paterne, mon permis de mettre en place un micro projet dans un de nos projets, tout en le cloisonnant du code parent (règles d’or vérifié grâce à l’outil présenté &lt;a href=&quot;https://github.com/qossmic/deptrac&quot;&gt;deptrac&lt;/a&gt;). Ce principe nous permettra de le transformer en micro service très facilement.&lt;/p&gt;

&lt;h2 id=&quot;phpstan-advanced-types&quot;&gt;PHPStan: Advanced Types&lt;/h2&gt;
&lt;p&gt;Cette conférence centrée sur l’outil d’analyse statique de code : PHPStan, a été présentée par son créateur &lt;a href=&quot;https://connect.symfony.com/profile/mirtes&quot;&gt;Ondřej Mirtes&lt;/a&gt;.
Il a commencé par nous rappeler quelle est la différence entre un langage compilé et un langage interprété, le premier ne se compile pas s’il y a des erreurs alors que le second ne plante qu’à l’exécution. Le but de PHPStan est de nous aider à identifier toutes les erreurs sans avoir besoin d’exécuter le code.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/symfonycon2022/phpstan.png&quot; alt=&quot;PHPstan&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Cet outil analyse toutes les fonctions, les propriétés, le typage PHP, mais aussi la PHPDoc. Ondřej nous a ensuite parlé de tous les types PHPStan avec des exemples, en voici quelques un qui ont marqué notre attention :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;non-empty-array&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;non-empty-string&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;literal-string&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;integer-range&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;integer-mask&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;integer-maskof&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conditional return types, union types, intersection types&lt;/code&gt; …&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Il finit en nous rappelant que l’utilisation de &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;@var&lt;/code&gt; est une mauvaise pratique et qu’il vaut mieux renforcer le typage quitte à modifier la documentation des &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vendor&lt;/code&gt; via les &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Stub files&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;gnap-the-future-of-oauth&quot;&gt;GNAP: The future of OAuth&lt;/h2&gt;
&lt;p&gt;[&lt;a href=&quot;https://slides.com/chalasr/gnap-the-future-of-oauth-2fefdf&quot;&gt;Slides&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://connect.symfony.com/profile/chalas_r&quot;&gt;Robin Chalas&lt;/a&gt; @chalas_r nous a présenté GNAP (Grant Negotiation and Authorization Protocol) : une initiative pour développer la prochaine génération de protocoles d’autorisation.
Pour mieux comprendre les enjeux, nous sommes repartis de l’historique d’oauth, ses évolutions et ses écueils. Le constat étant que même si de nombreux problèmes connus ont été résolus, aujourd’hui, pour bien utiliser OAuth 2, il faut lire une douzaine de RFC et s’assurer qu’elles soient pertinentes pour les différents cas d’utilisation.&lt;/p&gt;

&lt;p&gt;L’augmentation de la complexité du protocole dégrade l’expérience du développeur, ce qui va à l’encontre de son objectif principal qui est la simplicité pour les développeurs de clients.&lt;/p&gt;

&lt;p&gt;GNAP (prononcé “nap”) est une complète réécriture afin de répondre aux besoins en sécurité des applications modernes :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Pensé pour tous les clients, plateformes (pas uniquement web, possibilités de deeplinking mobile par exemple)&lt;/li&gt;
  &lt;li&gt;les interactions sont un concept clé&lt;/li&gt;
  &lt;li&gt;Du chiffrement partout et des mécanismes de rotation extensibles&lt;/li&gt;
  &lt;li&gt;Plusieurs Access Tokens / grant request&lt;/li&gt;
  &lt;li&gt;Gestion de l’identité intégrée&lt;/li&gt;
  &lt;li&gt;Plus developer friendly&lt;/li&gt;
  &lt;li&gt;Pas rétrocompatible avec OAUTH2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ce protocole est toujours à l’état de brouillon, le groupe de travail a été monté en octobre 2020 et lors du dernier rassemblement (nov. 2022), aucune modification du protocole n’a été actée. Le speaker conclut sur la nécessité de commencer à travailler sur l’implémentation de ce protocole dans l’écosystème PHP afin de supporter ce nouveau standard dont la finalisation ne devrait plus tarder. 
Pour aller plus loin &lt;a href=&quot;https://oauth.xyz/&quot;&gt;https://oauth.xyz/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;a-self-training-journey-to-the-certification-symfony&quot;&gt;A self-training journey to the certification Symfony&lt;/h2&gt;
&lt;p&gt;Cette conférence traite de la méthodologie et des bonnes pratiques pour obtenir la fameuse certification Symfony.
En effet, la conférencière, &lt;a href=&quot;https://connect.symfony.com/profile/ca-jou&quot;&gt;Camille Jouan&lt;/a&gt;, nous présente sa manière de préparer l’examen.
Elle commence par énoncer son plan d’action :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Rassembler un maximum d’informations (Symfony doc, site pour la préparation à la certification, etc)&lt;/li&gt;
  &lt;li&gt;Organiser un plan autour du quoi/comment/pourquoi&lt;/li&gt;
  &lt;li&gt;Faire une timeline avec les étapes prévues&lt;/li&gt;
  &lt;li&gt;Se fixer un objectif dans le temps&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;L’idée est d’accepter que cela ne sera pas parfait et que des retouches vont y être apportées&lt;/p&gt;

&lt;p&gt;Pour Camille, l’idéal serait de pouvoir faire un test blanc au bout d’un certain temps de préparation sans “grandes convictions” : le but étant de se familiariser avec l’exercice.
Si les fonds sont disponibles, &lt;a href=&quot;https://training.sensiolabs.com/fr/courses/SF5PRECERTIF-preparation-certifcation-symfony-5-online-sensiolabs-university&quot;&gt;un training est proposé par Sensiolabs&lt;/a&gt;.
En fonction de cet examen blanc, ajuster son plan, se concentrer sur des parties qui doivent être approfondies.
Un autre point sur lequel la conférencière a insisté est le monitoring : régulièrement faire un bilan sur son avancée pour s’adapter.
Des outils comme Trello, Excel, Google permettent d’en avoir une vision globale.&lt;/p&gt;

&lt;p&gt;Il est important de parler de ce projet autour de soi, notamment auprès de ses proches pour avoir du soutien, mais également auprès de son entreprise qui peut éventuellement proposer une subvention et ou un aménagement du temps de travail.&lt;/p&gt;

&lt;p&gt;Elle conclut son intervention par un dernier conseil : cette méthodologie est adaptable à la vie quotidienne et peut être utile dans d’autres situations.&lt;/p&gt;

&lt;h2 id=&quot;notre-retour-dexpérience&quot;&gt;Notre retour d’expérience&lt;/h2&gt;
&lt;p&gt;Cette nouvelle édition de la SymfonyCon nous a permis de découvrir ou d’approfondir certaines connaissances. 
Nous pouvons aussi nous rendre compte de notre travail quotidien et prendre du recul sur celui-ci.
Cette expérience anglophone était très enrichissante et les conférences proposées étaient variées.
Il y avait de la résolution de problèmes techniques, des retours d’expériences ou encore de la télémétrie.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/symfonycon2022/IMG-0773.jpg&quot; alt=&quot;Fresque Lego symfony&quot; /&gt;&lt;/p&gt;</content><author><name>backend</name></author><category term="conferences" /><category term="backend" /><category term="symfony" /><category term="php" /><summary type="html">En cette fin d’année, une petite équipe de chez Bedrock a assisté au grand retour de la SymfonyCon 2022 après 3 ans d’absence. Nous avons eu la chance de découvrir les nouveautés liées à Symfony 6.2 et d’assister aux conférences sur de nombreux sujets techs à Disneyland. La keynote présentée par Fabien Potencier, le créateur de Symfony, nous donne un avant-goût des nouvelles fonctionnalités qui seront présentes dans la future version de Symfony. Au programme, un nouveau composant Webhooks ainsi que l’évolution du composant Mailer.</summary></entry><entry><title type="html">Un onboarding facilité grâce à la revue de code!</title><link href="https://tech.bedrockstreaming.com/2022/11/15/onboarding-revue-code.html" rel="alternate" type="text/html" title="Un onboarding facilité grâce à la revue de code!" /><published>2022-11-15T00:00:00+00:00</published><updated>2022-11-15T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/11/15/onboarding-revue-code</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/11/15/onboarding-revue-code.html">&lt;p&gt;Au sein des équipes de développement, une activité bien connue est celle de la revue de code, et 
plus 
précisément de la &lt;strong&gt;revue du delta du code&lt;/strong&gt;. Il s’agit de l’inspection par nos 
pairs du code proposé par nos soins, qui se trouve ainsi commenté pour répondre aux 
exigences de qualité de l’équipe et du projet.&lt;/p&gt;

&lt;p&gt;Les risques d’incompréhensions inhérents à la communication écrite, de malentendus
ou encore les remarques &lt;em&gt;malheureuses&lt;/em&gt; peuvent rendre cet exercice redouté tant par les 
relecteurs et relectrices 
que 
par celles et ceux dont le code est relu.&lt;/p&gt;

&lt;p&gt;Avant d’arriver chez Bedrock, j’étais un peu 
inquiète. Je savais déjà que les 9 personnes de ma future équipe font tou(te)s de la revue de code. 
&lt;strong&gt;Comment échangerons-nous? Saurai-je faire “bonne impression” via mes commentaires 
sur leur code ?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;En arrivant, j’ai été très 
agréablement surprise de découvrir que l’équipe applique un 
standard, celui des conventions de commentaires, &lt;a href=&quot;https://conventionalcomments.org/&quot;&gt;ou conventional comments&lt;/a&gt;. &lt;strong&gt;Grâce à cela, mon 
onboarding a été grandement facilité&lt;/strong&gt; et j’ai découvert une façon plus efficace d’écrire mes 
commentaires !&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt; : cet article est inspiré de ma conférence “&lt;em&gt;Revue de code : on n’est pas 
venu-e-s pour
souffrir !&lt;/em&gt;” donnée à l’occasion du meet-up anniversaire Duchess chez Dataiku en 2022 et &lt;a href=&quot;https://afup.org/talks/4038-revue-de-code-on-n-est-pas-venu-pour-souffrir&quot;&gt;au Forum
PHP 2022&lt;/a&gt;.&lt;/p&gt;

&lt;iframe width=&quot;1127&quot; height=&quot;773&quot; src=&quot;https://www.youtube.com/embed/LVh6iQtJW2I&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h2 id=&quot;petit-rappel--pourquoi-faisons-nous-des-revues-de-code-&quot;&gt;Petit rappel : pourquoi faisons-nous des revues de code ?&lt;/h2&gt;

&lt;p&gt;Passer en revue le code proposé par ses co-équipier(e)s est largement répandu dans les 
équipes de développeurs et développeuses. Bien sûr, la qualité du code en elle-même se trouve 
améliorée 
car chacun apporte un regard neuf sur ce qui est proposé, mais ce n’est pas tout. La 
revue de code est également une façon de nous tenir informé(e) de 
l’implémentation de nouvelles features, d’apprendre autant du métier que de la 
technique et enfin, d’apprendre à travailler ensemble.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-07-code-review-onboarding/code-review.png&quot; alt=&quot;Pourquoi faisons-nous de la code review ?&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Voici une 
petite liste non exhaustive de l’intérêt de la revue de code :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Améliorer la qualité et la lisibilité du code grâce aux remarques de toutes les
personnes de l’équipe&lt;/li&gt;
  &lt;li&gt;Appliquer les standards adoptés par l’équipe (et les apprendre !)&lt;/li&gt;
  &lt;li&gt;Détecter et corriger les éventuels bugs fonctionnels&lt;/li&gt;
  &lt;li&gt;Favoriser la collaboration en équipe&lt;/li&gt;
  &lt;li&gt;Former les développeurs et développeuses au fur et à mesure des remarques&lt;/li&gt;
  &lt;li&gt;Partager les responsabilités : en approuvant une pull request ou une merge request, nous
sommes responsables en tant qu’équipe du code ajouté/modifié au tronc commun !&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;et-parfois-on-souffre&quot;&gt;…Et parfois, on souffre&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-07-code-review-onboarding/parfois-on-souffre.png&quot; alt=&quot;parfois on souffre&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Mais parfois, ce n’est pas tout rose. Les commentaires qu’on laisse peuvent vexer. On 
peut nous-même être vexé. Car certains jours, on peut manquer d’empathie. On peut avoir 
l’impression d’être plus compétent(e) en 
critiquant les autres, on veut se rassurer en se montrant plus qualifié(e). On peut également 
être habitué(e) à une culture de la compétition, nous poussant ainsi à faire des remarques désagréables à nos pairs.&lt;/p&gt;

&lt;h2 id=&quot;comment-le-formatage-de-commentaire-a-t-il-amélioré-mon-arrivée-dans-léquipe-&quot;&gt;Comment le formatage de commentaire a-t-il amélioré mon arrivée dans l’équipe ?&lt;/h2&gt;

&lt;p&gt;La standardisation des commentaires a énormément amélioré mon intégration dans 
l’équipe. En effet, grâce à cela :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;J’ai pu rapidement me rendre compte de ce qui était bloquant / non bloquant et ainsi me 
&lt;strong&gt;concentrer sur les actions essentielles et prioritaires&lt;/strong&gt; à mener;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;je n’ai pas eu à me poser de questions sur le ton employé par mes collègues ni sur leur 
intention&lt;/strong&gt;;&lt;/li&gt;
  &lt;li&gt;j’ai pu rapidement faire moi-même des revues de code &lt;strong&gt;sans craindre d’être mal comprise&lt;/strong&gt;;&lt;/li&gt;
  &lt;li&gt;j’ai eu des retours qui m’ont permis de &lt;strong&gt;progresser sur la connaissance du fonctionnel&lt;/strong&gt; et 
des standards de la team.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;améliorer-sa-posture&quot;&gt;Améliorer sa posture&lt;/h2&gt;

&lt;p&gt;Avant de parler du standard, je vous propose de nous interroger sur 
notre posture en tant que développeur et développeuse. Recevoir ou donner des commentaires, ce 
n’est pas aisé pour tous. &lt;strong&gt;Notre ego peut interférer et dégrader la qualité de nos 
échanges avec nos collègues&lt;/strong&gt;. Aussi, avant de chercher à formater nos commentaires, nous pouvons 
nous interroger sur leur contenu.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-07-code-review-onboarding/egoless.png&quot; alt=&quot;Egoless programming&quot; /&gt;&lt;/p&gt;

&lt;p&gt;L’Egoless Programming, proposé par &lt;a href=&quot;https://en.wikipedia.org/wiki/Gerald_Weinberg&quot;&gt;Gerald Weinberg&lt;/a&gt; en 1971 dans son livre &lt;em&gt;The Psychology of 
Computer Programming&lt;/em&gt;, présente une dizaine de commandements pour nous 
aider à progresser.&lt;/p&gt;

&lt;p&gt;Le principe est le suivant : &lt;strong&gt;réduire au minimum les facteurs personnels lors des interactions 
avec ses pairs&lt;/strong&gt;, pour favoriser le travail en équipe et produire le maximum de qualité.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Critiquez le code au lieu des personnes,&lt;/li&gt;
  &lt;li&gt;Soyez factuels sur le code,&lt;/li&gt;
  &lt;li&gt;N’attaquez jamais les personnes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Je vous recommande de regarder cette excellente conférence sur l’egoless programming, où Olivier 
Thelu prend le temps de revenir sur tous les concepts :&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/728605321?h=60e48e1686&amp;amp;title=0&amp;amp;byline=0&amp;amp;portrait=0&quot; width=&quot;1127&quot; height=&quot;773&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;a href=&quot;https://vimeo.com/728605321&quot;&gt;Les 10 commandements de la programmation sans &amp;eacute;go - Olivier Thelu - MiXiT 2022&lt;/a&gt; from &lt;a href=&quot;https://vimeo.com/mixitconf&quot;&gt;MiXiT&lt;/a&gt; on &lt;a href=&quot;https://vimeo.com&quot;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Une autre excellente conférence de Kim Laï Trinh, lead développeur, et son &lt;a href=&quot;https://afup.org/talks/3415-auto-critique-de-la-revue-de-code-bienveillante&quot;&gt;“Auto-critique de la 
revue de code
bienveillante”&lt;/a&gt;.&lt;/p&gt;

&lt;iframe width=&quot;1127&quot; height=&quot;773&quot; src=&quot;https://www.youtube.com/embed/jMzhP1n19e8&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h2 id=&quot;formatez-vos-commentaires-&quot;&gt;Formatez vos commentaires !&lt;/h2&gt;

&lt;p&gt;Une fois qu’on a adopté une posture qui nous aide à mieux recevoir et donner des commentaires dans le cadre de nos revues de code, on peut réfléchir à la façon dont on les formate.&lt;/p&gt;

&lt;p&gt;Grâce au standard des &lt;a href=&quot;https://conventionalcomments.org/&quot;&gt;conventional comments&lt;/a&gt;, nous disposons d’une convention pour écrire des 
commentaires clairs et visuels et limiter les incompréhensions. Chacun de nous est invité 
à réfléchir à l’intention de son commentaire &lt;strong&gt;avant&lt;/strong&gt; de l’écrire.&lt;/p&gt;

&lt;p&gt;Par exemple, avec ce commentaire qui peut prêter à confusion (le OMG qui signifie “Oh my god” 
peut être autant interprété comme quelque chose de négatif que de positif, notamment ici puisque 
nous n’avons pas le contexte 😈) :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-07-code-review-onboarding/commentaire-omg.png&quot; alt=&quot;Utilisateur Kittycat dit : &amp;quot;Omg&amp;quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ce commentaire peut être préfixé par &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;praise&lt;/code&gt;, ce qui signifie éloge. Cela change radicalement 
le ton du commentaire.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-07-code-review-onboarding/commentaire-praise-omg.png&quot; alt=&quot;praise : Omg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Voici un autre exemple laconique : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Poubelle&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-07-code-review-onboarding/commentaire-poubelle.png&quot; alt=&quot;Poubelle&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Celui-ci peut être amélioré en étant préfixé par l’étiquette &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nitpick&lt;/code&gt;, qui signifie 
“tatillonner”, ce qui diminue également son ton dramatique. De plus, l’urgence peut être 
indiquée (ici, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;non-bloquant&lt;/code&gt;) et le contexte est décrit et peut être exploité grâce à un patch 
proposant un code de remplacement.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-07-code-review-onboarding/commentaire-nitpick.png&quot; alt=&quot;nitpick (non-bloquant): le résultat peut être directement retourné (patch)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;La compréhension du commentaire est facilitée par l’effort fourni pour ajouter le maximum de
contexte possible. On gagne en lisibilité grâce à la catégorisation (étiquette), qui nous permet
également d’immédiatement savoir de quoi on parle. Par exemple, une &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;question&lt;/code&gt; ne sera pas lue
de la même façon qu’une &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;suggestion&lt;/code&gt; !&lt;/p&gt;

&lt;p&gt;La contextualisation permet de savoir si on traite le retour immédiatement ou si on ouvre une
nouvelle pull request plus tard, pour rémedier au point soulevé. On limite ainsi les
quiproquos ou les pertes de temps sur des actions non prioritaires.
Et surtout, on limite les mauvaises impressions sur le ton employé.&lt;/p&gt;

&lt;h3 id=&quot;description-du-standard&quot;&gt;Description du standard&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;label&amp;gt; [decorations]: &amp;lt;subject&amp;gt;

[discussion]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;étiquette (label)&lt;/strong&gt; : “étiquette” pour signifier de quel genre de commentaire il s’agit&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;sujet (subject)&lt;/strong&gt; : le commentaire en lui-même&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;contexte supplémentaire (decorations)&lt;/strong&gt; (optionnel)  : labels supplémentaires pour donner plus d’indications (entre parenthèses, séparés par des virgules).
Exemple : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;non-blocking&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;blocking&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test&lt;/code&gt; …&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;discussion (optional)&lt;/strong&gt; : contexte, raisonnement ou tout autre élément pour aider à 
comprendre le « pourquoi » et les « prochaines étapes » pour résoudre le commentaire&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;les-labels&quot;&gt;Les labels&lt;/h3&gt;

&lt;p&gt;Voici la liste de labels ou étiquettes, extraits du standard :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;praise&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nitpick&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;suggestion&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;issue&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;todo&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;question&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;thought&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;chore&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;typo&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;polish&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;quibble&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;L’équipe est, bien entendu, libre de choisir ou d’inventer ses labels ! Chez nous, le choix a été 
fait de respecter le standard tel qu’il est proposé, mais cela pourrait être rediscuté si besoin.&lt;/p&gt;

&lt;p&gt;Voici quelques définitions (pour le reste, &lt;a href=&quot;https://conventionalcomments.org/&quot;&gt;se référer au site du standard&lt;/a&gt;):&lt;/p&gt;

&lt;h4 id=&quot;praise-éloge&quot;&gt;Praise (éloge)&lt;/h4&gt;

&lt;p&gt;Grâce à ce commentaire, on souligne quelque chose de positif, on encourage la personne. Bien 
entendu, pas de second degré !&lt;/p&gt;

&lt;h4 id=&quot;suggestion-suggestion&quot;&gt;Suggestion (suggestion)&lt;/h4&gt;

&lt;p&gt;Les suggestions sont la majorité des commentaires qu’on laisse, en général. Il s’agit 
d’améliorations à apporter au sujet actuel. On cherchera à être explicite et clair,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;expliquer en quoi il s’agit d’une amélioration;&lt;/li&gt;
  &lt;li&gt;utiliser des patchs;&lt;/li&gt;
  &lt;li&gt;utiliser des décorations &lt;strong&gt;blocking&lt;/strong&gt; ou &lt;strong&gt;non-blocking&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;issue-problème&quot;&gt;Issue (problème)&lt;/h4&gt;

&lt;p&gt;Grâce aux issues, on met en évidence des problèmes spécifiques. Idéalement, on couple ce 
commentaire avec une &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Suggestion&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&quot;thought-pensée&quot;&gt;Thought (pensée)&lt;/h4&gt;

&lt;p&gt;Les pensées sont des idées qui surgissent lors de la relecture du code. Celles-ci ne sont pas 
bloquantes par nature, mais sont extrêmement précieuses, car elles peuvent conduire à des 
possibilités de mentorat.&lt;/p&gt;

&lt;h2 id=&quot;appropriez-vous-la-méthode-&quot;&gt;Appropriez-vous la méthode !&lt;/h2&gt;

&lt;p&gt;Bien entendu, vous n’êtes pas obligé d’utiliser toute la liste de labels proposée par le 
standard. Vous pouvez en choisir quelques uns, ou bien carrément vous en inspirer et créer les 
vôtres. C’est le choix qu’ont fait Camille et son équipe, &lt;a href=&quot;https://www.24joursdeweb.fr/2021/conventional-comments-faire-des-revues-de-code-avec-le-smiley/&quot;&gt;qu’elle décrit dans cet excellent 
article 
sur les conventional Comments et l’utilisation des emojis&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Ainsi, l’équipe a porté son choix sur une liste d’étiquettes illustrées par des emojis, qui 
traduisent à fois l’intention du commentaire et son urgence.
Voici quelques exemples, tirés de l’article :&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;🥜 peanuts&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;❓ question&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;💬 discussion&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;🚨 alerte&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;🚫 no-go&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;👏 bravo&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;⚠️ warning&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;☠️ bad idea&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;✨ magic&lt;/code&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;🔥 burn-it-all&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;quelques-autres-bonnes-pratiques-donboarding&quot;&gt;Quelques autres bonnes pratiques d’onboarding&lt;/h2&gt;

&lt;p&gt;Bien entendu, il y a plein d’autres façons d’aider vos nouveaux développeurs ou
nouvelles développeuses à découvrir le code. Voici quelques autres idées :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;On peut se familiariser avec le workflow d’une publication de pull request ou de merge 
request en faisant une petite modification (ajouter son nom dans un fichier, par exemple ?);&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;on peut être accompagné(e) d’un “buddy” qui nous est assigné à l’arrivée dans l’entreprise avec 
qui on fait les premières revues de code en direct, et pas par écrit.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Une dernière bonne pratique très largement répandue : si les échanges par commentaires sont trop 
nombreux sur une même pull request, pourquoi ne pas se retrouver directement et résoudre en pair 
les 
points discutés ?&lt;/p&gt;</content><author><name>Anne-Laure de Boissieu</name></author><category term="team" /><summary type="html">Au sein des équipes de développement, une activité bien connue est celle de la revue de code, et plus précisément de la revue du delta du code. Il s’agit de l’inspection par nos pairs du code proposé par nos soins, qui se trouve ainsi commenté pour répondre aux exigences de qualité de l’équipe et du projet.</summary></entry><entry><title type="html">Forum PHP 2022 - L’éléphant bleu n’a pas peur de la souris aux grandes oreilles</title><link href="https://tech.bedrockstreaming.com/2022/10/28/forum-php-afup-2022.html" rel="alternate" type="text/html" title="Forum PHP 2022 - L’éléphant bleu n’a pas peur de la souris aux grandes oreilles" /><published>2022-10-28T00:00:00+00:00</published><updated>2022-10-28T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/10/28/forum-php-afup-2022</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/10/28/forum-php-afup-2022.html">&lt;p&gt;Pour cette édition du Forum PHP qui s’est déroulée à Disneyland Paris, Bedrock a vu les choses en grand : première fois
sponsor Or sur un forum et pas moins de 32 Bedrockien(ne)s présent(e)s dont 4 en tant que conférencier(e)s !
Cette année encore, le forum a été un moment privilégié pour les échanges, le partage et vous avez été nombreux(ses) à
venir nous rencontrer sur notre stand et nous avons été ravis de pouvoir échanger avec vous.&lt;/p&gt;

&lt;p&gt;La richesse et la diversité des conférences ont fait de cette édition une grande réussite. Nous ne pouvons
malheureusement pas aborder toutes les conférences dans cet article, mais voici une sélection de 10 d’entre elles.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/forumphp2022/stand-bedrock.jpg&quot; alt=&quot;Le stand Bedrock&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;bedrock-au-forum-php&quot;&gt;Bedrock au Forum PHP&lt;/h2&gt;

&lt;p&gt;Grande première pour nous cette fois-ci : Bedrock avait un stand sur le forum PHP !
Notre équipe technique, ainsi que des membres de l’équipe RH a participé à la présentation de
l’entreprise. Nous avons pu, tous ensemble, vous accueillir sur le stand pour répondre aux questions sur notre activité,
notre organisation et la vie dans l’entreprise.&lt;/p&gt;

&lt;p&gt;De leurs propres mots :&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Notre présence au forum fut une réussite collective, qui nous a permis de nous faire connaître et mettre en lumière BEDROCK en tant que structure à part entière, et non plus en tant que « M6 Web ».
Nos équipes étaient ravies que Bedrock soit sponsor et ont pu se challenger sur de réels “casses-têtes” et non pas sur leur code.
Durant ces deux journées, le stand Bedrock a été un point de rendez-vous agréable pour nos équipes et pour les autres participants curieux d’apprendre à nous connaître.
Cette participation, au-delà d’être très formatrice pour la communauté Bedrock, a même parfois été assimilée à un « team building » pour reprendre les termes de nos collaborateurs, leur permettant de se retrouver dans un autre environnement et de participer à l’attractivité de leur entreprise.
Les équipes Backend &amp;amp; RH étaient fières de représenter Bedrock en participant à la vie du stand et de répondre aux questions des passants.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/forumphp2022/backend-managers.jpg&quot; alt=&quot;Nos 2 Backend managers, Mikael et FX en train d’animer l’épreuve des casse-têtes&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;les-conférences-quon-retient&quot;&gt;Les conférences qu’on retient&lt;/h2&gt;

&lt;h3 id=&quot;jour-1&quot;&gt;Jour 1&lt;/h3&gt;

&lt;h4 id=&quot;the-php-foundation-the-past-the-present-and-the-future---sebastian-bergmann-roman-pronskiy&quot;&gt;The PHP Foundation: The past, the present, and the future - Sebastian BERGMANN, Roman PRONSKIY&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;“PHP c’est simple, suffit de dégommer un mec, et ça n’existe plus…”
                                  	- Chuck Norris -&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Cette vision à peine exagérée de l’ami Chuck était assez proche de la réalité jusqu’à l’année dernière. En effet,
jusque-là, l’écrasante majorité de la connaissance internet et des implémentations des features de PHP reposaient sur
les épaules de &lt;em&gt;Nikita Popov&lt;/em&gt; et &lt;em&gt;Dmitry Stogov&lt;/em&gt;. Lesquels faisaient cela de manière non-professionnelle, comme un hobby,
alors que PHP est aujourd’hui utilisé pour environ &lt;a href=&quot;https://w3techs.com/technologies/details/pl-php&quot;&gt;70% des sites internets&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Tout ceci est résumé dans &lt;a href=&quot;https://blog.krakjoe.ninja/2021/05/avoiding-busses.html&quot;&gt;cet article&lt;/a&gt; (en anglais).&lt;/p&gt;

&lt;p&gt;Ce qui nous amène à un principe bien connu et très problématique de bon nombre d’entreprises : &lt;em&gt;le Bus Factor&lt;/em&gt;.&lt;/p&gt;

&lt;h5 id=&quot;bus-factor&quot;&gt;Bus Factor&lt;/h5&gt;

&lt;p&gt;Ce principe identifie &lt;em&gt;le nombre de personnes qui doivent être renversées par un bus&lt;/em&gt; pour que la connaissance d’un
projet disparaisse et que ce dernier soit réellement mis en péril. Appliqué à PHP, cela signifie que &lt;em&gt;si deux
personnes&lt;/em&gt; avaient été renversées par un bus ou &lt;em&gt;avaient croisé le chemin de Chuck&lt;/em&gt;, l’ensemble de la communauté PHP
aurait bien transpiré.&lt;/p&gt;

&lt;h5 id=&quot;la-php-foundation&quot;&gt;La PHP Foundation&lt;/h5&gt;

&lt;p&gt;En 2021, &lt;em&gt;Nikita Popov&lt;/em&gt; annonce son souhait de réduire drastiquement sa contribution au langage, et c’est là que
la &lt;a href=&quot;https://thephp.foundation/&quot;&gt;PHP Fundation&lt;/a&gt; est fondée autour de personnalités comme &lt;em&gt;Sebastian BERGMAN&lt;/em&gt; et
&lt;em&gt;Roman PRONSKIY&lt;/em&gt; qui ont animé cette conférence à laquelle nous avons eu la chance d’assister.&lt;/p&gt;

&lt;p&gt;L’objectif est simple : récolter des fonds pour pouvoir &lt;em&gt;rémunérer des personnes qui font évoluer le langage&lt;/em&gt; et
répartir la connaissance dudit langage entre un maximum de personnes pour &lt;em&gt;minimiser le Bus Factor&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;L’aspect juridique et financier de la chose est délégué à une structure
nommée &lt;a href=&quot;https://opencollective.com/phpfoundation&quot;&gt;Open Collective&lt;/a&gt;, dont l’activité est 100% transparente.
Les derniers chiffres font ainsi valoir qu’après déductions des charges, il reste cette année environ 580 000$ pour la
fondation.&lt;/p&gt;

&lt;p&gt;Les fonds &lt;em&gt;proviennent majoritairement de donations&lt;/em&gt; répartis comme suit :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;77% provenant d’entreprises (JetBrains, Livesport, Symfony…)&lt;/li&gt;
  &lt;li&gt;23% provenant d’individus&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Parmi les actuels core contributeurs on retrouve :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/arnaud-lb&quot;&gt;Arnaud Le Blanc&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/derickr&quot;&gt;Derick Rethans&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/Girgias&quot;&gt;George P. Banyard&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/iluuu1994&quot;&gt;Ilija Tovilo&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/bukka&quot;&gt;Jakub Zelenka&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/kocsismate&quot;&gt;Máté Kocsis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;le-futur-de-php-&quot;&gt;Le futur de PHP ?&lt;/h5&gt;

&lt;p&gt;Avec cette stratégie de contractualisation des core-contributeurs et le souci de partager la connaissance, on est en
droit d’espérer que le risque de mise en péril du langage soit fortement réduit. Qui plus est, &lt;strong&gt;l’arrivée prochaine de
la version 8.2 de PHP&lt;/strong&gt; semble montrer que la nouvelle équipe a su faire avancer le projet, pour notre plus grand plaisir.&lt;/p&gt;

&lt;h4 id=&quot;watch-the-clock---andreas-heighl&quot;&gt;Watch the clock - Andreas HEIGHL&lt;/h4&gt;

&lt;p&gt;Dans cette conférence, &lt;a href=&quot;https://twitter.com/heiglandreas&quot;&gt;Andreas&lt;/a&gt; aborde la douloureuse problématique du temps en PHP
et plus précisément le cauchemar que sont les tests sur la notion de temps réel.&lt;/p&gt;

&lt;p&gt;Afin de répondre à cette problématique, il évoque et explique en détail tout le cheminement intellectuel pour la mise en
place de la &lt;a href=&quot;https://github.com/php-fig/clock&quot;&gt;PSR-20&lt;/a&gt;. Elle donnera la possibilité, grâce à une “simple” interface, de
gérer plus facilement le temps réel et les tests associés. Malheureusement, la PSR-20 est actuellement encore à l’état
de brouillon et ne sera probablement pas mise à disposition avant longtemps.&lt;/p&gt;

&lt;p&gt;Afin de nous faire patienter, Andreas a développé sa propre implémentation de l’interface Clock qui sera proposée dans
la PSR-20 : &lt;a href=&quot;https://packagist.org/packages/stella-maris/clock&quot;&gt;https://packagist.org/packages/stella-maris/clock&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;comment-être-bien-onboardé-en-tant-que-développeuse-junior-reconvertie----amélie-abdallah&quot;&gt;Comment être bien onboardé en tant que développeuse junior reconvertie ? - &lt;a href=&quot;https://twitter.com/AlonahAmelie&quot;&gt;Amélie ABDALLAH&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;Amélie, alternante et en reconversion, a donné sa première conférence pour faire un retour d’expérience des onboardings
qu’elle a vécu dans ses 2 premières entreprises.&lt;/p&gt;

&lt;p&gt;Pour sa première expérience en tant que développeuse elle se retrouve à devoir coder dès le premier jour. Une fois
passée l’euphorie, je rappelle qu’elle est en reconversion et sur-motivée, elle se rend vite compte de tout ce qui ne
va pas :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;personne pour la former que ce soit techniquement ou concernant le métier&lt;/li&gt;
  &lt;li&gt;aucune présentation des autres équipes&lt;/li&gt;
  &lt;li&gt;aucun accompagnement de la part des supérieurs hiérarchiques&lt;/li&gt;
  &lt;li&gt;seule sur un projet où les règles métiers semblent complexes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Elle se sent rapidement perdue et son moral et sa motivation tombent en flèche.&lt;/p&gt;

&lt;p&gt;Concernant sa seconde entreprise, c’est tout l’inverse :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;pas de code pour les alternants/reconverti(e)s avant 2 semaines&lt;/li&gt;
  &lt;li&gt;un système de marrainage/parrainage&lt;/li&gt;
  &lt;li&gt;un repo avec des exercices et bonnes pratiques pour progresser&lt;/li&gt;
  &lt;li&gt;une rencontre avec toutes les équipes pour se connaître mais surtout pour bien comprendre les différents métiers de ses collègues&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Amélie conclut en incitant toutes les entreprises à envisager des candidat(e)s en reconversion qui, à la condition
d’être bien accompagné(e)s, seront sur-motivé(e)s et plein(e)s d’énergie.&lt;/p&gt;

&lt;p&gt;Cela nous permet de faire l’état des lieux de notre processus d’onboarding. Même si on peut trouver des pistes
d’amélioration, comme par exemple avoir une présentation des autres équipes et différents métiers bien plus tôt, on
constate que nous avons déjà mis en place beaucoup de bonnes pratiques :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;calendrier d’onboarding clair avec installation de la machine, présentation de l’équipe rejoint par la nouvelle personne, des locaux, des projets, etc.&lt;/li&gt;
  &lt;li&gt;système de marrainage/parrainage,&lt;/li&gt;
  &lt;li&gt;des formations disponibles sur les différentes technologies utilisées&lt;/li&gt;
  &lt;li&gt;ce qu’on appelle la &lt;em&gt;Bedrock Academy&lt;/em&gt;, qui donne une vision globale des métiers de l’entreprise&lt;/li&gt;
  &lt;li&gt;un rapport d’étonnement présenté par le nouvel arrivant qui nous permet d’améliorer notre onboarding en continu&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;ffi--de-nouveaux-horizons-pour-php---pierre-pelisset&quot;&gt;FFI : De nouveaux horizons pour PHP - Pierre PELISSET&lt;/h4&gt;

&lt;p&gt;Chez Karafun, Pierre Pelisset nous présente un moyen de dépasser les frontières habituelles de PHP.&lt;/p&gt;

&lt;p&gt;La mise en place de bar à karaoké nécessite en effet de manipuler du matériel spécifique. La transmission de données par
USB reste le moyen le plus simple de faire communiquer des systèmes, mais nativement rien n’existe en PHP. Jusqu’à
présent les équipes de Karafun utilisaient un script Python avec PySerial pour répondre à ce besoin.&lt;/p&gt;

&lt;p&gt;Depuis PHP 7.4, il est possible d’utiliser les &lt;a href=&quot;https://www.php.net/manual/en/book.ffi.php&quot;&gt;&lt;em&gt;Foreign Function Interface&lt;/em&gt; (FFI)&lt;/a&gt;
pour appeler directement des libraires C compilées depuis le code PHP. En se basant sur les bonnes librairies, il a été
ainsi possible pour les équipes de Karafun d’utiliser PHP dans la totalité de leur stack, et de remplacer leurs scripts
Python.&lt;/p&gt;

&lt;p&gt;Pierre nous présente ensuite la librairie &lt;a href=&quot;https://github.com/ppelisset/php-termios&quot;&gt;php-termios&lt;/a&gt; qu’il a implémentée
pour permettre d’utiliser Termios, une librairie de manipulation de terminal POSIX écrite en C, depuis PHP.&lt;/p&gt;

&lt;p&gt;L’interfaçage reste facile tant qu’il s’agit de types de données simples (comme des entiers), mais devient beaucoup plus
complexe lorsqu’il s’agit de manipuler des structures de données avancées (chaînes de caractères, objets, …).&lt;/p&gt;

&lt;p&gt;Idéalement, il faut créer des classes PHP ressemblant à la librairie C (mêmes noms de fonction, de constante, …), afin
de faciliter sa manipulation.&lt;/p&gt;

&lt;p&gt;L’utilisation des FFI introduit de nouvelles difficultés liées généralement aux programmes compilés. Ainsi, dans le cas
de Termios, les constantes utilisées varient selon la plateforme (Linux, MacOS, …). Il a donc fallu utiliser quelques
astuces pour les copier dynamiquement dans le code PHP. De même, pour distribuer le binaire compilé, il faut prendre en
compte l’architecture CPU de la machine exécutant le code.&lt;/p&gt;

&lt;h4 id=&quot;opentelemetry--vers-un-standard-pour-surveiller-vos-applications---benoit-viguier&quot;&gt;OpenTelemetry : vers un standard pour surveiller vos applications - Benoit Viguier&lt;/h4&gt;

&lt;p&gt;Lors de sa conférence, Benoit Viguier (développeur chez &lt;a href=&quot;https://platform.sh/&quot;&gt;Platform.sh&lt;/a&gt; au sein de l’équipe de &lt;a href=&quot;https://www.blackfire.io/&quot;&gt;Blackfire.io&lt;/a&gt;) est venu parler
d’un standard de monitoring soutenu par la Cloud Native Computing Foundation : OpenTelemetry. Il a d’abord commencé par
nous rappeler pourquoi nous faisons du monitoring.&lt;/p&gt;

&lt;p&gt;Le monitoring nous permet de savoir si nos services fonctionnent correctement (conforme au SLA|SLO), et si cela n’est
pas le cas, de savoir pourquoi cela ne fonctionne pas. Pour faire cela, il nous a présenté les différentes solutions de
monitoring qui existent, de la plus simple à mettre en place (Analytics), au plus|trop détaillé (logs) mais aussi via
des metrics qui eux demandent une plus grande intégration.&lt;/p&gt;

&lt;p&gt;Ensuite vient la présentation des promesses de ce nouveau standard (OpenTelemetry) et sa volonté d’uniformiser les trois
piliers du monitoring : logs, metrics et les traces, avec la volonté de rendre interopérable ces données collectées avec
n’importe quel service et ce qu’importe le langage.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/forumphp2022/open-telemetry.png&quot; alt=&quot;Schéma OpenTelemetry&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Afin de permettre cette interopérabilité pour la collecte, le traitement et l’envoi des données entre nos applications
et nos APMs, OpenTelemetry propose l’utilisation d’un &lt;a href=&quot;https://opentelemetry.io/docs/collector/&quot;&gt;collecteur&lt;/a&gt;. Ce collecteur possède trois composants par lesquels
notre donnée va transiter :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Receiver - Gère la récupération des données dans le collecteur. Il fonctionne aussi bien avec une mécanique de push que de pull et supporte nativement les protocoles HTTP et gRPC.&lt;/li&gt;
  &lt;li&gt;Processor - Permet le traitement des données avant l’envoi aux différents outils de monitoring.&lt;/li&gt;
  &lt;li&gt;Exporter - Envoie les données (via push ou pull) aux outils de monitoring.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Concernant l’utilisation du standard OpenTelemetry en PHP, il existe aujourd’hui un SDK qui, cependant, ne possède
pas beaucoup de fonctionnalités.&lt;/p&gt;

&lt;p&gt;Malgré son jeune âge (release v1.0 en 2021), OpenTelemetry a encore de beaux jours devant lui si la contribution et le
soutien de la communauté continuent. Il est important de rappeler que le standard n’est pas encore finalisé, par exemple
la fonctionnalité “logging” est encore en cours de développement et n’est disponible qu’en “draft”.&lt;/p&gt;

&lt;h3 id=&quot;jour-2&quot;&gt;Jour 2&lt;/h3&gt;

&lt;h4 id=&quot;typage-en-php-comment-ça-fonctionne----george-banyard&quot;&gt;Typage en PHP, comment ça fonctionne ? - George BANYARD&lt;/h4&gt;

&lt;p&gt;Lors de cette dissection du typage PHP, George Banyard, développeur salarié de la PHP Foundation, nous a expliqué (ou du
moins tenté) comment fonctionne le typage PHP grâce à des formules mathématiques. Mais avant de nous faire peur avec les
formules, il nous d’abord rappelé les différents types existants et futurs (PHP 8.1 et 8.2) et comment ils sont
représentés en C (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;zend_type&lt;/code&gt;,&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt; _zval_struct&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_zend_class_entry&lt;/code&gt;)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Types Primitifs&lt;/li&gt;
  &lt;li&gt;Types définis en espace utilisateur (classe, interfaces, enum)&lt;/li&gt;
  &lt;li&gt;Types Littéraux (false, true)&lt;/li&gt;
  &lt;li&gt;Type callable&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Types Composés (A&amp;amp;B, A&lt;/td&gt;
          &lt;td&gt;B, Forme Normale Disjonctive)&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;Alias de Type (PHP 8.2)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ensuite, il nous a expliqué le principe de &lt;strong&gt;substitution de Liskov&lt;/strong&gt; de différente manière.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Si φ(x) est une propriété démontrable pour tout objet x de&lt;/em&gt;
&lt;em&gt;type T, alors φ(y) est vraie pour tout objet y de type S tel que&lt;/em&gt;
&lt;em&gt;S est un sous-type de T&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Mathématique, en C mais aussi en image :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/forumphp2022/schema-maths.png&quot; alt=&quot;Schéma mathématique&quot; /&gt;&lt;/p&gt;

&lt;p&gt;En version très simplifiée, la substitution de Liskov permet de substituer un type par un autre type s’il est
mieux-disant. C’est par exemple sur ce principe que sont fondées &lt;a href=&quot;https://www.php.net/manual/en/language.oop5.variance.php&quot;&gt;la co-variance et la contra-variance&lt;/a&gt; en PHP.&lt;/p&gt;

&lt;p&gt;Après toutes ces informations, George nous a fait rêver avec les nouveautés qui pourraient arriver dans notre langage préféré :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;La possibilité de définir nos alias de type (numeric qui serait int ou float)&lt;/li&gt;
  &lt;li&gt;Pouvoir définir un typage pour les paramètres et le retour des callable directement dans la fonction : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;foo(fn&amp;lt;int,string&amp;gt;:bool $callable) {}&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Le paramètre in-out qui permet de vérifier que le type ne change pas entre l’entrée et la sortie d’une fonction, utile notamment dans le cas de passage par référence&lt;/li&gt;
  &lt;li&gt;Pouvoir créer des types génériques (par exemple &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;class Collection&amp;lt;string&amp;gt;&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Vous pouvez retrouver les slides de la conférence &lt;a href=&quot;https://gpb.moe/doc/PHP_Type_System_Talk__FR.pdf&quot;&gt;ici&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;protéger-votre-application-avec-len-tête-http-de-sécurité-content-security-policy---laurent-brunet&quot;&gt;Protéger votre application avec l’en-tête HTTP de sécurité “Content Security Policy” - Laurent BRUNET&lt;/h4&gt;

&lt;p&gt;Durant ce talk, Laurent BRUNET nous a rappelé l’importance de sécuriser les sites internet en nous parlant des attaques
les plus utilisées et dont on pourrait se défendre en exploitant correctement le header de réponse &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Content-Security-Policy&lt;/code&gt; (aka. CSP).&lt;/p&gt;

&lt;p&gt;Concrètement, le header CSP est délivré par le serveur en même temps que le HTML d’une page web et contraint les
navigateurs à s’assurer que le contenu de la page respecte les règles de sécurité définies grâce à de nombreuses directives.&lt;/p&gt;

&lt;p&gt;Il existe 2 variantes de ce header qui peuvent être utilisées conjointement :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;une forme bloquante qui empêchera tous contenus illicites d’être chargés par le navigateur
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Content-Security-Policy: &amp;lt;directive1&amp;gt; ;  &amp;lt;directive2&amp;gt; ;  &amp;lt;directiveN&amp;gt;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;une forme non-bloquante qui permet uniquement aux développeurs d’être avertis si du contenu illicite est présent sur la page
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Content-Security-Policy-Report-Only: &amp;lt;directive1&amp;gt; ;  &amp;lt;directive2&amp;gt; ;  &amp;lt;directiveN&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Et voici quelques unes des failles de sécurité évoquées durant ce talk, chacune accompagnée d’une des directives permettant de s’en protéger :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;on peut se protéger des attaques &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;XSS&lt;/code&gt; (e.g. injection de scripts dans une page web permettant d’exploiter les accès d’un utilisateur) en whitelistant les scripts autorisés à s’exécuter dans votre application avec &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;script-src &apos;nonce-MonIDDeScript&apos; &apos;sha256-MonHashDeScript&apos; &apos;strict-dynamic&apos; https: &apos;unsafe-inline&apos; *.example.com ;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;le Clickjacking (e.g. injection d’iframe invisible dans laquelle l’utilisateur va cliquer sans le savoir) peut être facilement contré en whitelistant vos iframes et celles de vos partenaires avec &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;frame-ancestors &apos;self&apos; https://example.com ;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;la faille Magecart (e.g. récupération des données bancaires en les envoyant vers un nom de domaine pirate difficile à détecter) disparaîtra en whitelistant les noms de domaines utilisés dans des appels AJAX avec &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;connect-src &apos;self&apos; https://example.com ;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Si le sujet vous intéresse, n’hésitez pas à consulter le talk de Laurent dès qu’il sera disponible en replay. En
attendant, profitez de &lt;a href=&quot;https://developer.mozilla.org/fr/docs/Web/HTTP/CSP&quot;&gt;la documentation du MDN&lt;/a&gt; et sachez
que &lt;a href=&quot;https://csp-evaluator.withgoogle.com&quot;&gt;Google fournit un service en ligne&lt;/a&gt; pour inspecter et valider les CSP de vos
pages web.&lt;/p&gt;

&lt;h4 id=&quot;tester-à-travers-openapi-ou-comment-valider-votre-documentation----stéphane-hulard&quot;&gt;Tester à travers OpenAPI, ou comment valider votre documentation ! - Stéphane Hulard&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/s_hulard&quot;&gt;Stéphane Hulard&lt;/a&gt; a commencé sa conférence par nous rappeler ce qu’est OpenAPI : il s’agit
d’une initiative qui vise à normaliser et standardiser la description d’APIs. Cela sert à l’interopérabilité,
l’automatisation et la fiabilité.&lt;/p&gt;

&lt;p&gt;Il faut voir la documentation comme une spécification de notre API. &lt;em&gt;“Une documentation n’a de sens que si elle reflète
l’état actuel de l’application.”&lt;/em&gt; Rien de mieux donc que d’intégrer la validation de notre documentation par rapport à
notre code, et inversement : que notre documentation valide notre code !&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/forumphp2022/presentation-validation-openapi.png&quot; alt=&quot;schéma de validation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://thephpleague.com/&quot;&gt;&lt;em&gt;thephpleague&lt;/em&gt;&lt;/a&gt; nous propose une solution pour faire ça : &lt;a href=&quot;https://github.com/thephpleague/openapi-psr7-validator&quot;&gt;openapi-psr7-validator&lt;/a&gt;.
Ce paquet peut valider les messages PSR-7 par rapport aux spécifications OpenAPI (3.0.x) exprimées en YAML ou JSON.&lt;/p&gt;

&lt;p&gt;Ce paquet se base sur les &lt;em&gt;PHP Standards Recommendations&lt;/em&gt; (PSR) qui sont des textes décrivant une manière commune de
résoudre un problème spécifique. De cette façon, les projets qui suivent ces recommandations auront une excellente
interopérabilité en suivant les mêmes recommandations et contrats.&lt;/p&gt;

&lt;p&gt;Stéphane nous parle ensuite de la librairie &lt;a href=&quot;https://github.com/CHStudio/Raven&quot;&gt;Raven&lt;/a&gt; qu’il vient de publier. Raven a
pour but de faciliter la validation au travers de la documentation, de s’appuyer sur de vraies données pour valider les
requêtes et réponses ainsi que valider le comportement de l’API testée. La librairie n’en est qu’à ses débuts, quelques
issues sont remontées sur le repository, n’hésitez pas à contribuer !&lt;/p&gt;

&lt;p&gt;Stéphane a mis à disposition les &lt;a href=&quot;https://public.chstudio.fr/talks/test-through-openapi-or-how-to-validate-your-documentation/fr-forum-php-2022.html#/&quot;&gt;slides de sa conférence ici&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;frankenphp-dans-les-entrailles-de-linterpréteur-php-de-machines-virtuelles-et-des-threads---kévin-dunglas&quot;&gt;FrankenPHP, dans les entrailles de l’interpréteur PHP, de machines virtuelles et des threads - &lt;a href=&quot;https://twitter.com/dunglas&quot;&gt;Kévin DUNGLAS&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;Chez Bedrock, nous utilisons majoritairement nginx et php-fpm pour servir nos applications. Nous avons aussi fait des
essais avec Road Runner comme alternative.&lt;/p&gt;

&lt;p&gt;Durant cette conférence, Kévin DUNGLAS nous a présenté une nouvelle alternative écrite en Go et nommée &lt;a href=&quot;https://frankenphp.dev/&quot;&gt;frankenphp&lt;/a&gt;.
Chouette effet d’annonce au passage, FrankenPHP a été ouvert au public en direct durant la conférence.&lt;/p&gt;

&lt;p&gt;En plus d’avoir un logo très mignon, ce nouveau serveur d’application PHP promet un gain de performance en gardant en
mémoire l’application chargée. Autre argument intéressant, la facilité d’installation et d’utilisation.&lt;/p&gt;

&lt;p&gt;Bien qu’il a plusieurs fois précisé que ce n’était pas prêt pour la production, cette nouvelle approche semble
prometteuse. Il est probable que nous ne tardions pas à l’essayer pour voir s’il est possible de gagner en performance.&lt;/p&gt;

&lt;h2 id=&quot;les-conférenciers-bedrock&quot;&gt;Les conférenciers Bedrock&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/forumphp2022/presentation-anne-laure.jpg&quot; alt=&quot;Anne-Laure durant sa présentation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Cette année, ce ne sont pas moins de 4 présentations qui étaient données par des personnes de chez Bedrock.&lt;/p&gt;

&lt;p&gt;Vous pourrez les trouver très bientôt en replay. Les liens seront partagés sur ce blog et les vidéos disponibles
sur &lt;a href=&quot;https://www.youtube.com/user/afupPHP&quot;&gt;la chaîne youtube de l’afup&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;En attendant, et pour rappel, il s’agissait des conférences suivantes :&lt;/p&gt;

&lt;h4 id=&quot;comprenez-comment-php-fonctionne-vos-applications-marcheront-mieux---pascal-martin&quot;&gt;Comprenez comment PHP fonctionne, vos applications marcheront mieux - Pascal MARTIN&lt;/h4&gt;

&lt;p&gt;À l’échelle à laquelle nous travaillons, avec des millions de personnes sur nos plateformes tous les jours, nous découvrons, atteignons, voire dépassons régulièrement des limites de l’approche traditionnelle de PHP et de php-fpm. Au cours de ce talk, Pascal souhaitait partager notre expérience de travail avec PHP, sur des sujets souvent peu connus par les développeurs et développeuses, pour aider le public à créer des applications qui répondent mieux aux attentes de leur public.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Pour exécuter du code, PHP consomme du processeur et de la mémoire. Quand une requête HTTP arrive, un processus php-fpm lui est dédié. Mais ces ressources sont limitées. Et, même dans le Cloud ou en serverless, scaler prend du temps et les coûts s’envolent !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Savez-vous combien de CPU et de RAM votre application réclame ? Et pendant quelle durée ? Si non ou sans comprendre « pourquoi », difficile de développer efficacement et de dimensionner un hébergement pérenne ! Peut-être que ça marche… Sur votre poste. Ou pendant un moment, en gaspillant de l’argent et des ressources. Mais l’expérience prouve que, tôt ou tard, ces questions vous rattraperont.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Cycle de vie de PHP, communication entre nginx et php-fpm, approche shared-nothing, compilation et cache d’opcodes, gestion interne de la mémoire ou même architecture logicielle et debugging… Pour qu’une application réponde aux attentes de son public, nous devons comprendre comment PHP fonctionne !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;sauve-un-e-dév-écris-une-doc----sarah-haïm-lubczanski&quot;&gt;Sauve un-e dév, écris une doc ! - Sarah HAÏM-LUBCZANSKI&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;Vous êtes développeur ou développeuse PHP : vous aimez programmer, réfléchir. Vous aimez créer des applications ou des bibliothèques de qualité. Mais pourquoi personne ne les utilise ? Parce que votre documentation n’est pas à la hauteur !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Justement : je suis Technical Writer et mon métier est de vous aider à valoriser votre logiciel auprès de ses utilisateurs et utilisatrices, à travers une bonne doc. Comprenons comment architecturer, concevoir et rédiger votre contenu. Découvrons les outils qui vous procureront une aide précieuse. Enfin, facilitons sa mise à jour pour qu’elle soit pérenne.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Dorénavant, vous saurez identifier les passages obligés et ceux où vous pouvez gagner du temps.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;revue-de-code--on-nest-pas-venu-pour-souffrir----anne-laure-de-boissieu&quot;&gt;Revue de code : on n’est pas venu pour souffrir ! - Anne-Laure DE BOISSIEU&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;J’ai rejoint ma nouvelle équipe il y a 6 mois, avec une appréhension. Comment allais-je vivre les revues de code par des collègues que je ne connais pas encore ? Incompréhensions, malentendus : la communication écrite rend cet exercice très délicat. Vous avez été blessé-e par un commentaire ? Etait-il vraiment mal intentionné ? Vous avez blessé quelqu’un sans le vouloir, à cause d’une tournure maladroite ?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Dans mon équipe, j’ai découvert un cadre qui m’a permis de me sentir bien accueillie dès mon arrivée. En adoptant une posture et une convention bien adaptée, on peut largement diminuer le risque de mal se comprendre. Non seulement on communique mieux, mais on améliore la qualité globale du projet.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Vous n’aurez plus aucune raison de souffrir !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;bff-notre-best-friend-forever-pour-faire-plein-dapplications-frontend----valentin-claras&quot;&gt;BFF, notre best friend forever pour faire plein d’applications frontend ? - Valentin CLARAS&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;Chez Bedrock nous fournissons des applications de streaming (ASVOD, AVOD) pour plusieurs clients en France et en Europe, chaque application étant déployée sur de nombreux appareils (ordinateur, mobile, set top box, tv connectée, consoles de jeux, tv stick etc …). Il était devenu très difficile de gérer la création et l’évolution de ces nombreuses applications qui requêtaient et formataient chacune elles-mêmes les données dont elles avaient besoin.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Pour cela, en 2018, nous avons décidé de nous lancer dans la création d’un Back For Front afin d’unifier et faciliter les interactions backend et frontend. Cette conférence fut l’occasion de passer en revue :&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;les concepts du Back For Front&lt;/li&gt;
    &lt;li&gt;l’architecture api-gateway et micro service mise en place&lt;/li&gt;
    &lt;li&gt;les gains fonctionnels et la vélocité gagnée&lt;/li&gt;
    &lt;li&gt;les différents mécanismes développés pour absorber les importants pics de charge (résilience, circuit breaker, fallbacks etc.)&lt;/li&gt;
    &lt;li&gt;les impacts techniques et organisationnels d’une telle architecture&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Aujourd’hui notre API Gateway BFF opère 92 frontends délivrant 1.5 milliards de vidéos par an pour 45 millions d’utilisateurs actifs (MaU).
Vous pourrez trouver un complément d’informations au sujet de notre BFF dans &lt;a href=&quot;https://tech.bedrockstreaming.com/2022/06/10/backend-bff-intro.html&quot;&gt;la suite d’articles dédié&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;pour-conclure&quot;&gt;Pour conclure&lt;/h2&gt;

&lt;p&gt;Nous sommes revenus la tête pleine de nouvelles idées. Ces deux jours de conférences nous ont permis de montrer le savoir faire présent chez Bedrock et nous avons aussi pu nous inspirer des connaissances d’autres personnes. Les formats variés répondaient aux goûts de chacun(e) et ont rendu ce forum unique.&lt;/p&gt;

&lt;p&gt;Les nombreuses activités proposées entre chaque conférence permettaient d’échanger entre pairs et comme toujours la communauté a été mise à l’honneur avec la construction d’une fresque LEGO représentant tous les logos des antennes de l’AFUP.&lt;/p&gt;

&lt;p&gt;Merci à tou(te)s les conférencier(e)s pour leur travail incroyable et merci l’AFUP pour l’organisation de ce superbe évènement !&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/forumphp2022/fresque-lego-communautaire.jpg&quot; alt=&quot;La fresque Lego communautaire&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Vivement l’année prochaine !&lt;/p&gt;</content><author><name>Bedrock</name></author><category term="afup" /><category term="php" /><category term="forumphp" /><category term="conference" /><summary type="html">Pour cette édition du Forum PHP qui s’est déroulée à Disneyland Paris, Bedrock a vu les choses en grand : première fois sponsor Or sur un forum et pas moins de 32 Bedrockien(ne)s présent(e)s dont 4 en tant que conférencier(e)s ! Cette année encore, le forum a été un moment privilégié pour les échanges, le partage et vous avez été nombreux(ses) à venir nous rencontrer sur notre stand et nous avons été ravis de pouvoir échanger avec vous.</summary></entry><entry><title type="html">BFF, notre best friend forever pour faire plein d’applications frontend ?</title><link href="https://tech.bedrockstreaming.com/2022/10/13/bff-notre-best-friend-forever-pour-faire-plein-d-applications-frontend.html" rel="alternate" type="text/html" title="BFF, notre best friend forever pour faire plein d’applications frontend ?" /><published>2022-10-13T00:00:00+00:00</published><updated>2022-10-13T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/10/13/bff-notre-best-friend-forever-pour-faire-plein-d-applications-frontend</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/10/13/bff-notre-best-friend-forever-pour-faire-plein-d-applications-frontend.html">&lt;p&gt;Chez Bedrock nous fournissons des applications de streaming (ASVOD, AVOD) pour plusieurs clients en France et en Europe, chaque application étant déployée sur de nombreux appareils (ordinateur, mobile, set top box, tv connecté, consoles de jeux, tv stick etc …). Il était devenu très difficile de gérer la création et l’évolution de ces nombreuses applications qui requêtaient et formataient chacune elles-mêmes les données dont elles avaient besoin.&lt;/p&gt;

&lt;p&gt;Pour cela, en 2018, nous avons décidé de nous lancer dans la création d’un Back For Front afin d’unifier et faciliter les interactions backend et frontend. Au cours de cette conférence nous passerons en revue :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;les concepts du back for front&lt;/li&gt;
  &lt;li&gt;l’architecture api-gateway et micro service mise en place&lt;/li&gt;
  &lt;li&gt;Les gains fonctionnels et la vélocités gagnée&lt;/li&gt;
  &lt;li&gt;les différents mécanismes développés pour absorber les importants pic de charge (résilience, circuit breaker, fallbacks etc.)&lt;/li&gt;
  &lt;li&gt;les impacts techniques et organisationnels d’une telle architecture&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Aujourd’hui notre API Gateway BFF opère 92 frontends délivrant 1.5 milliards de vidéos par an pour 45 millions d’utilisateurs actifs (MaU). Venez découvrir notre retour d’expérience sur la mise en place d’un tel projet.&lt;/p&gt;</content><author><name>Valentin CLARAS</name></author><category term="conference" /><category term="afup" /><category term="forumphp" /><category term="php" /><category term="bff" /><summary type="html">Chez Bedrock nous fournissons des applications de streaming (ASVOD, AVOD) pour plusieurs clients en France et en Europe, chaque application étant déployée sur de nombreux appareils (ordinateur, mobile, set top box, tv connecté, consoles de jeux, tv stick etc …). Il était devenu très difficile de gérer la création et l’évolution de ces nombreuses applications qui requêtaient et formataient chacune elles-mêmes les données dont elles avaient besoin.</summary></entry><entry><title type="html">Comprenez comment PHP fonctionne, vos applications marcheront mieux, Forum PHP 2022</title><link href="https://tech.bedrockstreaming.com/2022/10/13/comprenez-comment-php-fonctionne-vos-applications-marcheront-mieux.html" rel="alternate" type="text/html" title="Comprenez comment PHP fonctionne, vos applications marcheront mieux, Forum PHP 2022" /><published>2022-10-13T00:00:00+00:00</published><updated>2022-10-13T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/10/13/comprenez-comment-php-fonctionne-vos-applications-marcheront-mieux</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/10/13/comprenez-comment-php-fonctionne-vos-applications-marcheront-mieux.html">&lt;p&gt;Pour exécuter du code, PHP consomme du processeur et de la mémoire. Quand une requête HTTP arrive, un processus php-fpm lui est dédié. Mais ces ressources sont limitées. Et, même dans Le Cloud ou en serverless, scaler prend du temps et les coûts s’envolent !&lt;/p&gt;

&lt;p&gt;Savez-vous combien de CPU et de RAM votre application réclame ? Et pendant quelle durée ? Si non ou sans comprendre « pourquoi », difficile de développer efficacement et de dimensionner un hébergement pérenne ! Peut-être que ça marche… Sur votre poste. Ou pendant un moment, en gaspillant de l’argent et des ressources. Mais l’expérience prouve que, tôt ou tard, ces questions vous rattraperont.&lt;/p&gt;

&lt;p&gt;Cycle de vie de PHP, communication entre nginx et php-fpm, approche shared-nothing, compilation et cache d’opcodes, gestion interne de la mémoire ou même architecture logicielle et debugging… Pour qu’une application réponde aux attentes de son public, nous devons comprendre comment PHP fonctionne !&lt;/p&gt;</content><author><name>Pascal Martin</name></author><category term="conference" /><category term="afup" /><category term="forumphp" /><category term="php" /><summary type="html">Pour exécuter du code, PHP consomme du processeur et de la mémoire. Quand une requête HTTP arrive, un processus php-fpm lui est dédié. Mais ces ressources sont limitées. Et, même dans Le Cloud ou en serverless, scaler prend du temps et les coûts s’envolent !</summary></entry><entry><title type="html">Revue de code : on n’est pas venu pour souffrir !</title><link href="https://tech.bedrockstreaming.com/2022/10/13/revue-de-code-on-n-est-pas-venu-pour-souffrir.html" rel="alternate" type="text/html" title="Revue de code : on n’est pas venu pour souffrir !" /><published>2022-10-13T00:00:00+00:00</published><updated>2022-10-13T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/10/13/revue-de-code-on-n-est-pas-venu-pour-souffrir</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/10/13/revue-de-code-on-n-est-pas-venu-pour-souffrir.html">&lt;p&gt;J’ai rejoint ma nouvelle équipe il y a 6 mois, avec une appréhension. Comment allais-je vivre les revues de code par des collègues que je ne connais pas encore ? Incompréhensions, malentendus : la communication écrite rend cet exercice très délicat. Vous avez été blessé-e par un commentaire ? Etait-il vraiment mal intentionné ? Vous avez blessé quelqu’un sans le vouloir, à cause d’une tournure maladroite ?&lt;/p&gt;

&lt;p&gt;Dans mon équipe, j’ai découvert un cadre qui m’a permis de me sentir bien accueillie dès mon arrivée. En adoptant une posture et une convention bien adaptée, on peut largement diminuer le risque de mal se comprendre. Non seulement on communique mieux, mais on améliore la qualité globale du projet.&lt;/p&gt;

&lt;p&gt;Vous n’aurez plus aucune raison de souffrir !&lt;/p&gt;</content><author><name>Anne-Laure de Boissieu</name></author><category term="conference" /><category term="afup" /><category term="forumphp" /><category term="revue" /><summary type="html">J’ai rejoint ma nouvelle équipe il y a 6 mois, avec une appréhension. Comment allais-je vivre les revues de code par des collègues que je ne connais pas encore ? Incompréhensions, malentendus : la communication écrite rend cet exercice très délicat. Vous avez été blessé-e par un commentaire ? Etait-il vraiment mal intentionné ? Vous avez blessé quelqu’un sans le vouloir, à cause d’une tournure maladroite ?</summary></entry></feed>