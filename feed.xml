<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://tech.bedrockstreaming.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://tech.bedrockstreaming.com/" rel="alternate" type="text/html" /><updated>2023-03-30T09:13:45+00:00</updated><id>https://tech.bedrockstreaming.com/feed.xml</id><title type="html">Bedrock Tech Blog</title><subtitle>Blog technique de Bedrock</subtitle><entry><title type="html">De Node.js 10 Ã  Node.js 18, nous avons rattrapÃ© 8 ans de retard et de dette technique</title><link href="https://tech.bedrockstreaming.com/2023/03/25/de-node-js-10-a-node-js-18-nous-avons-rattrape-8-ans-de-retard-et-de-dette-technique-et-seule-une-approche-progressive-et-incrementale-etait-viable.html" rel="alternate" type="text/html" title="De Node.js 10 Ã  Node.js 18, nous avons rattrapÃ© 8 ans de retard et de dette technique" /><published>2023-03-25T00:00:00+00:00</published><updated>2023-03-25T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/03/25/de-node-js-10-a-node-js-18-nous-avons-rattrape-8-ans-de-retard-et-de-dette-technique-%E2%80%94-et-seule-une-approche-progressive-et-incrementale-etait-viable</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/03/25/de-node-js-10-a-node-js-18-nous-avons-rattrape-8-ans-de-retard-et-de-dette-technique-et-seule-une-approche-progressive-et-incrementale-etait-viable.html">&lt;p&gt;Difficile de faire Ã©voluer des applications et amÃ©liorer une stack si lâ€™ensemble est basÃ© sur une version obsolÃ¨te de Node.jsâ€¦ Dans cet article, nous verrons comment nous avons rÃ©ussi Ã  migrer vers une version rÃ©cente et maintenue de Node.js grÃ¢ce Ã  une approche progressive et incrÃ©mentale.&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#contexte-gÃ©nÃ©ral-et-fonctionnel&quot; id=&quot;markdown-toc-contexte-gÃ©nÃ©ral-et-fonctionnel&quot;&gt;Contexte gÃ©nÃ©ral et fonctionnel&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#contexte-technique&quot; id=&quot;markdown-toc-contexte-technique&quot;&gt;Contexte technique&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#objectif&quot; id=&quot;markdown-toc-objectif&quot;&gt;Objectif&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#une-premiÃ¨re-stratÃ©gie-problÃ©matique--la-mÃ©thode-rhinocÃ©ros-&quot; id=&quot;markdown-toc-une-premiÃ¨re-stratÃ©gie-problÃ©matique--la-mÃ©thode-rhinocÃ©ros-&quot;&gt;Une premiÃ¨re stratÃ©gie problÃ©matique : la mÃ©thode â€œrhinocÃ©rosâ€ ğŸ¦&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#la-stratÃ©gie-gagnante--une-migration-progressive-&quot; id=&quot;markdown-toc-la-stratÃ©gie-gagnante--une-migration-progressive-&quot;&gt;La stratÃ©gie gagnante : une migration progressive ğŸ“¶&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#motivation&quot; id=&quot;markdown-toc-motivation&quot;&gt;Motivation&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#plan-daction&quot; id=&quot;markdown-toc-plan-daction&quot;&gt;Plan dâ€™action&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#difficultÃ©s-rencontrÃ©es&quot; id=&quot;markdown-toc-difficultÃ©s-rencontrÃ©es&quot;&gt;DifficultÃ©s rencontrÃ©es&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#non-dÃ©coupage-des-Ã©tapes-de-migration&quot; id=&quot;markdown-toc-non-dÃ©coupage-des-Ã©tapes-de-migration&quot;&gt;Non dÃ©coupage des Ã©tapes de migration&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#mÃ©connaissance-de-typescript&quot; id=&quot;markdown-toc-mÃ©connaissance-de-typescript&quot;&gt;MÃ©connaissance de Typescript&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#suppression-prÃ©cipitÃ©e-de-librairies-obsolÃ¨tes&quot; id=&quot;markdown-toc-suppression-prÃ©cipitÃ©e-de-librairies-obsolÃ¨tes&quot;&gt;Suppression prÃ©cipitÃ©e de librairies obsolÃ¨tes&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#non-anticipation-de-la-complexitÃ©-liÃ©e-Ã -certaines-dÃ©pendances&quot; id=&quot;markdown-toc-non-anticipation-de-la-complexitÃ©-liÃ©e-Ã -certaines-dÃ©pendances&quot;&gt;Non anticipation de la complexitÃ© liÃ©e Ã  certaines dÃ©pendances&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#entretien-des-applications-legacy-en-mÃªme-temps&quot; id=&quot;markdown-toc-entretien-des-applications-legacy-en-mÃªme-temps&quot;&gt;Entretien des applications legacy en mÃªme temps&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#autres-avantages&quot; id=&quot;markdown-toc-autres-avantages&quot;&gt;Autres avantages&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#uniformisation-des-technologies-au-sein-de-la-sociÃ©tÃ©&quot; id=&quot;markdown-toc-uniformisation-des-technologies-au-sein-de-la-sociÃ©tÃ©&quot;&gt;Uniformisation des technologies au sein de la sociÃ©tÃ©&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#attractivitÃ©-et-rÃ©tention-des-dÃ©veloppeurs&quot; id=&quot;markdown-toc-attractivitÃ©-et-rÃ©tention-des-dÃ©veloppeurs&quot;&gt;AttractivitÃ© et rÃ©tention des dÃ©veloppeurs&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot; id=&quot;markdown-toc-conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;contexte-gÃ©nÃ©ral-et-fonctionnel&quot;&gt;Contexte gÃ©nÃ©ral et fonctionnel&lt;/h1&gt;

&lt;p&gt;Bedrock streaming est une co-entreprise (joint-venture) crÃ©Ã©e en 2020 par M6 Group et RTL Group, permettant Ã  7 diffuseurs et sociÃ©tÃ©s de mÃ©dias dans 5 pays dâ€™Europe de divertir 45 millions dâ€™utilisateurs chaque jour, sur tous les Ã©crans.&lt;/p&gt;

&lt;p&gt;Pour gÃ©rer tous leurs utilisateurs ainsi que leurs contenus, notamment vidÃ©os, les clients de Bedrock Streaming accÃ¨dent chacun Ã  une constellation dâ€™applications au sein dâ€™un back-office centralisÃ© (appelÃ© BO par la suite).&lt;/p&gt;

&lt;h1 id=&quot;contexte-technique&quot;&gt;Contexte technique&lt;/h1&gt;

&lt;p&gt;De part sa conception initiale, le BO est une application monorepo. Elle fournit (Ã  elle-mÃªme donc), des donnÃ©es via une API Symfony 4 (PHP 7.4), consommÃ©es uniquement par :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;des applications Vue.js 1 et Vue.js 2 gÃ©rÃ©es par la team backend (qui historiquement maintient le frontend de quelques applications) ;&lt;/li&gt;
  &lt;li&gt;des applications Vue.js 2 gÃ©rÃ©es par la team frontend.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Le tout, dans un environnement &lt;a href=&quot;https://github.com/nodejs/Release/blob/main/schedule.json#L50&quot;&gt;Node.js 10&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;objectif&quot;&gt;Objectif&lt;/h1&gt;

&lt;p&gt;Node.js 10 est arrivÃ© en fin de vie le 30 avril 2021. Il nâ€™est donc plus maintenu, que ce soit en terme de fonctionnalitÃ©s ou en terme de sÃ©curitÃ©. Naturellement, toutes les dÃ©pendances JS migrent progressivement vers un support des versions de Node.js supÃ©rieures, et abandonnent le support de cette version 10 devenue obsolÃ¨te.&lt;/p&gt;

&lt;p&gt;Il sâ€™agit donc de migrer la version de Node.js vers une version supÃ©rieure, dans lâ€™idÃ©al LTS afin de se prÃ©munir dâ€™une obsolescence prÃ©maturÃ©e. Dans un premier temps, Node.js 12.&lt;/p&gt;

&lt;p&gt;Voici plusieurs raisons qui poussent Ã  migrer Node.js :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Nouvelles fonctionnalitÃ©s (e.g. nouvelle implÃ©mentation pour lâ€™ES6 Module Support expÃ©rimental, source : &lt;a href=&quot;https://nodejs.medium.com/announcing-a-new-experimental-modules-1be8d2d6c2ff&quot;&gt;https://nodejs.medium.com/announcing-a-new-experimental-modules-1be8d2d6c2ff&lt;/a&gt; ) ;&lt;/li&gt;
  &lt;li&gt;Abandon de fonctionnalitÃ©s dÃ©faillantes (e.g. via dÃ©prÃ©ciation) ;&lt;/li&gt;
  &lt;li&gt;Performance (e.g. mise Ã  jour de V8 engine, source : &lt;a href=&quot;https://nodejs.medium.com/introducing-node-js-12-76c41a1b3f3f&quot;&gt;https://nodejs.medium.com/introducing-node-js-12-76c41a1b3f3f&lt;/a&gt; ) ;&lt;/li&gt;
  &lt;li&gt;SÃ©curitÃ© (e.g. mise Ã  jour de TLS, source : &lt;a href=&quot;https://nodejs.medium.com/introducing-node-js-12-76c41a1b3f3f&quot;&gt;https://nodejs.medium.com/introducing-node-js-12-76c41a1b3f3f&lt;/a&gt; ) ;&lt;/li&gt;
  &lt;li&gt;Ã‰volutions des dÃ©pendances externes. (e.g. Cypress qui abandonne les versions de Node.js non maintenues et qui requiert Node.js 14, 16 ou 18+, source : &lt;a href=&quot;https://docs.cypress.io/guides/references/changelog#12-0-0&quot;&gt;https://docs.cypress.io/guides/references/changelog#12-0-0&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;une-premiÃ¨re-stratÃ©gie-problÃ©matique--la-mÃ©thode-rhinocÃ©ros-&quot;&gt;Une premiÃ¨re stratÃ©gie problÃ©matique : la mÃ©thode â€œrhinocÃ©rosâ€ ğŸ¦&lt;/h1&gt;

&lt;p&gt;La dÃ©cision a Ã©tÃ© prise de migrer le repository de Node.js 10 vers Node.js 12 en dÃ©but dâ€™annÃ©e 2021.&lt;/p&gt;

&lt;p&gt;Empiriquement, cette mÃ©thode a montrÃ© plusieurs limites :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;mÃªme si la compilation semblait bien se dÃ©rouler, des erreurs apparaissaient au moment de lâ€™affichage de lâ€™UI â¡ Il semblait donc nÃ©cessaire de parcourir lâ€™intÃ©gralitÃ© des Ã©crans afin de dÃ©celer toutes les anomalies possibles â¡ Le travail de la QA Ã©tait alors consÃ©quent ;&lt;/li&gt;
  &lt;li&gt;mÃªme lorsquâ€™une anomalie est corrigÃ©e, une nouvelle peut apparaitre â¡ Il fallait re-parcourir les Ã©crans concernÃ©s (par exemple, aprÃ¨s avoir corrigÃ© une anomalie qui empÃªche lâ€™apparition dâ€™une modale, de nouvelles anomalies peuvent Ãªtre dÃ©celÃ©es au niveau des fonctionnalitÃ©s que permet cette modale) â¡ Le travail de la QA augmentait de faÃ§on exponentielle au fil des corrections dâ€™anomalies ;&lt;/li&gt;
  &lt;li&gt;des dizaines voire centaines de dÃ©pendances dans le projet Ã©taient dÃ©pendantes de Node.js 10 sans Ãªtre encore compatibles avec Node.js 12 â¡ Il sâ€™agissait donc de faire le point sur celles-ci, pour trouver des Ã©quivalents compatibles.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;AprÃ¨s plusieurs mois, bien que bon nombre dâ€™anomalies avaient pu Ãªtre corrigÃ©es, la situation stagnait et la fin ne semblait pas plus proche quâ€™au dÃ©but.&lt;/p&gt;

&lt;p&gt;Les raisons de lâ€™Ã©chec :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Lâ€™anciennetÃ© de certaines applications. Certaines dâ€™entre elles avaient plus de 8 ans dâ€™existence. En nâ€™ayant subi que quelques corrections seulement. Les connaissances fonctionnelles et techniques sâ€™Ã©taient donc estompÃ©es naturellement, en raison dâ€™une absence de documentation (autant fonctionnelle que technique). Il sâ€™agit lÃ  des dettes fonctionnelle et technique. Lorsquâ€™elles sont lÃ , elles sont relativement simples Ã  identifier. Mais câ€™est dÃ©jÃ  trop tardâ€¦ ;&lt;/li&gt;
  &lt;li&gt;Lâ€™absence de mise Ã  jour des technologies. Certaines technologies devenues obsolÃ¨tes (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jQuery 1.9&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vue.js 1&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Bootstrap 2.3&lt;/code&gt;) imposait non plus un refactor liÃ© Ã  une migration, mais une vÃ©ritable refonte ;&lt;/li&gt;
  &lt;li&gt;Lâ€™absence de tests. La couverture de tests Ã©tait alors faible voire nulle. Migrer sans rÃ©gression relevait alors dâ€™une chance non maitrisable ;&lt;/li&gt;
  &lt;li&gt;La faÃ§on dont la migration a Ã©tÃ© lancÃ©e Ã©tait trop tÃ©mÃ©raire : câ€™est la mÃ©thode rhinocÃ©ros.
    &lt;ul&gt;
      &lt;li&gt;crÃ©ation dâ€™une nouvelle branche (et dâ€™une PR pour cette branche)&lt;/li&gt;
      &lt;li&gt;suppression de Node.js 10 et installation de Node.js 12&lt;/li&gt;
      &lt;li&gt;correction de toutes les anomalies qui apparaissent !&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ce fonctionnement peut marcher pour des pÃ©rimÃ¨tres techniques plus petits ou du moins dont les contours sont prÃ©cisÃ©ment marquÃ©s ;&lt;/p&gt;

&lt;p&gt;Lâ€™organisation en Ã©quipe devenait compliquÃ©e. Au fur et Ã  mesure des dÃ©couvertes des anomalies au sein dâ€™une seule et unique PR, il devenait difficile de suivre tous les sujets, sans dÃ©coupage prÃ©cis et rigoureux.&lt;/p&gt;

&lt;p&gt;Face Ã  cette situation, dont les dÃ©veloppeurs et testeurs ne semblaient plus voir le bout, il a Ã©tÃ© dÃ©cidÃ© dâ€™employer une autre stratÃ©gie.&lt;/p&gt;

&lt;h1 id=&quot;la-stratÃ©gie-gagnante--une-migration-progressive-&quot;&gt;La stratÃ©gie gagnante : une migration progressive ğŸ“¶&lt;/h1&gt;

&lt;p&gt;De part un essoufflement des dÃ©veloppeurs et une nouvelle Ã©nergie insufflÃ©e par des dÃ©parts et arrivÃ©es dans lâ€™Ã©quipe, une nouvelle stratÃ©gie a Ã©mergÃ©. Face Ã  lâ€™Ã©chec de la premiÃ¨re, il a Ã©tÃ© proposÃ© plus simplement de partir sur des bases saines, afin de migrer les applications sur des fondations plus solides car maitrisÃ©es.&lt;/p&gt;

&lt;p&gt;Plus techniquement, cela sâ€™est traduit par :&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;CrÃ©ation dâ€™un nouveau rÃ©pertoire &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;modern-apps/&lt;/code&gt; dans le monorepo.&lt;/li&gt;
  &lt;li&gt;Mise en place dâ€™une architecture basÃ©e sur Node.js 16 (Oui oui, Node.js 16 directement ! Il sâ€™agissait de la version LTS en cours en date de dÃ©but 2022.) dans ce rÃ©pertoire seulement.&lt;/li&gt;
  &lt;li&gt;Migration des applications du BO, une par une, vers une stack plus moderne. En date de dÃ©but 2023, cette migration est toujours en cours.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;La motivation Ã©tait principalement portÃ©e par :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;une volontÃ© forte dâ€™abandonner des outils et technologies vieillissantes voire obsolÃ¨tes ;&lt;/li&gt;
  &lt;li&gt;une pression engendrÃ©e par lâ€™Ã©volution rapide des technologies :
    &lt;ul&gt;
      &lt;li&gt;Node.js sort une version LTS tous les ans ;&lt;/li&gt;
      &lt;li&gt;Vue.js 3 venait de sortir et lâ€™effort des dÃ©veloppeurs du framework allait se porter plutÃ´t sur cette version que sur la version 2.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;une pression engendrÃ©e par les autres Ã©quipes de la sociÃ©tÃ© qui, elles, Ã©taient Ã  jour (pour certaines), dont celle qui proposait des outils JS et TS dont lâ€™Ã©quipe pourrait avoir lâ€™usage, comme par exemple une librairie de configuration pour &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;eslint&lt;/code&gt; couplÃ© Ã  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vue&lt;/code&gt; ;&lt;/li&gt;
  &lt;li&gt;une excitation liÃ©e Ã  lâ€™utilisation dâ€™une stack rÃ©cente et de &lt;em&gt;cutting-edge tools&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;plan-daction&quot;&gt;Plan dâ€™action&lt;/h2&gt;

&lt;p&gt;Cette page blanche a nÃ©cessitÃ© un plan dâ€™action que voici :&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;CrÃ©ation dâ€™une application simplissime en guise de PoC, afin de montrer la viabilitÃ© dâ€™un travail sous Node.js 16 dans une sous-partie du projet en parallÃ¨le dâ€™un travail toujours actif sous Node.js 10 dans le reste du projet.&lt;/li&gt;
  &lt;li&gt;Mise en place dâ€™une certaines DX vis-Ã -vis des linters et formatters notamment (ainsi que dâ€™extensions dâ€™IDE), par lâ€™application de rÃ¨gles simples mais strictes, qui Ã©vitent aux dÃ©veloppeurs les tÃ¢ches sans plus-value, comme ajuster manuellement lâ€™indentation ou ajouter les points-virgules.&lt;/li&gt;
  &lt;li&gt;Migration des librairies internes au monorepo.&lt;/li&gt;
  &lt;li&gt;Migration du design system, ainsi que des outils affÃ©rents (Storybook).&lt;/li&gt;
  &lt;li&gt;Migration dâ€™une premiÃ¨re application, la plus simple possible. Lâ€™objectif Ã©tait alors de se rendre compte trÃ¨s concrÃ¨tement des Ã©tapes de migration dâ€™une application, afin dâ€™en tirer une documentation exploitable pour les futures applications. Il en est ressorti que la majeure partie du travail consistait Ã  refactor le code avec les nouvelles technologies choisies, en lâ€™occurrence :
    &lt;ol&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vue.js 3&lt;/code&gt; et sa &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Composition API&lt;/code&gt; (framework JS),&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vite&lt;/code&gt; (serveur de dev et de build),&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Pinia&lt;/code&gt; (global state management),&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vitest&lt;/code&gt; (framework de test unitaire),&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Cypress&lt;/code&gt; dans ses derniÃ¨res versions (framework de test end-to-end)&lt;/li&gt;
      &lt;li&gt;aussi et surtout &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Typescript&lt;/code&gt; (langage de programmation, sur-couche Ã  JS).&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Migration du processus de build et dâ€™intÃ©gration aux templates backend (via notamment une extension Twig implÃ©mentÃ©e par nos soins, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ViteAppExtension.php&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;Mise en place dâ€™une CI pour ces nouvelles applications, calquÃ©e sur celle des anciennes applications : linting, tests pour celles qui en avaient, dÃ©ploiement en preview, etc.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;En quelques mois seulement, il a Ã©tÃ© possible dâ€™obtenir un rÃ©sultat concret. Le rÃ©pertoire &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;modern-apps/&lt;/code&gt; a Ã©tÃ© initiÃ© en fÃ©vrier 2022, et dÃ¨s avril de la mÃªme annÃ©e, une premiÃ¨re application migrÃ©e Ã©tait livrÃ©e en production. Et cela, avec un seul dÃ©veloppeur Ã  plein temps sur le sujet.&lt;/p&gt;

&lt;h1 id=&quot;difficultÃ©s-rencontrÃ©es&quot;&gt;DifficultÃ©s rencontrÃ©es&lt;/h1&gt;

&lt;p&gt;Cette seconde stratÃ©gie nâ€™a bien sÃ»r pas Ã©tÃ© sans encombre. Voici les principales difficultÃ©s rencontrÃ©es, dont lâ€™Ã©quipe a su se prÃ©munir au fil du temps.&lt;/p&gt;

&lt;h2 id=&quot;non-dÃ©coupage-des-Ã©tapes-de-migration&quot;&gt;Non dÃ©coupage des Ã©tapes de migration&lt;/h2&gt;

&lt;p&gt;Lors de la migration dâ€™une des premiÃ¨res applications dont la complexitÃ© Ã©tait lÃ©gÃ¨rement supÃ©rieure aux prÃ©cÃ©dentes, nous nous sommes retrouvÃ©s embourbÃ©s dans une multitude de bugs techniques et fonctionnels. En effet, migrer implique plusieurs changements qui nâ€™ont pas nÃ©cessairement de rapport les uns avec les autres :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ajouter des types TS&lt;/li&gt;
  &lt;li&gt;migrer la librairie de Global State Management de &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vuex&lt;/code&gt; vers &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pinia&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;migrer la Global API de Vue (de &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;new Vue()&lt;/code&gt; vers &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;createApp()&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;migrer de lâ€™&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Options API&lt;/code&gt; vers la &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Composition API&lt;/code&gt; de Vue&lt;/li&gt;
  &lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Si tous ces changements sont opÃ©rÃ©s en mÃªme temps, comment rÃ©agir lors de lâ€™apparition dâ€™une anomalie ? Comment traquer efficacement cette anomalie ?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Solution adoptÃ©e&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Nous avons dÃ©cidÃ© de dÃ©couper plus finement nos dÃ©veloppements. Une PR doit concerner un pÃ©rimÃ¨tre rÃ©duit et bien dÃ©fini. Par exemple, la PR de migration de la librairie de Global State Management ne doit comporter que des modifications Ã  ce sujet, et doit fournir une application fonctionnelle dont les tests passent.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;mÃ©connaissance-de-typescript&quot;&gt;MÃ©connaissance de Typescript&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;TypeScript is a strongly typed programming language that builds on JavaScript, giving you better tooling at any scale.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Source : &lt;a href=&quot;https://www.typescriptlang.org/&quot;&gt;https://www.typescriptlang.org/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Ce langage de programmation, bien que son adoption parmi les dÃ©veloppeurs JS explose, sâ€™est avÃ©rÃ© une complÃ¨te nouveautÃ© dans lâ€™Ã©quipe. Il peut Ãªtre tentant dâ€™Ã©crire des &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;any&lt;/code&gt; partout, ou de supprimer le &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;strict mode&lt;/code&gt;â€¦&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Solution adoptÃ©e&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Nous avons dÃ©cidÃ© dâ€™intÃ©grer TS progressivement sans se mettre trop de pression quant Ã  lâ€™intÃ©gralitÃ© du typage de nos applications. Typescript permet justement cette intÃ©gration progressive aux projets.&lt;/p&gt;

  &lt;p&gt;Un trÃ¨s gros progrÃ¨s a aussi Ã©tÃ© rÃ©alisÃ© grÃ¢ce Ã  la gÃ©nÃ©ration automatique des types TS Ã  partir de lâ€™API (grÃ¢ce Ã  lâ€™&lt;em&gt;introspection system&lt;/em&gt; de GraphQL). Les donnÃ©es reÃ§ues du backend se voyaient alors avoir une structure directement exploitable dans le frontend.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;suppression-prÃ©cipitÃ©e-de-librairies-obsolÃ¨tes&quot;&gt;Suppression prÃ©cipitÃ©e de librairies obsolÃ¨tes&lt;/h2&gt;

&lt;p&gt;Lors du dÃ©coupage des Ã©tapes de migration, une problÃ©matique est apparue. Par exemple, si nous souhaitons migrer de &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vuex&lt;/code&gt; vers &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pinia&lt;/code&gt; dans un second temps, comment faire pour que lâ€™application reste fonctionnelle avec &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vuex&lt;/code&gt; dans le premier temps ?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Solution adoptÃ©e&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Nous avons dÃ©cidÃ© de conserver certaines librairies, le temps de la migration des applications. Il peut Ãªtre tentant de vouloir supprimer immÃ©diatement ce qui nous semble obsolÃ¨te, mais ces Ã©lÃ©ments ne seront vraiment obsolÃ¨tes que lorsque toutes les applications seront migrÃ©es ; mais pas le temps quâ€™elles le soient.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;non-anticipation-de-la-complexitÃ©-liÃ©e-Ã -certaines-dÃ©pendances&quot;&gt;Non anticipation de la complexitÃ© liÃ©e Ã  certaines dÃ©pendances&lt;/h2&gt;

&lt;p&gt;Bien que cet aspect nâ€™Ã©tait pas une surprise, certaines librairies ont apportÃ© plus de difficultÃ©s que dâ€™autres lors de la migration. Par exemple, lâ€™intÃ©gration de Vue 3 et la Composition API impliquait la montÃ©e de version de &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vee-validate&lt;/code&gt;, un librairie de validation de formulaire. Il sâ€™est avÃ©rÃ© que lâ€™implÃ©mentation imposÃ©e Ã©tait radicalement diffÃ©rente de la version prÃ©cÃ©dente (compatible avec Vue 2 et lâ€™Options API), moins intuitive et plus complexe.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Solution adoptÃ©e&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Ce cas de figure nâ€™est pas vraiment impressionnant car nous nous y attendions. Nous avons dÃ©cidÃ© dans un premier temps dâ€™effectuer une certaine veille technique, afin de remettre en cause le choix initial de cette librairie. Il sâ€™est avÃ©rÃ© que nous lâ€™avons conservÃ©e, ce qui amenait dans un second temps une montÃ©e en compÃ©tence quant Ã  lâ€™utilisation de celle-ci, en vue de son intÃ©gration.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;entretien-des-applications-legacy-en-mÃªme-temps&quot;&gt;Entretien des applications legacy en mÃªme temps&lt;/h2&gt;

&lt;p&gt;Une application donnÃ©e pouvait se retrouver dâ€™une part en cours de migration, et dâ€™autre part devoir recevoir une Ã©volution ou une correction dâ€™anomalie.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Solution adoptÃ©e&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Le choix et lâ€™ordre des applications Ã  migrer a Ã©tÃ© choisi en fonction des prioritÃ©s en cours. Nous avons choisi de migrer en premier les applications qui ne subissaient que trÃ¨s peu de modifications. Par la suite, et encore aujourdâ€™hui, nous livrons en production rapidement chaque application migrÃ©e, afin de ne pas avoir Ã  maintenir plusieurs versions en mÃªme temps (la version legacy Ã©tant tout de mÃªme conservÃ©e le temps de sâ€™assurer que la version moderne tourne correctement en production auprÃ¨s des clients). Dans les trÃ¨s rares cas oÃ¹ une application en cours de migration devait recevoir une Ã©volution ou une correction dâ€™anomalie, nous la traitions dans les 2 versions.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;autres-avantages&quot;&gt;Autres avantages&lt;/h1&gt;

&lt;h2 id=&quot;uniformisation-des-technologies-au-sein-de-la-sociÃ©tÃ©&quot;&gt;Uniformisation des technologies au sein de la sociÃ©tÃ©&lt;/h2&gt;

&lt;p&gt;Au sein de Bedrock, le back-office nâ€™est pas la seule application. Il existe aussi des applications frontend sur les mÃªmes technologies pour adresser lâ€™Ã©cran web ou les tÃ©lÃ©visions connectÃ©es. Bien que le framework utilisÃ© pour celles-ci soit React.js et non Vue.js, lâ€™outillage peut Ãªtre uniformisÃ© entre les projets et les Ã©quipes. La migration a permis de prÃ©parer le terrain pour mettre en place ces outils : TypeScript, PNPM, etc.&lt;/p&gt;

&lt;h2 id=&quot;attractivitÃ©-et-rÃ©tention-des-dÃ©veloppeurs&quot;&gt;AttractivitÃ© et rÃ©tention des dÃ©veloppeurs&lt;/h2&gt;

&lt;p&gt;Cette migration gÃ©nÃ©rale permet de mettre en place une stack rÃ©solument plus moderne et dâ€™utiliser des outils et technologies plus rÃ©cents. Nâ€™est-ce pas lÃ  un argument fort pour attirer des nouveaux dÃ©veloppeurs et retenir ceux dÃ©jÃ  en place ? Dans lâ€™Ã©quipe, plusieurs personnes ont Ã©mis des doutes sur leur volontÃ© de rester dans la sociÃ©tÃ© si la dÃ©cision de migrer, et donc dâ€™intÃ©grer des technologies plus Ã  jour, nâ€™avait pas Ã©tÃ© prise. En date de dÃ©but 2023, il fait peu de doutes que les projets en Vue 3 sont plus attractifs que les projets en Vue 2â€¦&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;En fin de compte, cette approche progressive et incrÃ©mentale, toujours en cours, permet de maintenir dans un rÃ©pertoire bien dÃ©fini une stack rÃ©cente dont les mises Ã  jour sont simples car petites. Par exemple, nous avons rÃ©cemment migrÃ© de Node.js 16 vers Node.js 18â€¦ en quelques jours !&lt;/p&gt;

&lt;p&gt;Cette grande aventure, toujours en cours, nous a permis de vraiment prendre conscience quâ€™il faut entretenir certes les applications mais aussi les versions des frameworks et outils ! Utiliser un nouvel outil ou une nouvelle technologie est un choix fort quâ€™il faut Ãªtre capable dâ€™assumer dans le temps.&lt;/p&gt;

&lt;p&gt;Il peut paraitre frustrant dâ€™entretenir des outils, sans gagner en performance ni en productivitÃ© mais seulement pour ne pas devenir obsolÃ¨te. Mettre lâ€™accent sur ces points, tout en sachant bien jauger jusquâ€™oÃ¹ doivent aller ces upgrades, est la marque dâ€™un certain professionnalisme.&lt;/p&gt;

&lt;p&gt;Il est vrai que dans lâ€™immÃ©diat, la valeur ajoutÃ©e pour le client est modÃ©rÃ©e : les gains restent trÃ¨s techniques, notamment en termes de stabilitÃ© et de performances. Ce nâ€™est que plus tard que les gains se feront concrÃ¨tement sentir : plus dâ€™efficacitÃ© et de productivitÃ© pour les Ã©volutions, et plus de fiabilitÃ©.&lt;/p&gt;

&lt;p&gt;Il est aussi important de savoir reconnaitre quâ€™une technologie utilisÃ©e (parfois avec fiertÃ© Ã  ses dÃ©buts) est devenue obsolÃ¨te, et quâ€™il faut sâ€™en dÃ©barrasser pendant quâ€™il est encore temps.&lt;/p&gt;</content><author><name>TimothÃ© Crespy</name></author><category term="node" /><category term="Node.js" /><category term="vue" /><category term="Vue.js" /><category term="vuex" /><category term="pinia" /><category term="vite" /><category term="Vite.js" /><category term="Vitest" /><category term="TypeScript" /><category term="developer retention" /><category term="migration" /><summary type="html">Difficile de faire Ã©voluer des applications et amÃ©liorer une stack si lâ€™ensemble est basÃ© sur une version obsolÃ¨te de Node.jsâ€¦ Dans cet article, nous verrons comment nous avons rÃ©ussi Ã  migrer vers une version rÃ©cente et maintenue de Node.js grÃ¢ce Ã  une approche progressive et incrÃ©mentale.</summary></entry><entry><title type="html">La gamification contre le legacy</title><link href="https://tech.bedrockstreaming.com/2023/03/20/La-gamification-contre-le-legacy.html" rel="alternate" type="text/html" title="La gamification contre le legacy" /><published>2023-03-20T00:00:00+00:00</published><updated>2023-03-20T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/03/20/La-gamification-contre-le-legacy</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/03/20/La-gamification-contre-le-legacy.html">&lt;h2 id=&quot;ce-que-vous-ne-voulez-pas-voir-dans-vos-backlogs&quot;&gt;Ce que vous ne voulez pas voir dans vos backlogsâ€¦&lt;/h2&gt;

&lt;p&gt;Elles sont lÃ , tapies dans lâ€™ombre de la colonne â€œTo doâ€ de vos backlogs, attendant que leur heure vienne. Ã€ chaque &lt;a href=&quot;https://blog.myagilepartner.fr/index.php/2017/01/17/la-product-backlog-refinement/&quot;&gt;backlog refinement&lt;/a&gt;, vous vous demandez sâ€™il ne faut pas tout simplement les annuler, puisque personne ne les prend en chargeâ€¦ De quoi parle-t-on ? De ces user stories qui existent dans le backlog de chaque Ã©quipe technique, pour traiter â€œun jourâ€ un sujet legacy. Ces petits aides-mÃ©moire de sujets â€œÃ  ne pas oublierâ€ qui nous poursuivent mais ne sont que peu souvent traitÃ©s, faute de priorisation.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;Un exemple de backlog legacy&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/Article-Target.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;Un exemple de backlog legacy&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Clean de code mort, montÃ©es de versions de layers Terraform, projets de refactoring jamais dÃ©butÃ©sâ€¦ autant de sujets pÃ©nibles Ã  traiter qui nÃ©cessitent du tempsâ€¦ et de la rÃ©silience. Parce que bien souvent, dÃ©buter lâ€™un de ces sujets revient Ã  sâ€™attaquer Ã  toutes les dÃ©pendances liÃ©es, Ã  gÃ©rer tous les impacts. Et parce quâ€™il sâ€™agit aussi de tÃ¢ches redondantes, non-automatisables, nâ€™apportant quasiment aucune valeur business immÃ©diatement mesurable.. Du â€œrunâ€, pur et simple. Dans le Slack de Bedrock, il y a un emoji tout trouvÃ© pour ce type de tÃ¢che : &lt;img alt=&quot;Gif exprimant la souffrance&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/souffrir.gif&quot; height=&quot;30&quot; width=&quot;30&quot; style=&quot;padding: 0&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Bien sÃ»r, on parvient parfois Ã  dÃ©gager du temps pour sâ€™atteler Ã  ces user stories. Mais il faut souvent plus dâ€™un sprint pour en venir Ã  bout, et lâ€™Ã©quipe en charge de leur rÃ©alisation peut rapidement se dÃ©courager devant lâ€™ampleur et le caractÃ¨re rÃ©pÃ©titif de la tÃ¢che.&lt;/p&gt;

&lt;p&gt;Nos Ã©quipes Ops et DevOps sont responsables de 23 repositories Terraform. Lorsquâ€™il a Ã©tÃ© nÃ©cessaire dâ€™upgrader tous nos layers en version 1.x, nous nous sommes dâ€™abord donnÃ© pour consigne que chaque personne qui tombait sur un layer obsolÃ¨te devait le mettre Ã  jour avant de poursuivre son travail. Oui mais voilÃ , mettre Ã  jour un layer Ã§a ne se fait pas en deux minutes, et bien souvent on refuse dâ€™abandonner ce sur quoi on travaillait jusquâ€™alors pour mettre Ã  jour sa version de Terraform. La consigne a alors Ã©voluÃ© : pour chaque layer Ã  mettre Ã  jour, on crÃ©Ã© une US en colonne â€œto doâ€â€¦ Vous voyez oÃ¹ lâ€™on veut en venir ? ğŸ˜&lt;/p&gt;

&lt;p&gt;Pour tenter de venir Ã  bout de ces sujets legacy que lâ€™on traÃ®ne comme des boulets, nous avons mis en place depuis octobre 2022 les â€œJeudis du funâ€, dont lâ€™organisation est prise en charge par la facilitatrice agile et la Project Manager Officer (PMO) du service Infrastructure (autrices de cet article).&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;Logo de la 1Ã¨re Ã©dition du â€œjeudi du funâ€&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/Article-logo.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;Logo de la 1Ã¨re Ã©dition du â€œjeudi du funâ€&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;Ã©radiquer-en-gamifiant-challengeant-sentraidant&quot;&gt;Ã‰radiquer en gamifiant, challengeant, sâ€™entraidant.&lt;/h2&gt;

&lt;p&gt;Lâ€™idÃ©e est simple : faire travailler ensemble, sur une journÃ©e, les cinq Ã©quipes de la verticale (trois Ã©quipes de SysAdmins et deux Ã©quipes DevOps) pour faire avancer un sujet legacy. Au cours de cette journÃ©e, les profils et les membres dâ€™Ã©quipe seront mixÃ©s, afin de ne pas travailler avec les mÃªmes collÃ¨gues quâ€™au quotidien. Leads, principal engineer, seniors et juniors : tout le monde participe Ã  la corvÃ©e !&lt;/p&gt;

&lt;p&gt;Il est difficile de convoquer 25 personnes sur une journÃ©e en leur disant que la journÃ©e est banalisÃ©e pour traiter des tÃ¢ches pÃ©nibles. Elles viendraient Ã  reculons. Deux axes ont Ã©tÃ© choisis pour faire de ces journÃ©es des journÃ©es â€œparticuliÃ¨resâ€ :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Gamifier&lt;/strong&gt; certains moments clÃ©s de la journÃ©e : la dÃ©couverte du sujet, la composition des Ã©quipes, la remise en jambe du dÃ©but dâ€™aprÃ¨s-midiâ€¦&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Challenger&lt;/strong&gt; les participants pour ne pas simplement leur demander de traiter du legacy, mais bien dâ€™Ãªtre la &lt;em&gt;meilleure&lt;/em&gt; Ã©quipe pour traiter du legacy. Celle qui ira le plus loin, qui en fera le plus.&lt;/li&gt;
  &lt;li&gt;(Un troisiÃ¨me axe, plus convivial, est choisi pour la fin de journÃ©e : partager un verre tous ensemble.)&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img alt=&quot;Le jeu de dÃ©couverte du sujet de la 3Ã¨me Ã©dition : Ansible&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/Article-jeu.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;Le jeu de dÃ©couverte du sujet de la 3Ã¨me Ã©dition : Ansible&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Lors de la 1Ã¨re Ã©dition, en octobre 2022, nous avons proposÃ© aux Ã©quipes un grand thÃ¨me : le repository â€œSysAdmin/Terraformâ€, centre nÃ©vralgique du travail de lâ€™Infra. Il y a beaucoup Ã  faire : les fameux upgrades de layers, du refactoring de code pour industrialiser nos process, des PRs ouvertes et restÃ©es en suspens depuis de nombreux moisâ€¦ chacun peut y trouver son compte. Chacune des six Ã©quipes composÃ©es ce jour-lÃ  disposait de dix minutes pour dÃ©finir Ã  quel chantier elle sâ€™attaquerait durant la journÃ©e. A lâ€™issue de ces dix minutes, le reprÃ©sentant de lâ€™Ã©quipe devait prÃ©senter aux autres le sujet choisi et lâ€™indicateur qui permettrait de juger si le travail a Ã©tÃ© accompli ou non, en fin de journÃ©e. Lâ€™Ã©quipe ayant proposÃ© le sujet le plus ambitieux sâ€™est vue attribuer des points bonus, rentrant en compte pour le calcul du score final.&lt;/p&gt;

&lt;p&gt;Pour la seconde Ã©dition le mois suivant, le sujet Ã©tait imposÃ© : toutes les Ã©quipes avaient pour objectif de mieux sÃ©curiser les secrets contenus dans le code Bedrock. Lâ€™Ã©quipe qui en traiterait le plus grand nombre lâ€™emporterait.&lt;/p&gt;

&lt;p&gt;Lors de la derniÃ¨re Ã©dition, en fÃ©vrier dernier, la compÃ©tition reposait Ã©galement sur le nombre de points gagnÃ©s par chaque Ã©quipe en fin de journÃ©e. Nous avons attribuÃ© un nombre de points Ã  chaque tÃ¢che pouvant Ãªtre traitÃ©e dans la journÃ©e, en fonction de sa complexitÃ© et/ou de sa prioritÃ©. Chaque Ã©quipe pouvait sâ€™organiser librement : choisir plusieurs petites tÃ¢ches ou deux plus importantesâ€¦&lt;/p&gt;

&lt;p&gt;Bien sÃ»r, pour que la compÃ©tition soit totale, chaque Ã©dition du jeudi du fun se termine par une remise de prix : distribution de goodies, de cartes â€œbonusâ€ ou â€œmalusâ€ valables dans nos â€œvraisâ€ sprints, de gourmandisesâ€¦ il faut que la rÃ©compense soit rÃ©elle pour que les participants se prennent au jeu.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;Exemple de lot pouvant Ãªtre remportÃ© lors du â€œJeudi du funâ€&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/Article-carte.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;Exemple de lot pouvant Ãªtre remportÃ© lors du â€œJeudi du funâ€&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Le risque avec la compÃ©tition, câ€™est de se laisser dÃ©border : gagner coÃ»te que coÃ»te, ajouter des points Ã  son compteur en faisant du â€œquick &amp;amp; dirtyâ€. Jusquâ€™Ã  prÃ©sent, la compÃ©tition dans la verticale Infra est restÃ©e bon enfant : les Ã©quipes se dÃ©fient entre elles tout au long de la journÃ©e, des points â€œbonusâ€ sont rÃ©clamÃ©s aux organisatrices au moindre prÃ©texteâ€¦ mais personne ne perd de vue lâ€™objectif principal : venir Ã  bout du sujet.&lt;/p&gt;

&lt;p&gt;Les Jeudis du Fun reposent donc sur le challenge et le jeu. Mais nous avions sous-estimÃ© un autre axe nous permettant de faire de ces journÃ©es un succÃ¨s : lâ€™entraide. A chaque Ã©dition, les retours les plus enthousiastes portent sur le fait de passer une journÃ©e Ã  travailler en cross-team. SysAdmins et DevOps apprennent les uns des autres, les juniors ont lâ€™occasion de former des leadsâ€¦ et chacun Ã©largit son spectre de compÃ©tences. Au-delÃ  du fait de venir Ã  bout de sujets legacy, lâ€™Ã©mulation engendrÃ©e par ces journÃ©es justifie Ã  elle-seule leur organisation.&lt;/p&gt;

&lt;p&gt;Et puis, quitte Ã  faire des jeudis du fun des journÃ©es particuliÃ¨res, autant y aller franchement : certains membres de nos Ã©quipes nâ€™hÃ©sitent pas Ã  venir dÃ©guisÃ©s pour ajouter une dose de fun. Vous avez croisÃ© une licorne, Pikachu ou un plombier dans lâ€™open space de Bedrock ? Aucun doute, câ€™Ã©tait un jeudi ! Un dress code a mÃªme Ã©tÃ© dÃ©fini lors de lâ€™Ã©dition de fÃ©vrier 2023.&lt;/p&gt;

&lt;h2 id=&quot;itÃ©rer-et-corriger-nos-erreurs-Ã -chaque-Ã©dition&quot;&gt;ItÃ©rer, et corriger nos erreurs Ã  chaque Ã©dition&lt;/h2&gt;

&lt;p&gt;Trois Ã©ditions du â€œjeudi du funâ€ ont Ã©tÃ© organisÃ©es jusquâ€™Ã  prÃ©sent. Ã€ la fin de chaque Ã©dition, les organisatrices recueillent le feed-back des participantes et participants, afin de corriger ce qui doit lâ€™Ãªtre et de capitaliser sur ce qui a marchÃ©. Voici le premier bilan que nous pouvons en tirer.&lt;/p&gt;

&lt;h3 id=&quot;de-limportance-du-choix-du-sujet&quot;&gt;&lt;em&gt;De lâ€™importance du choix du sujet&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Le succÃ¨s de la journÃ©e repose sur le choix du sujet. En choisissant un sujet fÃ©dÃ©rateur, comme lors de notre premiÃ¨re Ã©dition, et en laissant le soin Ã  chaque Ã©quipe de dÃ©finir quel chantier elle souhaitait mener, nous partions gagnantes. Le repo Sysadmin/Terraform sur lequel nous avons travaillÃ© lors de cette journÃ©e est un point de douleur pour lâ€™ensemble de nos Ã©quipes : chacun des participants a compris lâ€™intÃ©rÃªt de jouer le jeu et de retrousser ses manches. Les Ã©quipes ont mÃªme eu du mal Ã  clÃ´turer la journÃ©e, car elles voulaient finir ce quâ€™elles avaient commencÃ©.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;Au cours de la 1Ã¨re journÃ©e du â€œJeudi du funâ€&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/Article-slack.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;Au cours de la 1Ã¨re journÃ©e du â€œJeudi du funâ€&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Lors de la seconde Ã©dition en revanche, le sujet de cette Ã©dition a mis la journÃ©e en pÃ©ril. Nous avions demandÃ© aux Ã©quipes dâ€™ajouter un niveau de sÃ©curitÃ© Ã  lâ€™ensemble des secrets contenus dans la codebase de Bedrock. Cela a suscitÃ© quelques difficultÃ©s :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Tout dâ€™abord, il sâ€™agissait de trouver une mÃ©thode pour identifier tous les secrets concernÃ©s. Toutes les Ã©quipes du jeudi du fun ont alors planchÃ© sur ce sujet, en utilisant des mÃ©thodes et outils diffÃ©rents. Au final, nous ne sommes parvenus que tardivement (2h aprÃ¨s le lancement de la journÃ©e) Ã  nous mettre dâ€™accord sur une mÃ©thodologie. Autant de temps perdu que nous aurions pu consacrer au cÅ“ur du sujet, la sÃ©curisation des secrets.&lt;/li&gt;
  &lt;li&gt;En nous attaquant Ã  lâ€™ensemble des secrets de Bedrock, nous touchions forcÃ©ment Ã  des repositories projets dont nous ne sommes pas les &lt;em&gt;code owners.&lt;/em&gt; Ce nâ€™est pas une vÃ©ritable difficultÃ© en soi, puisquâ€™au quotidien, nous intervenons frÃ©quemment dans ces repos projets pour accompagner les Ã©quipes devs. En revanche, lâ€™ajout dâ€™un niveau de sÃ©curitÃ© supplÃ©mentaire sur des secrets implique de pouvoir tester, puis de merger nos modifications. Impossible de rÃ©aliser ces actions sans les Ã©quipes back et front responsables des projets, ou sans impacter leur travail. Notre pÃ©rimÃ¨tre dâ€™intervention lors de cette journÃ©e Ã  Ã©tÃ© considÃ©rablement limitÃ©.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;La complexitÃ© du sujet et le constat de notre incapacitÃ© Ã  avancer lors de cette journÃ©e ont rapidement conduit Ã  un dÃ©couragement des troupes. Nous sommes tout de mÃªme ressortis de cette Ã©dition avec des points positifs :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Une meilleure visibilitÃ© sur le pÃ©rimÃ¨tre de sÃ©curisation Ã  couvrir, en dÃ©finissant le nombre de secrets concernÃ©s,&lt;/li&gt;
  &lt;li&gt;Un workflow visant Ã  dÃ©tecter Ã  lâ€™avenir tout nouveau secret concernÃ©&lt;/li&gt;
  &lt;li&gt;â€¦ et la nÃ©cessitÃ© de mieux dÃ©finir les guidelines pour le choix du sujet !&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;entendu-pendant-la-2nde-Ã©dition-du-jeudi-du-fun-&quot;&gt;Entendu pendant la 2nde Ã©dition du jeudi du fun ğŸ˜…&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;ğŸ‘§ğŸ» : â€œAlors, quâ€™est-ce que tu fais de beau ?â€&lt;/p&gt;

  &lt;p&gt;ğŸ‘¦ : â€œJe souffreâ€&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ces guidelines nous ont aidÃ© Ã  dÃ©finir le choix de la thÃ©matique de la 3Ã¨me Ã©dition du jeudi du fun. Le sujet devait rÃ©pondre Ã  ces critÃ¨res :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ÃŠtre rÃ©alisable en une journÃ©e,&lt;/li&gt;
  &lt;li&gt;Permettre de terminer / accÃ©lÃ©rer un projet ou dâ€™Ã©radiquer du legacy,&lt;/li&gt;
  &lt;li&gt;ÃŠtre dans le pÃ©rimÃ¨tre dont lâ€™infra est le code owner,&lt;/li&gt;
  &lt;li&gt;Et Ãªtre â€œmorcelableâ€ en sous-pÃ©rimÃ¨tres, un pour chaque Ã©quipe.&lt;/li&gt;
  &lt;li&gt;Enfin, lâ€™avancÃ©e du sujet doit Ãªtre mesurable.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Pour lâ€™Ã©dition de fÃ©vrier 2023, nous avons donc â€œjouÃ©â€ avec la migration Ansible en cours de rÃ©alisation dans lâ€™une de nos Ã©quipes de SysAdmins. 45 rÃ´les Ansible restaient Ã  migrer vers notre nouveau template Ansible, utilisÃ© pour dÃ©ployer nos machines on-prem : il y a du travail pour tout le monde, câ€™est parti !&lt;/p&gt;

&lt;h3 id=&quot;et-finalement-est-ce-que-Ã§a-marche-&quot;&gt;Et finalement, est-ce que Ã§a marche ?&lt;/h3&gt;

&lt;p&gt;AprÃ¨s trois Ã©ditions, il nous semble nÃ©cessaire de prendre un peu de recul pour analyser si ces journÃ©es portent leur fruit. Les Ã©quipes sont ravies de travailler ensemble, certes, mais lâ€™objectif principal est-il rempli ? Les jeudis du fun permettent-ils de venir Ã  bout de sujets legacy ?&lt;/p&gt;

&lt;p&gt;La premiÃ¨re Ã©dition a fortement contribuÃ© Ã  Ã©radiquer du legacy : nous avons mis Ã  jour la quasi-totalitÃ© des layers Terraform, nous avons mergÃ© ou fermÃ© lâ€™entiÃ¨retÃ© des PRs, et nous avons initiÃ© des travaux de rework. Cependant, nous nâ€™avions pas dÃ©fini dâ€™indicateurs de rÃ©ussite assez fiables lors de cette premiÃ¨re itÃ©ration pour quantifier rÃ©ellement le travail accompli. Si toute la Verticale partage le sentiment dâ€™avoir avancÃ© lors de cette journÃ©e, nous ne savons pas le mesurer finement.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;Capture dâ€™Ã©cran du repo sysadmin/terraform au cours de la 1Ã¨re Ã©dition du â€œJeudi du funâ€&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/Article-git.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;Capture dâ€™Ã©cran du repo sysadmin/terraform au cours de la 1Ã¨re Ã©dition du â€œJeudi du funâ€&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Pour pallier cette difficultÃ©, nous avions dÃ©fini un indicateur de suivi trÃ¨s simple pour la seconde Ã©dition du jeudi du fun : nombre de secrets Ã  traiter / nombre de secrets traitÃ©s. Ainsi, nous savons que, lors de cette (difficile) journÃ©e, nous avons traitÃ© environ un quart du pÃ©rimÃ¨tre.&lt;/p&gt;

&lt;p&gt;Au lancement de la 3Ã¨me Ã©dition du jeudi du fun, nous avions 45 rÃ´les Ã  migrer vers notre nouveau template Ansible. Ã€ lâ€™issue de cette journÃ©e, lâ€™Ã©quipe responsable du sujet nâ€™en avait plus que 10 Ã  traiter. La mutualisation de nos forces a portÃ© ses fruits !&lt;/p&gt;

&lt;p&gt;Insuffisants lors de la premiÃ¨re Ã©dition, les indicateurs de suivi mis en place dans les Ã©ditions suivantes sont cruciaux pour Ã©valuer le ROI de ces journÃ©es de travail â€œparticuliÃ¨resâ€.&lt;/p&gt;

&lt;h2 id=&quot;les-coulisses-du-jeudi-du-fun&quot;&gt;Les coulisses du jeudi du fun&lt;/h2&gt;

&lt;p&gt;Les jeudis du fun sont organisÃ©s par deux personnes au sein de la verticale infra. Si les sÃ©ances de prÃ©paration de cette journÃ©e (qui dÃ©butent environ 3 semaines avant la tenue de lâ€™Ã©vÃ©nement) sont source de beaucoup de rires, il nâ€™empÃªche quâ€™elles doivent Ã©galement rÃ©pondre Ã  certaines problÃ©matiques.&lt;/p&gt;

&lt;h3 id=&quot;sadapter-aux-habitudes-de-travail-de-chacun&quot;&gt;&lt;em&gt;Sâ€™adapter aux habitudes de travail de chacun&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;En premier lieu, nous devons organiser une journÃ©e Ã  laquelle tous les membres de nos Ã©quipes puissent prendre part, quâ€™ils soient au bureau ou en tÃ©lÃ©travail. Tous les moments de la journÃ©e doivent tenir compte de cet Ã©lÃ©ment, quâ€™il sâ€™agisse des phases de travail en petits groupes, des sessions en plÃ©niÃ¨re (25 personnes) comme le lancement de la journÃ©e, la remise des prix ou les diffÃ©rents jeux qui ponctuent ces jeudis.&lt;/p&gt;

&lt;p&gt;Les phases de travail en Ã©quipe sont les plus simples Ã  gÃ©rer : nos Ã©quipes ont dÃ©jÃ  lâ€™habitude au quotidien de travailler avec des collÃ¨gues Ã  distance. Tout le monde se connecte sur une room de visioconfÃ©rence, et le tour est jouÃ©.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;Team mixte prÃ©sentiel / distanciel lors du 1er â€œjeudi du funâ€&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/Article-team-hybride.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;Team mixte prÃ©sentiel / distanciel lors du 1er â€œjeudi du funâ€&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Les moments en plÃ©niÃ¨re sont en revanche plus dÃ©licats Ã  gÃ©rer, car le brouhaha dâ€™une vingtaine de personnes rassemblÃ©es dans une mÃªme piÃ¨ce reste difficilement audible pour les personnes Ã  distance. Un prochain challenge pourrait Ãªtre dâ€™organiser un jeudi du fun 100% distanciel.&lt;/p&gt;

&lt;p&gt;Il est Ã©galement nÃ©cessaire de tenir compte de la faÃ§on de travailler de chacun : si certaines personnes sont capables de travailler en faisant fi du bruit dâ€™un open space, dâ€™autres ont besoin de plus de calme. Ã€ chaque Ã©dition, nous tentons dâ€™organiser le jeudi du fun sous diffÃ©rentes formes, pour tenir compte des besoins de chacun, mais nous nâ€™avons pas encore trouvÃ© la solution idÃ©ale.&lt;/p&gt;

&lt;p&gt;Lors de la premiÃ¨re Ã©dition, nous Ã©tions tous rassemblÃ©s dans le mÃªme open space, sans dispositif particulier pour les personnes ayant besoin dâ€™un environnement silencieux, et cette journÃ©e leur a Ã©tÃ© difficile Ã  supporter. De nombreuses autres Ã©quipes de Bedrock avec qui nous partageons dâ€™habitude cet open space Ã©taient en dÃ©placement ce jour-lÃ , ce qui a nÃ©anmoins permis de limiter nos nuisances sonores Ã  notre seule verticale.&lt;/p&gt;

&lt;p&gt;Pour la seconde Ã©dition, nous avions rÃ©servÃ© un open space dans les locaux de Bedrock pour ne pas prendre le risque de dÃ©ranger les autres Ã©quipes : lâ€™ambiance y a Ã©tÃ© dâ€™autant plus conviviale mais nâ€™a apportÃ© aucun mieux aux personnes ayant besoin de tranquillitÃ© pour travailler.&lt;/p&gt;

&lt;p&gt;Lors de notre derniÃ¨re Ã©dition, nous avons tentÃ© une approche hybride : la plupart des Ã©quipes Ã©taient rassemblÃ©es dans un mÃªme open space, et pour les personnes ayant besoin de sâ€™isoler, une salle de rÃ©union avait Ã©tÃ© rÃ©servÃ©e pour lâ€™occasion. Il semble que cette organisation a apportÃ© un mieux pour les personnes souffrant du bruit avec un Ã©cueil cependant : elles Ã©taient isolÃ©es des autres Ã©quipes tout au long de la journÃ©e, et le jeudi du fun repose (aussi) sur lâ€™Ã©mulation collectiveâ€¦&lt;/p&gt;

&lt;h3 id=&quot;les-autres-limites-de-lorganisation&quot;&gt;&lt;em&gt;Les autres limites de lâ€™organisation&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Au fil des Ã©ditions, nous avons rencontrÃ©, en tant quâ€™organisatrices, deux autres limites.&lt;/p&gt;

&lt;p&gt;La premiÃ¨re touche au choix du sujet. Si la dÃ©finition de la thÃ©matique de la premiÃ¨re journÃ©e a Ã©tÃ© Ã©vidente car le repository sysadmin/terraform est source de complaintes quotidiennes, trÃ¨s vite, nous avons eu besoin dâ€™aide pour dÃ©finir les sujets des Ã©ditions suivantes.  &lt;br /&gt;
En effet, il est difficile pour nous dâ€™apprÃ©hender un sujet dans sa globalitÃ© : y aura-tâ€™il du travail pour chaque Ã©quipe ? Le sujet est-il accessible pour tous nos profils, sans montÃ©e en compÃ©tence prÃ©alable ? Quelles sont concrÃ¨tement les actions Ã  conduire pour venir Ã  bout dâ€™un sujet ? Pour pallier Ã  ce problÃ¨me, nous avons rÃ©alisÃ© un tour de passe-passe : lâ€™Ã©quipe qui remporte le jeudi du fun gagne le droit de dÃ©finir avec nous le sujet de lâ€™Ã©dition suivante. Et Ã§a fonctionne ! Les gagnants participent avec plaisir au choix du prochain sujet &lt;del&gt;de torture&lt;/del&gt; de fun !&lt;/p&gt;

&lt;p&gt;La seconde limite concerne la rÃ©currence de lâ€™Ã©vÃ©nement. Initialement, nous avions prÃ©vu dâ€™organiser un jeudi du fun par mois, pour venir Ã  bout rapidement de nos sujets legacy. AprÃ¨s les deux premiÃ¨res Ã©ditions (organisÃ©es en octobre et novembre 2022), nous nous sommes aperÃ§ues que nous perdrions le fun de cette journÃ©e si elle revenait trop frÃ©quemment. Pour que cet Ã©vÃ©nement reste une journÃ©e de travail particuliÃ¨re Ã  laquelle les personnes participent avec plaisir, nous avons fait le choix dâ€™opter pour un format trimestriel.&lt;/p&gt;

&lt;h2 id=&quot;next-steps-et-prochains-dÃ©fis&quot;&gt;Next steps et prochains dÃ©fis&lt;/h2&gt;

&lt;p&gt;Dâ€™autres amÃ©liorations restent Ã  apporter, notamment autour de la gestion du reste Ã  faire. Comment finir correctement les travaux initiÃ©s dans cette journÃ©e, afin de ne pas crÃ©er de nouvelles user stories legacy ? Ce point est tout aussi important que celui sur le travail accompli au cours de ces journÃ©es. Entamer un rework et le laisser en chantier gÃ©nÃ¨re au moins autant de frustration que le manque de temps pour traiter du legacy.&lt;/p&gt;

&lt;p&gt;NÃ©anmoins, aprÃ¨s trois Ã©ditions du jeudi du fun, il nous semblait important de partager notre expÃ©rience, ne serait-ce que pour convaincre des Ã©quipes de devs de Bedrock de venir jouer avec nous lors dâ€™une prochaine Ã©dition !&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;Les participants du Jeudi du fun&quot; src=&quot;/images/posts/2023-03-16-la-gamification-contre-le-legacy/Article-team.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;Les participants du Jeudi du fun&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Pour vous donner un aperÃ§u de comment se dÃ©roulent ces fameux jeudis, voici &lt;em&gt;grosso modo&lt;/em&gt; le programme dâ€™une journÃ©e :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;â° 9h00 Petit dÃ©jeuner convivial (car câ€™est trÃ¨s important de commencer une telle journÃ©e en prenant des forces)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;â° 9h30 &lt;strong&gt;DÃ©but officiel de la journÃ©e&lt;/strong&gt; : on se retrouve en plÃ©niÃ¨re, dans une grande salle de rÃ©union, avec tous les participants et on (rÃ©)explique le contexte de la journÃ©e ainsi que le programme. 
On commence avec un petit jeu (5 minutes maximum) qui sert Ã  deviner le sujet du jour. Les sujets sont toujours gardÃ©s secrets jusquâ€™au lancement de la journÃ©e, ce qui donne lieu Ã  toutes sortes dâ€™hypothÃ¨ses les jours qui prÃ©cÃ¨dent (â€œOui, oui, bien sÃ»r on va recoder toute notre plateforme dans un autre langage jeudiâ€).On fait monter la pression !  &lt;br /&gt;
Lâ€™objectif de ce premier jeu est dâ€™Ã©nergiser un maximum nos collÃ¨gues et de leur permettre de commencer Ã  se projeter sur ce quâ€™ils vont pouvoir y faire. Le jeu change Ã  chaque fois, pour garder un effet de surprise. 
Ensuite, vient le temps de rÃ©vÃ©ler la constitution des Ã©quipes qui changent elles aussi Ã  chaque Ã©dition afin de permettre Ã  chaque personne de cÃ´toyer de nouveaux collÃ¨gues.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;â° 10h00 Les Ã©quipes partent travailler sur le sujet du jour, Ã  leurs postes de travail&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;â° 12h30 - 13h30 DÃ©jeuner&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;â° 13h30 Jeu de reprise (facultatif) : on se retrouve autour dâ€™un blind test ou un gartic phone, histoire de passer un bon moment et de se remettre en jambe pour lâ€™aprÃ¨s-midi. Câ€™est un court moment de &lt;em&gt;team building&lt;/em&gt; qui est trÃ¨s apprÃ©ciÃ© la plupart du temps (sauf lorsque les Ã©quipes ne veulent pas perdre un minute pour venir Ã  bout de leur objectif !)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;â° 14h00 Les Ã©quipes reprennent le travail initiÃ© le matin et essayent de finir un maximum de choses&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;â° 17h30 On se retrouve en plÃ©niÃ¨re pour le dÃ©brief de la journÃ©e : on fait le point sur le travail accompli, le dÃ©compte des points gagnÃ©s par chaque Ã©quipe et on fait le fameux podium ainsi que la remise des prix. 
On rÃ©cupÃ¨re Ã  chaud les premiers retours des participants.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;â° 18h00 Le verre de lâ€™amitiÃ©&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>[&quot;e_perrin&quot;, &quot;a_ferez&quot;]</name></author><category term="infra" /><category term="legacy" /><category term="retour d&apos;expÃ©rience" /><summary type="html">Elles sont lÃ , tapies dans lâ€™ombre de la colonne â€œTo doâ€ de vos backlogs, attendant que leur heure vienne. Ã€ chaque backlog refinement, vous vous demandez sâ€™il ne faut pas tout simplement les annuler, puisque personne ne les prend en chargeâ€¦ De quoi parle-t-on ? De ces user stories qui existent dans le backlogâ€¦</summary></entry><entry><title type="html">Bedrock Dev Facts #19</title><link href="https://tech.bedrockstreaming.com/2023/03/13/bedrock-dev-facts-19.html" rel="alternate" type="text/html" title="Bedrock Dev Facts #19" /><published>2023-03-13T00:00:00+00:00</published><updated>2023-03-13T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/03/13/bedrock-dev-facts-19</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/03/13/bedrock-dev-facts-19.html">&lt;p&gt;La fin de lâ€™hiver approche, il est temps de faire un bilan ! Quelles bÃªtises le froid aura-t-il apportÃ©es parmi les devs ? â„ï¸&lt;/p&gt;

&lt;h1 id=&quot;la-confiance-&quot;&gt;La confiance ğŸ¤&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/dev-facts-19/how-to-test.png&quot; alt=&quot;Image d&apos;une Pull Request indiquant &apos;How to test ? Trust me&apos;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;mieux-quun-readme&quot;&gt;Mieux quâ€™un readme&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Quand le mec tâ€™explique la solution, et finit par :&lt;/p&gt;

  &lt;p&gt;â€œEnfin Ã§a câ€™est si mon code a bien continuÃ© dâ€™Ãªtre copiÃ© collÃ© partoutâ€&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;une-Ã©thique-moi-&quot;&gt;Une Ã©thique, moi ?&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Moi je peux mettre du code dÃ©gueulasse un peu partout, câ€™est pas un problÃ¨me !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;le-socrate-des-temps-modernes&quot;&gt;Le Socrate des temps modernes&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;La vie est un Spike&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;on-apprend-de-ses-erreurs&quot;&gt;On apprend de ses erreurs&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Set up a reminder â€œ@myself ne jamais dire â€˜je finis aujourdâ€™huiâ€™â€ in this channel at 9h45AM every day.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;en-tout-bien-tout-honneur-ï¸&quot;&gt;En tout bien tout honneur â¤ï¸&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Ah bah go, mets-moi en dur si tu veux.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;git-101&quot;&gt;GIT 101&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Jâ€™en ai connu certains, Ã  chaque fois quâ€™ils avaient un conflit sur leur branche, ils supprimaient le repo avant de le re-cloner&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ten-seconds-before-disaster&quot;&gt;Ten seconds before disaster&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Le cache, câ€™est nul !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;shoehashole-boolean-&quot;&gt;shoeHasHole: boolean ğŸ‘Ÿ&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : â€˜tin jâ€™ai un trou dans ma chaussure&lt;/p&gt;

  &lt;p&gt;B : Tu es sÃ»r que câ€™est pas un false ?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;on-a-tous-un-env-de-test-certains-ont-aussi-un-env-de-prod&quot;&gt;On a tous un env de test. Certains ont aussi un env de prod.&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/dev-facts-19/dev-env.png&quot; alt=&quot;Extrait de code dÃ©finissant la variable DEV_ENV comme Ã©gal Ã  prod&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;peur-de-rien-sauf-dune-chose&quot;&gt;Peur de rien, sauf dâ€™une choseâ€¦&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : Ã‡a finit en devs qui se reconvertissent Boulanger Ã§a.&lt;/p&gt;

  &lt;p&gt;B : Certes, mais lâ€™inverse est vrai aussi, il arrive que des Boulangers se reconvertissent aprÃ¨s Ãªtre devenus allergiques Ã  la Farine.&lt;/p&gt;

  &lt;p&gt;A : Câ€™est pour Ã§a que je ne me reconvertirai pas en Barmanâ€¦ trop peurâ€¦&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;la-confiance-second-Ã©pisode-&quot;&gt;La confiance, second Ã©pisode ğŸ¤&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Câ€™est pas nâ€™importe quoi, juste un peu yolo !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;comme-de-leau-de-roche-trouble-&quot;&gt;Comme de lâ€™eau de roche trouble !&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Franchement, je trouve Ã§a clair ! Mais je comprends pas..&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;de-rares-gÃ©nies-&quot;&gt;De rares gÃ©nies ğŸ’¡&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;On est peut-Ãªtre des lumiÃ¨res, mais Ã§a ne veut pas dire quâ€™on est tous allumÃ©s !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;cassage-de-prod-dans-3-2-1&quot;&gt;Cassage de prod dans 3â€¦ 2â€¦ 1â€¦&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Jâ€™le sens bien lÃ . Jâ€™le sens bien bien bien.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;its-not-a-bug-its-a-feature&quot;&gt;Itâ€™s not a bug, itâ€™s a feature&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Jâ€™ai vÃ©rifiÃ©, le bug marchait bien.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;toujours-lire-les-petites-lignes-&quot;&gt;Toujours lire les petites lignes ğŸ”&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Tout* marche du coup !&lt;/p&gt;

  &lt;p&gt;(*pour lâ€™instant)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;miaou-&quot;&gt;Miaou ğŸ±ğŸ“ˆ&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : Je thÃ©orise que le chat ne miaule devant la porte que pour savoir sâ€™il pourrait passer quand il aura envie.&lt;/p&gt;

  &lt;p&gt;B : Ouah ton chat il fait du monitoring de la porte !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;facile-comme-tout-&quot;&gt;Facile comme tout !&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;TKT ! tu mets ton JSON dans le yaml et Ã§a ira !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;une-grande-histoire-damour-Ã©pisode-1&quot;&gt;Une grande histoire dâ€™amour, Ã©pisode 1&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Moi, jâ€™adore le JSON&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;une-grande-histoire-damour-Ã©pisode-2&quot;&gt;Une grande histoire dâ€™amour, Ã©pisode 2&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Le mail et le DNS câ€™est ma grande passion&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;partir-comme-un-roi-&quot;&gt;Partir comme un roi ğŸ‘‘&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/dev-facts-19/mic-drop.png&quot; alt=&quot;Image d&apos;une pull request nommÃ©e &amp;quot;Wesh je fais ce squash et je touche plus a rien. Mic drop.&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;les-grandes-questions-de-la-vie-&quot;&gt;Les grandes questions de la vie ğŸ¥&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Dâ€™ailleurs câ€™est LinkedIn ou pain au linked ?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;lhumour-pour-les-nuls&quot;&gt;Lâ€™humour pour les nuls&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : &lt;em&gt;Pouffe de rire&lt;/em&gt;&lt;/p&gt;

  &lt;p&gt;B : Tout va bien ?&lt;/p&gt;

  &lt;p&gt;A : DÃ©solÃ©, je viens de relire ma vanne&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;les-progrÃ¨s-de-lia-&quot;&gt;Les progrÃ¨s de lâ€™IA ğŸ¤–&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : Alors B, câ€™est quoi le format de date php de la constante de format â€˜câ€™ ?&lt;/p&gt;

  &lt;p&gt;B : Tu mâ€™as pris pour chatGPT ou quoi ?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;un-stagiaire-en-dÃ©tresse&quot;&gt;Un stagiaire en dÃ©tresse&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;TLDR: Ã€ lâ€™aide svp&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;la-sÃ©curitÃ©-pour-les-nuls&quot;&gt;La sÃ©curitÃ© pour les nuls&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Brian is in the Keychain.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;promis-dans-le-contexte-cest-vrai&quot;&gt;Promis dans le contexte câ€™est vrai&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;On doit afficher des ronds, alors câ€™est mieux sâ€™ils nous envoient des carrÃ©s.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1&gt;ğŸ˜³&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;(Au pire, si on a la main sur une regexp, câ€™est dÃ©jÃ  plus quâ€™il nâ€™en faut pour me faire rÃªver)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;la-sÃ©lection-naturelle&quot;&gt;La sÃ©lection naturelle&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Je suis dâ€™accord que lÃ  il y a un bug, mais câ€™est un bug parce que je suis con !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;-1&quot;&gt;ğŸµ&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Je suis en train de me rappeler de mon weekend, et spoiler mettre du rhum dans son thÃ© ce nâ€™est pas une bonne idÃ©e.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;error--task-completed-successfully&quot;&gt;Error : Task completed successfully&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/dev-facts-19/error-success.png&quot; alt=&quot;Screen de popup d&apos;erreur indiquant &apos;Build failed to complete successfully&apos;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;la-confiance-30-&quot;&gt;La confiance, 3.0 ğŸ¤&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Coucou, aujourdâ€™hui, je pÃ¨te la reco (en prod), mais câ€™est sous contrÃ´le.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;un-instant-de-rÃ©alisme&quot;&gt;Un instant de rÃ©alisme&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Personnellement, je sais pas ce que je fous en dÃ©veloppeur !&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;thomas-the-train-&quot;&gt;Thomas the train ğŸš†&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/dev-facts-19/tchou-tchou.png&quot; alt=&quot;Message de status Slack indiquant &apos;Working remotely from the tchou tchuou&apos;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;turlututu-chapeau-pointu-&quot;&gt;Turlututu chapeau pointu !&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;On aurait dÃ» dire câ€™est â€œchapeau perchÃ©â€.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;mieux-quun-rappel-automatique-&quot;&gt;Mieux quâ€™un rappel automatique ğŸ¤¯&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : Du coup, tu as envoyÃ© un mail ?&lt;/p&gt;

  &lt;p&gt;B : Pas encore non ! Jâ€™attendais dâ€™y penser !&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Bedrock</name></author><category term="devfacts" /><category term="humour" /><summary type="html">La fin de lâ€™hiver approche, il est temps de faire un bilan ! Quelles bÃªtises le froid aura-t-il apportÃ©es parmi les devs ? â„ï¸</summary></entry><entry><title type="html">Why is Transit Gateway service not right for us?</title><link href="https://tech.bedrockstreaming.com/2023/03/02/aws_transit_gateway.html" rel="alternate" type="text/html" title="Why is Transit Gateway service not right for us?" /><published>2023-03-02T00:00:00+00:00</published><updated>2023-03-02T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/03/02/aws_transit_gateway</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/03/02/aws_transit_gateway.html">&lt;p&gt;Managing the network of many interconnected AWS accounts can quickly lead to having a messy network architecture.&lt;br /&gt;
Transit Gateway (TGW) service seems to be the way out of this. So how do you know if TGW is right for you?&lt;/p&gt;

&lt;p&gt;This blog post will introduce how the service works and explain why we chose not to carry on with our migration to AWS Transit Gateway.
&lt;!--more--&gt;&lt;/p&gt;
&lt;h2 id=&quot;transit-gateways-backstory&quot;&gt;Transit Gatewayâ€™s backstory&lt;/h2&gt;

&lt;p&gt;Transit Gateway is a network transit hub that connects multiple VPCs and On-Premises sites to allows control traffic between them.&lt;br /&gt;
It was created to provide a new approach of network implementation on AWS and to make network administration smoother.&lt;/p&gt;

&lt;p&gt;VPC peering is a point-to-point connection between 2 VPCs.&lt;br /&gt;
It is a great example of complex network management because it adds a new topology to the network architecture.&lt;br /&gt;
On this diagram you can see an example of VPC peering usage. Itâ€™s not that messy yet but at scale it will be.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-03-02-aws_tgw/tgw.png&quot; alt=&quot;Network architecture without Transit Gateway&quot; /&gt;&lt;/p&gt;

&lt;p&gt;By acting as a â€œcloud routerâ€, TGW centralizes network connections and takes control of packet forwarding between VPCs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-03-02-aws_tgw/tgw2.png&quot; alt=&quot;Network architecture with Transit Gateway&quot; /&gt;&lt;/p&gt;

&lt;p&gt;VPC peerings are not required anymore, we go back to a simpler star network topology thanks to Transit Gateway which really does address the complexity and restrictions of VPC peerings.&lt;br /&gt;
At that point, TGW seems to be the perfect answer for a simpler network architecture.&lt;/p&gt;

&lt;h2 id=&quot;what-about-tgw-at-bedrock&quot;&gt;What about TGW at Bedrock?&lt;/h2&gt;

&lt;p&gt;We operate more than 20 different AWS accounts for our customersâ€™ platforms. Each account has a VPC with at least 3 private and 3 public subnets. We also manage AWS accounts for internal tools like ECR repositories, monitoring tools and shared s3 buckets. We configured Site-to-Site VPNs from On-Premises infrastructure to all the VPCs in these accounts.&lt;/p&gt;

&lt;p&gt;From the creation of new AWS accounts to deploying the tenantsâ€™ platform, onboarding a new customer requires a lot of work and time.&lt;/p&gt;

&lt;p&gt;Configuring VPCs Site-to-Site VPN is one of the steps that requires a lot of work. This is why we were interested in Transit Gateway at first.&lt;/p&gt;

&lt;h3 id=&quot;proof-of-concept&quot;&gt;Proof of concept&lt;/h3&gt;

&lt;p&gt;We created a production like Proof of Concept infrastructure using three AWS accounts, two different regions, multiple VPCs and a single Site-to-Site VPN from TGW to On-Premises firewall.&lt;/p&gt;

&lt;h4 id=&quot;how-did-we-test-tgw&quot;&gt;How did we test TGW?&lt;/h4&gt;

&lt;p&gt;We started by trying to split routing domains.&lt;br /&gt;
Centralizing network connections also means (with correct ACLs or Security Groups) that VPCs can reach all other VPCs. We want to control that.&lt;br /&gt;
Transit Gateway attachments read their routes in the TGW route table they are associated to. This is how we manage routing domains.&lt;br /&gt;
We create a Transit Gateway routing table and create routes for target networks.&lt;br /&gt;
TGW attachments are able to propagate routes in a route table if we want to. But because of routing domains, we canâ€™t use that option and we have to add routes manually (attachments only read routes in the route table).&lt;/p&gt;

&lt;p&gt;Then we tested Transit Gateway peering.&lt;br /&gt;
TGW is a regional service, this means that we need to have a TGW for each active AWS region. We use TGW peering to interconnect them.&lt;br /&gt;
We expected to have some way to propagate routes dynamically in the Transit Gateway peering route table. But it is not possible.&lt;/p&gt;

&lt;p&gt;The last thing we tested is migrating from VPC Site-to-Site VPN to TGW VPN.&lt;br /&gt;
Because of the amount of VPC Site-to-Site VPN we have, it was important for us to know if we could get a minimal down time on On-Premises to VPC connections when migrating to the Transit Gateway VPN.&lt;br /&gt;
This process requires a lot of time because routes have to be deleted and created manually on each side.&lt;/p&gt;

&lt;p&gt;Even if we noticed some pain points, tests went well. So we decided to initiate the migration to the Transit Gateway service.&lt;/p&gt;

&lt;h3 id=&quot;why-did-we-choose-to-rollback&quot;&gt;Why did we choose to rollback?&lt;/h3&gt;

&lt;p&gt;Everything was okay at first, we successfully migrated two VPC Site-to-Site VPN to our Transit Gateway VPN.&lt;/p&gt;

&lt;p&gt;But then previous pain points became barriers:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;creating and managing routing domains is possible, but makes it impossible to use dynamic route propagation&lt;/li&gt;
  &lt;li&gt;there is not option to propagate routes in VPC route table, they all have to be created manually&lt;/li&gt;
  &lt;li&gt;data transfer cost is too high (and multiplied by the number of region on which you deployed TGW if your packets go through all these regions)&lt;/li&gt;
  &lt;li&gt;migrating to Transit Gateway requires a planned maintenance because there is a network downtime&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We took some time to talk about what to do next and concluded that migrating to Transit Gateway will just move the complexity of configuring VPC Site-to-Site VPNs to configuring TGW attachments and routes.&lt;/p&gt;

&lt;p&gt;AWS support did not suggest enough solutions to the problems we faced, so we decided to rollback to VPC Site-to-Site VPNs.&lt;/p&gt;</content><author><name>Christian VAN DER ZWAARD</name></author><category term="on-premise" /><category term="cloud" /><category term="aws" /><category term="network" /><summary type="html">Managing the network of many interconnected AWS accounts can quickly lead to having a messy network architecture. Transit Gateway (TGW) service seems to be the way out of this. So how do you know if TGW is right for you? This blog post will introduce how the service works and explain why we chose not to carry on with our migration to AWS Transit Gateway.</summary></entry><entry><title type="html">Projet XState</title><link href="https://tech.bedrockstreaming.com/2023/02/08/projet-xstate.html" rel="alternate" type="text/html" title="Projet XState" /><published>2023-02-08T00:00:00+00:00</published><updated>2023-02-08T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/02/08/projet-xstate</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/02/08/projet-xstate.html">&lt;p&gt;Dans une application frontend moderne, la gestion dâ€™Ã©tat est un Ã©lÃ©ment central de son bon fonctionnement. MalgrÃ© les nombreuses librairies disponibles (Redux, MobX, Recoilâ€¦), cette tache reste complexe Ã  rÃ©aliser et il est facile de perdre le contrÃ´le.&lt;/p&gt;

&lt;p&gt;Dans lâ€™objectif de rester maitre de son application, je vous propose de dÃ©couvrir XState, une librairie reposant sur le concept de machine Ã  Ã©tats. Si lâ€™outil ne fait pas tout, le concept de machine Ã  Ã©tat aide grandement Ã  concevoir une application rÃ©siliente.&lt;/p&gt;

&lt;p&gt;Pour prÃ©senter au mieux les concepts, la thÃ©orie sera suivie de pratique au travers dâ€™un live coding.&lt;/p&gt;</content><author><name>Maxime Blanc</name></author><category term="xstate" /><category term="lyonjs" /><category term="meetup" /><category term="react" /><category term="javascript" /><category term="conference" /><summary type="html">Dans une application frontend moderne, la gestion dâ€™Ã©tat est un Ã©lÃ©ment central de son bon fonctionnement. MalgrÃ© les nombreuses librairies disponibles (Redux, MobX, Recoilâ€¦), cette tache reste complexe Ã  rÃ©aliser et il est facile de perdre le contrÃ´le.</summary></entry><entry><title type="html">A journey into connected TVs industrialisation process, Part 1</title><link href="https://tech.bedrockstreaming.com/2023/01/10/bedrock-app-launcher.html" rel="alternate" type="text/html" title="A journey into connected TVs industrialisation process, Part 1" /><published>2023-01-10T00:00:00+00:00</published><updated>2023-01-10T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2023/01/10/bedrock-app-launcher</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2023/01/10/bedrock-app-launcher.html">&lt;p&gt;At Bedrock, we build and run streaming applications on a wide variety of OTT devices (more than 60 different ecosystems). While testing and experimenting is easy on web and mobile devices, even for non-developers, itâ€™s not as easy for Connected TV (CTV). In this article, youâ€™ll discover how all of our employees can now access testing and pre-release environments on TV devices, with ease and without any technical knowledge.&lt;/p&gt;

&lt;h2 id=&quot;bedrock-tvjs-project&quot;&gt;Bedrock TvJS Project&lt;/h2&gt;

&lt;h3 id=&quot;how-does-it-work-&quot;&gt;How does it work ?&lt;/h3&gt;

&lt;p&gt;To address the growing number of CTVs vendors in the market, we have a one-and-only monorepo project named â€œTVJSâ€. It is a React application which we can deploy almost everywhere almost anywhere with the same code, UI and UX. The magic part? There isnâ€™t much manufacturer-specific code in that application, most of those particularities are handled by our homemade JS library named PELO (Platform Easy Life Officer). &lt;em&gt;For non-French readers, â€œpÃ©loâ€ is a Lyon/Grenoble city slang to designate â€œsomeoneâ€.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-01-10-bedrock-app-launcher/pelo-cli.png&quot; alt=&quot;Pelo&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In a few words, PELO is a set of libraries showing a unified front API for TV developers, so they donâ€™t have to keep in mind every TV specific details and custom APIs (like lifecycle, keyboard, storage handling, and more). PELO also provides several CLI tools allowing the use of proprietary manufacturer SDKs, with a common shared API.&lt;/p&gt;

&lt;p&gt;There are at least two ways to deploy a TV application:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;A fully packaged solution, where all application files and resources are stored on the TV. Everytime you want to update it, application you have to go through the manufacturer QA process. Doing so, you can develop either a web application that will run through the TVâ€™s Web Engine, or a native TV application.&lt;/li&gt;
  &lt;li&gt;The hosted solution, where the TV packaged application only redirects to a web application that you are responsible for. It grants much more flexibility, and delivery speed, as deployment and propagation of a new version are almost instantaneous.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We chose the second way as we are addressing a big number of devices and need all the flexibility we can have for deployments â€“ and, sadly, for rollbacks too. Therefore, we host and deploy our CTV applications like any other website and we control the TV Browser Engine to navigate to specific domain names.&lt;/p&gt;

&lt;p&gt;Three teams are working on this project, on the same repository:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a team dedicated to Core features (like catalog, user lifecycle)&lt;/li&gt;
  &lt;li&gt;a team dedicated to Player features (video playback and advertising)&lt;/li&gt;
  &lt;li&gt;and a team supporting legacy devices&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Developer teams are supported by a QA team. It is responsible for functional quality assurance on Pull Requests and pre-releases. Quality assurance designates any processes to ensure a service meets its quality requirements in terms of experience, stability, â€¦&lt;/p&gt;

&lt;h3 id=&quot;develop--release-process&quot;&gt;Develop &amp;amp; release process&lt;/h3&gt;

&lt;p&gt;We do our maximum to ensure the best quality of service and experience of what we deliver to our customers and their end-users. We have a strong culture of automated testing &amp;amp; tech reviewing which allows us to deliver almost without a sweatâ€¦ Still, at our scale, missing a bug means a bad experience for thousands or millions of people! And thatâ€™s something we wonâ€™t accept without a fight!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;One of Bedrockâ€™s Values is: ROCK-SOLID, ALWAYS&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As a consequence, we also have dedicated QA teams testing our work for a subset of device models and versions, before it is being merged to the main codebase, and before going to production as part of a release. They are doing so by connecting TVs to specific environments that are deployed on-demand: previews and staging.&lt;/p&gt;

&lt;p&gt;Letâ€™s show off a little bit: at the beginning of 2022, thanks to the TVJS project, we were able to deploy production code to 7 manufacturers, and 38 device versions, meaning 266 combinations to check before launching a release into production! And these numbers are ever increasing!&lt;/p&gt;

&lt;h3 id=&quot;my-wish-make-testing-environments-easily-accessible&quot;&gt;My wish: make testing environments easily accessible&lt;/h3&gt;

&lt;p&gt;We love showing-off a bit over the applications we deliver on such a huge number of device models, but that doesnâ€™t go with ease nor without pain.&lt;/p&gt;

&lt;p&gt;Testing a specific environment on a device was not possible for non-project members (other teams, support, business &amp;amp; product teams, managers â€¦). Starting a preview or a staging application requires a deep understanding of the project, proprietary SDKs (even with our PELO CLI), shell, Git commands and advanced knowledge of how devices work in Developer Mode. This was a major issue: it causes interruptions for developers, slows delivery down, reduces our Time To Market.&lt;/p&gt;

&lt;p&gt;QA teams assigned to the project know its basics, they can use PELO CLI and proprietary SDKs, but cannot debug issues they may encounter with such tools: they have to ask developers to take actions for them (as this is not their core job). Using those tools is also time-consuming and time is of the essence when running quality checks while preparing a release.&lt;/p&gt;

&lt;p&gt;Many teams also want to start environments by themselves, to test their own developments on back-end services, to investigate when a customer creates a support ticket, â€¦
The most important of them are Video teams, responsible for video encoding, transcoding and packaging: they are constantly testing new streams and features, and need a way to test their content by themselves, without asking around for a TVJS developer.&lt;/p&gt;

&lt;h2 id=&quot;our-answer-the-launcher-app-&quot;&gt;Our answer: The Launcher App !&lt;/h2&gt;

&lt;h3 id=&quot;what-does-it-do-&quot;&gt;What does it do ?&lt;/h3&gt;

&lt;p&gt;Iâ€™ve developed a TV application to quickly and efficiently start a specific environment. Using the TV remote, people can select the wanted environment and be redirected to it instantly, having the app like they would with the specific app installed.&lt;/p&gt;

&lt;p&gt;Typing long texts is painful for TV users. So, when selecting the preview environment, it shows another set of options where users can input a specific PR number. A background process will ask our Github if it knows the PR number, if it is deployed on the selected customer/manufacturer and will pre-fill the branch name. If not specified, it will default back to our master preview that is updated whenever we merge code to the master branch.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-01-10-bedrock-app-launcher/launcher-demo.gif&quot; alt=&quot;Launcher demo&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;technical-architecture&quot;&gt;Technical Architecture&lt;/h3&gt;

&lt;p&gt;The launcher is part of the TVJS monorepo, developed using React and re-using modules and packages for UI and Navigation allowing it to have minimum maintenance cost.&lt;/p&gt;

&lt;p&gt;For the first iterations of development of the launcher, I hosted it on AWS Amplify, but the Core team quickly integrated it back to a regular production deployment process we have at Bedrock.&lt;/p&gt;

&lt;p&gt;An automatic process builds the javascript bundle and assets and sends everything to AWS S3. The launcher will then be served through Fastly CDN. We build and deploy a unique launcher per compatible manufacturer on their own domain names (as-of-writing, Samsung Tizen, LG webOS and Hisense). For security reasons, those Fastly services are only accessible from our office networks.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-01-10-bedrock-app-launcher/launcher-tech-arch.png&quot; alt=&quot;Launcher technical architecture&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;unreliability-of-launcher-app-installation&quot;&gt;Unreliability of launcher app installation&lt;/h3&gt;

&lt;p&gt;Iâ€™m proud of this launcher and it is already saving loads of time for our QA teams ! They love it, as it helps them focus on their primary role: ensuring service &amp;amp; experience quality. Still, installing the launcher application on every device in our office is a huge amount of work! And, unfortunately, not a persistent one.&lt;/p&gt;

&lt;p&gt;To develop and test apps on live devices, we need to set them in â€œDeveloper Modeâ€. And each manufacturer has its own way, more or less time-consuming. Worse, whenever Developer Mode expires, all applications installed during this time are uninstalled from the device! Which means we have to install the launcher again after a brief period of time.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://developer.samsung.com/smarttv/develop/getting-started/using-sdk/tv-device.html&quot;&gt;Tizen Developer Mode&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://webostv.developer.lge.com/develop/getting-started/developer-mode-app&quot;&gt;LG webOS Developer Mode&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That period of time varies. For Samsung Tizen, weâ€™re not absolutely sure, but itâ€™s almost a month. For LG webOS, it is 50 hours if you donâ€™t extend the Developer Mode or if you connect another TV with the same Developer Account.&lt;/p&gt;

&lt;p&gt;Specifically for LG, I did set up a CRON that automatically extends the Developer Mode, but sometimes it is being disconnected without reasonâ€¦ Or a mishandling by team members can cause the CRON to fail.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-01-10-bedrock-app-launcher/webos-cron.png&quot; alt=&quot;LG webOS CRON configuration to extend Developer Mode&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2023-01-10-bedrock-app-launcher/webos-extend-devmode.gif&quot; alt=&quot;Programmatically extending the Developer Mode on LG webOS&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Therefore, we arenâ€™t 100% sure the launcher application will be up and ready on all the office devices when work begins in the morning, which means developers will have to manually re-install the launcher when asked by another Bedrock employee. It generates frustration for both QA and developers as they are wasting precious time to re-install the launcher.&lt;/p&gt;

&lt;p&gt;Donâ€™t worry though, I already have a couple of ideas to ensure the installation becomes reliable! Iâ€™ll talk more about these it in a future article.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Any Bedrock employee can now start an office CTV, use the launcher app, select customer and environment, hit Letâ€™s Go and access the environment they need to work!&lt;/p&gt;

&lt;p&gt;What we started to measure, and hopefully weâ€™ll have more refined metrics over the next months, is the time QA teams are gaining per day. They needed an average of 15 minutes to start up a TV, set up the Developer Mode, and install the wanted app through CLI. They are validating 5 PRs per day, on 2 different devices at minimum, they almost gain one hour per day. That means our Time To Market is faster, and our QA teams have more time to do exploratory testing as well as refining their tests and writing more automated tests. Something that is not as measurable as time, is the enhanced peace of mind for them to go to work every morning knowing they have a tool designed for them to focus on their core work.&lt;/p&gt;

&lt;p&gt;This has improved the QA team overall velocity! And it makes the whole project more accessible for any employee. However, there is still room for improvement regarding launcher deployment and stability over time, and this is something I will cover in our next article.&lt;/p&gt;

&lt;p&gt;I hope you liked this article and it helped you if youâ€™re trying to achieve something similar!&lt;/p&gt;</content><author><name>Bedrock</name></author><summary type="html">At Bedrock, we build and run streaming applications on a wide variety of OTT devices (more than 60 different ecosystems). While testing and experimenting is easy on web and mobile devices, even for non-developers, itâ€™s not as easy for Connected TV (CTV). In this article, youâ€™ll discover how all of our employees can now access testing and pre-release environments on TV devices, with ease and without any technical knowledge.</summary></entry><entry><title type="html">Nos retours sur lâ€™HAProxyConf Paris 2022</title><link href="https://tech.bedrockstreaming.com/2022/12/23/haproxyconf-paris-2022.html" rel="alternate" type="text/html" title="Nos retours sur lâ€™HAProxyConf Paris 2022" /><published>2022-12-23T00:00:00+00:00</published><updated>2022-12-23T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/12/23/haproxyconf-paris-2022</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/12/23/haproxyconf-paris-2022.html">&lt;p&gt;Bedrock Ã©tait prÃ©sent lors de la ConfÃ©rence HAProxy qui se dÃ©roulait Ã  Paris en novembre 2022 : en tant que speaker, avec la prÃ©sentation de Vincent Gallissot, mais aussi en tant que spectateur. Cet article relate les points forts qui nous ont marquÃ©s.&lt;/p&gt;

&lt;p&gt;La prÃ©sentation de Vincent Gallissot, Lead Cloud Architect chez Bedrock, mettait en valeur lâ€™usage dâ€™HAProxy en tant que brique essentielle de notre infrastructure. Chez Bedrock, nous dÃ©veloppons et maintenons une plateforme de streaming qui a Ã©tÃ© migrÃ©e dans le Cloud en 2019. Cette prÃ©sentation Ã©tait grandement inspirÃ©e de lâ€™article intitulÃ© &lt;a href=&quot;https://tech.bedrockstreaming.com/2021/12/15/scaling-bedrock-video-delivery-to-50-million-users.html&quot; target=&quot;_blank&quot;&gt;â€œScaling Bedrock video delivery to 50 million usersâ€&lt;/a&gt;, dans lequel vous trouverez plÃ©thore dâ€™informations concernant nos utilisations dâ€™HAProxy.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-12-23-haproxyconf-paris-2022/keynote_conf_2022_bedrockstreaming.jpg&quot; alt=&quot;Vincent Gallissot presentation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sommaire&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#ce-que-des-millions-de-requÃªtes-par-seconde-signifient-en-termes-de-coÃ»t-et-dÃ©conomie-dÃ©nergie&quot;&gt;Ce que des millions de requÃªtes par seconde signifient en termes de coÃ»t et dâ€™Ã©conomie dâ€™Ã©nergie&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#un-outil-pour-les-gouverner-tous&quot;&gt;Un outil pour les gouverner tous&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#vous-reprendrez-bien-un-peu-de-pÃ©taoctets-&quot;&gt;Vous reprendrez bien un peu de pÃ©taoctets?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ce-que-des-millions-de-requÃªtes-par-seconde-signifient-en-termes-de-coÃ»t-et-dÃ©conomie-dÃ©nergie&quot;&gt;Ce que des millions de requÃªtes par seconde signifient en termes de coÃ»t et dâ€™Ã©conomie dâ€™Ã©nergie.&lt;/h2&gt;

&lt;p&gt;La keynote dâ€™ouverture avait pour orateur &lt;a href=&quot;https://twitter.com/willytarreau&quot; target=&quot;_blank&quot;&gt;Willy Tarreau&lt;/a&gt;, le Lead Developer dâ€™HAProxy.&lt;br /&gt;
Au travers dâ€™une dÃ©monstration concrÃ¨te mÃ©langeant software et hardware, lâ€™objectif Ã©tait de :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;transmettre lâ€™idÃ©e quâ€™ajouter une brique logicielle dans un systÃ¨me ne le dÃ©grade pas pour autant, bien au contraire&lt;/li&gt;
  &lt;li&gt;sensibiliser lâ€™audience quant Ã  la consommation dâ€™Ã©nergie de nos systÃ¨mes&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;contexte-technique-et-premiÃ¨res-amÃ©liorations&quot;&gt;Contexte technique et premiÃ¨res amÃ©liorations&lt;/h3&gt;

&lt;p&gt;Pour ce premier cas dâ€™Ã©tude, Willy Tarreau nous prÃ©sente le cas dâ€™un service de vente en ligne.&lt;/p&gt;

&lt;p&gt;La stack technique est composÃ©e de PHP / pgSQL (NodeJS + Symfony) et les images sont stockÃ©es en base de donnÃ©es. Câ€™est cette architecture qui sera mise Ã  lâ€™Ã©preuve lors des tests de charge Ã  venir.&lt;/p&gt;

&lt;p&gt;Dans un premier temps, plusieurs amÃ©liorations (sans HAProxy) sont proposÃ©es. Il peut sâ€™agir dâ€™un simple rappel, voir dâ€™un pro-tip dâ€™architecture pour les plus novices : Les images en base de donnÃ©es, câ€™est une mauvaise idÃ©e.&lt;/p&gt;

&lt;p&gt;En les dÃ©plaÃ§ant vers un CDN, le systÃ¨me peut rapidement et simplement doubler ses performances, la base de donnÃ©es Ã©tant un goulot dâ€™Ã©tranglement. La taille des pages peut Ãªtre optimisÃ©e via lâ€™activation de lâ€™option http â€œgzipâ€. Les informations de sessions sont elles aussi enregistrÃ©es en base de donnÃ©es. Afin dâ€™amÃ©liorer les performances, il est possible dâ€™ajouter du caching via des outils tels que Memcache.&lt;/p&gt;

&lt;p&gt;Suite Ã  cela, une premiÃ¨re amÃ©lioration dâ€™architecture serait dâ€™ajouter un NLB (Network Load Balancer) en amont du systÃ¨me qui distribuerait les requÃªtes entrantes vers plusieurs unitÃ©s de calculs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-12-23-haproxyconf-paris-2022/keynote_conf_2022_request_arch.png&quot; alt=&quot;next architecture schematic keynote&quot; /&gt;&lt;/p&gt;

&lt;p&gt;SchÃ©ma dâ€™architecture, premiÃ¨re version&lt;/p&gt;

&lt;p&gt;Dans le cas prÃ©sent, les requÃªtes entrantes sont distribuÃ©es de faÃ§on alÃ©atoire entre les diffÃ©rentes unitÃ©s de traitement. Chacun de ces backends se connectant Ã  la mÃªme et unique base de donnÃ©es.&lt;br /&gt;
Le benchmark ci-dessous (efficacitÃ©, au sens nombre de requÃªtes traitÃ©es en fonction du nombre dâ€™unitÃ©s de calcul), ne montre pas une croissance linÃ©aire. Il sâ€™agit dâ€™une courbe tendant vers une pente nulle (voir nÃ©gative pour les plus grosses architectures).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-12-23-haproxyconf-paris-2022/keynote_conf_2022_nlb_stats.png&quot; alt=&quot;stats of nlb with backends&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Graphique reprÃ©sentant lâ€™efficacitÃ© du systÃ¨me en fonction du nombre de backends&lt;/p&gt;

&lt;h3 id=&quot;comment-expliquer-que-cette-architecture-ne-scale-pas-linÃ©airement-&quot;&gt;Comment expliquer que cette architecture ne scale pas linÃ©airement ?&lt;/h3&gt;

&lt;p&gt;MalgrÃ© les amÃ©liorations apportÃ©es pour les sessions grÃ¢ce au cache, il subsiste encore un problÃ¨me.&lt;/p&gt;

&lt;p&gt;Le NLB est un composant qui ne fait que rÃ©partir la charge sans tenir compte de lâ€™historique des requÃªtes. En effet, celui-ci va distribuer la charge dâ€™entrÃ©e alÃ©atoirement vers les backends.&lt;br /&gt;
Chaque backend reÃ§oit des requÃªtes provenant de nâ€™importe quel utilisateur impliquant alors un cache-miss trÃ¨s Ã©levÃ© : lâ€™utilisateur est rarement trouvÃ© dans le cache, ce qui gÃ©nÃ¨re une requÃªte supplÃ©mentaire en base de donnÃ©es et dÃ©grade les performances en plus de consommer inutilement des ressources.&lt;/p&gt;

&lt;h3 id=&quot;et-si-nous-ajoutons-haproxy-Ã -notre-systÃ¨me-&quot;&gt;Et si nous ajoutons HAProxy Ã  notre systÃ¨me ?&lt;/h3&gt;

&lt;p&gt;Câ€™est ici quâ€™entre en jeu HAProxy en remplaÃ§ant le NLB. Pour cela, pas besoin dâ€™un foudre de guerre en termes de ressources.&lt;/p&gt;

&lt;p&gt;Les tests ont Ã©tÃ© effectuÃ©s sur une machine ARM Breadbee cadencÃ©e Ã  1 GHz et possÃ©dant 64 Mo de RAM. Nous verrons Ã©galement par la suite quâ€™on pourrait mÃªme se passer dâ€™une machine supplÃ©mentaire.&lt;/p&gt;

&lt;p&gt;Le but dâ€™HAProxy est de spÃ©cialiser les caches des backends et plus globalement de forcer les sessions utilisateurs vers les mÃªmes backends.&lt;/p&gt;

&lt;p&gt;Pour cela, HAProxy effectue une inspection de la couche 7 du trafic et renvoie toutes les requÃªtes dâ€™un mÃªme utilisateur sur une mÃªme machine en rÃ©duisant ainsi les cache-miss aux seuls cas des nouveaux clients se connectant Ã  la plateforme. Ainsi, le nombre dâ€™appels Ã  la base de donnÃ©es pour rÃ©cupÃ©rer les informations de session est drastiquement rÃ©duit, la majoritÃ© dâ€™entre elles Ã©tant stockÃ©es en cache.&lt;/p&gt;

&lt;p&gt;Autre fonctionnalitÃ© de taille : HAProxy limite le nombre de requÃªtes faites en parallÃ¨le sur un mÃªme backend, ce qui limite les locks de processus et les temps dâ€™attente. Ceci a pour consÃ©quence directe de rÃ©duire la consommation CPU.&lt;/p&gt;

&lt;p&gt;Ces deux amÃ©liorations permettent Ã  lâ€™application de scaler de faÃ§on beaucoup plus linÃ©aire, tout en rÃ©duisant les consommations CPU et Ã©nergÃ©tiques inutiles. Globalement, les performances initiales sont largement dÃ©passÃ©es avec deux fois moins de backends.&lt;/p&gt;

&lt;h3 id=&quot;a-partir-de-quand-est-il-intÃ©ressant-de-franchir-le-pas-&quot;&gt;A partir de quand est-il intÃ©ressant de franchir le pas ?&lt;/h3&gt;

&lt;p&gt;Maintenant que les bÃ©nÃ©fices dâ€™HAProxy ont Ã©tÃ© prÃ©sentÃ©s, la prochaine Ã©tape est de se demander : quand est-ce quâ€™on se lance ? La question est considÃ©rÃ©e en termes de performance, mais aussi sous un angle pÃ©cunier.&lt;br /&gt;
Si HAProxy peut Ãªtre intÃ©grÃ© sans augmenter les coÃ»ts du systÃ¨me, câ€™est encore mieux.&lt;/p&gt;

&lt;p&gt;Ajouter HAProxy dans un systÃ¨me composÃ© dâ€™un seul backend nâ€™apporte pas de bÃ©nÃ©fice : il nâ€™y a pas de load-balancing possible. Avec deux backends, si on divise le besoin de processing par deux, nous nâ€™avons plus quâ€™un seul backend et donc pas de load-balancing possible.&lt;br /&gt;
Câ€™est en fait Ã  partir de 4 backends que lâ€™ajout dâ€™un HAProxy en entrÃ©e devient intÃ©ressant :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;en retirant 2 serveurs de nos backends en conservant une puissance Ã©quivalente (cf les tests ci-dessus)&lt;/li&gt;
  &lt;li&gt;et en recyclant un des deux backends retirÃ©s en hÃ´te pour HAProxy
En fin de compte, pour une mÃªme puissance de traitement, un backend est retirÃ© ce qui permet de rÃ©duire les coÃ»ts de fonctionnement. Ce principe sâ€™applique Ã©galement sur un grand nombre de backends.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Câ€™est lÃ  que prend tout son sens lâ€™expression qui avait Ã©tÃ© utilisÃ©e pour conclure cette keynote : â€œHAProxy is a free software running on free hardwareâ€.&lt;/p&gt;

&lt;p&gt;Chez Bedrock, nous appliquons aussi ces diffÃ©rentes techniques de Consistent Hashing en entrÃ©e de notre CDN vidÃ©o. Nos caches vidÃ©os sont spÃ©cialisÃ©s et chaque utilisateur est redirigÃ© vers un unique backend lors de la lecture dâ€™une vidÃ©o.&lt;br /&gt;
Pour en savoir plus, vous pouvez consulter notre article au sujet du &lt;a href=&quot;https://tech.bedrockstreaming.com/2021/11/18/hsdo.html&quot; target=&quot;_blank&quot;&gt;Consistent Hashing&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;un-outil-pour-les-gouverner-tous&quot;&gt;Un outil pour les gouverner tous&lt;/h2&gt;

&lt;p&gt;Dans notre activitÃ© en informatique, nous sommes amenÃ©s Ã  dÃ©livrer de plus en plus rapidement des applications, des mises Ã  jour, etcâ€¦ Nous avons donc adoptÃ© la philosophie DevOps et tout un panel dâ€™outils autour de celle-ci afin de sÃ©curiser, monitorer et automatiser chaque Ã©tape de nos pipelines de livraison.&lt;/p&gt;

&lt;p&gt;Le cas de figure du load balancing est intÃ©ressant dans ce type dâ€™organisation, il est essentiel dâ€™exposer de nouvelles applications sur les environnements de production mais Ã©tant donnÃ© que la maÃ®trise de cet outil requiert une comprÃ©hension du rÃ©seau, la responsabilitÃ© incombe souvent Ã  lâ€™Ã©quipe Ops de le gÃ©rer.&lt;/p&gt;

&lt;h3 id=&quot;vous-souhaitez-mieux-gÃ©rer-votre-flotte-haproxy-&quot;&gt;Vous souhaitez mieux gÃ©rer votre flotte HAProxy ?&lt;/h3&gt;

&lt;p&gt;Anjelko Iharos, directeur de lâ€™ingÃ©nierie Ã  HAProxy Technologies nous a prÃ©sentÃ© leur nouvel outil dâ€™automatisation : HAProxy Fusion Control Plane, packagÃ© dans la version entreprise de HAProxy.&lt;/p&gt;

&lt;p&gt;Celui-ci va amener une nouvelle interface enrichie afin de gÃ©rer toutes les instances HAProxy et les outils gravitant autour de ces derniÃ¨res.&lt;/p&gt;

&lt;p&gt;On peut citer :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;La possibilitÃ© pour les dÃ©veloppeurs de router eux-mÃªme leurs applications sans avoir besoin dâ€™un Ops dans leurs pipelines de CI via lâ€™API Fusion.&lt;/li&gt;
  &lt;li&gt;GÃ©rer les WAF de HAProxy de maniÃ¨re centralisÃ©e et rÃ©percuter cette configuration sur un ensemble de clusters/instances.&lt;/li&gt;
  &lt;li&gt;Permettre aux Ops de gÃ©rer la structure de leurs load balancers, ajouter de nouvelles instances, gÃ©rer les certificats SSL, le tuning des performances depuis un seul point dâ€™entrÃ©e.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;est-ce-rÃ©silient-&quot;&gt;Est-ce rÃ©silient ?&lt;/h3&gt;

&lt;p&gt;Fusion Control Plane est livrÃ© avec tout un set de features intÃ©ressantes pour assurer sa maintenabilitÃ© et sa rÃ©silience :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Une pleine observabilitÃ© avec une application unifiÃ©e de rÃ©cupÃ©ration de logs, mÃ©triques et rapports dans la mÃªme interface. Lâ€™export de ces data est possible, notamment pour les transposer dans un dashboard tiers (Grafana, par exemple).&lt;/li&gt;
  &lt;li&gt;Un systÃ¨me de RBAC permettant de mieux gÃ©rer les pÃ©rimÃ¨tres de chacune des Ã©quipes dans le control plane.&lt;/li&gt;
  &lt;li&gt;La gestion centralisÃ©e de la configuration, la validation des configurations et le bot management. La partie WAF est packagÃ©e avec OWASP (communautÃ© publiant des recommandations pour la sÃ©curisation des applications web) ModSecurity Core Rule Set (CRS) pour la dÃ©tection des vulnÃ©rabilitÃ©s. Dans le cadre dâ€™un cluster un systÃ¨me de failover automatique avec auto-Ã©lection du leader (Ã  la maniÃ¨re de GOSSIP avec Consul).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;une-vue-de-lavenir-&quot;&gt;Une vue de lâ€™avenir ?&lt;/h3&gt;

&lt;p&gt;Aujourdâ€™hui, Fusion Control Plane limite son scope Ã  HAProxy Entreprise et Community Edition, les IngressController ne sont pour le moment pas encore supportÃ©s.&lt;/p&gt;

&lt;p&gt;Il nâ€™est pas encore pleinement compatible avec les features offertes par AWS (Gestion des ASG et de Route53) mais câ€™est en cours de dÃ©veloppement chez HAProxy Technologies.&lt;/p&gt;

&lt;p&gt;Le produit semble prometteur et intÃ©ressant. Les possibilitÃ©s quâ€™il nous offre pour laisser la main aux dÃ©veloppeurs sur la mise en place de routes vers leurs applications cÃ´tÃ© on-premise est vraiment un gros plus, mais il nous manque pour le moment le support de lâ€™IngressController HAProxy utilisÃ© sur nos cluster Kubernetes, ce qui nous empÃªche dâ€™en profiter au maximum.&lt;/p&gt;

&lt;h2 id=&quot;vous-reprendrez-bien-un-peu-de-pÃ©taoctets-&quot;&gt;Vous reprendrez bien un peu de pÃ©taoctets ?&lt;/h2&gt;

&lt;p&gt;Chez Bedrock, un Ã©lÃ©ment central de notre mÃ©tier est de fournir de la vidÃ©o Ã  nos utilisateurs. (Incroyable pour une boite qui fait de la VOD hein? ğŸ˜€).&lt;/p&gt;

&lt;p&gt;Pour ce faire nous avons nos propres serveurs CDN hÃ©bergÃ©s sur Paris, en complÃ©ment des CDN publics comme Cloudfront ou Fastly. Cette annÃ©e nous avons servis plusieurs centaines de PB de donnÃ©es via nos serveurs et nous espÃ©rons pouvoir au moins doubler ce trafic lâ€™annÃ©e prochaine !&lt;/p&gt;

&lt;p&gt;Notre architecture CDN est constituÃ©e dâ€™un logiciel appelÃ© LBCDN qui â€œload-balanceâ€ la charge sur les CDN, on-prem et publics, en redirigeant un utilisateur vers un serveur CDN spÃ©cifique.&lt;br /&gt;
Nos serveurs en eux-mÃªmes sont basÃ©s sur Nginx avec une configuration assez simple en direct IO sur de gros SSD.&lt;/p&gt;

&lt;p&gt;La HAproxy conf 2022 nous a pas mal inspirÃ©s pour rÃ©pondre Ã  nos problÃ©matiques avec ces deux confÃ©rences :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.haproxyconf.com/presentations/boost-your-web-apps-with-haproxy-and-varnish/&quot; target=&quot;_blank&quot;&gt;Boost your web apps with HAProxy and Varnish, by JÃ©rÃ©my Lecour CTO of Evolix&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.haproxyconf.com/presentations/was-that-really-haproxy/&quot; target=&quot;_blank&quot;&gt;Was That really HAProxy, by Ricardo Nabinger Sanchez performance engineer at Taghos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ces deux prÃ©sentations font Ã©tat dâ€™une architecture sur les CDN intÃ©ressante oÃ¹ HAProxy est utilisÃ© pour mettre â€œen sandwichâ€ lâ€™outil (ou les outils) faisant fonction de CDN.
Lâ€™architecture prÃ©sentÃ©e semble permettre une configuration bien plus fine que ce que nous avons actuellement avec seulement Nginx.&lt;/p&gt;

&lt;p&gt;Par exemple, sur nos CDN on-prem nous devons aujourdâ€™hui utiliser une astuce pour que Nginx puisse dynamiquement aller rÃ©soudre le nom de domaine du backend sur lequel il source ses fichiers. Cela est dÃ©jÃ  un peu dommage de ne pas avoir de mÃ©canisme disponible nativement. De plus, ce mÃ©canisme est difficile Ã  coupler avec dâ€™autres permettant dâ€™avoir du fail-over par exemple.&lt;/p&gt;

&lt;p&gt;Câ€™est ici quâ€™HAProxy pourrait intervenir pour rÃ©soudre notre problÃ©matique car il nous permet dâ€™avoir du fail over et des tests plus fins sur lâ€™Ã©tat de santÃ© des backends.&lt;/p&gt;

&lt;p&gt;De plus, nous sommes en train de tester une solution de second-tier de CDN qui, du fait de la complexitÃ© ajoutÃ©e Ã  notre architecture de CDN, profiterait beaucoup dâ€™une plus grande finesse de configuration.&lt;/p&gt;

&lt;p&gt;â€œMais attends, tu nâ€™as parlÃ© que de HAProxy en backend lÃ , tu triches un peu non? Câ€™est pas un sandwich câ€™est une tartine de HAProxy lÃ !â€
Tout Ã  fait, notre cas dâ€™usage actuel nâ€™a pas forcÃ©ment besoin dâ€™un HAProxy en frontal de Nginx.&lt;/p&gt;

&lt;p&gt;MAIS!&lt;/p&gt;

&lt;p&gt;Câ€™est lÃ  que les confÃ©rences sont intÃ©ressantes car elles montrent que lâ€™on peut mixer les backends.&lt;br /&gt;
Dans la confÃ©rence prÃ©sentÃ©e par Ricardo, lâ€™utilisation de deux backends (Varnish et hyper-cache) sur un mÃªme serveur est permise par un HAProxy. Cela permet de profiter de la complÃ©mentaritÃ© de ces services.&lt;br /&gt;
Dans notre cas, nous nâ€™avons pas besoin de cela mais une autre confÃ©rence nous a mis la puce Ã  lâ€™oreille : &lt;a href=&quot;https://www.haproxyconf.com/presentations/writing-haproxy-filters-in-rust/&quot; target=&quot;_blank&quot;&gt;Writing HAProxy Filters in Rust&lt;/a&gt;, by Aleksandr Orlenko.&lt;br /&gt;
Cela pourrait nous permettre, avec un HAProxy en frontal, dâ€™agrÃ©ger plus finement les mesures de performances du serveur afin dâ€™optimiser lâ€™usage de ses ressources, ou dÃ©porter une partie du trafic sur un serveur moins chargÃ©, ou encore de rÃ©cupÃ©rer une partie des traitements actuellement effectuÃ©s par le LBCDN.&lt;/p&gt;

&lt;p&gt;Ajouter cette fonctionnalitÃ© serait la belle cerise au kirsch au sommet de ce sandwich de HAProxy.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-12-23-haproxyconf-paris-2022/keynote_conf_2022_cake.png&quot; alt=&quot;cake illustration&quot; /&gt;&lt;/p&gt;

&lt;p&gt;â€œIl est bizarre ton sandwichâ€&lt;/p&gt;

&lt;p&gt;â€œBon dâ€™accord, câ€™est plutÃ´t un gÃ¢teau Ã  Ã©tages.â€&lt;/p&gt;

&lt;p&gt;â€œOk câ€™est mieux, mais je prÃ©fÃ¨re les macarons de la HAProxy Conf 2022 quand mÃªme.â€&lt;/p&gt;

&lt;h2 id=&quot;a-une-prochaine-fois-&quot;&gt;A une prochaine fois !&lt;/h2&gt;

&lt;p&gt;La HAProxyConf, câ€™Ã©tait deux jours de confÃ©rences avec des orateurs venus de tous les coins du globe.&lt;br /&gt;
Une belle occasion pour nous dâ€™en apprendre plus sur un outil que nous utilisons quotidiennement chez Bedrock.&lt;br /&gt;
Dans cet article, nous nâ€™avons pas pu faire mention de tout ce qui nous a intÃ©ressÃ©. Nous pourrions notamment citer les trÃ¨s intÃ©ressantes confÃ©rences au sujet de :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Docker et leur utilisation de lâ€™outil Keda&lt;/li&gt;
  &lt;li&gt;Ou encore de SoundCloud et leurs mesures anti-DDOS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cette confÃ©rence Ã©tait aussi lâ€™occasion dâ€™Ã©changer avec lâ€™Ã©quipe HAProxy autour de sujets techniques qui nous concernent, de voir que nous utilisions dÃ©jÃ  certaines bonnes pratiques, mais aussi que nous avions de quoi nous amÃ©liorer.&lt;/p&gt;

&lt;p&gt;Suite Ã  cette confÃ©rence, câ€™est HAProxy Fusion que nous attendons le plus. Fusion sâ€™annonce comme lâ€™outil idÃ©al pour manager une flotte dâ€™HAProxy. Jusquâ€™Ã  prÃ©sent, nous devions utiliser une solution maison &lt;a href=&quot;https://tech.bedrockstreaming.com/2021/11/18/hsdo&quot; target=&quot;_blank&quot;&gt;HSDO&lt;/a&gt;, fonctionnelle, mais trÃ¨s probablement moins bien intÃ©grÃ©e quâ€™un outil directement fourni par HAProxy.&lt;/p&gt;</content><author><name>Bedrock</name></author><category term="haproxy" /><category term="haproxyconf" /><category term="conference" /><summary type="html">Bedrock Ã©tait prÃ©sent lors de la ConfÃ©rence HAProxy qui se dÃ©roulait Ã  Paris en novembre 2022 : en tant que speaker, avec la prÃ©sentation de Vincent Gallissot, mais aussi en tant que spectateur. Cet article relate les points forts qui nous ont marquÃ©s.</summary></entry><entry><title type="html">How Micro-Services changed our caching architecture</title><link href="https://tech.bedrockstreaming.com/2022/12/23/varnish-operator.html" rel="alternate" type="text/html" title="How Micro-Services changed our caching architecture" /><published>2022-12-23T00:00:00+00:00</published><updated>2022-12-23T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/12/23/varnish-operator</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/12/23/varnish-operator.html">&lt;p&gt;At Bedrock we use Cloudfront or Fastly for two different reason. To protect our applications from potential Distributed Denial of Service Attack. And to provide a layer of cache in front of our applications. No need to go down to the app for an easily cacheable response.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;before the project&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image0.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;At least that is what we thought in 2018 when we were migrating from on premise to the Cloud.&lt;/p&gt;

&lt;p&gt;At that time we had a Varnish instance caching everything at the border  of our on premise infrastructure. All the applications were running either on virtual machines or on bare metal servers. Those applications were mostly called by the end-userâ€™s browser. Whenever an application called another application it did it through Varnish.&lt;/p&gt;

&lt;p&gt;This is ideal if applications are mostly called from the outside world. The Varnish instance caches all cacheable content, and it does not cost too much time as it was in the same Data Center.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;historically-before-2018&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image2.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;
In 2023, we think otherwise. We have now a &lt;a href=&quot;https://kops.sigs.k8s.io/&quot;&gt;KOps&lt;/a&gt; managed Kubernetes cluster running on EC2 spot instances in private subnets at AWS. As we migrated to the cloud we also embarked on the journey of splitting monolith into smaller more manageable microservices.&lt;/p&gt;

&lt;p&gt;With less monoliths the Bedrock product is more resilient and easier to scale but it changes the topologies of network calls. Before there were far more calls coming from the internet from end-users browsers. Now with the new architecture coming into place inter-app requests have increased.&lt;/p&gt;

&lt;p&gt;One solution would be to directly call the ingress of the applications, staying inside the cluster but without the benefit of caching as it is handled by the CDN. This would lead to unsustainable increase in CPU usage, and probably very little gain in terms of response time.&lt;/p&gt;

&lt;p&gt;A better solution for us would be to have the caching of CDN inside the cluster. This would enable us to have fast response time and little to no increase in CPU usage.&lt;/p&gt;

&lt;h1 id=&quot;enter-varnish-operator&quot;&gt;Enter Varnish-Operator&lt;/h1&gt;

&lt;p&gt;We tested the project &lt;a href=&quot;https://github.com/IBM/varnish-operator&quot;&gt;IBM/Varnish-Operator&lt;/a&gt;. This project allows us to create Custom Resources for Kubernetes handled by the Varnish-Operator. This object is called a VarnishCluster, the configuration is pretty simple to get started. This enables us to have a caching layer, between the Ingress-Controller and the Application.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;varnishcluster&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image1.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;VarnishCluster also uses Varnish Configuration Language (VCL) which we are pretty familiar with since we use Varnish On-Premise since 2015, and developers use it regularly to configure Fastly distribution.&lt;/p&gt;

&lt;p&gt;By adding cache using VarnishCluster to an application that is not fully cacheable, we almost divided itâ€™s average response time by two. It is not a surprise as inter api calls used to look like the following graph:&lt;/p&gt;
&lt;center&gt;&lt;img alt=&quot;before-varnishcluster&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image3.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;We changed parameters in the application after adding VarnishCluster so that it calls other app inside the cluster like in the following graph:&lt;/p&gt;
&lt;center&gt;&lt;img alt=&quot;after-varnishcluster&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image4.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;a-few-details&quot;&gt;A few details&lt;/h1&gt;

&lt;p&gt;Before I wrap this up, here are a few details about the implementations.&lt;/p&gt;

&lt;p&gt;As you will be able to read in the Varnish documentation:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;â€œBy default Varnish will use 100 megabytes of malloc(3) storage for caching objects, if you want to cache more than that, you should look at the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-s&lt;/code&gt; argument.â€&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So if you give many Gigs of memory to your Varnish container it wonâ€™t be attributed to the Varnish process. You can set it with the argument &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-s storage=malloc,&amp;lt;Number&amp;gt;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;As we use only Spot nodes that can be terminated by AWS at any moment with only 2 minutes notice, we want to give more resilience to our Varnish Clusters pod as cache is stored in RAM memory.
You lose all your cache at each restart of the Varnish Container.&lt;/p&gt;

&lt;p&gt;We configured &lt;a href=&quot;https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity&quot;&gt;podAntiAffinity&lt;/a&gt; between application pods and VarnishClustersâ€™ to avoid scheduling those pods on the same node and be vulnerable to reclaims.&lt;/p&gt;

&lt;p&gt;We added a &lt;a href=&quot;https://kubernetes.io/docs/tasks/run-application/configure-pdb/&quot;&gt;podDisruptionBudget&lt;/a&gt; to avoid losing all our pods at the same time. We also customized the VCL a bit to make Varnish serve stale content in case our application is unreachable.&lt;/p&gt;

&lt;p&gt;We also added a Prometheus Service Monitor to make sure all Varnish metrics would be scraped by &lt;a href=&quot;https://tech.bedrockstreaming.com/2022/09/06/monitoring-at-scale-with-victoriametrics.html&quot;&gt;Victoria Metrics&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;in-the-future&quot;&gt;In the Future&lt;/h1&gt;

&lt;p&gt;In next versions we would like to add the possibility to configure &lt;a href=&quot;https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#priorityclass&quot;&gt;PriorityClass&lt;/a&gt; of VarnishClusters pod. PriorityClasses are used to order workloads priority.
In a context of scaling and of scarcity of resources, the scheduler will evict pods of lower priority to make room for the pod it is trying to schedule.&lt;/p&gt;

&lt;p&gt;For now our VarnishClusterâ€™s pods have the PriorityClass by default but it is more critical than any other applications as it holds a cache in its memory.&lt;/p&gt;

&lt;p&gt;Also we do not have logs of Varnish. We would like to be able to stream VarnishLog content into &lt;a href=&quot;https://grafana.com/oss/loki/&quot;&gt;Loki&lt;/a&gt;. This would be super useful to debug and to investigate if we ever encounter bugs or unexpected behaviors.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;center&gt;&lt;img alt=&quot;average-Response-time after apps call through VarnishCluster&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image5.png&quot; /&gt;
&lt;p&gt;Average response time going down, red bar is when we pushed it in production&lt;/p&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;With the generalization of microservices, Bedrock needed to rethink its architecture to optimize not only for browser to API calls but also for more API to API usage. By adding VarnishCluster in front of our applications and calling them directly from inside the cluster we improved significantly the Bedrock product.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/IBM/varnish-operator&quot;&gt;The Github project&lt;/a&gt; is still young and lacks important features, we hope with this article to help draw attention to this project and potential contributors.&lt;/p&gt;

&lt;center&gt;&lt;img alt=&quot;meme-contribute-pls&quot; src=&quot;/images/posts/2022-12-23-varnish-operator/image6.jpg&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Arthur Zinck</name></author><category term="on-premise" /><category term="cloud" /><category term="cdn" /><category term="varnish" /><category term="aws" /><category term="cloud" /><category term="fastly" /><category term="varnish-operator" /><category term="cloudfront" /><category term="alb" /><summary type="html">At Bedrock we use Cloudfront or Fastly for two different reason. To protect our applications from potential Distributed Denial of Service Attack. And to provide a layer of cache in front of our applications. No need to go down to the app for an easily cacheable response.</summary></entry><entry><title type="html">Ce que nous retenons de la droidcon London 2022</title><link href="https://tech.bedrockstreaming.com/2022/11/22/droidcon-london-2022.html" rel="alternate" type="text/html" title="Ce que nous retenons de la droidcon London 2022" /><published>2022-11-22T00:00:00+00:00</published><updated>2022-11-22T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/11/22/droidcon-london-2022</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/11/22/droidcon-london-2022.html">&lt;p&gt;La communautÃ© Android a apportÃ© le soleil sur Londres les 27 et 28 octobre 2022. La droidcon London a rÃ©uni plus de 1400 dÃ©veloppeurs autour de lâ€™Ã©cosystÃ¨me Android, de ses outils et enjeux actuels. Jetpack Compose, Ã©videmment, mais aussi Gradle, modularisation, optimisation et autres sujets plus divers ont Ã©tÃ© abordÃ©s lors de ce rendez-vous incontournable pour la communautÃ©.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/entrance.jpg&quot; alt=&quot;droidcon London 2022 entrance&quot; /&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#Ã§a-compile----rafi-panoyan&quot; id=&quot;markdown-toc-Ã§a-compile----rafi-panoyan&quot;&gt;Ã‡a compile ? - Rafi Panoyan&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#vous-reprendrez-bien-un-peu-de-gradle-enterprise-&quot; id=&quot;markdown-toc-vous-reprendrez-bien-un-peu-de-gradle-enterprise-&quot;&gt;Vous reprendrez bien un peu de Gradle Enterprise ?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#dessine-moi-un-module&quot; id=&quot;markdown-toc-dessine-moi-un-module&quot;&gt;&lt;em&gt;Dessine-moi un module&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#trucs-et-astuces&quot; id=&quot;markdown-toc-trucs-et-astuces&quot;&gt;Trucs et astuces&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#design-the-world---damien-cuny&quot; id=&quot;markdown-toc-design-the-world---damien-cuny&quot;&gt;Design the world - Damien Cuny&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#to-compose&quot; id=&quot;markdown-toc-to-compose&quot;&gt;To Compose&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#design-system&quot; id=&quot;markdown-toc-design-system&quot;&gt;Design System&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#vers-linfini-et-au-delÃ &quot; id=&quot;markdown-toc-vers-linfini-et-au-delÃ &quot;&gt;Vers lâ€™infini et au-delÃ &lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#la-gestion-des-erreurs---david-yim&quot; id=&quot;markdown-toc-la-gestion-des-erreurs---david-yim&quot;&gt;&lt;strong&gt;La gestion des erreurs&lt;/strong&gt; - David Yim&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#vÃ©rification-des-entrÃ©es&quot; id=&quot;markdown-toc-vÃ©rification-des-entrÃ©es&quot;&gt;VÃ©rification des entrÃ©es&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#le-type-either&quot; id=&quot;markdown-toc-le-type-either&quot;&gt;Le type Either&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#kotlin-result&quot; id=&quot;markdown-toc-kotlin-result&quot;&gt;Kotlin Result&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#conclusion&quot; id=&quot;markdown-toc-conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#Ã -la-prochaine-&quot; id=&quot;markdown-toc-Ã -la-prochaine-&quot;&gt;Ã€ la prochaine !&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;Ã§a-compile----rafi-panoyan&quot;&gt;Ã‡a compile ? - Rafi Panoyan&lt;/h2&gt;

&lt;p&gt;Les sujets de compilation ont tenu une place trÃ¨s importante lors de cette Ã©dition de la droidcon Londres 2022. 
Quâ€™il sâ€™agisse dâ€™optimiser ses temps de compilation, de repenser la crÃ©ation de modules et des dÃ©pendances entre eux, de factoriser les logiques des scripts de compilation, 
nous avons eu une emphase claire sur lâ€™importance dâ€™adresser ces sujets.&lt;/p&gt;

&lt;h3 id=&quot;vous-reprendrez-bien-un-peu-de-gradle-enterprise-&quot;&gt;Vous reprendrez bien un peu de Gradle Enterprise ?&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/nellyspageli&quot;&gt;Nelson Osacky&lt;/a&gt;, qui travaille chez Gradle, a prÃ©sentÃ© tous les outils que la formule &lt;a href=&quot;https://gradle.com/&quot;&gt;Gradle Entreprise&lt;/a&gt; met Ã  disposition des dÃ©veloppeurs pour analyser en dÃ©tail les compilations.&lt;/p&gt;

&lt;p&gt;Vous voulez vÃ©rifier que la compilation incrÃ©mentale est bien appliquÃ©e partout oÃ¹ cela est possible ? Un script permet de comparer, dans des conditions reproductibles, 
les entrÃ©es et sorties de vos builds, et analyse les tÃ¢ches empÃªchant ce mÃ©canisme central dans la rÃ©duction des temps de compilation.&lt;/p&gt;

&lt;p&gt;Vous voulez vous assurer que Gradle est bien capable de retrouver le cache de vos tÃ¢ches sur un mÃªme poste ou bien depuis le cloud ? 
LÃ  aussi des outils vous permettent dâ€™identifier prÃ©cisemment les points qui ne tirent pas parti de ces mÃ©canismes.&lt;/p&gt;

&lt;p&gt;On regrettera que ces outils soient disponibles uniquement pour la formule payante de Gradle. Cependant, les &lt;a href=&quot;https://scans.gradle.com/&quot;&gt;scans Gradle&lt;/a&gt; sont, eux,
gratuits et illimitÃ©s, et permettent tout de mÃªme de mesurer et comparer des compilations et ainsi suivre lâ€™impact des diffÃ©rentes optimisations que vous pourriez apporter.&lt;/p&gt;

&lt;h3 id=&quot;dessine-moi-un-module&quot;&gt;&lt;em&gt;Dessine-moi un module&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;La modularisation ayant un impact sur les temps de compilation, plusieurs confÃ©rences ont abordÃ© ce sujet trÃ¨s en vogue dans la communautÃ© Android.&lt;/p&gt;

&lt;p&gt;Un point de vue intÃ©ressant de &lt;a href=&quot;https://twitter.com/josef_raska&quot;&gt;Josef Raska&lt;/a&gt; nous invite Ã  nous poser la question de la pertinence de modulariser selon le contexte. 
Ne pas suivre une tendance mais se poser la question de lâ€™utilitÃ© dâ€™un nouveau module, et encore plus de ses dÃ©pendances avec les autres modules. 
VoilÃ  des propos qui invitent Ã  mesurer concrÃ¨tement lâ€™impact du chantier de la modularisation dans nos applications.&lt;/p&gt;

&lt;p&gt;Ainsi, si on peut penser que modulariser permet de rÃ©duire les temps de compilation (en tirant parti de la parallÃ©lisation des tÃ¢ches par exemple), 
un chemin de dÃ©pendances trop long entre le module initial et la dÃ©pendance la plus profonde va entraÃ®ner une augmentation du temps de compilation.&lt;/p&gt;

&lt;p&gt;Vigilance, donc, sur les â€œhubs de dÃ©pendancesâ€ (ces dÃ©pendances dont beaucoup de modules ont besoin, et qui ont besoin de beaucoup de modules).&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/dep-hub.png&quot; alt=&quot;Dependency hub&quot; /&gt;
  &lt;figcaption&gt;1. Hub de dÃ©pendances&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;hr /&gt;

&lt;p&gt;De la mÃªme maniÃ¨re, un chemin de dÃ©pendances de trop grande profondeur ne permettra pas de tirer parti de la parallÃ©lisation des tÃ¢ches de compilation.
Sur le schÃ©ma ci-dessous, on peut voir quâ€™un chemin de profondeur 4 existe pour aller du module applicatif vers le module le plus bas dans la hiÃ©rarchie.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/dep-height.png&quot; alt=&quot;Dependency height&quot; /&gt;
  &lt;figcaption&gt;2. Profondeur de dÃ©pendances&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;hr /&gt;

&lt;p&gt;Josef Raska propose le schÃ©ma suivant avec un dÃ©coupage API/implÃ©mentation afin de rÃ©duire au maximum cette profondeur, et ainsi compiler plus rapidement.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/dep-height-fix.png&quot; alt=&quot;Dependency height fix&quot; /&gt;
  &lt;figcaption&gt;3. Profondeur de dÃ©pendances rÃ©duite&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;hr /&gt;

&lt;p&gt;Android Studio et son analyse de dÃ©pendances peut Ãªtre trÃ¨s utile pour vÃ©rifier et mesurer cela.
Josef Raska a dâ€™ailleurs crÃ©Ã© un plugin Gradle afin de spÃ©cifier ces rÃ¨gles Ã  lâ€™echelle dâ€™un projet et de sâ€™assurer quâ€™elles soient respectÃ©es : &lt;a href=&quot;https://github.com/jraska/modules-graph-assert&quot;&gt;modules-graph-assert&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;trucs-et-astuces&quot;&gt;Trucs et astuces&lt;/h3&gt;

&lt;p&gt;AprÃ¨s ces conseils trÃ¨s avisÃ©s mais structurellement chronophages Ã  mettre en place (surtout sur de gros projets dÃ©jÃ  crÃ©Ã©s), dâ€™autres confÃ©renciers se sont plutÃ´t tournÃ©s vers les â€œquick-winâ€. Des changements peu coÃ»teux, aux gains plus modestes mais qui sâ€™additionnent, il en existe quelques-uns.&lt;/p&gt;

&lt;p&gt;Ainsi, si Gradle nous permet dâ€™activer des fonctionnalitÃ©s de caching (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;org.gradle.unsafe.configuration-cache=true&lt;/code&gt; pour gagner du temps lors de la phase de configuration par exemple), il est aussi possible de dÃ©sactiver des fonctionnalitÃ©s du plugin Android si elles ne nous sont pas utiles.&lt;/p&gt;

&lt;p&gt;Voici une petite liste des propriÃ©tÃ©s qui sont activÃ©es par dÃ©faut, mÃªme lorsquâ€™elles ne sont pas utilisÃ©es dans les modules :&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;android {
  buildFeatures {
    buildConfig false
    aidl false
    renderScript false
    resValues false
    shaders false
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Si vous nâ€™utilisez pas les valeurs liÃ©es Ã  la configuration de votre compilation, ne gÃ©nÃ©rez pas de &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BuildConfig&lt;/code&gt;.
Si vous nâ€™avez pas de resources dans votre module, dÃ©sactivez la gÃ©nÃ©ration de &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;resValue&lt;/code&gt; !&lt;/p&gt;

&lt;p&gt;Retrouvez ici la liste de ces fonctionnalitÃ©s, leur utilitÃ© et leurs valeurs par dÃ©faut : &lt;a href=&quot;https://developer.android.com/reference/tools/gradle-api/4.1/com/android/build/api/dsl/BuildFeatures&quot;&gt;BuildFeatures&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;design-the-world---damien-cuny&quot;&gt;Design the world - Damien Cuny&lt;/h2&gt;

&lt;p&gt;Il y a un peu plus dâ€™un an sortait la version 1.0 de &lt;a href=&quot;https://developer.android.com/jetpack/compose&quot;&gt;Jetpack Compose&lt;/a&gt;, le nouveau toolkit dÃ©claratif pour la crÃ©ation dâ€™interfaces Android. Dâ€™autre part, le design system &lt;a href=&quot;https://m3.material.io/&quot;&gt;Material Design 3&lt;/a&gt; vient de sortir en version stable et son implÃ©mentation &lt;a href=&quot;https://developer.android.com/jetpack/androidx/releases/compose-material&quot;&gt;Compose Material&lt;/a&gt; sont Ã©galement disponibles.&lt;br /&gt;
Avec tout cela, le design a, cette annÃ©e encore, tenu une place de choix dans lâ€™agenda de cette droidcon 2022 Ã  Londres.&lt;br /&gt;
Mais comment utiliser tout cela correctement ? Comment sâ€™en servir pour implÃ©menter un design system personnalisÃ© ? Jusquâ€™oÃ¹ peut-on aller ?
Autant de questions auxquelles ont tentÃ© de rÃ©pondre les nombreuses prÃ©sentations sur le sujet.&lt;/p&gt;

&lt;h3 id=&quot;to-compose&quot;&gt;To Compose&lt;/h3&gt;

&lt;p&gt;Compose facilite beaucoup de choses dans lâ€™implÃ©mentation et le maintien dâ€™interfaces sur Android. Cependant, cela nÃ©cessite de rÃ©apprendre Ã  faire certaines choses que lâ€™on maÃ®trise dÃ©jÃ  avec le systÃ¨me de &lt;a href=&quot;https://developer.android.com/reference/android/view/View&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;View&lt;/code&gt;&lt;/a&gt;.&lt;br /&gt;
Dessiner dans un canvas en est une, et &lt;a href=&quot;https://twitter.com/hi_man_shoe&quot;&gt;Himanshu Singh&lt;/a&gt; dans sa prÃ©sentation &lt;em&gt;â€œComposing in your canvasâ€&lt;/em&gt;, nous montre les piÃ¨ges Ã  Ã©viter pour rÃ©aliser cela avec Compose.&lt;/p&gt;

&lt;p&gt;La recomposition peut Ã©galement Ãªtre source de problÃ¨mes et de latences si Compose est mal utilisÃ©. Dans sa prÃ©sentation &lt;em&gt;â€œUnderstanding recomposition performance pitfallsâ€&lt;/em&gt;, &lt;a href=&quot;https://twitter.com/jossiwolf&quot;&gt;Jossi Wolf&lt;/a&gt; et &lt;a href=&quot;https://twitter.com/shikasd_&quot;&gt;Andrei Shikov&lt;/a&gt; nous donnent, Ã  partir dâ€™un exemple concret, les meilleures astuces pour lâ€™utiliser Ã  bon escient.&lt;/p&gt;

&lt;h3 id=&quot;design-system&quot;&gt;Design System&lt;/h3&gt;

&lt;p&gt;En faisant le parallÃ¨le avec la saga Ã©pique de JRR Tolkien, &lt;a href=&quot;https://medium.com/@danielbbeleza&quot;&gt;Daniel Beleza&lt;/a&gt;, dans sa prÃ©sentation &lt;em&gt;â€œOne design system to rule them allâ€&lt;/em&gt;, nous explique comment il a rÃ©ussi, tout en se passant de &lt;a href=&quot;https://material.io&quot;&gt;Material design&lt;/a&gt;, Ã  unifier et automatiser son propre design system.&lt;br /&gt;
Cela demande, Ã©videmment, une collaboration totale de la part de lâ€™Ã©quipe de design, mais une fois cette intÃ©gration faite, les bÃ©nÃ©fices et lâ€™autonomie se ressentent de part et dâ€™autre.&lt;br /&gt;
Des outils tel que &lt;a href=&quot;https://www.figma.com/&quot;&gt;Figma&lt;/a&gt;, &lt;a href=&quot;https://square.github.io/kotlinpoet/&quot;&gt;Kotlin Poet&lt;/a&gt; ou des plugins Android Studio custom lui ont permis dâ€™automatiser ensuite ce processus.&lt;/p&gt;

&lt;p&gt;Material Design est un design system. Il a lâ€™avantage dâ€™Ãªtre bien documentÃ©, uniforme et rÃ©guliÃ¨rement enrichi. De plus, il est dÃ©jÃ  implÃ©mentÃ© dans lâ€™ancien systÃ¨me de View Android et plus rÃ©cemment dans Jetpack Compose avec &lt;a href=&quot;https://developer.android.com/jetpack/androidx/releases/compose-material&quot;&gt;Compose Material&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Une des diffÃ©rences majeures entre Compose et le systÃ¨me de View sur Android est son dÃ©coupage. Dans Compose, Material nâ€™est implÃ©mentÃ© et nâ€™apparaÃ®t que dans la partie la plus hautes alors que dans le systÃ¨me de View, son implÃ©mentation est rÃ©partie dans toutes les couches de la librairie.&lt;br /&gt;
Il est donc assez complexe de se passer de Material avec le systÃ¨me de View mais cela est complÃ©tement envisageable, voire recommandÃ©, dans certains cas avec Compose.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/views-vs-compose.png&quot; alt=&quot;Views VS Compose&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Pour illustrer cela &lt;a href=&quot;https://twitter.com/seebrock3r&quot;&gt;Sebastiano Poggi&lt;/a&gt; (la moitiÃ© de &lt;a href=&quot;https://www.youtube.com/c/CodewiththeItalians&quot;&gt;Coding with the italians&lt;/a&gt;) est venu nous prÃ©senter, dans &lt;em&gt;â€œCompose beyond Materialâ€&lt;/em&gt;, les questions Ã  se poser avant de se lancer dans son design system et comment le package &lt;a href=&quot;https://developer.android.com/jetpack/androidx/releases/compose-foundation&quot;&gt;Foundation&lt;/a&gt; de Compose peut nous aider.&lt;/p&gt;

&lt;p&gt;Pour terminer il nous donne de nombreux conseils concrets sur lâ€™implÃ©mentation de composants sans Material. Le principal, rejoint la prÃ©sentation dâ€™introduction de cette droidcon, &lt;em&gt;â€œThe Silver Bullet Syndrome Directorâ€™s Cut - Complexity Strikes Back!â€&lt;/em&gt;, un bon design system est un design system qui correspond Ã  nos besoins et qui y rÃ©pond le plus simplement possible.&lt;/p&gt;

&lt;h3 id=&quot;vers-linfini-et-au-delÃ &quot;&gt;Vers lâ€™infini et au-delÃ &lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/chrisbanes&quot;&gt;Chris Bane&lt;/a&gt; et &lt;a href=&quot;https://twitter.com/mrmans0n&quot;&gt;Nacho Lopez&lt;/a&gt; dans leur prÃ©sentation &lt;em&gt;â€œBranching out Jetpack Composeâ€&lt;/em&gt;, nous ont racontÃ© comment lâ€™aventure du passage Ã  Compose sâ€™est dÃ©roulÃ©e chez Twitter, une des premiÃ¨res apps Ã  lâ€™adopter.&lt;br /&gt;
Avec une code base aussi consÃ©quente (plus de &lt;strong&gt;1000 modules&lt;/strong&gt;, dont 300 pour le design, rÃ©partis sur plus de 30 Ã©quipes), ils ont dÃ» progressivement convaincre les Ã©quipes, les former et les accompagner.&lt;br /&gt;
La question de continuer Ã  utiliser Material Design sâ€™est Ã©galement posÃ©e chez eux. Ils lâ€™ont dans un premier temps conservÃ© pour faciliter le passage sur Compose, pour finalement le retirer complÃ¨tement en se basant, eux aussi, sur le package Foundation.&lt;br /&gt;
Leur prÃ©sentation rÃ©sume bien lâ€™ensemble des Ã©tapes et des questions par lesquelles ils sont passÃ©s pour accomplir cette transition.&lt;/p&gt;

&lt;p&gt;Afin de remettre les choses en perspective, &lt;a href=&quot;https://twitter.com/askashdavies&quot;&gt;Ash Davies&lt;/a&gt; nous rappelle que Compose est un simple pattern de dÃ©veloppement multiplateforme. De ce fait, il peux Ãªtre appliquÃ© Ã  autre chose quâ€™Ã  de lâ€™UI comme le propose Jetpack Compose. Il nous explique dans &lt;em&gt;â€œDemystifying Molecule: Running Your Own Compositions For Fun And Profitâ€&lt;/em&gt;, comment lâ€™appliquer Ã  la couche domaine dâ€™un projet pour le â€œFunâ€.&lt;/p&gt;

&lt;h2 id=&quot;la-gestion-des-erreurs---david-yim&quot;&gt;&lt;strong&gt;La gestion des erreurs&lt;/strong&gt; - David Yim&lt;/h2&gt;

&lt;p&gt;La gestion des erreurs a Ã©tÃ© le sujet de plusieurs prÃ©sentations Ã  la droidcon. Ces prÃ©sentations avaient pour objectif de servir de piqÃ»re de rappel sur lâ€™importance de bien prendre en compte ce problÃ¨me concernant tous les dÃ©veloppeurs. Aujourdâ€™hui, nous avons tous les outils pour gÃ©rer facilement nos erreurs. Cependant, par paresse et comme nous prÃ©fÃ©rons penser de maniÃ¨re positive, nous ne pensons souvent quâ€™aux cas de succÃ¨s et les cas dâ€™erreurs sont souvent brouillons voire ne sont mÃªme pas spÃ©cifiÃ©s.&lt;/p&gt;

&lt;p&gt;Les speakers mâ€™ont marquÃ© avec un exemple de mauvaise gestion dâ€™erreur qui a coÃ»tÃ© plusieurs centaines de milliers de dollars. Lâ€™exemple parlait dâ€™une faille sur le site japonais de 7-Eleven, une chaÃ®ne de supÃ©rettes, dont elle a Ã©tÃ© victime. Dans la base de donnÃ©es de ce projet, les dÃ©veloppeurs ont ajoutÃ© un champ â€œdate de naissanceâ€ comme nullable. Plus tard, ce champ est devenu non-nullable. Par paresse, le dÃ©veloppeur qui a rendu ce champ non-nullable a mis par dÃ©faut un 1er janvier 2019 sur cette date lorsquâ€™elle nâ€™Ã©tait pas renseignÃ©e, simplement pour satisfaire son compilateur. Le problÃ¨me est que ce champ fut plus tard utilisÃ© dans la fonctionnalitÃ© de mot de passe oubliÃ© du site. En utilisant la date par dÃ©faut du 1er janvier 2019, un hacker a pu rÃ©cupÃ©rer des comptes utilisateurs et voler des informations bancaires. Cet exemple mâ€™a marquÃ© par lâ€™habitude que nous avons en tant que dÃ©veloppeur de nous soucier que de satisfaire notre compilateur plutÃ´t que de vraiment discuter de solutions rÃ©flÃ©chies Ã  nos problÃ¨mes techniques.&lt;/p&gt;

&lt;p&gt;Plusieurs mÃ©thodes de gestion des erreurs existent et les speakers en ont prÃ©sentÃ©s quelques-unes.&lt;/p&gt;

&lt;h4 id=&quot;vÃ©rification-des-entrÃ©es&quot;&gt;VÃ©rification des entrÃ©es&lt;/h4&gt;

&lt;p&gt;Lâ€™une des mÃ©thode pour Ãªtre certain de ne pas avoir de problÃ¨me est de vÃ©rifier les donnÃ©es que lâ€™on reÃ§oit. Prenons un exemple simple :&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;data class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Rien nâ€™empÃªche dâ€™instancier cette classe de la maniÃ¨re suivante :&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;email&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Cela peut crÃ©er des problÃ¨mes par le futur, alors quâ€™il y a un moyen dâ€™Ã©viter cela&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Email&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;isEmpty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Regex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;EMAIL_FORMAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;matches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Email format is not correct&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;data class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Email&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Cette mÃ©thode peut paraÃ®tre un peu exagÃ©rÃ©e dans cet exemple. Mais dans un contexte oÃ¹ la classe &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;User&lt;/code&gt; serait utilisÃ©e par un grand nombre dâ€™Ã©quipes et que les rÃ¨gles mÃ©tier de lâ€™&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Email&lt;/code&gt; serait complexe, cette mÃ©thode prendrait tout son sens pour Ã©viter dâ€™avoir de mauvaises surprises !&lt;/p&gt;

&lt;h4 id=&quot;le-type-either&quot;&gt;Le type Either&lt;/h4&gt;

&lt;p&gt;Le type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Either&lt;/code&gt; est un moyen de diffÃ©rencier les cas de succÃ¨s des cas dâ€™erreurs. Il est disponible dans la &lt;a href=&quot;https://arrow-kt.io/&quot;&gt;librairie Arrow&lt;/a&gt; ou facilement reproduisible :&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;sealed&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nothing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;()&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Nothing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Lâ€™utilisation de ce type est quâ€™il est soit un type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt;, soit un type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt;. On peut ainsi dÃ©finir par exemple que le &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt; est un cas de succÃ¨s et que le type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;B&lt;/code&gt; est un cas dâ€™erreur.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;data class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;when&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Left&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;The user is called ${(either as Either.Left&amp;lt;User&amp;gt;).value.name}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Right&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;either&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Either&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;GrÃ¢ce Ã  ce type, on peut par exemple savoir si un appel Ã  une API a rÃ©ussi ou non, ce qui nous permet de gÃ©rer plus facilement nos cas dâ€™erreurs.&lt;/p&gt;

&lt;h4 id=&quot;kotlin-result&quot;&gt;Kotlin Result&lt;/h4&gt;

&lt;p&gt;La classe &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Result&lt;/code&gt; est similaire au type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Either&lt;/code&gt; et a pour avantage dâ€™Ãªtre directement inclue dans Kotlin et que lâ€™on nâ€™a pas Ã  se synchroniser pour savoir si le cÃ´tÃ© gauche est le cas de succÃ¨s ou dâ€™erreur.&lt;/p&gt;

&lt;div class=&quot;language-kotlin highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;data class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;py&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;when&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isSuccess&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;The user is called ${result.getOrNull()?.name}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isFailure&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exceptionOrNull&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nc&quot;&gt;OU&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;onSuccess&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;The user is called ${user.name}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;onFailure&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Plusieurs mÃ©thodes existent pour prendre en compte nos cas dâ€™erreurs. Laquelle est la meilleure ? Eh bien vous vous y attendez sÃ»rement, mais Ã§a dÃ©pend ! On choisira une mÃ©thode ou une autre selon ce qui nous arrange par rapport Ã  la situation, nos choix dâ€™outils techniques ou nos effectifs. Lâ€™important Ã©tant de prendre en compte ces cas dâ€™erreurs et de ne pas laisser leur rÃ©solution au hasard. Les cas dâ€™erreurs ne sont en fait que dâ€™autres usecases de lâ€™utilisateur et souvent ne sont pas des edgecase. Ils mÃ©ritent donc dâ€™Ãªtre tout autant rÃ©flÃ©chis et spÃ©cifiÃ©s que les cas de succÃ¨s !&lt;/p&gt;

&lt;h2 id=&quot;Ã -la-prochaine-&quot;&gt;Ã€ la prochaine !&lt;/h2&gt;

&lt;p&gt;Il est toujours intÃ©ressant de mesurer lâ€™engouement pour tel ou tel sujet dans la communautÃ© Android en analysant les prÃ©sentations lors des diffÃ©rentes confÃ©rences technologiques.&lt;/p&gt;

&lt;p&gt;Sans aucun doute, cette droidcon Ã©tait sous le signe de Jetpack Compose, qui bÃ©nÃ©ficie dâ€™un suivi et dâ€™un engagement fort de Google et de toute la communautÃ©.&lt;br /&gt;
Tout lâ€™enjeu ici est de rester au contact des innovations et de lâ€™Ã©volution de la plateforme Android, et Jetpack Compose offre un dÃ©fi que nous avons commencÃ© Ã  relever chez Bedrock.&lt;/p&gt;

&lt;p&gt;Nous attendons avec impatience de voir oÃ¹ va Android, et avons Ã  coeur de participer Ã  cette aventure qui nous lie tous !&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-11-22-droidcon-london/hall.jpg&quot; alt=&quot;Hall droidcon London 2022&quot; /&gt;&lt;/p&gt;</content><author><name>[&quot;rpanoyan&quot;, &quot;d_yim&quot;, &quot;d_cuny&quot;]</name></author><category term="android" /><category term="droidcon" /><category term="conference" /><summary type="html">La communautÃ© Android a apportÃ© le soleil sur Londres les 27 et 28 octobre 2022. La droidcon London a rÃ©uni plus de 1400 dÃ©veloppeurs autour de lâ€™Ã©cosystÃ¨me Android, de ses outils et enjeux actuels. Jetpack Compose, Ã©videmment, mais aussi Gradle, modularisation, optimisation et autres sujets plus divers ont Ã©tÃ© abordÃ©s lors de ce rendez-vous incontournable pour la communautÃ©.</summary></entry><entry><title type="html">How many DynamoDB RCU and WCU should we reserve to achieve maximum cost reductions, when our workloads are changing all the time?</title><link href="https://tech.bedrockstreaming.com/2022/11/22/dynamodb-reservations.html" rel="alternate" type="text/html" title="How many DynamoDB RCU and WCU should we reserve to achieve maximum cost reductions, when our workloads are changing all the time?" /><published>2022-11-22T00:00:00+00:00</published><updated>2022-11-22T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/11/22/dynamodb-reservations</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/11/22/dynamodb-reservations.html">&lt;p&gt;Many of the microservices in our VOD and Replay platform use DynamoDB as their database.&lt;br /&gt;
Performance is very good if the data is architected for it, scalability is reasonably fast, and the serverless aspect offloads a lot of the administration and hosting work. Whether itâ€™s performance, resilience or time-to-market, DynamoDB helps us achieve our business goals.&lt;/p&gt;

&lt;p&gt;That said, when we spend several hundred thousand dollars on DynamoDB every year, any optimization is good for us!&lt;/p&gt;

&lt;p&gt;With DynamoDB, committing to a certain capacity for a year can help reduce costs â€“ up to 50% savings on that capacity. But how do we know how much to reserve when traffic on our platform varies throughout the day?&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#dynamodb-a-not-always-obvious-cost-model&quot;&gt;DynamoDB: a not always obvious cost model!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#how-many-wcus-and-rcus-do-we-consume&quot;&gt;How many WCUs and RCUs do we consume?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#in-theory-how-much-should-we-reserve-to-achieve-maximum-savings&quot;&gt;In theory: how much should we reserve, to achieve maximum savings?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#in-practice-lets-calculate-how-much-to-reserve&quot;&gt;In practice: letâ€™s calculate how much to reserve!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#finally-lets-create-those-reservations&quot;&gt;Finally, letâ€™s create those reservations!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#after-reserving-viewing-the-costs&quot;&gt;After reserving, viewing the costs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;dynamodb-a-not-always-obvious-cost-model&quot;&gt;DynamoDB: a not always obvious cost model!&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;&lt;a href=&quot;#in-practice-lets-calculate-how-much-to-reserve&quot;&gt;To skip all the theory about how DynamoDB is priced and WCUs, RCU, on-demand and provisionned billing modes, click hereâ€¦&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;DynamoDB is serverless&lt;sup id=&quot;fnref:serverless-but-still-some-work&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:serverless-but-still-some-work&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But, as with many AWS services, you have to think for a while before you really understand DynamoDB costsâ€¦&lt;/p&gt;

&lt;h3 id=&quot;out-of-scope-costs&quot;&gt;Out of scope costs&lt;/h3&gt;

&lt;p&gt;We pay for the volume of data stored, the volume of data backed up. These costs are outside the scope of this article and I wonâ€™t talk about them again today. They are not zero, however, and can even be a significant part of your bill â€“ for example, if you store large data for a long time&lt;sup id=&quot;fnref:dynamodb-standard-ia&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:dynamodb-standard-ia&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; in DynamoDB. Something you probably shouldnâ€™t do!&lt;/p&gt;

&lt;h3 id=&quot;wcus-and-rcus&quot;&gt;WCUs and RCUs&lt;/h3&gt;

&lt;p&gt;Each DynamoDB table can be configured in either &lt;em&gt;on-demand&lt;/em&gt; or &lt;em&gt;provisioned&lt;/em&gt; billing mode.&lt;/p&gt;

&lt;p&gt;In the second case, we pay for RCUs &lt;em&gt;(Read Capacity Units)&lt;/em&gt; and WCUs &lt;em&gt;(Write Capacity Units)&lt;/em&gt;, depending on the capacity we provision for each table.&lt;br /&gt;
Reservations only matter for these RCUs and WCUs, in purple in the screenshot below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/01-ddb-cost-by-api-operation.png&quot; alt=&quot;Cost by API Operation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Over the past year, our WCU and RCU costs in provisioned mode represent about half of our DynamoDB costs.&lt;br /&gt;
Storage and backups have costs that we consider negligible today.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;And, from a financial standpoint, we work with far too many pay-per-request tables&lt;sup id=&quot;fnref:why-so-much-pay-per-request&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:why-so-much-pay-per-request&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; for my taste.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/dynamodb/pricing/&quot;&gt;The documentation&lt;/a&gt; will tell you more, but in very broad terms:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;One WCU is consumed when writing one line of data. Or for each 1 KB block written.&lt;/li&gt;
  &lt;li&gt;One RCU is consumed to read one line of data. Or for each 4 KB block read.&lt;/li&gt;
  &lt;li&gt;In eventually-consistent read mode, only 1/2 RCU is consumed to read one line of data. Or for each 4 KB block.&lt;/li&gt;
  &lt;li&gt;Transactional mode costs twice as much.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As you can imagine, the first optimization is to store only what is necessary and to request DynamoDB in the way that best meets the needs of the application, including consistency and costs. Developing a data schema that efficiently meets the needs of the application is crucial. I highly recommend you read &lt;a href=&quot;https://www.dynamodbbook.com/&quot;&gt;Alex DeBrieâ€™s very good â€œThe DynamoDB Bookâ€&lt;/a&gt;! Financial optimization based on reservations should â€“ and can â€“ only come afterwards, when usage patterns have been dealt with.&lt;/p&gt;

&lt;h3 id=&quot;the-on-demand--pay-per-request-mode&quot;&gt;The on-demand / pay-per-request mode&lt;/h3&gt;

&lt;p&gt;In &lt;em&gt;on-demand&lt;/em&gt; mode, we &lt;em&gt;theoretically&lt;/em&gt; donâ€™t have to worry about scalability, DynamoDB handles it for us&lt;sup id=&quot;fnref:dynamodb-on-demand-scalability&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:dynamodb-on-demand-scalability&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;In this mode, we pay for each RCU and WCU we consume. If we donâ€™t use DynamoDB, we donâ€™t pay. If we use DynamoDB, we pay.&lt;br /&gt;
The counterpart is that RCUs and WCUs are more expensive in this mode than in the one presented below.&lt;/p&gt;

&lt;p&gt;This mode is therefore very practical, in my opinion, in two cases:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In an environment where we only perform a few queries from time to time (dev, staging).&lt;/li&gt;
  &lt;li&gt;For tables that are usually not used much, but receive large and sudden peaks of requests at certain times.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This mode is not adapted, especially because costs are too high:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For tables where consumption is stable or varies slowly. Typically, tables for which usage follows our daily traffic wave, which is gentle enough on most applications for a reactive auto-scaling mechanism to meet our needs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;provisioned-mode&quot;&gt;Provisioned mode&lt;/h3&gt;

&lt;p&gt;In &lt;em&gt;provisioned&lt;/em&gt; mode, we configure how many RCUs and WCUs we want and we pay for that number of RCUs and WCUs â€“ no matter if we consume them or not.&lt;br /&gt;
This billing mode is therefore less flexible than &lt;em&gt;on-demand&lt;/em&gt;. On the other hand, RCUs and WCUs are less expensive.&lt;/p&gt;

&lt;p&gt;In &lt;em&gt;provisioned&lt;/em&gt; mode, we can set up an auto-scaler on the RCUs and WCUs of the tables that need it. It will dynamically reconfigure the provisioned RCUs and WCUs for those tables, to approximate the actual usage. With an auto-scaler, we can pay as close as possible to our actual consumption, at the provisioned price, which is lower than the on-demand one.&lt;br /&gt;
However, scale-out is not instantaneous: it takes several minutes to detect it needs to act, and then up to several minutes &lt;em&gt;(especially on a large table)&lt;/em&gt; to do so. Also, scale-in can only be triggered around once per hour. For more detailed information, read &lt;a href=&quot;https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html&quot;&gt;the documentation&lt;/a&gt; and &lt;a href=&quot;https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ServiceQuotas.html&quot;&gt;the quota page&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This mode is especially recommended, in my opinion and considering our workloads:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;As often as possible, since each RCU and WCU costs much less than in on-demand mode.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This mode is not suitable:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;On tables where consumption varies very abruptly.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;in-provisioned-mode-reservations&quot;&gt;In provisioned mode, reservations&lt;/h3&gt;

&lt;p&gt;By agreeing to pay for a certain amount of RCU and WCU for one year &lt;em&gt;(or even three years in some regions)&lt;/em&gt;, these RCU and WCU become even cheaper: up to ~50%&lt;sup id=&quot;fnref:50-percent-savings&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:50-percent-savings&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; cheaper than in default-provisioned mode.&lt;br /&gt;
Reserving capacity is a great way to considerably reduce the cost of read/write operations on DynamoDB!&lt;/p&gt;

&lt;p&gt;Reservations lock us for one year. We will pay for the reserved RCUs and WCUs, whether we use them or not.&lt;br /&gt;
It is therefore important to calculate correctly the reservations to be made.&lt;/p&gt;

&lt;p&gt;Also, we pay a part of the total yearly amount at the beginning of the commitment &lt;em&gt;(= â€œupfrontâ€)&lt;/em&gt;, which means we must be able to invest a certain amount in advance.&lt;br /&gt;
The other part is spread over all the months of the commitment period.&lt;/p&gt;

&lt;p&gt;As a consequence, the &lt;em&gt;big question&lt;/em&gt;, to which the rest of this document tries to answer, is: &lt;em&gt;â€œhow many RCU and WCU should we reserve to keep our costs as low as possible?â€&lt;/em&gt;&lt;br /&gt;
When our consumption varies throughout the day, this calculation is pretty funÂ ;-)&lt;/p&gt;

&lt;p&gt;Reservations are global to an AWS account, or even to all accounts on a consolidated bill&lt;sup id=&quot;fnref:consolidated-billing&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:consolidated-billing&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;â†’ Reserved pricing is documented on the &lt;a href=&quot;https://aws.amazon.com/dynamodb/pricing/provisioned/&quot;&gt;page of â€œprovisionedâ€ pricing&lt;/a&gt;.&lt;br /&gt;
â†’ You can also read &lt;a href=&quot;https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-reservation-models/amazon-dynamodb-reservations.html&quot;&gt;this whitepaper&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;how-many-wcus-and-rcus-do-we-consume&quot;&gt;How many WCUs and RCUs do we consume?&lt;/h2&gt;

&lt;p&gt;For the rest of our reasoning and this article, we only count the consumption in &lt;em&gt;provisioned&lt;/em&gt; mode (and exclude &lt;em&gt;on-demand&lt;/em&gt;), since thatâ€™s where we can play with reservations.&lt;br /&gt;
Also, we count provisioned WCU and RCU and not what is actually consumed â€“ so beware of any potential &lt;em&gt;waste&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;On the DynamoDB Web Console home screen, we can see, for an account and a region, how many WCUs and RCUs are provisioned at the current time:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/02-ddb-capacity-used-right-now-in-one-account-and-region.png&quot; alt=&quot;DynamoDB Capacity used, right now, in one account and region&quot; /&gt;&lt;/p&gt;

&lt;p&gt;But these numbers only give a view at a given instant, in a single AWS account and in a single region.&lt;br /&gt;
We deploy our platform across dozens of accounts and multiple regions, with traffic that changes throughout the day, so this is not enough.&lt;/p&gt;

&lt;h3 id=&quot;table-wcusrcus&quot;&gt;Table WCUs/RCUs&lt;/h3&gt;

&lt;p&gt;For a global view of all tables in an account in a region, we can query Cloudwatch Metrics, analyzing the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ProvisionedWriteCapacityUnits&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ProvisionedReadCapacityUnits&lt;/code&gt; metrics:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/03-ddb-write-capacity-per-table-cloudwatch-metrics-CENSORED.png&quot; alt=&quot;Write capacity per table, Cloudwatch metrics&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The Stacked Area view shows, at any given time, the total WCUs (or RCUs) provisioned for all of our tables, in an account and a region.&lt;/p&gt;

&lt;h3 id=&quot;wcurcu-of-gsi&quot;&gt;WCU/RCU of GSI&lt;/h3&gt;

&lt;p&gt;We also need to count the WCUs/RCUs of the Global Secondary Indexes â€“ and these are different metrics! Or, at least, the metrics are shown in a different category in the Cloudwatch web console.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/04-ddb-write-capacity-per-gsi-cloudwatch-metrics-CENSORED.png&quot; alt=&quot;Write capacity per GSI, Cloudwatch metrics&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;so-in-total&quot;&gt;So, in totalâ€¦&lt;/h3&gt;

&lt;p&gt;To get the total, you have to consider this metric for the tables and for the Global Secondary Indexes! In the Cloudwatch console, you have to search in two categories.&lt;br /&gt;
Graphing it all :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/05-ddb-write-capacity-all-cloudwatch-metrics-CENSORED.png&quot; alt=&quot;Total write capacity, Cloudwatch metrics&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Of course, this is to be looked at for WCUs, but also for RCUs, following exactly the same principle.&lt;br /&gt;
And, again, weâ€™re working in multiple accounts and regions.&lt;/p&gt;

&lt;h2 id=&quot;in-theory-how-much-should-we-reserve-to-achieve-maximum-savings&quot;&gt;In theory: how much should we reserve, to achieve maximum savings?&lt;/h2&gt;

&lt;p&gt;Once we know how much capacity weâ€™re actually using, we can move on to reservations.&lt;/p&gt;

&lt;p&gt;But the calculation would be far too easy if our usage was flat!&lt;br /&gt;
In reality, thanks to auto-scaling, our provisioned capacity follows our usual traffic pattern: a wave.&lt;/p&gt;

&lt;p&gt;And, two things:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;if we reserve more than we provision, weâ€™ll waste money.&lt;/li&gt;
  &lt;li&gt;if we reserve less than we provision, we wonâ€™t save as much as we could.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reserve-at-the-bottom-of-the-wave&quot;&gt;Reserve at the bottom of the wave&lt;/h3&gt;

&lt;p&gt;A first idea is to reserve the lowest value we provision throughout the day: what we provision at the bottom of our traffic wave, at night.&lt;/p&gt;

&lt;p&gt;In this case, we are not wasting money, as we always provision 100% or more of our reservation.&lt;br /&gt;
But we are probably minimizing our savings, since we are provisioning more than the reservation, all day long.&lt;/p&gt;

&lt;h3 id=&quot;reserve-at-the-top-of-the-wave&quot;&gt;Reserve at the top of the wave&lt;/h3&gt;

&lt;p&gt;A second idea, kind of the opposite, is to reserve the highest value we provision throughout the day.&lt;br /&gt;
This way, we will never pay the full rate for any WCU/RCU.&lt;/p&gt;

&lt;p&gt;But, in this case, we will be wasting a lot of money, since all day long we will be provisioning less than our reservation.&lt;br /&gt;
This is a &lt;em&gt;bad idea&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;reserve-in-the-middle-thanks-to-careful-calculations&quot;&gt;Reserve â€œin the middleâ€, thanks to careful calculations&lt;/h3&gt;

&lt;p&gt;Now, the real solution: calculate the &lt;em&gt;right value&lt;/em&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Less than &lt;em&gt;the highest value&lt;/em&gt;, to minimize waste.&lt;/li&gt;
  &lt;li&gt;And more than &lt;em&gt;the lowest value&lt;/em&gt;, to optimize savings.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;in-practice-lets-calculate-how-much-to-reserve&quot;&gt;In practice: letâ€™s calculate how much to reserve!&lt;/h2&gt;

&lt;p&gt;Manipulating metrics in Cloudwatch, for visualization, may be acceptable, although we rarely do it since we use other stacks for our metrics. And aggregating metrics from multiple accounts should be feasible &lt;em&gt;(we havenâ€™t tried it)&lt;/em&gt;.&lt;br /&gt;
But for calculations, it is not enough.&lt;/p&gt;

&lt;h3 id=&quot;exporting-metrics&quot;&gt;Exporting metrics&lt;/h3&gt;

&lt;p&gt;As a first step, we exported the metrics visualized above, to be able to manipulate them in another tool â€“ in a spreadsheet, for example.&lt;br /&gt;
To export these metrics from Cloudwatch, we can query its API. We need to do this for all accounts and for each table, which is complicated to do manually.&lt;/p&gt;

&lt;p&gt;To simplify the task, we started working with a script that exports this data to a CSV file.&lt;br /&gt;
Specifically, this script exports one data point per hour: the number of WCUs or RCUs actually provisioned during that hour.&lt;/p&gt;

&lt;p&gt;Running this script for a &lt;em&gt;representative week&lt;/em&gt;, we have enough data to calculate the ideal reservations.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;ğŸ—“ï¸ Representative week?&lt;/strong&gt;&lt;br /&gt;
Of course, we have to be careful to choose the week we focus on.&lt;br /&gt;
If we work with data from a week with a huge unexplained peak of traffic, the results of our calculation will fit that week, but not so much to the rest of the year!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;a-google-spreadsheet-calculation&quot;&gt;A Google Spreadsheet calculation&lt;/h3&gt;

&lt;p&gt;Importing this data into a Google Spreadsheet, we get two columns: a date+time and a number of WCUs.&lt;br /&gt;
And this is for each one-hour range during an entire week:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-01-date-and-conso-english.png&quot; alt=&quot;Date and usage&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;â„¹ï¸ Only twelve hours&lt;/strong&gt;&lt;br /&gt;
Here, I only reproduce twelve rows corresponding to twelve hours, but keep in mind that there are actually 168 rows in my spreadsheet: one row per hour, 24 hours per day, for 7 days.&lt;br /&gt;
Also, the values used for this article are all &lt;em&gt;simulated&lt;/em&gt;, to avoid sharing sensitive information, but they scrupulously respect the shape of our traffic and usage wave.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The next step is to integrate the cost of these WCUs.&lt;br /&gt;
Easy anough, we multiply the number of WCUs by the cost of a WCU in Paris, i.e. $0.000772.&lt;br /&gt;
And the sum of the cost of each line gives us the total cost, without reservation:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-02-cost-without-reservation-english.png&quot; alt=&quot;Costs, without any reservation&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;the-calculations-on-an-assumption&quot;&gt;The calculations, on an assumption&lt;/h3&gt;

&lt;p&gt;Now, letâ€™s assume, for the time being, that we reserve 25,000 WCUs:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The upfront, each hour, is $5.07991.&lt;/li&gt;
  &lt;li&gt;And, each hour, we also have to pay $3.82500 for this capacity, since the upfront is only partial.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In addition:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;During some hours, when we consume less than 25,000 WCU, we will not pay anything extra.&lt;/li&gt;
  &lt;li&gt;During some other hours, when we consume more than 25,000 WCU, we will have to pay a supplement, at the full provisioned rate.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Adding these data, we obtain a different hourly cost, often lower than the one determined above.&lt;br /&gt;
And, therefore, we get a lower total cost as well:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-03-cout-including-reservations-english.png&quot; alt=&quot;Costs, with reservations&quot; /&gt;&lt;/p&gt;

&lt;p&gt;With this hypothesis of a 25,000 WCU reservation, over these twelve hours, we would pay 135 dollars instead of 229 dollars without reservation.&lt;br /&gt;
We would then realize 40.96% savings!&lt;/p&gt;

&lt;h3 id=&quot;the-calculations-until-we-find-the-right-value&quot;&gt;The calculations, until we find the right value&lt;/h3&gt;

&lt;p&gt;Of course, during the hours when we consume less than 25,000 WCU, we are wasting capacity: we are paying for it, without using it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-04-waste-english.png&quot; alt=&quot;Wasted reservations&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The goal of the game is to find the &lt;em&gt;right number&lt;/em&gt; of WCUs to reserve: we want to reduce the total cost as much as possible, maximizing the percentage of savings.&lt;/p&gt;

&lt;p&gt;To do so, we try different values for the number of WCUs reserved, until we find the one that maximizes the percentage of savings:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-05-maximize-percentage-savings-table-english.png&quot; alt=&quot;Maximizing savings percentages (table)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Hereâ€™s the same thing as a graph:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/spreadsheet-05-maximize-percentage-savings-graphic-english.png&quot; alt=&quot;Maximizing savings percentages (graph)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here, over these twelve hours, the optimal approach would be to reserve 23,000 WCU.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;ğŸ’ª Getting real: an entire week&lt;/strong&gt;&lt;br /&gt;
In reality, we perform exactly the same calculation and we follow this very same logic, on 168 lines of data, corresponding to a &lt;em&gt;representative week&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;easier-calculations&quot;&gt;Easier calculations?&lt;/h3&gt;

&lt;p&gt;The first year we tried to reserve capacity, we quickly wrote a script to collect the data from Cloudwatch and export it as CSV.&lt;/p&gt;

&lt;p&gt;We still havenâ€™t, after three or four years now, written a program that would perform the calculations based on this data to come up with the &lt;em&gt;right value&lt;/em&gt; for the number of WCUs or RCUs to reserve.&lt;br /&gt;
As a matter of facts, copying and pasting data from the CSV export to a spreadsheet only takes a minute, we reuse the same year after year, and its visual aspect is nice!&lt;/p&gt;

&lt;p&gt;Also, we only do these calculations and reservations twice a year, so we donâ€™t spend too much time working on this, while still refining more often than once each year.&lt;br /&gt;
Each time, the process takes two of us&lt;sup id=&quot;fnref:pair-reserving&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:pair-reserving&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt; about two hours, or one day per year in totalâ€¦ And the most time-consuming part is talking to our colleagues who are heavy DynamoDB users, and asking them &lt;em&gt;â€œare you planning to reduce the consumption of your project over the coming year?â€&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;finally-lets-create-those-reservations&quot;&gt;Finally, letâ€™s create those reservations!&lt;/h2&gt;

&lt;p&gt;We calculated how many WCUs and how many RCUs we should reserve to achieve the best possible savings, hoping the week we chose to base our calculations on was actually a &lt;em&gt;representative week&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;a-commitment-be-careful&quot;&gt;A commitment: be carefulâ€¦&lt;/h3&gt;

&lt;p&gt;A reservation commits us to pay for a year, whether we use this capacity or not.&lt;/p&gt;

&lt;p&gt;So, itâ€™s always a good idea to take a moment to validate with our colleagues that they are not planning to use less DynamoDB in the near future.&lt;br /&gt;
Of course, the answer is often partly &lt;em&gt;â€œit dependsâ€&lt;/em&gt;, since usage depends on new projects as well as on the traffic on our platforms, but if we can already anticipate the next planned optimizations, itâ€™s always a good thing.&lt;/p&gt;

&lt;p&gt;In November 2022, we can only open DynamoDB reservations for one year if we work in the AWS Paris region.&lt;br /&gt;
Other regions &lt;em&gt;(us-east-1 for example) allow&lt;/em&gt; reservations for three years, which means more substantial savings. On the other hand, would we be willing to commit for three years and lose a major advantage of &lt;em&gt;The Cloud&lt;/em&gt;, its flexibility?&lt;/p&gt;

&lt;h3 id=&quot;which-account-to-reserve-on&quot;&gt;Which account to reserve on?&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/dynamodb/pricing/provisioned/&quot;&gt;The documentation&lt;/a&gt; says (emphasis mine):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you have multiple accounts linked with consolidated billing, &lt;strong&gt;reserved capacity units purchased&lt;/strong&gt; either &lt;strong&gt;at the payer account level&lt;/strong&gt; or linked account level &lt;strong&gt;are shared with all accounts connected to the payer account&lt;/strong&gt;.&lt;br /&gt;
Reserved capacity is applied first to the account that purchased it and then any unused capacity is applied to other linked accounts.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We have configured our AWS accounts to have a single payer account.&lt;br /&gt;
We have decided to make all our reservations in this account and they are applied to the child accounts without discrimination.&lt;br /&gt;
This applies to DynamoDB but also to RDS, EC2, Elasticacheâ€¦&lt;/p&gt;

&lt;h3 id=&quot;reserving&quot;&gt;Reserving!&lt;/h3&gt;

&lt;p&gt;To reserve, we go through the AWS DynamoDB Web console, in our payer account, in the region where these reservations will be used.&lt;/p&gt;

&lt;p&gt;On this screen, you can see how many WCUs and RCUs we have already reserved.&lt;br /&gt;
Since we make several reservations during the year, the reservations already in progress are to be subtracted from the values calculated above!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/ddb-reservations-history-CENSORED.png&quot; alt=&quot;Reservations history&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To create a new reservation, click on &lt;em&gt;â€œPurchase reserved capacityâ€&lt;/em&gt; and fill in the formÂ ;-)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/creating-a-reservation-23k.png&quot; alt=&quot;Reserving 23,000 WCU: this is not free!&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;after-reserving-viewing-the-costs&quot;&gt;After reserving, viewing the costs&lt;/h2&gt;

&lt;p&gt;Once the reservations are made, in AWS Cost Explorer, the upfront cost is clearly visible.&lt;br /&gt;
It is charged at once, on the day we opened the reservation:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/cost-explorer-after-reservation-01-CENSORED.png&quot; alt=&quot;Cost Explorer, after reserving&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To have a daily view of WCU/RCU costs &lt;em&gt;(reserved + provisioned in addition to reservations)&lt;/em&gt;, remember to fill in &lt;em&gt;â€œShow costs as: Amortized costsâ€&lt;/em&gt; to smooth the monthly price of reservations over all days of the month:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/aws/dynamodb-reservations/cost-explorer-after-reservation-02-amortized-CENSORED.png&quot; alt=&quot;Amortized view&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Reservations and one payer account&lt;/strong&gt;&lt;br /&gt;
Since reservations, which cover the bulk of our DynamoDB costs, are made on our payer account, the bulk of our DynamoDB costs go back to this accountâ€¦ And not to the tenant/environment accounts.&lt;br /&gt;
Good luck tracking costs and allocating them to projects and teams ğŸ’ª&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;We work with DynamoDB a lot, for several dozen microservices, and we face several types of infrastructure costs: on-demand reads/writes, provisioned reads/writes, storage, backups.&lt;br /&gt;
In exchange for a loss of flexibility and through reservations that commit us for a year, AWS allows us to reduce the cost of provisioned reads/writes.&lt;/p&gt;

&lt;p&gt;Determining how much to reserve, in the face of a constantly changing load, is not easy.&lt;br /&gt;
We need to have a certain vision on the evolution of usage, over a year, and must accept to lose flexibility.&lt;br /&gt;
And we need to find the &lt;em&gt;right values&lt;/em&gt; to reserve for read and write capacity.&lt;/p&gt;

&lt;p&gt;With three or four years of hindsight, by making reservations twice a year and by following the method detailed in this article, we realize savings of about 30% to 35% on our read and write capacity in provisioned mode.&lt;br /&gt;
On our scale, this saving represents several tens of thousands of dollars per year â€“ which is great, considering we only spend a few hours working on this every six months!&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:serverless-but-still-some-work&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;DynamoDB is one of the &lt;em&gt;most serverless&lt;/em&gt; services we use and I like it a lot. Still, there are a few &lt;em&gt;admin&lt;/em&gt; tasks left in our hands. Typically, we have to specify the capacity we need and configure an auto-scaler. We also have to enable encryption, backups, to setup permissions â€“ and to check all this is done, for all tables, managed by many teams.Â &lt;a href=&quot;#fnref:serverless-but-still-some-work&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:dynamodb-standard-ia&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;If you do store a lot of data for a long time in DynamoDB, take a look at &lt;a href=&quot;https://aws.amazon.com/dynamodb/standard-ia/&quot;&gt;Standard-IA&lt;/a&gt;, it might help you reduce costs.Â &lt;a href=&quot;#fnref:dynamodb-standard-ia&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:why-so-much-pay-per-request&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Why do we use pay-per-request so much? Well, in short, because this mode is more flexible than the provisioned one, and several of our projects are willing to pay much more in exchange for this flexibility.Â &lt;a href=&quot;#fnref:why-so-much-pay-per-request&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:dynamodb-on-demand-scalability&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;DynamoDB in on-demand mode and scalability: in practice, AWS hides whatâ€™s going on, but doesnâ€™t scale to infinity instantly either.Â &lt;a href=&quot;#fnref:dynamodb-on-demand-scalability&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:50-percent-savings&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;50% is kind of the maximum possible saving we can achieve if our usage is flat and we reserve exactly what we provision. Flat usage might be what you see on your applications, but itâ€™s not how our platform works!Â &lt;a href=&quot;#fnref:50-percent-savings&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:consolidated-billing&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;At Bedrock, we have a dedicated billing account â€“ a &lt;em&gt;â€œpayer accountâ€&lt;/em&gt; â€“ that aggregates costs from all our other accounts. Reservations are also shared amongst all (whitelisted) accounts that have a shared payer account.Â &lt;a href=&quot;#fnref:consolidated-billing&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:pair-reserving&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;For these kind of calculations and reservations, we usually work in pair, as this involves large amounts of money. Lowering risk of doing a costly mistake is quite a good idea.Â &lt;a href=&quot;#fnref:pair-reserving&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Pascal Martin</name></author><category term="aws" /><category term="dynamodb" /><category term="finops" /><summary type="html">Many of the microservices in our VOD and Replay platform use DynamoDB as their database. Performance is very good if the data is architected for it, scalability is reasonably fast, and the serverless aspect offloads a lot of the administration and hosting work. Whether itâ€™s performance, resilience or time-to-market, DynamoDB helps us achieve our business goals. That said, when we spend several hundred thousand dollars on DynamoDB every year, any optimization is good for us! With DynamoDB, committing to a certain capacity for a year can help reduce costs â€“ up to 50% savings on that capacity. But how do we know how much to reserve when traffic on our platform varies throughout the day?</summary></entry></feed>