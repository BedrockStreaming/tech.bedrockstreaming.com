<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://tech.bedrockstreaming.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://tech.bedrockstreaming.com/" rel="alternate" type="text/html" /><updated>2022-10-07T13:02:51+00:00</updated><id>https://tech.bedrockstreaming.com/feed.xml</id><title type="html">Bedrock Tech Blog</title><subtitle>Blog technique de Bedrock</subtitle><entry><title type="html">API Platform Conference 2022</title><link href="https://tech.bedrockstreaming.com/2022/10/07/api-platform-conference-2022.html" rel="alternate" type="text/html" title="API Platform Conference 2022" /><published>2022-10-07T00:00:00+00:00</published><updated>2022-10-07T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/10/07/api-platform-conference-2022</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/10/07/api-platform-conference-2022.html">&lt;p&gt;En cette pÃ©riode de rentrÃ©e, Bedrock participait Ã  lâ€™&lt;a href=&quot;https://api-platform.com/con/2022&quot;&gt;API Platform Conference 2022&lt;/a&gt;, oÃ¹ nous avons eu le plaisir dâ€™assister Ã  une partie des confÃ©rences proposÃ©es. Un grand merci Ã  toutes les personnes chez &lt;a href=&quot;https://les-tilleuls.coop/&quot;&gt;Les-Tilleuls.coop&lt;/a&gt; pour lâ€™organisation de cet Ã©vÃ¨nement !
Pour cette seconde Ã©dition, le programme Ã©tait rÃ©parti sur deux jours, les 15 &amp;amp; 16 septembre 2022.&lt;/p&gt;

&lt;p&gt;En introduction Ã  cette confÃ©rence, KÃ©vin Dunglas, crÃ©ateur dâ€™&lt;a href=&quot;https://api-platform.com/&quot;&gt;API Platform&lt;/a&gt;, a mis en ligne la version 3.0.0 du framework en nous prÃ©sentant certaines nouvelles fonctionnalitÃ©s dÃ©veloppÃ©es telles que le support natif de XDebug. Il a profitÃ© de lâ€™occasion pour prÃ©senter un petit historique dâ€™API Platform.&lt;/p&gt;

&lt;h2 id=&quot;domain-driven-design-with-api-platform-3&quot;&gt;Domain-driven design with API Platform 3&lt;/h2&gt;

&lt;p&gt;Lors de cette confÃ©rence, &lt;a href=&quot;https://twitter.com/chalas_r&quot;&gt;Robin Chalas&lt;/a&gt; et &lt;a href=&quot;https://twitter.com/matarld&quot;&gt;Mathias Arlaud&lt;/a&gt; nous ont parlÃ© de lâ€™utilisation dâ€™API Platform dans le cadre du Domain Driven Development et de lâ€™Architecture Hexagonale.
Les prÃ©sentateurs ont commencÃ© cette prÃ©sentation par plusieurs rappels et prÃ©sentations sur des sujets comme :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Domain Driven Design&lt;/li&gt;
  &lt;li&gt;Structures hexagonales&lt;/li&gt;
  &lt;li&gt;CQRS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ces rappels ont permis dâ€™enchainer sur lâ€™utilisation du framework dans ce contexte Ã  travers un &lt;a href=&quot;https://github.com/mtarld/apip-ddd&quot;&gt;exemple de projet&lt;/a&gt; DDD utilisant API Platform 3 et suivant lâ€™architecture hexagonale.&lt;/p&gt;

&lt;p&gt;Ils expliquent comment implÃ©menter API Platform dans notre code en dÃ©taillant plusieurs points :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Lâ€™implÃ©mentation des providers cÃ´tÃ© query&lt;/li&gt;
  &lt;li&gt;Lâ€™implÃ©mentation des processors cÃ´tÃ© command&lt;/li&gt;
  &lt;li&gt;Le systÃ¨me dâ€™opÃ©ration&lt;/li&gt;
  &lt;li&gt;Les providers/processors qui appellent lâ€™app via les bus&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;comment-alice-gardens-gÃ¨re-t-elle-son-code-mÃ©tier-via-les-Ã©vÃ¨nements&quot;&gt;Comment Alice Gardenâ€™s gÃ¨re-t-elle son code mÃ©tier via les Ã©vÃ¨nements&lt;/h2&gt;

&lt;p&gt;Nous avons pu assister Ã  la confÃ©rence â€œComment Alice Gardenâ€™s gÃ¨re-t-elle le code mÃ©tier via des Ã©vÃ¨nementsâ€¯?â€ proposÃ©e par leur technical architect &lt;a href=&quot;https://twitter.com/epatwon&quot;&gt;Nicolas Lemahieu&lt;/a&gt;. Tout dâ€™abord, il nous a prÃ©sentÃ© le contexte de son entreprise Alice Gardenâ€™s qui fait de la vente de mobilier dâ€™extÃ©rieur. En se basant sur la stack technique dÃ©jÃ  prÃ©sente : Symfony, RabbitMQ, MariaDB et sans tout refondre, comment faire pour mieux gÃ©rer le code mÃ©tier actuellement Ã©parpillÃ© un peu partout dans le code.&lt;/p&gt;

&lt;p&gt;Ils utilisaient beaucoup de subscribers Doctrine, ce qui entraÃ®ne plusieurs problÃ¨mes :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Des subscribers nombreux = plus de logique au flush&lt;/li&gt;
  &lt;li&gt;Code plus difficile Ã  maintenir et Ã  comprendre&lt;/li&gt;
  &lt;li&gt;Lâ€™augmentation du risque de boucles infinies implique que chaque changement entraÃ®ne des boucles sur le UnitOfWork&lt;/li&gt;
  &lt;li&gt;Duplication de code&lt;/li&gt;
  &lt;li&gt;Code fortement couplÃ© Ã  Doctrine et manque de typage&lt;/li&gt;
  &lt;li&gt;Du cÃ´tÃ© du profiler Symfony, cela devient compliquÃ© aussi dÃ¨s quâ€™on commence Ã  en avoir beaucoup&lt;/li&gt;
  &lt;li&gt;Les tests sont compliquÃ©s :
    &lt;ul&gt;
      &lt;li&gt;Unitaires quasi impossibles,&lt;/li&gt;
      &lt;li&gt;Fonctionnels possibles, mais demandent beaucoup de ressources en temps et donc dâ€™argent&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nicolas Lemahieu a donc prÃ©sentÃ© les diffÃ©rentes solutions envisagÃ©es ainsi que leurs avantages et inconvÃ©nients :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Domain Driven Development : sÃ©paration trÃ¨s nette du mÃ©tier et de lâ€™infra, mais demande beaucoup trop dâ€™effort Ã  mettre en place, car aucune correspondance avec les bundles dÃ©jÃ  existants (risque de rÃ©gression trop haut, coÃ»t de dÃ©veloppement trop grandâ€¦)&lt;/li&gt;
  &lt;li&gt;Garder les Ã©vÃ¨nements et sâ€™affranchir de Doctrine : câ€™est la solution qui a Ã©tÃ© retenue parce quâ€™elle permettait de rÃ©utiliser un maximum de lâ€™existant&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Puis, nous avons pu apprendre comment implÃ©menter cette solution :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;CrÃ©ation dâ€™une abstraction supplÃ©mentaire â€œBusinessObjectâ€ : nouveau dossier Business dans src oÃ¹ :
    &lt;ul&gt;
      &lt;li&gt;EntitÃ© = objet mÃ©tier&lt;/li&gt;
      &lt;li&gt;MÃ©thodes des entitÃ©s = rÃ¨gles mÃ©tier&lt;/li&gt;
      &lt;li&gt;Toutes les interfaces entitÃ© Ã©tendent BusinessObjectInterface&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Classes abstraites dans Business&lt;/li&gt;
  &lt;li&gt;ImplÃ©mentation dâ€™events custom pour chaque objet mÃ©tier et par type dâ€™event&lt;/li&gt;
  &lt;li&gt;Event provider : fournit les Ã©vÃ¨nements qui sont mis dans une collection puis tag dans les services&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;En conclusion, chez Alice Gardenâ€™s, ils ont rÃ©ussi Ã  nâ€™avoir quâ€™un seul Doctrine Subscriber, donc une seule boucle de UnitOfWork et des tests facilitÃ©s, car câ€™est seulement du PHP. La dÃ©pendance Ã  Doctrine est Ã©liminÃ©e et il suffira de dÃ©placer le provider pour adapter le code Ã  une autre infrastructure.&lt;/p&gt;

&lt;h2 id=&quot;rÃ©utiliser-et-partager-vos-opÃ©rations-personnalisÃ©es-avec-api-platform&quot;&gt;RÃ©utiliser et partager vos opÃ©rations personnalisÃ©es avec API Platform&lt;/h2&gt;

&lt;p&gt;GrÃ¢ce Ã  &lt;a href=&quot;https://mobile.twitter.com/jean_beru&quot;&gt;Hubert Lenoir&lt;/a&gt; et &lt;a href=&quot;https://mobile.twitter.com/jjarrie&quot;&gt;JÃ©rÃ©my JarriÃ©&lt;/a&gt; de lâ€™entreprise SensioLabs, nous avons pu apprendre Ã  rÃ©utiliser et partager les opÃ©rations avec API Platform. Ils utilisent 3 API REST faites avec API Platform v3. Des opÃ©rations gÃ©nÃ©riques comme â€œlikerâ€ peuvent sâ€™appliquer sur des ressources diffÃ©rentes (articles, photos, pages, etc.), on peut donc rÃ©utiliser du code.&lt;/p&gt;

&lt;p&gt;Les principes pour faire cette utilisation gÃ©nÃ©rique de code sont simples :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Un seul contrÃ´leur pour plusieurs ressources = un contrÃ´leur de comportement&lt;/li&gt;
  &lt;li&gt;Une interface pour que les entitÃ©s puissent adopter ce comportement&lt;/li&gt;
  &lt;li&gt;Trait pour les mÃ©thodes du comportement (1 Ã  n comportements, donc classe abstraite ou interface impossible)&lt;/li&gt;
  &lt;li&gt;Ajouter des services intermÃ©diaires&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Il survient un seul problÃ¨me avec ce pattern : la duplication des annotations API Platform. La solution est dâ€™ajouter des dÃ©corations (design pattern decorator) sur les mÃ©tadatas dâ€™API Platform. Il est donc simple de crÃ©er des comportements indÃ©pendants des ressources qui pourront Ãªtre facilement rÃ©utilisÃ©s. Ce projet Ã©tait encore Ã  lâ€™Ã©tat de POC, mais JÃ©rÃ©my et Hubert allaient mettre Ã  jour la version plus aboutie sur le &lt;a href=&quot;https://github.com/JJarrie/reuse-behaviour&quot;&gt;repository GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;la-revue-de-code-est-un-art&quot;&gt;La revue de code est un art&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/SmaineDev&quot;&gt;Smaine Milianni&lt;/a&gt; a proposÃ© une confÃ©rence sur les conseils Ã  suivre afin dâ€™effectuer une revue de code. Nous avons pu rÃ©aliser quâ€™au sein de Bedrock nous appliquions dÃ©jÃ  de nombreux principes.&lt;/p&gt;

&lt;p&gt;Nous appliquons dÃ©jÃ  :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Un template de PR pour dÃ©crire les caractÃ©ristiques du bug ou de lâ€™US :
    &lt;ul&gt;
      &lt;li&gt;Quoi, pourquoi, comment, comment tester, etc.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Des noms de commits explicites&lt;/li&gt;
  &lt;li&gt;La bienveillance&lt;/li&gt;
  &lt;li&gt;Le challenge du code des autres personnes&lt;/li&gt;
  &lt;li&gt;La connaissance des nombreux concepts de code (SOLID, KISSâ€¦)&lt;/li&gt;
  &lt;li&gt;Faire du pair review ou mob review&lt;/li&gt;
  &lt;li&gt;Un request bot dÃ©jÃ  en place&lt;/li&gt;
  &lt;li&gt;Tester et ne pas se fier uniquement Ã  la lecture du code&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nous avons aussi pu prendre du recul et noter des conseils Ã  appliquer. Chacun a pu transmettre ses idÃ©es Ã  son Ã©quipe. Le rappel quâ€™une revue câ€™est aussi souligner le positif et pas seulement challenger le code. Cette confÃ©rence est trÃ¨s concrÃ¨te et facilement applicable Ã  Bedrock.&lt;/p&gt;

&lt;h2 id=&quot;fighting-impostor-syndrome-a-practical-handbook&quot;&gt;Fighting impostor syndrome: a practical handbook&lt;/h2&gt;

&lt;p&gt;Lors de cette confÃ©rence, &lt;a href=&quot;https://twitter.com/mupsigraphy&quot;&gt;Marine Gandy&lt;/a&gt; commence sa prÃ©sentation par dÃ©finir ce que le syndrome de lâ€™imposteur est : une peur de lâ€™Ã©chec, la crainte que quelquâ€™un dise que nous ne sommes pas capables, mais aussi le sentiment de ne pas mÃ©riter de rÃ©ussir.
Elle nous explique que ce terme Ã©tait tout dâ€™abord attribuÃ© exclusivement aux femmes, mais quâ€™aprÃ¨s une Ã©tude montrant que 70% de la population Ã©tait touchÃ©e, il se serait gÃ©nÃ©ralisÃ© Ã  tous les genres.
Marine Gandy nous Ã©nonce que la tech est trÃ¨s touchÃ©e par ce phÃ©nomÃ¨ne pour plusieurs raisons comme le fait quâ€™il y ait beaucoup de renouveau dans ce corps de mÃ©tier et que nous avons vite lâ€™impression de retourner Ã  nos dÃ©buts lorsque nous changeons de techno, crÃ©ant ainsi un sentiment dâ€™instabilitÃ©. 
Dans ce contexte, Marine nous parle de &lt;a href=&quot;https://www.universite-paris-saclay.fr/sites/default/files/media/2020-02/erreur-fondamentale-d-attribution-atelierfbjip2018.pdf&quot;&gt;lâ€™effet Julien Lepers&lt;/a&gt; en prenant pour exemple le fait de se trouver dans une Ã©quipe de personnes bien plus expÃ©rimentÃ©es que nous oÃ¹ la situation influe sur la personne.
Pour finir, la confÃ©renciÃ¨re nous prÃ©sente plusieurs pistes Ã  suivre pour Ã©viter ou minimiser ce genre de sentiment :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ArrÃªter de se comparer aux autres&lt;/li&gt;
  &lt;li&gt;Se challenger sur de nouveaux domaines pour se rendre compte quâ€™on peut toujours apprendre&lt;/li&gt;
  &lt;li&gt;Travailler sur ses faiblesses pour permettre de se sentir plus compÃ©tent&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mon-combat-contre-larachnophobie&quot;&gt;Mon combat contre lâ€™arachnophobie&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/Deuchnord&quot;&gt;JÃ©rÃ´me Tanghe&lt;/a&gt;, par son arachnophobie, nous a expliquÃ© comment il est arrivÃ© Ã  contribuer Ã  API Platform afin dâ€™ajouter une option pour cacher la mascotte Webby. Et câ€™est ce dont il nous a parlÃ©, Ã  savoir comment bien dÃ©marrer sa premiÃ¨re pull request pour contribuer au logiciel libre. La premiÃ¨re Ã©tape Ã©tant de trouver le bon repository qui nous conviendrait parmi les projets existants. Dans le but dâ€™identifier un sujet sur lequel contribuer, il ne faut pas hÃ©siter Ã  utiliser la fonctionnalitÃ© des tags sur les issues, par exemple le tag hacktoberfest dans le cadre dâ€™API Platform. Une fois le sujet trouvÃ©, il faut maintenant identifier la branche de base Ã  partir de laquelle faire sa pull request, cela peut sâ€™agir dâ€™une version spÃ©cifique choisie ou mÃªme de la branche principale. La contribution au logiciel libre ou Ã  lâ€™open source ne passe pas uniquement par des pull requests uniquement basÃ©s sur le code. Il est Ã©galement possible de tester les prÃ©versions (release-candidate), signaler des bugs, faire des suggestions, amÃ©liorer la documentation ou encore rÃ©diger des traductions. Enfin, il est conseillÃ© de prendre en compte chaque retour sur dâ€™autres pull requests, cela permet notamment de dÃ©couvrir les principes et standards du projet.&lt;/p&gt;

&lt;h2 id=&quot;pourquoi-je-nutilise-pas-api-platform&quot;&gt;Pourquoi je nâ€™utilise pas API Platform&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/FredBouchery&quot;&gt;FrÃ©dÃ©ric Bouchery&lt;/a&gt;, sâ€™est dÃ©cidÃ©ment perdu en se retrouvant Ã  prÃ©senter cette confÃ©rence Ã  lâ€™API Platform conference 2022. MalgrÃ© tout, cela lui a permis de nous partager son introspection : Mais au fait, pourquoi il ne sâ€™en sert pas ?&lt;br /&gt;
Dans cette premiÃ¨re partie de sa confÃ©rence, FrÃ©dÃ©ric nâ€™hÃ©site pas Ã  utiliser beaucoup de sarcasme. Il nous explique quâ€™il ne sâ€™en sert pas, car API Platform est Ã©crit en PHP et pour lui, câ€™est une technologie vieillissante qui ne devrait pas tarder Ã  rejoindre Cobolt. Ã‰galement parce quâ€™API Platform utilise Symfony, alors que tout le monde le sait trÃ¨s bien, enfin surtout les Google Trend, Laravel est plus utilisÃ© dans le monde. De plus, FrÃ©dÃ©ric nâ€™aime pas la magie et API Platform en est rempli : sÃ©rialisation et dÃ©sÃ©rialisation Ã  tout va alors que lui est capable de faire une API en seulement quelques lignes avec du PHP pur sans artifice. Enfin, il reproche Ã  API Platform de devenir compliquÃ© Ã  utiliser si le projet qui se base dessus est complexe, trop de personnalisation et de configurations doivent Ãªtre effectuÃ©es. &lt;br /&gt;
Dans cette deuxiÃ¨me partie, FrÃ©dÃ©ric fait tomber son masque sarcastique et dÃ©cide de revenir sur les points quâ€™il a abordÃ©s prÃ©cÃ©demment :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Les tendances concernant un langage ne sont pas des bons indicateurs, en effet imaginer le futur ou la mort de PHP via des statistiques dont certaines basÃ©es sur lâ€™opinion publique nâ€™est pas une bonne faÃ§on de faire&lt;/li&gt;
  &lt;li&gt;PHP, câ€™est aujourdâ€™hui 75% des sites du monde entier et 54% parmi le top 1000 des sites internet frÃ©quemment utilisÃ©s&lt;/li&gt;
  &lt;li&gt;MalgrÃ© tout, il nous conseille de ne pas Ãªtre mono technologique non plus. Sâ€™intÃ©resser Ã  dâ€™autres langages est une bonne chose&lt;/li&gt;
  &lt;li&gt;API Plateform a quand mÃªme de bonnes performances : 99% de rÃ©ponses avec une moyenne de 91â€‰ms sur 5 000 requÃªtes comparÃ©es Ã  son code PHP pur avec une moyenne de 21â€‰ms pour 5 000 requÃªtes Ã©galement sachant que son code ne prend pas en compte la sÃ©curitÃ©&lt;/li&gt;
  &lt;li&gt;Le framework Laravel utilisant des composants Symfony, il est dÃ¨s lors difficile de les comparer. MÃªme si factuellement Laravel est plus utilisÃ© dans le monde, on nâ€™utilise pas du Laravel ou du Symfony pour les mÃªmes raisons et câ€™est une bonne chose que les deux coexistent ensemble&lt;/li&gt;
  &lt;li&gt;Il pensait quâ€™avec la complexitÃ© de ses projets, il Ã©tait trop dur de passer Ã  API Platform, mais il sâ€™est rendu compte que ce nâ€™Ã©tait pas nÃ©cessairement vrai&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;En conclusion de sa confÃ©rence et sans aucun sarcasme, FrÃ©dÃ©ric nâ€™hÃ©site pas Ã  se livrer Ã  nous et finit par nous dire quâ€™il va finalement utiliser API Platform 3 pour un projet.&lt;/p&gt;

&lt;h2 id=&quot;whats-new-in-caddy-the-webserver-of-api-platform&quot;&gt;Whatâ€™s New in Caddy, the webserver of API Platform&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/_francislavoie&quot;&gt;Francis Lavoie&lt;/a&gt; nous a prÃ©sentÃ© plusieurs nouveautÃ©s dans &lt;strong&gt;Caddy&lt;/strong&gt;, un webserver Ã©crit en Go ayant beaucoup de fonctionnalitÃ©s activÃ©es par dÃ©faut et fourni avec API Platform dans &lt;a href=&quot;https://api-platform.com/docs/distribution/caddy/&quot;&gt;lâ€™installation de base&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Parmi les nouveautÃ©s prÃ©sentÃ©es, il nous a notamment parlÃ© dâ€™amÃ©liorations au niveau des &lt;strong&gt;request matchers&lt;/strong&gt; avec des matchers rÃ©utilisables, des expressions et des fonctions. Il a ensuite parlÃ© dâ€™une gestion native de &lt;a href=&quot;https://www.authelia.com&quot;&gt;Authelia&lt;/a&gt; permettant de dÃ©lÃ©guer facilement lâ€™authentification depuis la configuration du serveur.
Enfin, la directive &lt;strong&gt;file_server&lt;/strong&gt; peut maintenant servir des fichiers provenant dâ€™autres sources que le systÃ¨me de fichiers local, par exemple depuis un &lt;strong&gt;bucket S3&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Certaines fonctionnalitÃ©s sont dÃ©sormais activÃ©es par dÃ©faut comme &lt;strong&gt;HTTP/3&lt;/strong&gt; et la suppression du log des headers dâ€™authentification oÃ¹ il est Ã©galement possible de crÃ©er des filtres pour retirer dâ€™autres informations.&lt;/p&gt;

&lt;h2 id=&quot;webauthn--se-dÃ©barrasser-des-mots-de-passe-dÃ©finitivement&quot;&gt;WebAuthn : se dÃ©barrasser des mots de passe. DÃ©finitivement.&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://mobile.twitter.com/florentmorselli&quot;&gt;Florent Morselli&lt;/a&gt; nous fait une proposition : il est de plus en plus possible aujourdâ€™hui de se passer complÃ¨tement des mots de passe.&lt;/p&gt;

&lt;p&gt;Il a commencÃ© par nous rappeler les problÃ¨mes rÃ©currents : mots de passe trop faibles et/ou trop courts, rÃ©utilisation sur plusieurs sites, la multiplication des fuites de bases de donnÃ©es, etc.&lt;/p&gt;

&lt;p&gt;La solution proposÃ©e : &lt;a href=&quot;https://webauthn.io&quot;&gt;WebAuthn&lt;/a&gt;, un standard dâ€™authentification multifacteur permettant dâ€™identifier les utilisateurs via des donnÃ©es biomÃ©triques, des clÃ©s physiques ou sans aucune information aprÃ¨s la premiÃ¨re authentification sur un appareil.&lt;/p&gt;

&lt;p&gt;CÃ´tÃ© implÃ©mentation, Florent nous a prÃ©sentÃ© deux projets : un &lt;a href=&quot;https://github.com/web-auth/webauthn-symfony-bundle&quot;&gt;bundle Symfony&lt;/a&gt; pour le cÃ´tÃ© backend et un &lt;a href=&quot;https://github.com/web-auth/webauthn-stimulus&quot;&gt;composant Symfony UX&lt;/a&gt; pour le frontend.&lt;/p&gt;

&lt;h2 id=&quot;php-websockets-or-how-to-communicate-with-clients-in-real-time&quot;&gt;PHP WebSockets, or how to communicate with clients in real-time&lt;/h2&gt;

&lt;p&gt;Habituellement connue pour faire des confÃ©rences sur Git, &lt;a href=&quot;https://twitter.com/vanamerongen&quot;&gt;Pauline Vos&lt;/a&gt; nous a fait une dÃ©mo en live de lâ€™utilisation des &lt;strong&gt;WebSockets&lt;/strong&gt; en PHP.&lt;/p&gt;

&lt;p&gt;Elle a commencÃ© par une rapide explication de diffÃ©rents protocoles de communication en temps rÃ©el existant : &lt;em&gt;WebRTC&lt;/em&gt; chez Google, &lt;em&gt;Mercure&lt;/em&gt; chez Symfony et &lt;em&gt;Livewire&lt;/em&gt; chez Laravel.
Les WebSockets Ã©tant de simples tunnels Ã  donnÃ©es, ces protocoles permettent de les enrichir de diverses fonctionnalitÃ©s : identification, structures de messages, reconnexion auto, etc.&lt;/p&gt;

&lt;p&gt;Vient ensuite la dÃ©mo qui consistait en une mini webapp de tombola en ligne. Elle a Ã©tÃ© dÃ©coupÃ©e en diffÃ©rentes Ã©tapes (prÃ©parÃ©es dans des branches Git) avec, pour chaque Ã©tape, une prÃ©sentation du code et des tests en live via lâ€™outil &lt;a href=&quot;https://websocketking.com&quot;&gt;WebSocketKing&lt;/a&gt;.
Pour lâ€™Ã©tape finale, un QR code a Ã©tÃ© affichÃ© Ã  lâ€™Ã©cran pour permettre aux spectateurs et spectatrices de participer en live. Le hasard a voulu que le nom tirÃ© soit &lt;a href=&quot;https://twitter.com/s0yuka&quot;&gt;Antoine Bluchet&lt;/a&gt;, le contributeur principal dâ€™API Platform !&lt;/p&gt;

&lt;h2 id=&quot;comment-remettre-la-tech-au-service-du-bien-commun-&quot;&gt;Comment (re)mettre la tech au service du bien commun ?&lt;/h2&gt;

&lt;p&gt;Pour conclure ces deux jours de confÃ©rences intenses en savoir et en Ã©motions, animÃ© par &lt;a href=&quot;https://twitter.com/gregcop1&quot;&gt;GrÃ©gory Copin&lt;/a&gt;Â : &lt;a href=&quot;https://twitter.com/HeleneMaitre&quot;&gt;HÃ©lÃ¨ne Marchois&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/paulandrieux&quot;&gt;Paul Andrieux&lt;/a&gt; et &lt;a href=&quot;https://twitter.com/dunglas&quot;&gt;KÃ©vin Dunglas&lt;/a&gt; nous ont proposÃ© une excellente table ronde riche en idÃ©es et porteuse (dâ€™un peu) dâ€™espoir. Le sujet Ã©tant de savoir sâ€™il est possible de faire Ã©voluer la tech dans le but de rejoindre les objectifs de dÃ©part du logiciel libre.&lt;/p&gt;

&lt;p&gt;Lâ€™apparition du mouvement du logiciel libre puis celle du web se sont bÃ¢ties sur de grands espoirs et de beaux objectifsÂ : Ã©mancipation des individus, partage des connaissances Ã  lâ€™Ã©chelle planÃ©taire, libertÃ© dâ€™expression, constructions de bien commun appartenant Ã  toutes et tous et maintenues collectivement. Malheureusement, force est de constater que le web comme le logiciel libre ont Ã©tÃ© dÃ©tournÃ©s de leurs objectifs de base et que les idÃ©auxÂ quâ€™ils portaient ont Ã©tÃ© bien mis Ã  malÂ : surveillance de masse, capitalisation de ces biens communs et prÃ©carisation des individus et des libertÃ©s.&lt;/p&gt;

&lt;p&gt;KÃ©vin nous explique ensuite la diffÃ©rence entre logiciel libre et open source : API Platform est un logiciel libre plus quâ€™open source, mÃªme si techniquement, câ€™est les deux. Historiquement, le logiciel libre est apparu dans le but de crÃ©er un bien commun pour lâ€™humanitÃ© et sâ€™est Ã©largi avec, notamment, la notion de commons via WikipÃ©dia. La diffÃ©rence avec lâ€™open source est que si le code est disponible, ce nâ€™est pas uniquement pour bÃ¢tir tout et nâ€™importe quoi avec, mais câ€™est un code qui porte des valeurs et qui a pour but de faire en sorte que tout le monde sans distinction puisse facilement crÃ©er de nouveaux outils qui puissent Ãªtre partagÃ©s, qui appartiennent Ã  un ensemble de personnes et qui vont socialiser le travail qui est rÃ©alisÃ© en commun lÃ -dessus. Le but du logiciel libre Ã  la base, câ€™est de faire en sorte que ces valeurs de transparence, de dÃ©mocraties, de partage de connaissance sâ€™Ã©tendent via le logiciel Ã  lâ€™ensemble de la sociÃ©tÃ©. Donc si vous aussi, vous voulez utiliser un logiciel libre, la condition est que, vous aussi, vous devez faire quelque chose qui sert lâ€™humanitÃ© : crÃ©er un bien commun et mettre aussi Ã  disposition le code source du logiciel. En lâ€™occurrence, API Platform, est une licence permissive, câ€™est-Ã -dire quâ€™il est possible de faire tout et nâ€™importe quoi avec, mais ce nâ€™est pas le cas pour le logiciel &lt;a href=&quot;https://github.com/dunglas/mercure&quot;&gt;Mercure&lt;/a&gt; par exemple, oÃ¹ si vous lâ€™utilisez et le modifiez, vous Ãªtes obligÃ© de redistribuer les Ã©lÃ©ments.&lt;/p&gt;

&lt;p&gt;Quant Ã  lâ€™open source, câ€™est une initiative qui est arrivÃ©e bien aprÃ¨s le logiciel libre et est une offensive de multinationale de la technologie qui veut dÃ©politiser le mouvement du logiciel libre. Le point de dÃ©part Ã©tant que, techniquement, câ€™est trÃ¨s intÃ©ressant de crÃ©er du logiciel ensemble, de partager les coÃ»ts de maintenance entre diffÃ©rentes entreprises ou personnes et câ€™est surtout trÃ¨s intÃ©ressant dâ€™avoir accÃ¨s au secret de fabrication pour les choses qui ont peu de valeur ajoutÃ©e. Mais lâ€™objectif final Ã©tant de capitaliser, faire du business et capter la valeur sur ce qui a une trÃ¨s forte valeur ajoutÃ©e. Par exemple, pour macOS, toutes les briques de bases sont complÃ¨tement libres, dÃ©veloppÃ©es par une communautÃ© de personne, dâ€™entreprise et essentiellement beaucoup de bÃ©nÃ©voles et dâ€™hobbyiste. Et dans ce cas-lÃ , ce qui a une extrÃªme valeur ajoutÃ©e, câ€™est lâ€™UI au-dessus du matÃ©riel ou encore les jolis outils qui coÃ»tent une fortune. Ce qui permet Ã  Apple dâ€™Ãªtre la boite la plus riche du monde en rÃ©utilisant le travail de personnes qui nâ€™ont pas fait Ã§a pour macOS Ã  la base.&lt;/p&gt;

&lt;p&gt;Les trois personnes intervenantes reprÃ©sentant chacune une SCOP, la table ronde sâ€™est ensuite naturellement tournÃ©e vers le lien entre le logiciel libre et le mouvement coopÃ©ratif. Le lien Ã©tant la vision politique du logiciel libre via son socle de valeurÂ : libertÃ©, transparence, gouvernance partagÃ©e et coopÃ©ration. On retrouve cet esprit de transparence, de fonctionnement dÃ©mocratique et de fonctionnement par coopÃ©ration Ã  lâ€™intÃ©rieur de la SCOP et entre les diffÃ©rentes SCOP.
Sâ€™en est ajoutÃ©e la question du sens par rapport Ã  son travail. Effectivement, le logiciel libre, comme le mouvement coopÃ©ratif, redonne du sens, principalement car cela ouvre le champ des possibles en vue des enjeux climatiques et sociaux actuels. MÃªme si lâ€™on vit dans une sociÃ©tÃ© qui est rÃ©gie par le profit, la compÃ©tition fÃ©roce et le pouvoir, il existe des possibilitÃ©s de sâ€™organiser autrement et qui fonctionne quand mÃªme Ã  une Ã©chelle consÃ©quente, bien quâ€™encore insuffisante. Des actions individuelles existent et sont possibles. Pour cela, nous vous recommandons de regarder &lt;a href=&quot;https://www.youtube.com/watch?v=XpY7p062zIo&amp;amp;list=PL3hoUDjLa7eSo7-CAyiirYfhJe4h_Wxs4&quot;&gt;la confÃ©rence dâ€™HÃ©lÃ¨ne&lt;/a&gt; Ã  lâ€™API Platform Conference de lâ€™annÃ©e derniÃ¨re quâ€™elle rÃ©sume et Ã©toffe lors de cette table ronde.&lt;/p&gt;

&lt;p&gt;Et bien sÃ»r, quand cela sera possible, nous vous encourageons fortement de regarder le replay de cette confÃ©rence (&lt;a href=&quot;https://www.youtube.com/c/Les-tilleulsCoop&quot;&gt;sur la chaine des Tilleuls&lt;/a&gt;) qui redonne un peu dâ€™espoir quant aux futurs des organisations dÃ©mocratiques de nos mÃ©tiers.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Merci Ã  toutes et tous les speakers, Ã  API Platform ainsi quâ€™aux Tilleuls-coop pour cet Ã©vÃ¨nement ! Nous avons pu en apprendre plus sur API Platform et revenir la tÃªte pleine dâ€™idÃ©es pour nos projets futurs et prÃ©sents ! Ã€ lâ€™annÃ©e prochaine peut-Ãªtre !&lt;/p&gt;</content><author><name>backend</name></author><category term="conferences" /><category term="backend" /><category term="api" /><category term="php" /><summary type="html">En cette pÃ©riode de rentrÃ©e, Bedrock participait Ã  lâ€™API Platform Conference 2022, oÃ¹ nous avons eu le plaisir dâ€™assister Ã  une partie des confÃ©rences proposÃ©es. Un grand merci Ã  toutes les personnes chez Les-Tilleuls.coop pour lâ€™organisation de cet Ã©vÃ¨nement ! Pour cette seconde Ã©dition, le programme Ã©tait rÃ©parti sur deux jours, les 15 &amp;amp; 16 septembre 2022.</summary></entry><entry><title type="html">Bedrock Dev Facts #18</title><link href="https://tech.bedrockstreaming.com/2022/10/07/bedrock-dev-facts-18.html" rel="alternate" type="text/html" title="Bedrock Dev Facts #18" /><published>2022-10-07T00:00:00+00:00</published><updated>2022-10-07T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/10/07/bedrock-dev-facts-18</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/10/07/bedrock-dev-facts-18.html">&lt;p&gt;Câ€™est maintenant lâ€™automne ğŸğŸƒ, on vous propose les devfacts de cette fin dâ€™Ã©tÃ© et il y a du lourd !&lt;/p&gt;

&lt;h1 id=&quot;cogito-ergo-sum&quot;&gt;Cogito ergo sum&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Le seul truc que je â€œsaisâ€ câ€™est â€œon paye 200 par mois pour avoir un direct connectâ€ ; mais peut-Ãªtre que je sais que je ne sais rien.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1&gt;ğŸ‘‹ğŸ”¥ğŸ™ŠğŸ‰&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Je te fais confiance, je te laisserai mettre des emoji sur ma tombe&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;la-prioritÃ©-cest-important&quot;&gt;La prioritÃ© câ€™est important&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Câ€™est plus important que des trucs moins importants.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;biafine-nÃ©cessaire&quot;&gt;Biafine nÃ©cessaire&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Un QA voulant faire une vanne au morning&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Le QA: â€œQuâ€™est-ce qui a deux lettres et qui marche pas?â€&lt;/p&gt;

  &lt;p&gt;RÃ©ponse du dev: â€œLa QA ?â€&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;3615-croissants&quot;&gt;3615 croissants&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Parlant dâ€™une Ã©volution majeure&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Est-ce que câ€™est OK pour vous pour quâ€™on MEP aujourdâ€™hui ou pas ?&lt;/p&gt;

  &lt;p&gt;Ã€ priori pas de contre-indications. Peut-Ãªtre acheter directement une boulangerie ?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;sugar-&quot;&gt;Sugar !&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Câ€™est du sucre syntaxique&lt;/p&gt;

  &lt;p&gt;Quand il y a trop de sucre, tu risques du diabÃ¨te&lt;/p&gt;

  &lt;p&gt;Surtout que le diabÃ¨te syntaxique, câ€™est le pire&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;la-metric&quot;&gt;LA metric&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Je crois quâ€™on est bon, on a pas plus dâ€™erreur que dâ€™user.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;le-verre-Ã -moitiÃ©-plein&quot;&gt;Le verre Ã  moitiÃ© plein&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Du coup Ã§a a cassÃ© je suppose?&lt;/p&gt;

  &lt;p&gt;Ouais, enfin pas totalement, presque un succÃ¨s.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;la-montagne-Ã§a-vous-gagne&quot;&gt;La montagne Ã§a vous gagne&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;En parlant de son ascension du Ventoux Ã  vÃ©lo:&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;â€œMoi je pensais vraiment que jâ€™Ã©tais prÃªtâ€&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;mais-pourquoi-&quot;&gt;Mais pourquoi ?&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Essayant de comprendre pourquoi une commande met beaucoup de temps sur sa machine.&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Je suis sur master, branche Ã  jour, yarn rÃ©alisÃ© juste avant, et je pense pas que mon PC soit particuliÃ¨rement atteint de maladie congÃ©nitale
(Enfin, jâ€™espÃ¨re pas?)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;read-me-please&quot;&gt;Read me please&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Tout est dans le README (que les gens liront pas de toute faÃ§on mais bon).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;les-Ã©toiles-ï¸&quot;&gt;Les Ã©toiles â­ï¸&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;ÃŠtre responsable dâ€™un incident, câ€™est pas marrant câ€™est sÃ»r. 
Mais Ã§a forme !
Casser la prod et la rÃ©parer Ã§a donne une Ã©toile sur le maillot, et je peux te dire quâ€™on est plusieurs ici Ã  avoir plus dâ€™Ã©toiles que le drapeau amÃ©ricain.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;review-main-dans-la-main&quot;&gt;Review main dans la main&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;La peer review, câ€™est la meilleure des reviews.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;patterns&quot;&gt;Patterns&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;A : â€œJe pense que je vais devoir faire un singleton pour Ã§aâ€¦â€&lt;/p&gt;

  &lt;p&gt;B : â€œSinon, tu devrais pouvoir aussi faire des multitons ?â€&lt;/p&gt;

  &lt;p&gt;C : â€œOn appelle Ã§a une boÃ®te de conserve.â€&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;à¶¸&quot;&gt;à¶¸&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Ã‡a devait Ãªtre en base64 des Maya&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;time-is-relative&quot;&gt;Time is relative&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Je pense que la premiÃ¨re fois ce sera long â€¦et aprÃ¨s ce ne sera pas long, mais ce sera long quand mÃªme.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;bim&quot;&gt;:bim:&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Alors lâ€™intelligence elle existe dÃ©jÃ , elle sâ€™appelle vous-mÃªmeâ€¦ mais actuellement elle nâ€™est pas disponible.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;ï¸&quot;&gt;â˜•ï¸&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Tu peux mettre autant de code brouette dans tes pull request que de sucre dans ton cafÃ© : Lâ€™important, câ€™est que Ã§a soit bien diluÃ©. 
Moi, je ne sucre pas mon cafÃ©.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;-1&quot;&gt;ğŸ”&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Normalement jâ€™utilise un vrai IDE. Mais je ne sais pas monter le zoom sur PHPStorm&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;encore-une-histoire-de-date&quot;&gt;Encore une histoire de date&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Câ€™est une fois par semaine, les releases mensuelles ?&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Bedrock</name></author><category term="devfacts" /><category term="humour" /><summary type="html">Câ€™est maintenant lâ€™automne ğŸğŸƒ, on vous propose les devfacts de cette fin dâ€™Ã©tÃ© et il y a du lourd !</summary></entry><entry><title type="html">Subtitles, open captions, closed captions, SDH, oh my!</title><link href="https://tech.bedrockstreaming.com/2022/09/20/captioning-in-the-streaming-world.html" rel="alternate" type="text/html" title="Subtitles, open captions, closed captions, SDH, oh my!" /><published>2022-09-20T00:00:00+00:00</published><updated>2022-09-20T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/09/20/captioning-in-the-streaming-world</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/09/20/captioning-in-the-streaming-world.html">&lt;h1 id=&quot;subtitles-open-captions-closed-captions-sdh-oh-my&quot;&gt;Subtitles, open captions, closed captions, SDH, oh my!&lt;/h1&gt;

&lt;p&gt;Wait, what? Subtitles and captions are not the same? Have you noticed the popular Â« cc Â» logo in a player you use, standing for Â« Closed Captions Â» but you have never heard of Open Captions? In this article we are going to dive into the different textual representations used in the streaming world.&lt;/p&gt;

&lt;h2 id=&quot;subtitles-vs-captions-a-matter-of-accessibility&quot;&gt;Subtitles vs Captions: a matter of accessibility&lt;/h2&gt;

&lt;p&gt;Since both terms are often mixed up, in this post we are going to explain in details the different types of subtitles and captions.&lt;/p&gt;

&lt;p&gt;Subtitles exist in order to help the viewer understand the spoken language in the content being watched, assuming that the viewer can hear. This is the important part. You can think of subtitles as the closest translation of what is being said, textually represented on the screen.&lt;/p&gt;

&lt;h3 id=&quot;closed-captions&quot;&gt;Closed Captions&lt;/h3&gt;

&lt;p&gt;Closed Captions on the other hand, assume that the viewer is deaf (or hard of hearing) hence cannot understand what is being said, regardless of the spoken language. For this reason and contrary to subtitles, it will describe spoken dialogues as well as all important audio information such as music, sounds, speaker information when it makes sense (for example narrated content). In terms of appearance, closed captions are usually white text on a black background. An important note is that they are not supported through digital connections such as HDMI.&lt;/p&gt;

&lt;p&gt;Subtitles and closed captions are separate files that provide information for the receiver to decode. Theyâ€™re not part of the stream and both can be turned off.&lt;/p&gt;

&lt;h3 id=&quot;subtitles-for-the-deaf-and-hard-of-hearing&quot;&gt;Subtitles for the Deaf and Hard of Hearing&lt;/h3&gt;

&lt;p&gt;Subtitles for the Deaf and Hard of Hearing, known as SDH, are a combination between subtitles and closed captions. They can be in the same language of the video original audio and bring some additional non-spoken information (speaker identification, sound effects, etc.) and/or be translated. This makes the content accessible for the deaf and hard of hearing who can read and understand foreign languages.&lt;/p&gt;

&lt;h3 id=&quot;open-captions&quot;&gt;Open Captions&lt;/h3&gt;

&lt;p&gt;The most important difference between Closed and Open Captions is that Open Captions are always visible and cannot be turned off. Think of them as Â« burned Â» in the video stream: they are not a separate file. Because of this, quality and readability may be affected. Open captions are widely used on social media for retention. Since there is a high chance that the end user is scrolling through content without sound, ensuring the display of text on the video helps catch and retain attention. In other cases where closed captions cannot be used for example if you have no control on the media player that will play your file, you may provide open captions to be sure to display a textual translation. The downside might be that part of the audience dislikes the superfluous text burned in the stream.&lt;/p&gt;

&lt;h3 id=&quot;forced-subtitles&quot;&gt;Forced subtitles&lt;/h3&gt;

&lt;p&gt;There is often a misconception around forced subtitles (sometimes referred as forced narratives) as they are mistaken with open captions. The name Â« forced Â» might suggest that they are burned in the video stream like open captions but there is a difference. Forced subtitles are actually distributed in a separate file and, despite their name, are not necessarily displayed. On our platform, if a subtitle or closed captions track is selected by the user, forced subtitles will not show up. We will come back to this later.&lt;/p&gt;

&lt;p&gt;Actually, forced subtitles are a text representation of a communication element like a spoken dialogue, specify a character ID that are not described in the original (or dubbed) audio stream. A common example would be to translate alien language. Despite watching a movie in your native (or any language that does not require you to activate subtitles), you would not be able to understand. Thatâ€™s where forced subtitles come into play and ensure that you have a textual representation of what is being said even if you set subtitles to off, hence the Â« forced Â» attribute.&lt;/p&gt;

&lt;p&gt;However, imagine you are French and watch a Spanish show for instance. If you set the subtitles to French in order to be able to understand the content, forced subtitles wonâ€™t show up since you already have a textual representation of the content. Same goes for closed captions: if set to off, forced subtitles will display, if any. Otherwise, they wonâ€™t show up. To ensure better user experience, forced subtitles content should be included in all other tracks (regular subtitles, SDH, CC).&lt;/p&gt;

&lt;p&gt;If available, forced subtitles should be displayed in the preferred language set up by the user.&lt;/p&gt;

&lt;p&gt;To sum up, here is a table comparing the different technologies:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Â &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Subtitles&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;SDH&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Closed Captions&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Open Captions&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Forced Subtitles&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Can be turned off&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;âœ”ï¸&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;âœ”ï¸&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;âœ”ï¸&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Â &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;*&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Appearance&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Varies&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Varies&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Usually white text / black background&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Varies&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Varies&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Position&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Bottom third, centered&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Bottom third, centered&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Varies&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Varies&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Bottom third, centered&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;HDMI Supported&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;âœ”ï¸&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;âœ”ï¸&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Â &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;âœ”ï¸&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;âœ”ï¸&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Describes music and sounds&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Â &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;âœ”ï¸&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;âœ”ï¸&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;âœ”ï¸&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Â &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Describes speaker ID&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Â &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;âœ”ï¸&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;âœ”ï¸&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;âœ”ï¸&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Â &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Available in source language&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Â &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;âœ”ï¸&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;âœ”ï¸&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;âœ”ï¸&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;âœ”ï¸&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;*: Forced subtitles do not show up in the track selection tool making them impossible to turn on or off. However, the business rules of the media platform will take care of displaying them, if needed.&lt;/p&gt;</content><author><name>Hugo Riffiod</name></author><category term="streaming" /><category term="subtitles" /><category term="captions" /><category term="video" /><category term="player" /><summary type="html">Subtitles, open captions, closed captions, SDH, oh my!</summary></entry><entry><title type="html">Monitoring at scale with Victoria Metrics</title><link href="https://tech.bedrockstreaming.com/2022/09/06/monitoring-at-scale-with-victoriametrics.html" rel="alternate" type="text/html" title="Monitoring at scale with Victoria Metrics" /><published>2022-09-06T00:00:00+00:00</published><updated>2022-09-06T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/09/06/monitoring-at-scale-with-victoriametrics</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/09/06/monitoring-at-scale-with-victoriametrics.html">&lt;h1 id=&quot;monitoring-at-bedrock-&quot;&gt;Monitoring at Bedrock :&lt;/h1&gt;
&lt;p&gt;At &lt;a href=&quot;https://www.bedrockstreaming.com/&quot;&gt;Bedrock Streaming&lt;/a&gt;, a large part of our applications are hosted on Kubernetes clusters, others use the EC2 service from AWS and a small part are hosted on â€œOnPremiseâ€ servers.&lt;/p&gt;

&lt;p&gt;From 2018 until January 2022, we used Prometheus to monitor all these platforms, because Prometheus met all our needs: keeping control over our monitoring solution and supporting service discovery, which is essential in environments such as Kubernetes or AWS EC2. Prometheus also supports custom exporters we developed internally.&lt;/p&gt;

&lt;p&gt;Over the years, our business has grown significantly, so the load on our platforms has increased. Indirectly, the load on our Prometheus instances has also increased, to the point where certain limitations have become too much for us. This is why we have changed our monitoring/alerting stack.&lt;/p&gt;

&lt;h1 id=&quot;limits-of-prometheus&quot;&gt;Limits of Prometheus&lt;/h1&gt;
&lt;p&gt;Prometheus does not have a native High Availability mode: to have high availability, we had to duplicate our Prometheus instances. This implies that our targets were â€œscrappedâ€ by all our Prometheus instances (same for our rules and records).
To avoid this, we had to use sharding, but this made the infrastructure more complex. More information on this subject in this &lt;a href=&quot;https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/high-availability.md&quot;&gt;documentation&lt;/a&gt; from the Prometheus operator&lt;/p&gt;

&lt;p&gt;Prometheus is not designed to store metrics on a long-term basis, as mentioned in the &lt;a href=&quot;https://prometheus.io/docs/prometheus/latest/storage/#operational-aspects&quot;&gt;documentation&lt;/a&gt; :&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&amp;gt; Prometheusâ€™s local storage is not intended to be durable long-term storage; external solutions offer extended retention and data durability.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Prometheusâ€™s local storage is not intended to be durable long-term storage; external solutions offer extended retention and data durability.
We worked around this limitation by using Victoria Metrics (VMCluster) as a LongTermStorage via the remote_write protocol&lt;/p&gt;

&lt;p&gt;All processes (scrapping, ingest, storage, etc.) were, until now, managed in the same â€œprometheusâ€ instance, which implied a less flexible and vertical scaling only (since recently a &lt;a href=&quot;https://prometheus.io/blog/2021/11/16/agent/&quot;&gt;Prometheus agent&lt;/a&gt; is available for the â€œscrappingâ€ part).&lt;/p&gt;

&lt;p&gt;The RAM and CPU usage of a Prometheus instance is correlated to the number of metrics (and their cardinality) it has to manage. In our case, several Prometheus instances consumed more than 64 GB of RAM and 26 CPUs each, in order to absorb our peak loads. In a Kubernetes cluster, this high resources consumption can cause problems, especially for scheduling.&lt;/p&gt;

&lt;p&gt;The Write-Ahead Log (WAL) system can cause rather slow restarts if the Prometheus instance runs out of RAM and can cause the Prometheus instance to hang for varying lengths of time. During the replay of the WAL, Prometheus doesnâ€™t scrape anything, thus there is no alerting and no way of knowing if something is going on.&lt;/p&gt;

&lt;h2 id=&quot;the-cardinality-of-metrics&quot;&gt;The cardinality of metrics&lt;/h2&gt;
&lt;p&gt;When our Kubernetes clusters manage a large number of pods, a constraint quickly appears: cardinality.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&amp;gt; The cardinality of a metric is the number of TimeSeries of that metric with single-valued labels.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/cardinality-example.png&quot; alt=&quot;schema of cardinality&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the example above, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;status_code&lt;/code&gt; label has a cardinality of 5, app has a cardinality of 2 and the overall cardinality of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;server_reponses&lt;/code&gt; metric is 10.&lt;/p&gt;

&lt;p&gt;In this example, any Prometheus instance can handle this cardinality, but if you add for example the label &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pod_name&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;client_IP&lt;/code&gt; (or both) to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;server_reponses&lt;/code&gt; metric, the cardinality increases for each different clients calls and for each pod.&lt;/p&gt;

&lt;p&gt;You should read the excellent &lt;a href=&quot;https://www.robustperception.io/cardinality-is-key/&quot;&gt;article&lt;/a&gt; from â€œRobust Perceptionâ€ for more details on this subject.&lt;/p&gt;

&lt;p&gt;At Bedrock the high cardinality metrics come from our HAProxy ingress. For our needs, we retrieve several labels like the name of the ingress pod as well as its IP address, but more importantly the name and IP address of the destination pod. In a cluster that can grow to more than 15,000 pods, the combination of unique labels (cardinality) is very significant for some of our ingress metrics.&lt;/p&gt;

&lt;p&gt;We found that Prometheus performed poorly when we had multiple metrics with high cardinalities (&amp;gt; 100,000), and resulted in over-consumption of RAM.&lt;/p&gt;

&lt;p&gt;During a high load event, Prometheus could consume up to 200 GB of RAM before being OOMKilled. When this happened, we would go completely blind as we had no metrics or alerting.
This also impacts us on scalability in our Kubernetes clusters, as we use &lt;a href=&quot;https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#scaling-on-custom-metrics&quot;&gt;CustomMetrics&lt;/a&gt; very heavily in HPAs to scale the number of pods in our applications.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;RAM and CPU consumption of our prometheus instances (the red lines represent the reboots of our instances, we also see a loss of metrics)&lt;/em&gt;
&lt;img src=&quot;/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/prometheus-ram.png&quot; alt=&quot;RAM consumption of prometheus &quot; /&gt;
&lt;img src=&quot;/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/prometheus-cpu.png&quot; alt=&quot;RAM consumption of prometheus &quot; /&gt;&lt;/p&gt;

&lt;p&gt;Prometheus is still a good solution, which has served its purpose well for several years, but we have reached its limits in our production environments.&lt;/p&gt;

&lt;h1 id=&quot;replacing-prometheus&quot;&gt;Replacing Prometheus?&lt;/h1&gt;

&lt;p&gt;We spent time optimizing Prometheus to absorb the amount of metrics and their cardinality, in particular by either directly removing high cardinality metrics if they were totally unused, or by removing the labels of certain metrics that caused high cardinalities.
We have also optimized the Prometheus configuration directly, as well as the maximum IOPS of our EBS. The RAM and CPU consumption of Prometheus is linked to the number of metrics to manage and their cardinality. But we always have more traffic and therefore always more pods in our clusters: we should have perpetually increased Prometheus instances resources. This was a problem for scalability and costs.&lt;/p&gt;

&lt;p&gt;Can we replace a critical tool like this? What are our short, medium and long term needs? How can we optimize costs? And especially in what timeframe?
The emergency of recent incidents forced us to exclude solutions such as &lt;a href=&quot;https://thanos.io/&quot;&gt;Thanos&lt;/a&gt; and &lt;a href=&quot;https://cortexmetrics.io/&quot;&gt;Cortex&lt;/a&gt;. Testing these solutions completely would have required too much time, which we did not have.&lt;/p&gt;

&lt;p&gt;It is also important to consider that we were already using Victoria Metrics, but only for the Long Term Storage part, without any problems.
Could replacing Prometheus with a stack based entirely on Victoria Metrics overcome the limitations we had with Prometheus?
High availability and fault tolerance is well-supported, their &lt;a href=&quot;https://docs.victoriametrics.com/guides/k8s-ha-monitoring-via-vm-cluster.html&quot;&gt;documentation&lt;/a&gt; explains how to manage this.&lt;/p&gt;

&lt;p&gt;Managing long-term data is possible, as we were already doing it.
Victoria Metrics is built around a set of microservices. Each one is built in order to serve a specific job, and each supports vertical and especially horizontal scaling (with sharding). A very important point when used in a Kubernetes environment.&lt;/p&gt;

&lt;p&gt;In addition, Victoria Metrics seemed to handle high cardinality metrics better (see &lt;a href=&quot;https://valyala.medium.com/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b&quot;&gt;article&lt;/a&gt; on this subject). It is also possible to do &lt;a href=&quot;https://docs.victoriametrics.com/vmagent.html#cardinality-limiter&quot;&gt;rate limiting&lt;/a&gt; on the number of Time Series to be ingested:&lt;/p&gt;

&lt;p&gt;CPU and RAM consumption is lower with better performance than with Prometheus and even other TSDBs, several comparative articles on this subject have already been published:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://promcon.io/2019-munich/talks/remote-write-storage-wars/&quot;&gt;Remote Write Storage Wars&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f&quot;&gt;Prometheus vs VictoriaMetrics benchmark on node_exporter metrics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://valyala.medium.com/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4&quot;&gt;When size matters â€” benchmarking VictoriaMetrics vs Timescale and InfluxDB&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/faun/comparing-thanos-to-victoriametrics-cluster-b193bea1683&quot;&gt;Comparing Thanos to VictoriaMetrics cluster&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We also wanted to keep the Prometheus language: &lt;a href=&quot;https://prometheus.io/docs/prometheus/latest/querying/basics/&quot;&gt;PromQL&lt;/a&gt; in order to keep our Grafana dashboards and all our Prometheus alerts. Even though Victoria Metrics offers its own MetricsQL language, it is perfectly compatible with PromQL.&lt;/p&gt;

&lt;p&gt;You can see the &lt;a href=&quot;https://docs.victoriametrics.com/#prominent-features&quot;&gt;main features&lt;/a&gt; of Victoria Metrics as well as various &lt;a href=&quot;https://docs.victoriametrics.com/#case-studies-and-talks&quot;&gt;case studies&lt;/a&gt; in their documentation.&lt;/p&gt;

&lt;h1 id=&quot;poc-of-victoria-metrics&quot;&gt;POC of Victoria Metrics&lt;/h1&gt;
&lt;p&gt;We wanted to validate the performance and consumption of a stack entirely based on Victoria Metrics, the results were really encouraging.&lt;/p&gt;

&lt;p&gt;Test environment :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;1500 web app pods&lt;/li&gt;
  &lt;li&gt;250 Haproxy Ingress pods (metric with high cardinality enabled)&lt;/li&gt;
  &lt;li&gt;3700 scrapped targets&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Comparative table between Prometheus and Victoria Metrics :&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Â &lt;/th&gt;
      &lt;th&gt;Prometheus&lt;/th&gt;
      &lt;th&gt;Victoria Metrics&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;CPU consumption&lt;/td&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;RAM consumption&lt;/td&gt;
      &lt;td&gt;30Go&lt;/td&gt;
      &lt;td&gt;11Go&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;New TimeSeries / min&lt;/td&gt;
      &lt;td&gt;50K&lt;/td&gt;
      &lt;td&gt;6.5M&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Max active TimeSeries&lt;/td&gt;
      &lt;td&gt;7M&lt;/td&gt;
      &lt;td&gt;91M&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Max cardinality&lt;/td&gt;
      &lt;td&gt;4 metrics &amp;gt; 100K&lt;/td&gt;
      &lt;td&gt;10+ metrics &amp;gt; 1M&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;Graph on the CPU consumption of Victoria Metrics components&lt;/em&gt;
&lt;img src=&quot;/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/cpu-poc-vm.png&quot; alt=&quot;cpu-usage-poc-vm&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Number of active â€œTimeSeriesâ€ in Victoria Metrics&lt;/em&gt;
&lt;img src=&quot;/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/active-ts-poc-vm.png&quot; alt=&quot;active-ts-poc-vm&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Our benchmark persuaded us to use Victoria Metrics as a replacement for Prometheus.&lt;/p&gt;

&lt;h1 id=&quot;implementation-of-victoria-metrics-&quot;&gt;Implementation of Victoria Metrics :&lt;/h1&gt;
&lt;p&gt;We used the official &lt;a href=&quot;https://github.com/VictoriaMetrics/helm-charts/blob/master/charts/victoria-metrics-k8s-stack/README.md&quot;&gt;victoria-metrics-k8s-stack&lt;/a&gt; Helm chart which is based on an &lt;a href=&quot;https://github.com/VictoriaMetrics/helm-charts/tree/master/charts/victoria-metrics-operator&quot;&gt;operator&lt;/a&gt;. This chart Helm permits to deploy a complete monitoring and alerting stack in a Kubernetes cluster.&lt;/p&gt;

&lt;p&gt;A VMCluster (Insert, Select, Storage) is deployed to manage access to metrics. The collection of metrics (push/pull) from exporters in Prometheus format is handled by the VMagent. Its configuration is done in the form of a Prometheus configuration file. It is able to :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Manage the relabeling of metrics.&lt;/li&gt;
  &lt;li&gt;Temporarily store the metrics it has collected if the VMCluster is unavailable or not able to send the metrics to the VMCluster.&lt;/li&gt;
  &lt;li&gt;Limit the cardinality of metrics.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One of the advantages of using this Helm chart is that it will deploy essential components to properly monitor a Kubernetes cluster such as Kube-state-metrics or prometheus-node-exporter, but also scraping configurations for services such as Kubelet, KubeApiServer, KubeControllerManager, KubeDNS, KubeEtcd, KubeScheduler, KubeProxy&lt;/p&gt;

&lt;p&gt;Alerting is also managed via a VMAlert component, which will execute the alerting and recording rules set by VictoriaMetrics. Notifications are managed by an Alertmanager which is also deployable via this chart.&lt;/p&gt;

&lt;p&gt;One of the advantages of using this Helm chart is that it will deploy essential components to properly monitor a Kubernetes cluster such as &lt;em&gt;Kube-state-metrics&lt;/em&gt; or &lt;em&gt;prometheus-node-exporter&lt;/em&gt;, but also scraping configurations for services such as &lt;em&gt;Kubelet, KubeApiServer, KubeControllerManager, KubeDNS, KubeEtcd, KubeScheduler, KubeProxy&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This is what our monitoring and alerting stack based on this Helm chart looks like.&lt;/em&gt;
&lt;img src=&quot;/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/stack-vm.png&quot; alt=&quot;stack-vm&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;resumption-of-the-history&quot;&gt;Resumption of the history&lt;/h1&gt;
&lt;p&gt;We wanted to keep historical metrics of our Kubernetes clusters. Victoria Metrics provides a tool to manage the export and import of data from different TSDB: &lt;a href=&quot;https://docs.victoriametrics.com/vmctl.html&quot;&gt;vmctl&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In order not to overload our monitoring stack, we splitted the exports into smaller or larger time ranges, depending on the history of the cluster. For clusters with little activity and therefore few metrics, exports/imports were split day by day, for others we had to use smaller time slots.
A home-made bash script launched several kubernetes jobs simultaneously and took care of restarting one of them as soon as another one ended.&lt;/p&gt;

&lt;p&gt;Below an extract of the definition of our Kubernetes job with the arguments we used to do our history transfer by time range:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;vmctl&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;victoriametrics/vmctl&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;1&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;vm-native&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--vm-native-src-addr=http://victoria-metrics-cluster-vmselect.monitoring.svc.cluster.local.:8481/select/001/prometheus&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--vm-native-dst-addr=http://vminsert-victoria-metrics-k8s-stack.monitoring.svc.cluster.local.:8480/insert/000/prometheus&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--vm-native-filter-match={__name__!~&quot;_vm.*&quot;}&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--vm-native-filter-time-start=&quot;{ { start } }&quot;&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--vm-native-filter-time-end=&quot;{ { end } }&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;restartPolicy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Never&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;feedback-after-months-of-use&quot;&gt;Feedback after months of use&lt;/h1&gt;
&lt;p&gt;Since we have been using our new monitoring stack, we have encountered a few bugs (as with all solutions).
Most of the time, these were not impactful, except for one that caused us a production incident.
We had an overconsumption of RAM of VMStorage which was fixed in version 1.76. I would like to highlight the responsiveness of the VictoriaMetrics team, whether on slack or on GitHub: I have had several discussions with them on various subjects, and they have always been reactive&lt;/p&gt;

&lt;p&gt;Victoria Metrics regularly releases new versions, including performance improvements and new features. The &lt;a href=&quot;https://docs.victoriametrics.com/CHANGELOG.htm&quot;&gt;changelog&lt;/a&gt; will give you an idea of the latest improvements and their frequency.&lt;/p&gt;

&lt;p&gt;Victoria Metrics has an &lt;a href=&quot;https://victoriametrics.com/products/enterprise/&quot;&gt;Enterprise&lt;/a&gt; version that adds some features, including one that we are interested in but have not yet tested: downsampling.
We have configured a one-year retention for each of our Kubernetes clusters, and on some clusters thatâ€™s mean more than 7 TB of data per VMStorage.&lt;/p&gt;

&lt;p&gt;The downsampling allows you to configure how many metrics you want to keep per time interval.&lt;/p&gt;

&lt;p&gt;In this example: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-downsampling.period=24h:10s,1w:30s,30d:1m,360d:5m&lt;/code&gt;, (assuming we collect metrics every 5 seconds) we only keep:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;one measurement point every 10 seconds beyond 24 hours (instead of one point every 5 seconds)&lt;/li&gt;
  &lt;li&gt;one measurement point every 30 seconds beyond 7 days&lt;/li&gt;
  &lt;li&gt;one measurement point every minute beyond 30 days&lt;/li&gt;
  &lt;li&gt;one measurement point every 5 minutes beyond one year&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It is rarely necessary to keep all the measurements of our metrics on such a long scale, when we want to retrieve measurements that are several months old, it is usually to see a trend and not all the measurements.
With this option, we could greatly reduce the storage used by our metrics.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Through this article, you have discovered why and how we migrated our monitoring stack of our Kubernetes clusters at Bedrock from Prometheus to Victoria Metrics.&lt;/p&gt;

&lt;p&gt;This was an important and critical subject for us, as monitoring is a critical need.
Now our monitoring stack, based entirely on Victoria Metrics, is robust and capable of absorbing large load peaks.&lt;/p&gt;

&lt;p&gt;Here are some indicators of the victoria metrics stack performance of one of our Kubernetes clusters during last 6 months:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;active time series: up to 39 million (average 7.4M)&lt;/li&gt;
  &lt;li&gt;total number of datapoints: 12 trillion&lt;/li&gt;
  &lt;li&gt;ingestion rate : up to 1.3 million new samples per second (average 227K)&lt;/li&gt;
  &lt;li&gt;churn rate : up to 117 Million new time series per day (average 30.6 Million)&lt;/li&gt;
  &lt;li&gt;disk usage (data + index): 15 TB&lt;/li&gt;
  &lt;li&gt;sample rate : up to 4.99M (average 343K)&lt;/li&gt;
  &lt;li&gt;scrape target : up to 49K (average 4.4K)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/total-datapoint-vm-last-6m.png&quot; alt=&quot;total-datapoint-vm-last-6m&quot; /&gt;
&lt;img src=&quot;/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/active-ts-vm-last-6m.png&quot; alt=&quot;active-ts-vm-last-6m&quot; /&gt;
&lt;img src=&quot;/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/ingestion-rate-vm-last-6m.png&quot; alt=&quot;ingestion-rate-vm-last-6m&quot; /&gt;
&lt;img src=&quot;/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/cpu-usage-vm-last-6m.png&quot; alt=&quot;cpu-usage-vm-last-6m&quot; /&gt;
&lt;img src=&quot;/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/ram-usage-vm-last-6m.png&quot; alt=&quot;ram-usage-vm-last-6m&quot; /&gt;
&lt;img src=&quot;/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/churn-rate-vm-last-6m.png&quot; alt=&quot;churn-rate-vm-last-6m&quot; /&gt;
&lt;img src=&quot;/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/sample-rate-vm-last-6m.png&quot; alt=&quot;sample-rate-vm-last-6m&quot; /&gt;
&lt;img src=&quot;/images/posts/2022-09-06-monitoring-at-scale-with-victoriametrics/scrape-target-vm-last-6m.png&quot; alt=&quot;scrape-target-vm-last-6m&quot; /&gt;&lt;/p&gt;</content><author><name>Julien Menan</name></author><category term="k8s" /><category term="kubernetes" /><category term="monitoring" /><category term="prometheus" /><category term="scaling" /><category term="victoriametrics" /><category term="cardinality" /><summary type="html">Monitoring at Bedrock : At Bedrock Streaming, a large part of our applications are hosted on Kubernetes clusters, others use the EC2 service from AWS and a small part are hosted on â€œOnPremiseâ€ servers.</summary></entry><entry><title type="html">Is machine learning a unicorn hiding a series of if and else?</title><link href="https://tech.bedrockstreaming.com/2022/09/05/machine-learning-if-else.html" rel="alternate" type="text/html" title="Is machine learning a unicorn hiding a series of if and else?" /><published>2022-09-05T00:00:00+00:00</published><updated>2022-09-05T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/09/05/machine-learning-if-else</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/09/05/machine-learning-if-else.html">&lt;p&gt;Recently, a colleague asked me:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;All good with your if and else machine learning system?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It was a joke but this one made me think.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This is a running gag: machine learning is only a series of if and else.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-09-05-machine-learning-if-else/unicorn_forest.jpg&quot; alt=&quot;unicorn in the forest&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Beyond the joke, it is true?&lt;/p&gt;

&lt;p&gt;Yes! â€¦and no. As always, it depends.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Quick answer&lt;/strong&gt;: Machine learning is a bunch of mathematical and statistical operations. Sometimes, the operations you use can be translated into &lt;em&gt;if&lt;/em&gt; and &lt;em&gt;else&lt;/em&gt; clauses, and sometimes not. But you never write the series of &lt;em&gt;if&lt;/em&gt; and &lt;em&gt;else&lt;/em&gt; yourself.&lt;/p&gt;

&lt;h2 id=&quot;a-recap-of-machine-learning&quot;&gt;A recap of machine learning&lt;/h2&gt;
&lt;p&gt;The idea of machine learning is: you have some data, and you apply an algorithm to these to detect a pattern. You put this pattern into a function.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-09-05-machine-learning-if-else/ML%20recap.png&quot; alt=&quot;machine learning representation schema&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Then, youâ€™ll be able to use this function on new data to extract new information.&lt;/p&gt;

&lt;h2 id=&quot;a-decision-tree-with-a-series-of-if-and-else&quot;&gt;A decision tree with a series of if and else&lt;/h2&gt;

&lt;p&gt;There are different types of machine learning. If you decide to build a decision tree (a famous way to do machine learning) to know the form of a diamond, youâ€™ll get something like that:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-09-05-machine-learning-if-else/decision_tree.png&quot; alt=&quot;decision tree&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If you translate it with code, youâ€™ll get something like that:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carat&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diamond&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;red&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plate&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;red&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plate&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grey&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pentagon&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Then, yes, you can see that here, you have a series of &lt;em&gt;if&lt;/em&gt; and &lt;em&gt;else&lt;/em&gt;.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;And decision trees are used a lot in machine learning. Most of the time, you donâ€™t use decision trees directly but forests of decision trees in the Random Forest algorithm or a series of decision trees in the Gradient Boosted Trees algorithm.&lt;/p&gt;

&lt;h2 id=&quot;but-many-algorithms-in-machine-learning-are-just-the-generation-of-plain-mathematical-formulas&quot;&gt;But, many algorithms in machine learning are just the generation of plain mathematical formulas&lt;/h2&gt;

&lt;p&gt;Letâ€™s take another famous way to do machine learning: a neural network. What youâ€™ll get at the end is more something like that:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;a*10+b*15+c*16+20â€¦
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then, the process doesnâ€™t try to find a series of &lt;em&gt;if&lt;/em&gt; and &lt;em&gt;else&lt;/em&gt;, but a mathematical formula.&lt;/p&gt;

&lt;p&gt;I would like to finish with a last example: recommender systems. There are many ways to build a recommendation system. One which is well known is matrix factorization.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Matrix factorization, what?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I wonâ€™t explain deeply what it is about, but as a sum up, itâ€™s a manipulation of matrices. It comes from linear algebra.
Here is a definition: &lt;a href=&quot;https://en.wikipedia.org/wiki/Matrix_decomposition&quot;&gt;Matrix decomposition&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The result is something like that:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Vector A * Vector B
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;As a result, yes, you have types of machine learning that will generate a series of &lt;em&gt;if&lt;/em&gt; and &lt;em&gt;else&lt;/em&gt;. But, you have also plenty of algorithms that try to find the variables of an equation or vectors.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;you-never-write-the-series-of-if-and-else-yourself&quot;&gt;You never write the series of if and else yourself&lt;/h2&gt;

&lt;p&gt;Letâ€™s go back to the decision tree. As youâ€™ve seen previously, the result could be translated as a series of &lt;em&gt;if&lt;/em&gt; and &lt;em&gt;else&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;But, you donâ€™t write directly this code. You generate it usingâ€¦ mathematical operations. Yes, again!&lt;/p&gt;

&lt;p&gt;As an example, you can get the result of a decision tree using an optimisation algorithm with the Shannon Entropy formula:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-09-05-machine-learning-if-else/formula.png&quot; alt=&quot;shannon entropy formula&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Letâ€™s suppose you want to guess the form (pentagon or plate) of a diamond according to its attributes. You have three diamonds:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;carat&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;size&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;form&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;high&lt;/td&gt;
      &lt;td&gt;small&lt;/td&gt;
      &lt;td&gt;plate&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;low&lt;/td&gt;
      &lt;td&gt;high&lt;/td&gt;
      &lt;td&gt;plate&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;low&lt;/td&gt;
      &lt;td&gt;small&lt;/td&gt;
      &lt;td&gt;pentagon&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The process is the following:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;The data is split randomly: a random &lt;em&gt;if&lt;/em&gt; statement is created like &lt;em&gt;if carat is high&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;The process checks if it helps to generate a more accurate view of the data: by doing this &lt;em&gt;if&lt;/em&gt;, are the data separated correctly? Do we have pentagons mostly from one side and plates from another?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;To be able to know if the data are separated correctly, the Shannon entropy formula is used&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;if yes, the process keeps the &lt;em&gt;if carat is high&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;if not, it generates another one&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Then, by keeping the &lt;em&gt;if&lt;/em&gt; you get something like that:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-09-05-machine-learning-if-else/decision_tree_first_step.png&quot; alt=&quot;decision tree - first step&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The translation with a code is:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carat&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diamond&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;red&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plate&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;#The process doesn&apos;t know yet how to handle that
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that you have a branch (below &lt;em&gt;low&lt;/em&gt;) with a plate and a pentagon. It corresponds to the &lt;em&gt;else&lt;/em&gt; where the process doesnâ€™t know what to put yet.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;So, the data below &lt;em&gt;low&lt;/em&gt; is split randomly: another &lt;em&gt;if&lt;/em&gt; is created&lt;/li&gt;
  &lt;li&gt;The process checks if it helps to generate a more accurate view of the data&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;if yes, the process keeps the new &lt;em&gt;if&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;if not, it generates another one&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;By keeping the new &lt;em&gt;if&lt;/em&gt;, you get another branch:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-09-05-machine-learning-if-else/decision_tree_second_step.png&quot; alt=&quot;decision tree - second step&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The translation with a code is:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;red&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plate&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grey&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pentagon&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;At the end, you get a final tree decision:
&lt;img src=&quot;/images/posts/2022-09-05-machine-learning-if-else/decision_tree_final.png&quot; alt=&quot;decision tree - final&quot; /&gt;&lt;/p&gt;

&lt;p&gt;with a final code:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carat&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diamond&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;red&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plate&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;red&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plate&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grey&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pentagon&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Of course, in real life, data are more complicated and the process must iterate a lot until getting the perfect tree. The process used is an optimisation algorithm. This is the part called &lt;em&gt;learning&lt;/em&gt; in machine learning.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Mathematical optimization [â€¦] is the selection of a best element, with regard to some criterion, from some set of available alternatives (definition from Wikipedia)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;If you want to know how the Shannon entropy works with mathematical formulas, youâ€™ve got this article: &lt;a href=&quot;https://medium.zenika.com/classification-in-machine-learning-example-of-decision-tree-with-shannon-entropy-945fc8e2a3fb&quot;&gt;Classification in machine learning - Example of Decision Tree with Shannon Entropy&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Then as a result, yes, you can have machine learning algorithms that will build a series of &lt;em&gt;if&lt;/em&gt; and &lt;em&gt;else&lt;/em&gt;. But to generate it, youâ€™ll use mathematical operations.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note that for other algorithms such as the matrix factorisation or neural networks, you donâ€™t use a process with the Shannon entropy formula, but other optimisation algorithms that donâ€™t generate a series of if and else but, as previously seen, vectors or formulas.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;so-why-do-we-sometimes-say-that-machine-learning-is-a-bunch-of-if-and-else-statements&quot;&gt;So why do we sometimes say that machine learning is a bunch of if and else statements?&lt;/h2&gt;

&lt;p&gt;To my opinion, because of expert systems. They are the ancestors of machine learning in artificial intelligence.&lt;/p&gt;

&lt;p&gt;Artificial intelligence is a way to simulate human cognitive abilities. In the history of artificial intelligence, people thought that they would be able to target that with expert systems. These are big series of hardcoded rules and thenâ€¦ of &lt;em&gt;if&lt;/em&gt; and &lt;em&gt;else&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;To conclude, most of the time, machine learning is not a series of &lt;em&gt;if&lt;/em&gt; and &lt;em&gt;else&lt;/em&gt;. Itâ€™s just mathematics and for some techniques, they are very old. Iâ€™m thinking of linear regressions or Bayesian probabilities. These were used long before the existence of computers.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Photo of the unicorn by &lt;a href=&quot;https://unsplash.com/@stephenleo1982?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&quot;&gt;Stephen Leonardi&lt;/a&gt; on &lt;a href=&quot;https://unsplash.com/s/photos/unicorn?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&quot;&gt;Unsplash&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</content><author><name>Nastasia Saby</name></author><category term="machine learning" /><category term="Data Science" /><summary type="html">Recently, a colleague asked me:</summary></entry><entry><title type="html">Using a circuit breaker to spare the API we are calling</title><link href="https://tech.bedrockstreaming.com/2022/09/02/backend-circuit-breaker.html" rel="alternate" type="text/html" title="Using a circuit breaker to spare the API we are calling" /><published>2022-09-02T00:00:00+00:00</published><updated>2022-09-02T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/09/02/backend-circuit-breaker</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/09/02/backend-circuit-breaker.html">&lt;p&gt;Hi! Weâ€™re going to start our &lt;a href=&quot;#from-the-same-series&quot;&gt;fourth article&lt;/a&gt; about Bedrockâ€™s API gateway.
Today we will talk about the circuit breaker pattern, what it is, and how weâ€™re using it.&lt;/p&gt;

&lt;h2 id=&quot;the-circuit-breaker-pattern&quot;&gt;The Circuit Breaker Pattern&lt;/h2&gt;

&lt;p&gt;With this pattern, our API Gateway detects errors when calling its dependencies.
It will stop calling them if a given threshold (ratio of errors) is crossed.&lt;/p&gt;

&lt;p&gt;The circuit breaker allows us to spare the dependencies in difficulty, but also avoid taking time to do something that will most likely fail.&lt;/p&gt;

&lt;p&gt;Youâ€™ll find a more detailed explanation about the circuit breaker on Martin FOWLERâ€™s &lt;a href=&quot;https://martinfowler.com/bliki/CircuitBreaker.html&quot;&gt;blog&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;where-to-use-it&quot;&gt;Where to use it?&lt;/h2&gt;

&lt;p&gt;As soon as a service call is not mandatory for our BFF to answer something that a frontend application can read, then we can use the circuit breaker pattern.&lt;/p&gt;

&lt;p&gt;If an API cannot handle a sudden increase in traffic (for example: itâ€™s not scaling fast enough or its database starts to throttle), itâ€™s better to stop calling it temporarily.
When the right timeouts are configured, an API throttling will result in an error, as seen &lt;a href=&quot;/2022/08/25/backend-errors-connections.html&quot;&gt;in the previous article&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here are some examples:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Video progress information&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Displaying a video progress bar is useful for end users, but itâ€™s better to not display this information instead of risking the entire page to not be displayed!
If the service that stores video viewing sessions is (slowing) down, we can stop asking for this information and stop displaying the video progress bar.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-09-02-backend-circuit-breaker/progress-bar.png&quot; alt=&quot;a video with a progress bar&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;User geolocation&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The geolocation service allows us to know where the end user is in the world. Based on this information we lock some area restricted contents.
If this service goes down for some reason, we will stop calling it, and instead use a default area matching the area of our customer as itâ€™s the majority case.&lt;/p&gt;

&lt;h2 id=&quot;implementation-and-configuration&quot;&gt;Implementation and configuration&lt;/h2&gt;

&lt;p&gt;So far weâ€™re only using the circuit breaker pattern with HTTP calls.
This is made possible thanks to the &lt;a href=&quot;https://github.com/ackintosh/ganesha&quot;&gt;Ganesha library&lt;/a&gt;, and its Guzzle middleware.&lt;/p&gt;

&lt;p&gt;The Guzzle middleware is created as a service within the Symfony service definitions.
Itâ€™s then injected into our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HttpClientFactory&lt;/code&gt; that will handle the creation of all the different clients.
The responsibility of using the circuit breaker falls on each service that will create a http client.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;Ackintosh\Ganesha\GuzzleMiddleware&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;factory&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;@...Infrastructure\HttpClient\CircuitBreaker\CircuitBreakerMiddlewareFactory&apos;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;buildWithRateStrategy&apos;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;arguments&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;$timeWindow&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;60&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;$failureRateThreshold&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;40&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;$minimumRequests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;$intervalToHalfOpen&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;60&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;monitoring-the-circuit-breaker&quot;&gt;Monitoring the circuit breaker&lt;/h2&gt;

&lt;p&gt;At Bedrock, weâ€™re used to monitor everything. The circuit breaker makes no exception to this rule.
Usually we store time spent and response code for every outgoing http call.
To see when the circuit breaker is open, we catch the ganeshaâ€™s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RejectedException&lt;/code&gt; to save a dedicated &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;666&lt;/code&gt; http status.&lt;/p&gt;

&lt;p&gt;This allows us to look for the exact number of calls avoided.
Below lies an example of a monitoring chart showing some errors happening during a usual night.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-09-02-backend-circuit-breaker/monitoring-1.png&quot; alt=&quot;monitoring excluding less reliable services&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We also have to query slower services that often trigger our circuit breaker because they cannot answer in the short timeout we impose.
Thereafter, the same monitoring chart including such services.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-09-02-backend-circuit-breaker/monitoring-2.png&quot; alt=&quot;monitoring including less reliable service&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;going-further&quot;&gt;Going further&lt;/h2&gt;

&lt;p&gt;So far, we have identified two areas for improvements described below.&lt;/p&gt;

&lt;h3 id=&quot;different-configurations&quot;&gt;Different configurations&lt;/h3&gt;

&lt;p&gt;Weâ€™re only using a single configuration for the circuit breaker.
We should allow each service to choose from a named list of configurations when creating a client, &lt;a href=&quot;/2022/08/25/backend-errors-connections.html&quot;&gt;similarly to the different guzzle configuration we are using&lt;/a&gt;.
The main obstacle is a lack of hindsight which prevent us to have fine-tuned values.
This is something that will definitively be improved over time as we monitor over long period.&lt;/p&gt;

&lt;h3 id=&quot;staled-cache-when-the-circuit-breaker-is-open&quot;&gt;Staled cache when the circuit breaker is open&lt;/h3&gt;

&lt;p&gt;For many editorial contents, weâ€™re using a staled cache version of the data as a fallback.
To do so, weâ€™re using &lt;a href=&quot;https://github.com/Kevinrob/guzzle-cache-middleware&quot;&gt;another guzzle middleware&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Sadly, the two middlewares donâ€™t work together. We have to chose which one to use based on the criticality of the content and the API behind. 
This is something that we aim at solving with a bit of R&amp;amp;D.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In todayâ€™s post weâ€™ve seen our usage of the circuit breaker pattern.
It allows us to spare the services we are calling, and avoid slowing us down in case of throttling.&lt;/p&gt;

&lt;p&gt;Next time, we will talk about our ultimate layer of protection to ensure the BFF always responds something readable to frontend applications.&lt;/p&gt;

&lt;h2 id=&quot;from-the-same-series&quot;&gt;From the same series&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;/2022/06/10/backend-bff-intro.html&quot;&gt;Whatâ€™s a BFF&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2022/08/12/backend-fallbacks.html&quot;&gt;Handling API failures in a gateway&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2022/08/25/backend-errors-connections.html&quot;&gt;Whatâ€™s an error, and handling connexion to multiple APIs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2022/09/02/backend-circuit-breaker.html&quot;&gt;Using a circuit breaker&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Valentin CLARAS</name></author><category term="backend" /><category term="php" /><category term="api" /><category term="api-gateway" /><category term="back-for-front" /><category term="resiliency" /><category term="circuit-breaker" /><summary type="html">Hi! Weâ€™re going to start our fourth article about Bedrockâ€™s API gateway. Today we will talk about the circuit breaker pattern, what it is, and how weâ€™re using it.</summary></entry><entry><title type="html">Prescaling pods in Kubernetes, we open source our solution</title><link href="https://tech.bedrockstreaming.com/2022/09/01/kubernetes-prescaling-we-open-source-our-solution.html" rel="alternate" type="text/html" title="Prescaling pods in Kubernetes, we open source our solution" /><published>2022-09-01T00:00:00+00:00</published><updated>2022-09-01T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/09/01/kubernetes-prescaling-we-open-source-our-solution</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/09/01/kubernetes-prescaling-we-open-source-our-solution.html">&lt;p&gt;Previously we &lt;a href=&quot;https://tech.bedrockstreaming.com/2022/02/03/prescaling.html&quot;&gt;discussed&lt;/a&gt; how we manage the load of our Kubernetes clusters and how we can anticipate our needs with prescaling. Today, we are here to share our solution that we have reworked and open sourced! 
&lt;img src=&quot;/images/posts/2022-09-01-kubernetes-prescaling-we-open-source-our-solution/br-opensource.png&quot; alt=&quot;BedrockStreaming Logo&quot; /&gt;&lt;/p&gt;

&lt;p&gt;At &lt;a href=&quot;https://www.bedrockstreaming.com/&quot;&gt;Bedrock Streaming&lt;/a&gt;, we provide streaming platforms to our customers (6play, Salto, Videoland and many others), we have a good knowledge of the daily load peaks and we know in advance the programs that are likely to generate a lot of traffic. We can therefore rely not only on reactive scaling, which has its limits (cf. &lt;a href=&quot;https://tech.bedrockstreaming.com/2022/02/03/prescaling.html&quot;&gt;prescaling article&lt;/a&gt;) but also on prescaling.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&amp;gt; &lt;strong&gt;Prescaling&lt;/strong&gt; consists of increasing the number of critical application pods in our clusters in advance in order to be ready to face a sudden traffic peak.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Initially, we developed an in-house solution in Python for a simple reason: it was the language that most people in the team knew. Since we had time to test our solution, we thought it would be great to share it with everyone. But to do so, we had to make some adjustments.&lt;/p&gt;

&lt;h2 id=&quot;we-rewrote-everything-in-go&quot;&gt;We rewrote everything in go&lt;/h2&gt;

&lt;p&gt;Many open source projects we use are written in Golang. In addition, the DevOps/Cloud world is mostly focused on Go. So, we decided to rewrite our prescaling solution in Go in order to make our teams more skilled in this language. The other goal was to make it cloud agnostic. In the Python version, we had an API part that stored prescaling events in a DynamoDB table, which made the solution dependent on AWS. Since prescaling is Kubernetes oriented, we had thought in the first versions in Python to store these events in Custom Resources (CRD) but due to lack of time, we did not implement it. We took advantage of the redesign to implement it and remove the dependency with AWS DynamoDB.&lt;/p&gt;

&lt;p&gt;We also wanted to simplify the project. In the first versions, we had two bricks: one containing the exporter and another the API. We merged the two applications into one monolith. The API is CRUD and can handle CRD events.&lt;/p&gt;

&lt;h2 id=&quot;here-we-go-we-open-source-it&quot;&gt;Here we go, we open source it&lt;/h2&gt;

&lt;p&gt;The great moment has come. Our prescaling solution is now available on GitHub in its alpha version: &lt;a href=&quot;https://github.com/BedrockStreaming/prescaling-exporter&quot;&gt;https://github.com/BedrockStreaming/prescaling-exporter&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This is the version we currently use in all our clusters. Letâ€™s quickly see how to implement the solution (you can find more details in the repo README).&lt;/p&gt;

&lt;p&gt;The prescaling-exporter is distributed with helm charts in order to install it in kubernetes cluster.&lt;/p&gt;

&lt;h3 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h3&gt;

&lt;p&gt;The following bricks must be installed in the k8s cluster:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Prometheus&lt;/code&gt; Stack or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Victoria Metrics Stack&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Prometheus Adapter&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It is possible to use another metrics stack but we do not provide an example at this time.&lt;/p&gt;

&lt;p&gt;Clone the repo and run the following command with Helm3:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;helm &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;prescaling-exporter ./helm/prescaling-exporter &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; prescaling-exporter &lt;span class=&quot;nt&quot;&gt;--create-namespace&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Itâ€™s required to add the following configuration to Prometheus adapter:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- &quot;metricsQuery&quot;: &quot;avg(&amp;lt;&amp;lt;.Series&amp;gt;&amp;gt;{&amp;lt;&amp;lt;.LabelMatchers&amp;gt;&amp;gt;})&quot;
    &quot;name&quot;:
      &quot;as&quot;: &quot;prescale_metric&quot;
    &quot;resources&quot;:
      &quot;overrides&quot;:
        &quot;namespace&quot;:
          &quot;resource&quot;: &quot;namespace&quot;
    &quot;seriesQuery&quot;: &quot;prescale_metric&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;daily-prescaling-event&quot;&gt;Daily prescaling event&lt;/h3&gt;

&lt;p&gt;We have chosen to manage the configuration of daily events directly on the HPA (HorizontalPodAutoscaler) of the applications. Here is how to activate it, through annotations:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;autoscaling/v2beta1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;HorizontalPodAutoscaler&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;annotations&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;annotations.scaling.exporter.replica.min&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;annotations.scaling.exporter.time.end&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;annotations.scaling.exporter.time.start&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;External&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;external&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;metricName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;prescaling_metric&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;metricSelector&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;matchLabels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;deployment&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;targetValue&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We are able to control the start and end time of the prescaling and the minimum number of pods we want during this window. Please note that if the number of pods we want for prescaling is less than the current number of pods, the solution will not downscale the application and the HPA will continue to behave as usual.&lt;/p&gt;

&lt;h3 id=&quot;one-time-events&quot;&gt;One-time events&lt;/h3&gt;

&lt;p&gt;We can also record one-off events. For example, at Bedrock Streaming, during an important soccer match, we will record a special event in a Custom Resource Definition. 
One-time events allow to prescale all applications having annotations on their HPA by multiplying their prescaling minimum replicas (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;annotations.scaling.exporter.replica.min&lt;/code&gt;) by the multiplier of the event in question.&lt;/p&gt;

&lt;p&gt;To record a one-time event, an OpenAPI UI (formerly known as Swagger) is exposed by the prescaling exporter at the url &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/swagger/index.html&lt;/code&gt;. We can also register a new event from here or directly by making an api call to the following address &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/api/v1/events/&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-09-01-kubernetes-prescaling-we-open-source-our-solution/post-prescaling-event.png&quot; alt=&quot;Screenshot POST prescaling event&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;Whatâ€™s next?&lt;/h2&gt;

&lt;p&gt;We will continue to improve the solution. For example, we are thinking about removing annotations on HPAs and replacing them with a new dedicated CRD.&lt;/p&gt;

&lt;p&gt;All contributions are welcome, donâ€™t hesitate to come and exchange with us on GitHub if you want to use the solution, we would be delighted.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Authors:&lt;a href=&quot;https://www.linkedin.com/in/jeremy-planckeel-44426112b/&quot;&gt; JÃ©rÃ©my Planckeel&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/in/valentin-chabrier-180937142/&quot;&gt;Valentin Chabrier&lt;/a&gt;&lt;/p&gt;</content><author><name>[&quot;j_planckeel&quot;, &quot;v_chabrier&quot;]</name></author><category term="k8s" /><category term="kubernetes" /><category term="pods" /><category term="prometheus" /><category term="scaling" /><category term="hpa" /><category term="resiliency" /><category term="go" /><category term="prescaling" /><category term="opensource" /><summary type="html">Previously we discussed how we manage the load of our Kubernetes clusters and how we can anticipate our needs with prescaling. Today, we are here to share our solution that we have reworked and open sourced!</summary></entry><entry><title type="html">BFFâ€™s error definition, and handling connections to multiple API</title><link href="https://tech.bedrockstreaming.com/2022/08/25/backend-errors-connections.html" rel="alternate" type="text/html" title="BFFâ€™s error definition, and handling connections to multiple API" /><published>2022-08-25T00:00:00+00:00</published><updated>2022-08-25T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/08/25/backend-errors-connections</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/08/25/backend-errors-connections.html">&lt;p&gt;A &lt;em&gt;quick&lt;/em&gt; sidetrack in &lt;a href=&quot;#from-the-same-series&quot;&gt;our series&lt;/a&gt; about Bedrockâ€™s API gateway.
This piece defines what are we talking about when we say â€œan errorâ€, and explains how we handle the numerous connections to services we are calling.&lt;/p&gt;

&lt;h2 id=&quot;definition&quot;&gt;Definition&lt;/h2&gt;

&lt;p&gt;In &lt;a href=&quot;/2022/08/12/backend-fallbacks.html&quot;&gt;the previous article&lt;/a&gt;, weâ€™ve seen how we handle errors.
This was mainly from a business point of view, and how itâ€™s done in our domain.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;But what is â€œan errorâ€?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This term is a bit generic, and the definition will be too: &lt;em&gt;an error is anything unexpected by the application&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;In our context of an API Gateway, we are restricting this to the services we are calling.&lt;/p&gt;

&lt;p&gt;This can be, but not exhaustively, a service not responding because:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;itâ€™s offline;&lt;/li&gt;
  &lt;li&gt;itâ€™s taking too much time to answer;&lt;/li&gt;
  &lt;li&gt;itâ€™s responding with a 5** error (when talking about an API);&lt;/li&gt;
  &lt;li&gt;itâ€™s giving us an invalid or unexpected content.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;what-are-the-consequences-of-those-errors&quot;&gt;What are the consequences of those errors?&lt;/h2&gt;

&lt;p&gt;The first issue is: we wonâ€™t be able to display some part of the application as intended.
Weâ€™ve &lt;a href=&quot;https://tech.bedrockstreaming.com/2022/08/12/backend-fallbacks.html#handling-failures&quot;&gt;talked about this previously&lt;/a&gt; already.&lt;/p&gt;

&lt;p&gt;The second error, more insidious, is that it can slow down our BFF terribly.&lt;/p&gt;

&lt;p&gt;The BFF response time is, on average, equals to the slowest service the BFF is calling.
If a service that usually responds in 200ms starts slowing down to an average response time of 1s and also times out half the time, it will increase the BFF response time to 1,5s (1s average, and 50% retry).&lt;/p&gt;

&lt;p&gt;Thatâ€™s why we must be careful when configuring those timeouts.
The BFF exposes a response-time Service Level Objective (SLO), and frontend applications will cut any connection that takes too long.
Losing some parts of the responses is better than slowing the BFF down to a point where frontend wonâ€™t get any response at all.&lt;/p&gt;

&lt;h2 id=&quot;how-are-we-mitigating-the-errors&quot;&gt;How are we mitigating the errors?&lt;/h2&gt;

&lt;p&gt;For any remote service, we configure short timeouts, and retry when we must.
A short timeout is a timeout that usually match the SLO of the called services, and that will match 99% of our calls.
When the SLO of the called service is higher than ours, we use a shorter timeout and accept that a larger parts of the calls will be cut.
The values are tailored according to our usages.
We use our monitoring to adapt those values in order to reduce the number of errors, while minimizing the impact on the BFF response time.
We are also constantly challenging our colleagues to improve the average response time of their services that we are calling.&lt;/p&gt;

&lt;p&gt;The choice of using retries is based on the information criticality.
For example, retrieving the userâ€™s previous viewing sessions, is important for his/her experience, so weâ€™re using a retry here.
On the opposite, analytics are less important, so we donâ€™t use any retry there.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;na&quot;&gt;app.http_client_configs.best_effort&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;retry&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;timeout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.6&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;connect_timeout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.1&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;app.http_client_configs.fast_fail&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;retry&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;timeout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.6&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;connect_timeout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.1&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;app.http_client_configs.long_fail&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;retry&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;timeout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;connect_timeout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.1&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;app.http_client_configs.reliant&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;retry&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;timeout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;60&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;connect_timeout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Above, you can see the yaml configuration our Symfony application uses to build its Guzzle clients.&lt;/p&gt;

&lt;p&gt;Each configuration can cascade onto the clients, making variants available for our Symfony services.&lt;/p&gt;

&lt;p&gt;Below lies a Symfony configuration example:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;We have an interface &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BFF\Domain\Content\Repository&lt;/code&gt; from the domain for a content repository.&lt;/li&gt;
  &lt;li&gt;The interface is linked to an implementation &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BFF\Infra\HttpContentClient&lt;/code&gt; inside the infrastructure.&lt;/li&gt;
  &lt;li&gt;The implementation is built with variants (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;best_effort&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fast_fail&lt;/code&gt;) from a factory using the matching Guzzle configurations.&lt;/li&gt;
  &lt;li&gt;Other services use a chosen repository &lt;em&gt;according to their needs and criticality&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;c1&quot;&gt;# Service definition with its aliases.&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;BFF\Domain\Content\Repository&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;@BFF\Domain\Content\Repository.fast_fail&apos;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;BFF\Domain\Content\Repository.best_effort&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;@BFF\Infra\HttpContentClient.best_effort&apos;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;BFF\Domain\Content\Repository.fast_fail&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;@BFF\Infra\HttpContentClient.fast_fail&apos;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Concrete implementations&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;BFF\Infra\HttpContentClient.best_effort&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;BFF\Infra\HttpContentClient&apos;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;factory&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;@BFF\Infra\ContentClientFactory&apos;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;create&apos;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;bind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;$clientConfig&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;%app.http_client_configs.best_effort%&apos;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;BFF\Infra\HttpContentClient.fast_fail&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;BFF\Infra\HttpContentClient&apos;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;factory&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;@BFF\Infra\ContentClientFactory&apos;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;create&apos;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;bind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;$clientConfig&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;%app.http_client_configs.fast_fail%&apos;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Other services using the Repository&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;BFF\Domain\Navigation\NavBarResolver&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;$content&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;@BFF\Domain\Content\Repository.best_effort&apos;&lt;/span&gt;

    &lt;span class=&quot;na&quot;&gt;BFF\Domain\Layout\BlockResolver&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;$content&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;@BFF\Domain\Content\Repository.fast_fail&apos;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;This is an over simplified example as we have more layers and wrappers used for things like caching, monitoring, logging, etc.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this article, weâ€™ve clarified what an error is, and explained that we cannot generalize the configuration and usage of our APIs. Timeouts and retries, especially, must be tailored depending on the criticality of each call.&lt;/p&gt;

&lt;p&gt;This was a deviation on the road to our next article, where we will talk about monitoring the errors and stopping calls to failing APIs by implementing the circuit-breaker pattern.&lt;/p&gt;

&lt;h2 id=&quot;from-the-same-series&quot;&gt;From the same series&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;/2022/06/10/backend-bff-intro.html&quot;&gt;Whatâ€™s a BFF&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2022/08/12/backend-fallbacks.html&quot;&gt;Handling API failures in a gateway&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2022/08/25/backend-errors-connections.html&quot;&gt;Whatâ€™s an error, and handling connection to multiple APIs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2022/09/02/backend-circuit-breaker.html&quot;&gt;Using a circuit breaker&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Valentin CLARAS</name></author><category term="backend" /><category term="php" /><category term="api" /><category term="api-gateway" /><category term="back-for-front" /><category term="error" /><category term="timout" /><category term="retry" /><category term="slo" /><category term="guzzle" /><summary type="html">A quick sidetrack in our series about Bedrockâ€™s API gateway. This piece defines what are we talking about when we say â€œan errorâ€, and explains how we handle the numerous connections to services we are calling.</summary></entry><entry><title type="html">Les spikes : quand, comment, pour quoi faire ?</title><link href="https://tech.bedrockstreaming.com/how-to-spike" rel="alternate" type="text/html" title="Les spikes : quand, comment, pour quoi faire ?" /><published>2022-08-23T00:00:00+00:00</published><updated>2022-08-23T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/how-to-spike</id><content type="html" xml:base="https://tech.bedrockstreaming.com/how-to-spike">&lt;p&gt;Câ€™est une histoire bien connue, dans la vie de nâ€™importe quel dÃ©veloppeur : un ticket arrive dans le backlog, dÃ©crivant une problÃ©matique relativement complexe. Câ€™est parfois une question de technologie inconnue, ou parfois simplement un chantier un peu trapu. Je pense que toutes les Ã©quipes ont, au moins une fois dans leur vie, fait face Ã  ce genre de tÃ¢che impossible : câ€™est lâ€™occasion des regards dÃ©sespÃ©rÃ©s, alors quâ€™un junior se lamente en disant Â« Mais par oÃ¹ est-ce quâ€™il faut commencer ? Â». Et câ€™est lÃ  quâ€™on rÃ©pond : Â« Essaye de faire un spike Â».&lt;/p&gt;

&lt;p&gt;Faire un spike ? Quelle excellente idÃ©e ! Encore faudrait-il savoir ce quâ€™est un spike, comment Ã§a marche, et Ã  quoi Ã§a sert.&lt;/p&gt;

&lt;p&gt;Je vous propose donc ensemble de voir dans cet article : quâ€™est-ce quâ€™un spike, quand lâ€™utiliser, et comment considÃ©rer quâ€™il est rÃ©ussi ?&lt;/p&gt;

&lt;h1 id=&quot;spike-help-&quot;&gt;spike â€“help ğŸ“š&lt;/h1&gt;

&lt;p&gt;Si je devais citer &lt;a href=&quot;https://en.wikipedia.org/wiki/Spike_(software_development)&quot;&gt;Wikipedia&lt;/a&gt;, je dirais quâ€™un Spike, câ€™est â€œune mÃ©thode de dÃ©veloppement de produit, dÃ©rivÃ©e de lâ€™extrÃªme programming, et qui cherche Ã  crÃ©er le code le plus simple possible pour obtenir des solutions potentiellesâ€.&lt;/p&gt;

&lt;p&gt;En gros, le but dâ€™un spike, câ€™est de rÃ©pondre Ã  la question &lt;em&gt;â€œComment on fait ?â€&lt;/em&gt; avec un prototype de code rÃ©alisÃ© grÃ¢ce Ã  une sÃ©rie de petites Ã©tapes simples. Un spike nâ€™est pas une formule magique qui va vous permettre de rÃ©aliser la tÃ¢che impossible que votre client vous a donnÃ©. En revanche, le spike va vous permettre de savoir si la tÃ¢che impossible ou compliquÃ©e Ã  premiÃ¨re vue est en fait possible, et si oui, comment.
Il arrivera Ã©galement que votre spike vous permette de constater quâ€™une tÃ¢che donnÃ©e peut Ãªtre rÃ©alisÃ©e de plusieurs maniÃ¨res : que ce soit en passant par des librairies diffÃ©rentes, avec une implÃ©mentation changeante, ou autre chose encore. Dans ces cas, le spike va Ã©galement vous servir Ã  essayer ces diffÃ©rentes possibilitÃ©s, et Ã  choisir celle qui est la plus appropriÃ©e !&lt;/p&gt;

&lt;p&gt;Le moyen le plus simple est de procÃ©der morceau par morceau. Alors je vous propose quâ€™on sâ€™y mette maintenant, et quâ€™on regarde quoi faire !&lt;/p&gt;

&lt;h1 id=&quot;kowalski-analysis--&quot;&gt;â€œkowalski, analysis !â€ ğŸ“Š&lt;/h1&gt;

&lt;p&gt;Avant toute chose, il faut savoir exactement ce que vous souhaitez faire. Rien ne sert de mettre la charrue avant les bÅ“ufs.&lt;/p&gt;

&lt;p&gt;Si ce nâ€™est pas fait, Ã©crivez noir sur blanc les lignes exactes qui vont dÃ©finir votre tÃ¢che comme finie. Que ce soit connecter votre utilisateur de faÃ§on sÃ©curisÃ©e, afficher une vidÃ©o sans heurt, ou juste avoir une page qui clignote en blanc et bleu, il faut que vous ayez une liste de &lt;em&gt;bullet points&lt;/em&gt;, qui dÃ©finit prÃ©cisÃ©ment ce que vous voulez faire.&lt;/p&gt;

&lt;p&gt;Votre objectif final est de rÃ©aliser tout ce que vous avez sur cette liste : strictement rien de moins, mais aussi strictement rien de plus ! Pas de demande implicite de type â€œAh mais je voulais aussi que lâ€™image soit visible en noir et blancâ€ : si ce nâ€™est pas sur la liste, ce nâ€™est pas Ã  faire.&lt;/p&gt;

&lt;p&gt;Cette liste peut Ãªtre Ã©crite selon votre format favori : un cahier des charges, une sÃ©rie de directives &lt;em&gt;Gherkin&lt;/em&gt;, lâ€™important câ€™est quâ€™elle soit Ã©crite, claire et prÃ©cise. En dâ€™autres termes, vous dÃ©finissez ici votre propre cahier des charges.&lt;/p&gt;

&lt;p&gt;Le rÃ©sultat final doit donc Ãªtre quelque chose dans ce style :&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;As a client
I want to see my product in 3 dimensions
So that I can know what it looks like

As a client
I want to be able to rotate my product using the arrow keys
So that I can check it out entirely

As a client
I want to be able to zoom on my product
So that I can see even the smallest details
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Une fois que vous savez quoi faire, on peut vraiment commencer Ã  mettre la main dans le code !&lt;/p&gt;

&lt;h1 id=&quot;-todo--make-the-code-below-work-&quot;&gt;// TODO : make the code below work ğŸ’»&lt;/h1&gt;

&lt;p&gt;Stop. LÃ¢chez tout.&lt;/p&gt;

&lt;p&gt;Je vous vois dÃ©jÃ , votre liste de points en main, Ã  tenter de la faire rentrer dans votre gros projet Ã  grands coups de burin, de vous gratter la tÃªte Ã  comprendre pourquoi Ã§a ne rentre pas, et quâ€™est-ce qui a bien pu casser, cette fois.&lt;/p&gt;

&lt;p&gt;Un peu de calme : le but dâ€™un spike nâ€™est pas de faire tout fonctionner, pas du tout. Prenez de la distance, et on va y aller en douceur.&lt;/p&gt;

&lt;p&gt;Pour commencer, isolez une partie de votre projet et de vos points objectifs. Il existe plusieurs moyens de sâ€™y prendre : crÃ©er un nouveau projet, crÃ©er une nouvelle page avec seulement quelques composants, dÃ©charger votre backendâ€¦ On veut un environnement le plus propre possible.
Beaucoup de projets sont vieux, et si mal conÃ§us quâ€™il &lt;a href=&quot;/2021/09/01/bonnes-pratiques-web&quot;&gt;aurait fallu les jeter au bout de deux ans&lt;/a&gt;. On cherche ici Ã  se dÃ©tacher au maximum de cette dette technique.&lt;/p&gt;

&lt;p&gt;Nâ€™hÃ©sitez pas Ã  utiliser des &lt;em&gt;mocks&lt;/em&gt;, des faux appels et rÃ©sultats au reste de votre application :  en simulant comment se comporte le reste de votre projet sans vÃ©ritablement y faire appel, vous diminuez au maximum votre marge dâ€™erreur, et vous assurez que vous contrÃ´lez la moindre information qui transite par votre code.&lt;/p&gt;

&lt;p&gt;Maintenant seulement, vous pouvez prendre votre clavier, et coder. Regardez comment implÃ©menter chacun de ces points dans votre code propre de maniÃ¨re Ã©purÃ©e.
Ã‡a fonctionne du premier coup ? GÃ©nial, notez comment vous avez fait ! Ã‡a ne marche pas ? Dommage, mais ce nâ€™est pas une raison pour Ctrl+Z et recommencer. Notez bien ce qui nâ€™a pas marchÃ©, avant de retenter ! Si Ã§a ne marche toujours pas au bout de 2/3 essais, pas de soucis, nâ€™hÃ©sitez pas Ã  laisser ce point de cÃ´tÃ© et passer Ã  un autre. Mais Ã©crivez tout, car cela va vous servir trÃ¨s bientÃ´t !&lt;/p&gt;

&lt;h1 id=&quot;ifbug--true--deletebug-consolelogit-works---&quot;&gt;if(bug == true) { delete(bug); console.log(â€œIt works !â€); } ğŸ¤–&lt;/h1&gt;

&lt;p&gt;Il peut cependant arriver que, parfois, tous vos efforts ne mÃ¨nent Ã  rien. Vous avez dÃ©jÃ  passÃ© plusieurs jours sur les diffÃ©rents sujets du spike, et vous nâ€™avez pas encore identifiÃ© de solution pour faire fonctionner le tout.
Dans ce cas-lÃ , pas de panique ! Il sâ€™agit Ã©galement dâ€™un des objectifs du spike. AprÃ¨s tout, si vous nâ€™avez pas pu rÃ©aliser votre objectif dans un cadre rÃ©duit, il est bien probable que vous nâ€™auriez jamais pu le faire fonctionner dans votre projet lui-mÃªme.&lt;/p&gt;

&lt;p&gt;Les mÃªmes points quâ€™indiquÃ©s ci-dessus continuent de sâ€™appliquer : notez ce que vous avez tentÃ© et les soucis rencontrÃ©s avec chaque implÃ©mentation. Puis, continuez le processus dÃ©taillÃ© ici : ce nâ€™est pas parce que votre code nâ€™as pas fonctionnÃ© quâ€™il ne doit surtout pas Ãªtre prÃ©sentÃ©. Peut-Ãªtre un de vos collÃ¨gues trouvera-t-il la ligne qui vous manque, ou le point-virgule que vous avez oubliÃ© : mais peut-Ãªtre aussi quâ€™il vous aidera Ã  comprendre ensemble pourquoi la solution ne fonctionne pas dans votre cadre.
Et puis, vous pourrez alors vous poser la question : est-ce quâ€™il faut bien faire comprendre que la tÃ¢che demandÃ©e est irrÃ©alisable, ou est-ce quâ€™il faut prÃ©voir un chantier pour rÃ©ussir Ã  trouver un moyen de remplir la requÃªte ?&lt;/p&gt;

&lt;h1 id=&quot;linstant-doc-&quot;&gt;Lâ€™instant doc ğŸ“&lt;/h1&gt;

&lt;p&gt;Une fois que vous avez terminÃ© de coder, il est temps pour vous de poser votre IDE, et de sortir votre outil de documentation favori : Confluence, Jira, que sais-je. 
Puis, Ã©crivez un compte-rendu de votre aventure. PrÃ©sentez lâ€™origine de votre spike (Le &lt;strong&gt;Pourquoi&lt;/strong&gt;), ce que vous avez tentÃ© (Le &lt;strong&gt;Comment&lt;/strong&gt;). Expliquez ce qui a marchÃ© et ce qui nâ€™a pas marchÃ© : cela vous servira lorsque vous implÃ©menterez vraiment la feature !
Enfin, Ã©crivez Ã©galement les Ã©tapes quâ€™il faudrait suivre pour terminer la feature : ajoutez un maximum de dÃ©tails techniques. Ce sera autant de problÃ©matiques en moins pour le pauvre dev qui va rÃ©cupÃ©rer les US aprÃ¨s vous.&lt;/p&gt;

&lt;p&gt;Je vous suggÃ¨re donc de faire un plan de ce type :&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;ProblÃ¨me&lt;/strong&gt; - Expliquez ici lâ€™Ã©tat initial. Quâ€™est-ce qui Ã©tait demandÃ© ? Pourquoi avoir choisi de faire un spike ? Quel en est lâ€™objectif ?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Observations&lt;/strong&gt;  - Indiquez lÃ  vos rÃ©flexions et le code que vous avez produit. Expliquez ce que vous avez tentÃ©, les problÃ¨mes rencontrÃ©s et les solutions Ã©tablies, vos pistes de rÃ©flexion. Nâ€™hÃ©sitez surtout pas Ã  dÃ©tailler !&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Actions&lt;/strong&gt; - Enfin, dÃ©taillez dans cette derniÃ¨re partie ce quâ€™il restera Ã  faire afin de transformer ce spike en une feature fonctionnelle. Quels bugs corriger ? Quels points nâ€™ont pas encore Ã©tÃ© rÃ©alisÃ©s, et comment faire pour les rÃ©aliser ?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Pour la derniÃ¨re Ã©tape, je vous conseille de rÃ©aliser un tableau dâ€™actions &lt;em&gt;SMART&lt;/em&gt; afin de dÃ©finir au mieux les tÃ¢ches Ã  rÃ©aliser.
Le principe SMART suppose quâ€™une tÃ¢che doit Ãªtre composÃ©es des cinq caractÃ©ristiques suivantes afin dâ€™Ãªtre pertinente :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Elle doit Ãªtre &lt;strong&gt;SpÃ©cifique&lt;/strong&gt;, afin que lâ€™objectif soit clair et concis (Quâ€™est-ce que je dois faire ? Exemple de rÃ©ponse : Â« Il faut que lâ€™image dâ€™un objet soit en 3D Â»)&lt;/li&gt;
  &lt;li&gt;Elle doit Ãªtre &lt;strong&gt;Mesurable&lt;/strong&gt;, pour dÃ©finir un objectif quantifiable (Quant est-ce que ma tÃ¢che sera finie ? Exemple de rÃ©ponse : Â« Il faut que je puisse faire tourner lâ€™image avec les flÃ¨ches gauches et droites du clavier  Â»))&lt;/li&gt;
  &lt;li&gt;Elle doit Ãªtre &lt;strong&gt;Atteignable&lt;/strong&gt;, sans demander de dÃ©crocher les Ã©toiles (Comment rÃ©aliser ma tÃ¢che ? Exemple de rÃ©ponse : Â« Utiliser la mÃ©thode &lt;em&gt;Get3D&lt;/em&gt; de la librairie &lt;em&gt;Easy3D&lt;/em&gt; Â»))&lt;/li&gt;
  &lt;li&gt;Elle doit Ãªtre &lt;strong&gt;RÃ©aliste&lt;/strong&gt; au sujet en cours, donc nÃ©cessaire Ã  lâ€™accomplissement final (Est-ce quâ€™il est pertinent de prendre du temps pour faire Ã§a ? Exemple de rÃ©ponse : Â« Afin que notre client puisse voir lâ€™avant et lâ€™arriÃ¨re de nos produits Â»)&lt;/li&gt;
  &lt;li&gt;Elle doit Ãªtre dÃ©finie de faÃ§on &lt;strong&gt;Temporelle&lt;/strong&gt;, afin de ne pas pouvoir sâ€™Ã©terniser (Pour quand ma tÃ¢che doit-elle Ãªtre rÃ©alisÃ©e ? Exemple de rÃ©ponse : Â« A rÃ©aliser avant que la feature soit considÃ©rÃ©e terminÃ©e Â»)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Dans le cas oÃ¹ une des tÃ¢ches que vous avez devisÃ© ne peut pas rÃ©pondre Ã  un de ces cinq points, alors il est probable quâ€™elle ne soit pas suffisamment prÃ©cise : peut-Ãªtre la tÃ¢che manque-t-elle de cadre ou de contexte, ou le temps nÃ©cessaire pour la rÃ©aliser ne peut que difficilement Ãªtre justifiÃ©. Je vous invite alors Ã  la supprimer, ou Ã  la fusionner avec une autre jusquâ€™Ã  enfin pouvoir rÃ©pondre Ã  ces cinq questions !&lt;/p&gt;

&lt;p&gt;Bien entendu, nâ€™hÃ©sitez pas Ã  modifier le plan de cette documentation comme vous lâ€™entendez : vous Ãªtes celui qui allez lâ€™utiliser, aprÃ¨s tout !&lt;/p&gt;

&lt;p&gt;La doc est finie ? Il ne reste plus que deux Ã©tapes, puis on pourra enfin considÃ©rer ce spike comme fini !&lt;/p&gt;

&lt;h1 id=&quot;presentation_spikeppt-&quot;&gt;Presentation_Spike.ppt ğŸ¬&lt;/h1&gt;

&lt;p&gt;Avant de pouvoir clÃ´turer ce spike, il serait bien dâ€™avoir des retours extÃ©rieurs. Pour Ã§a, rien de mieux que de le prÃ©senter Ã  votre Ã©quipe !
Organisez ensemble une rÃ©union, pas trÃ¨s longue. Au sein de mon Ã©quipe, une demi-heure suffit. Il vous faudra peut-Ãªtre un peu moins ou un peu plus de temps.&lt;/p&gt;

&lt;p&gt;Utilisez cette prÃ©sentation afin de montrer, Ã©tape par Ã©tape, ce que vous avez rÃ©alisÃ©. Rappelez tout dâ€™abord les objectifs du spike, avant dâ€™expliquer votre analyse du problÃ¨me et les objectifs que vous avez identifiÃ©s. Puis, prÃ©sentez les diffÃ©rentes implÃ©mentations que vous avez tentÃ©es, avant de conclure en montrant votre documentation et en expliquant les tÃ¢ches qui restent Ã  accomplir pour rÃ©aliser la feature objectif.&lt;/p&gt;

&lt;p&gt;Il est trÃ¨s important que vous ne prÃ©sentiez pas uniquement le code que vous avez rÃ©ussi Ã  faire fonctionner, mais aussi vos tentatives Ã©chouÃ©es, et ce pour plusieurs raisons. Tout dâ€™abord, il est tout Ã  fait possible quâ€™un de vos collÃ¨gues, en voyant votre prÃ©sentation, rÃ©alise une de vos erreurs et vous lâ€™indique. Mais surtout, si quelquâ€™un dâ€™autre que vous rÃ©cupÃ¨re une des tÃ¢ches restantes, il risque de tenter les mÃªmes pistes que vous, et rencontrer les mÃªmes problÃ©matiques que vous !&lt;/p&gt;

&lt;p&gt;Une fois votre prÃ©sentation terminÃ©e, dÃ©battez avec le reste de votre Ã©quipe. Sâ€™ils sont dâ€™accord avec vous sur le plan dâ€™action que vous avez Ã©tabli grÃ¢ce Ã  votre tableau SMART, il vous reste une toute derniÃ¨re Ã©tape Ã  accomplir !&lt;/p&gt;

&lt;h1 id=&quot;happily-ever-after-&quot;&gt;â€œHappily ever afterâ€¦â€ ğŸ’­&lt;/h1&gt;

&lt;p&gt;Maintenant que tous vos coÃ©quipiers ont pu constater et valider votre travail, il ne vous reste plus quâ€™Ã  acter la mise en place : et pour Ã§a, rien de mieux que, aux cÃ´tÃ©s de votre &lt;em&gt;Product Owner&lt;/em&gt; (Ou de lâ€™Ã©quivalent dans votre Ã©quipe) de crÃ©er des tÃ¢ches, &lt;em&gt;User Story&lt;/em&gt;, post-its, ou quoi que ce soit, pour que les Ã©tapes restantes soient visibles et accessibles par tous !&lt;/p&gt;

&lt;p&gt;Nâ€™hÃ©sitez pas Ã  le guider pour ajouter encore une fois des dÃ©tails techniques dans ces US ou tÃ¢ches : vous avez rÃ©alisÃ© lâ€™analyse, il serait dommage de ne pas lâ€™utiliser, et ce sera autant de temps gagnÃ© pour votre Ã©quipe. Tant que vous y Ãªtes, pensez aussi Ã  ajouter un lien vers votre documentation, ou vers une vidÃ©o de votre prÃ©sentationâ€¦ Plus il y aura de dÃ©tails, mieux Ã§a sera !&lt;/p&gt;

&lt;p&gt;Il est Ã©galement possible, comme indiquÃ© plus haut, que la tÃ¢che qui a entraÃ®nÃ© la rÃ©alisation de ce spike se dÃ©couvre Ãªtre impossible Ã  implÃ©menter. Il sâ€™agit lÃ  Ã©galement dâ€™un point Ã  faire avec votre &lt;em&gt;Product Owner&lt;/em&gt;, afin de dÃ©cider ensemble de la procÃ©dure Ã  suivre : peut-Ãªtre faudra-t-il redÃ©finir les critÃ¨res dâ€™acceptation, ou bien laisser tomber complÃ¨tement cette idÃ©e.&lt;/p&gt;

&lt;h1 id=&quot;return-0&quot;&gt;return 0;&lt;/h1&gt;

&lt;p&gt;Vous avez fini votre spike ! Ce qui Ã©tait Ã  lâ€™origine une tÃ¢che complexe, confuse ou impossible Ã  prÃ©voir, est dÃ©sormais divisÃ©e en une sÃ©rie dâ€™Ã©tapes, qui sera dÃ©sormais bien plus aisÃ©e Ã  rÃ©aliser pour votre Ã©quipe. Alors, satisfait ?&lt;/p&gt;</content><author><name>Etienne Doyon</name></author><category term="spike" /><category term="methodologie" /><category term="cytron" /><category term="tech" /><summary type="html">Câ€™est une histoire bien connue, dans la vie de nâ€™importe quel dÃ©veloppeur : un ticket arrive dans le backlog, dÃ©crivant une problÃ©matique relativement complexe. Câ€™est parfois une question de technologie inconnue, ou parfois simplement un chantier un peu trapu. Je pense que toutes les Ã©quipes ont, au moins une fois dans leur vie, fait face Ã  ce genre de tÃ¢che impossible : câ€™est lâ€™occasion des regards dÃ©sespÃ©rÃ©s, alors quâ€™un junior se lamente en disant Â« Mais par oÃ¹ est-ce quâ€™il faut commencer ? Â». Et câ€™est lÃ  quâ€™on rÃ©pond : Â« Essaye de faire un spike Â».</summary></entry><entry><title type="html">Handling dependencies failures in an API gateway</title><link href="https://tech.bedrockstreaming.com/2022/08/12/backend-fallbacks.html" rel="alternate" type="text/html" title="Handling dependencies failures in an API gateway" /><published>2022-08-12T00:00:00+00:00</published><updated>2022-08-12T00:00:00+00:00</updated><id>https://tech.bedrockstreaming.com/2022/08/12/backend-fallbacks</id><content type="html" xml:base="https://tech.bedrockstreaming.com/2022/08/12/backend-fallbacks.html">&lt;p&gt;Welcome to our second article about the backend architecture and its api gateway.
In &lt;a href=&quot;/2022/06/10/backend-bff-intro.html&quot;&gt;the first part&lt;/a&gt;, we talked about the BFF and all services it depends on.
Today weâ€™re going to take a look at what to do when one of them (or many), fails to respond.&lt;/p&gt;

&lt;h2 id=&quot;service-dependencies&quot;&gt;Service dependencies&lt;/h2&gt;

&lt;p&gt;As seen previously, the BFF uses multiple data sources and services to create a full layout.&lt;/p&gt;

&lt;p&gt;Those services are used to gather the contents to be displayed in the application:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;getting user personalisation data;&lt;/li&gt;
  &lt;li&gt;advertising and analytics configuration;&lt;/li&gt;
  &lt;li&gt;asking if the user has some authorizations.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If we donâ€™t want our BFF to become one giant SPOF &lt;a href=&quot;#notes&quot;&gt;(1)&lt;/a&gt;, we need to be resilient to the death &lt;a href=&quot;#notes&quot;&gt;(2)&lt;/a&gt; of those dependencies, any of them, at any time!
You must keep in mind that &lt;strong&gt;our top priority is to always be able to answer something readable&lt;/strong&gt; to the frontend applications.&lt;/p&gt;

&lt;h2 id=&quot;ddd&quot;&gt;DDD&lt;/h2&gt;

&lt;p&gt;First thing first, we are using a DDD &lt;a href=&quot;#notes&quot;&gt;(3)&lt;/a&gt; approach for our modeling.
This means that we focus on the business, as described by our Product Owner. We try not to worry about the various implementation of our backendâ€™s friends and their different services.&lt;/p&gt;

&lt;p&gt;A picture is always easier to understand.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-08-12-backend-fallbacks/ddd-page-min.png&quot; alt=&quot;asking for a layout to the domain means asking a interface for&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Above, we can see that when a user ask for a layout A, we are looking to resolve who is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt;.
From the domain point of view, the page collection is only an interface.&lt;/p&gt;

&lt;p&gt;In the picture below, we see the â€œPage collection implem (Infra)â€.
Itâ€™s a layer implementing the interface defined in the domain. It uses multiple clients that call the services behind.
Itâ€™s its responsibility to chose which service to look on for the page.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-08-12-backend-fallbacks/ddd-page-full.png&quot; alt=&quot;page collection implementation chose the correct data source&quot; /&gt;&lt;/p&gt;

&lt;p&gt;DDD is a too large subjects to be perfectly defined in this article. If you want to dig deeper into it, there are multiple great reads, feel free to check them out!
Now, how does this help us?&lt;/p&gt;

&lt;h2 id=&quot;handling-failures&quot;&gt;Handling failures&lt;/h2&gt;

&lt;p&gt;Failures handling is done by the middle layer seen in the previous example.
Its goal is to catch error &lt;a href=&quot;#notes&quot;&gt;(4)&lt;/a&gt;, and convert them to something expected and defined by the interface.&lt;/p&gt;

&lt;p&gt;That said, its responsibility is not to know what the expected answer is. To do that, we use the domain.&lt;/p&gt;

&lt;p&gt;Letâ€™s see with a small code sample.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: The following example is not a real use-case, but itâ€™s representative and simple enough to illustrate how it works.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In the code below, we see a class that represents the subscribing status of a user, which has two properties:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;hasAccess&lt;/code&gt; controls whether the user can read protected contents;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;isSubscribed&lt;/code&gt; is used in analytics, and to show subscription pages.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-php highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;?php&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SubscribeStatus&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__construct&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;readonly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$hasAccess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;readonly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$isSubscribed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createAnonymous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;self&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createSubscribed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;self&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To create such an object, we use either one of the two static functions, depending on the status we get from the subscriptions API.
This is done in the middle layer, but the business is kept in the domain.&lt;/p&gt;

&lt;p&gt;To handle the failure, we add a new named constructor, dedicated to this specific case.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    public static function createUnknown(): self
    {
        return new self(true, false);
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When an error happens and we canâ€™t retrieve the user subscription status, we now have a fallback option.
With this fallback option, the user will:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;be able to access any content, itâ€™s better to let an anonymous user access a content it should not, that blocking a paying customer;&lt;/li&gt;
  &lt;li&gt;still be reported as not subscribed and will see all available offers.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Most of the time, the answer is even simpler than this one.&lt;/p&gt;

&lt;p&gt;Another example would be userâ€™s viewing statuses. If we canâ€™t retrieve them, we donâ€™t display any progress bar.
Users wonâ€™t be able to tell if they have seen a content, but they will still be able to navigate the application.&lt;/p&gt;

&lt;h2 id=&quot;infrastructure-solution-the-stale-cache&quot;&gt;Infrastructure solution, the stale cache&lt;/h2&gt;

&lt;p&gt;In some cases, the above solution doesnâ€™t work.
For example, contents information cannot be replaced by default values. If we donâ€™t know about a video or a program, we cannot guess what it is.&lt;/p&gt;

&lt;p&gt;Luckily, we can rely on the stale cache.
Stale cache is an old cache entry which is expired. When the cache finds such entry, it usually ignores it and asks for a new version of the response.
In case of failure, we can use the available staled version.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2022-08-12-backend-fallbacks/stale-cache-usage.png&quot; alt=&quot;following first example, when the http fails to answer, we use the stale cached response&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The limitation is that a response must have been cached at least once, in order to have a staled version.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When there is no stale cache, we donâ€™t display the content &lt;a href=&quot;#notes&quot;&gt;(5)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So far, we are only using it with http implementation:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;called API must answers with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stale-if-error&lt;/code&gt; cache directive, it allows for the response to be used while stale when an error happens;&lt;/li&gt;
  &lt;li&gt;called API can answer with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stale-while-revalidate&lt;/code&gt; cache directive, for better performances;&lt;/li&gt;
  &lt;li&gt;calling API can query with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max-stale&lt;/code&gt; cache directive, to use stale response see &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control#cache_directives&quot;&gt;the mdn for more on those headers&lt;/a&gt;;&lt;/li&gt;
  &lt;li&gt;on the client side, we are using the &lt;a href=&quot;https://github.com/Kevinrob/guzzle-cache-middleware&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Kevinrob/guzzle-cache-middleware&lt;/code&gt;&lt;/a&gt; to do the job.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For an entry cached for up to 10 minutes (answered with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max-age&lt;/code&gt;), we allow up to 4 hours of stale cache (with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;stale-if-error&lt;/code&gt;).
Since we are using a shared cache, we are using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max-stale&lt;/code&gt; when querying, with a random value up to 1 hour.
This makes most requests use the last stale response while one of them ask for a fresher response.
Those values are chosen according to our platform usages where peak visitor last for about 2 to 3 hours at night.&lt;/p&gt;

&lt;p&gt;We plan to expand its usage to other kinds of cached entries, such as manually saved data, and database queries.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In todayâ€™s post, we have seen how we handle the loss of our dependencies by anticipating their potential failures and preparing default acceptable behaviours.&lt;/p&gt;

&lt;p&gt;Next time, we will see how we can spare some traffic on those dependencies when theyâ€™re struggling with traffic.&lt;/p&gt;

&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;SPOF, as &lt;a href=&quot;https://en.wikipedia.org/wiki/Single_point_of_failure&quot;&gt;single point of failure&lt;/a&gt; since all frontend applications have to rely on the BFF, I cannot resist linking this excellent &lt;a href=&quot;https://xkcd.com/2347/&quot;&gt;xkcd&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;By â€œdeathâ€, we mean anything unexpected. It can be a 500 error code, a timeout, a wrong content. We will talk a bit more about this in the next article.&lt;/li&gt;
  &lt;li&gt;DDD, as domain driven design, you can read more about it on &lt;a href=&quot;https://martinfowler.com/bliki/DomainDrivenDesign.html&quot;&gt;Martin FOWLERâ€™s website&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Throwing errors is still allowed, but restricted to domain exceptions, and must be specified in the methodâ€™s declaration in the interface (i.e. via a comment).&lt;/li&gt;
  &lt;li&gt;There will be a dedicated article on partial rendering.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;from-the-same-series&quot;&gt;From the same series&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;/2022/06/10/backend-bff-intro.html&quot;&gt;Whatâ€™s a BFF&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2022/08/12/backend-fallbacks.html&quot;&gt;Handling API failures in a gateway&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2022/08/25/backend-errors-connections.html&quot;&gt;Whatâ€™s an error, and handling connection to multiple APIs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2022/09/02/backend-circuit-breaker.html&quot;&gt;Using a circuit breaker&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
&lt;p&gt;In the meantime, feel free to have a look at other articles available on this blog:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ğŸ‡ºğŸ‡¸ &lt;a href=&quot;/2022/07/08/encrypt-aws-amis.html&quot;&gt;Encrypt AWS AMIs: one way to do it wrong&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;ğŸ‡«ğŸ‡· &lt;a href=&quot;/2022/06/13/kubecon-2022-part-1.html&quot;&gt;Bedrock Ã  la kubecon 2022 (4 articles)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Valentin CLARAS</name></author><category term="backend" /><category term="php" /><category term="api" /><category term="api-gateway" /><category term="back-for-front" /><category term="resiliency" /><summary type="html">Welcome to our second article about the backend architecture and its api gateway. In the first part, we talked about the BFF and all services it depends on. Today weâ€™re going to take a look at what to do when one of them (or many), fails to respond.</summary></entry></feed>